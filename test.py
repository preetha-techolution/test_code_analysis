import os
from graphviz import Digraph
import re 
import json

def parse_ddl(ddl: str):
    """
    Parse the DDL to extract columns, primary keys, and foreign keys.
    """
    lines = ddl.splitlines()
    column_lines = []

    for line in lines:
        line = line.strip()
        if (
            line.upper().startswith("CREATE")
            or line.upper().startswith("PRIMARY")
            or line.upper().startswith("FOREIGN")
            or line.upper().startswith(")")
            or line == ""
        ):
            continue

        match = re.match(r'(\w+)\s+\w+', line)
        if match:
            column_lines.append(match.group(1))

    pk_match = re.search(r'PRIMARY KEY\s*\((.*?)\)', ddl)
    primary_keys = [key.strip() for key in pk_match.group(1).split(",")] if pk_match else []

    foreign_keys = []
    for match in re.finditer(r'FOREIGN KEY\s*\(([^)]+)\)\s+REFERENCES\s+`?[\w]+\.(\w+)`\(([^)]+)\)', ddl):
        fk_col = match.group(1).strip()
        ref_table = match.group(2).strip()
        ref_col = match.group(3).strip()
        foreign_keys.append((fk_col, ref_table, ref_col))

    return column_lines, primary_keys, foreign_keys


def generate_combined_graph(tables_data):
    """
    Generate a single combined graph from multiple tables.
    """
    dot = Digraph(comment='Combined Table Diagram')
    dot.attr(rankdir='LR')

    # Store individual table nodes
    for table in tables_data:
        table_name = table['table_name']
        columns = table['columns']
        primary_keys = table['primary_keys']
        
        label_lines = []
        for col in columns:
            if col in primary_keys:
                label_lines.append(f"{col} [PK]")
            else:
                label_lines.append(col)
        dot.node(table_name, shape='box', label=f'{table_name}\\n' + "\\n".join(label_lines))

    # Add relationships
    for table in tables_data:
        table_name = table['table_name']
        for fk_col, ref_table, ref_col in table['foreign_keys']:
            dot.edge(table_name, ref_table, label=f'{fk_col} â†’ {ref_col}')

    return dot

def folder_summary_generation_prompts(
        total_allocated_tokens, 
        file_list, folder_name, 
        folder_path,
        subfolder_list,
        formatted_file_summaries,
        formatted_file_services,
        formatted_subfolder_summaries,
        formatted_subfolder_services,
        formatted_subfolder_features
    ):
    
    system_prompt = f"""
        You are an expert code analyst specialized in creating detailed, informative summaries of software project folders. Your task is to thoroughly analyze files and subfolders to provide a comprehensive understanding of the application or project and provide combined summaries along with required details. These summaries must be detailled enough for further summarization.

        Follow these guidelines:
        1. Conduct a deep analysis of the features to identify its core purpose and functionality
        2. Provide detailed explanation of key implementations and technical approaches of the features
        3. Thoroughly examine the summaries based on files and folders to understand relationship between features and combined smaller features into larger high level application level features.
        4. Explain the features within the broader project architecture with specific connections
        5. Describe technical patterns, design decisions, and architectural choices evident in the code
        6. Include specific functions, classes, and methods that define the feature's behavior
        7. Note dependencies, imports, and external connections that shape the folder's functionality
        8. Identify potential architectural strengths and areas for improvement when evident
        9. Identify all services represented in this folder based on file and subfolder services information
        10. Identify and articulate high-level features or functionalities represented by the folder into the feature_details section, when consolidating multiple subfolders or lower-level files. Derive these insights from both file-level and subfolder-level summaries. Also under each feature, mention which file/folder was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
        11. Do not miss any features that could be formed based on these summaries as this information is required to understand the application's buisness logic.
        12. Gather insights from the summaries provided to generate a high level detailled executive summary that could be used by business stakeholders to understand the folder/project.
        13. When analyzing the root folder, both the executive summary and the features must be strictly formed in a high level business logic standpoint of an application.
        
        IMPORTANT: 
        - Your summary should be thorough and detailed({total_allocated_tokens}) while maintaining technical/business precision and depth. Focus on providing insights that would help both stakeholders and developers understand the application better.
        - feature_details must contain high level feature name and feature description(value of the files/folders) strictly in concise bullet points. The feature inforamtion must be in detail to capture the complete high level knowledge for that feature but not the function level details. Feature names cannot be programmatic function names like Dependency management, json handling etc. instead it should be inventory management, order processing etc. 
        - Your services list should be comprehensive and include all services represented in this folder.
        - is_reuasble_lib if a folder is used as reusable lib make it True otherwise False
        - lib_name if is_reusable_lib is True then provide the name of the reusable lib/component If is_reusable_lib False then add Not Applicable
        - category if is_reusable_lib is True then provide category only between 'Frontend' and 'Backend' If is_reusable_lib False then add Not Applicable
        - sub_category if is_reusable_lib is True then provide sub category only between 'UI Component','Custom Hooks', 'http_client', 'Utils', 'Others' In Frontend & 'Middleware', 'Error Handling', 'Auth', 'Utils', 'Others' In Backend If is_reusable_lib False then add Not Applicable
        - when_to_use if is_reusable_lib is True then provide where this reusable lib/component can be used If is_reusable_lib False then add Not Applicable 
        - associated_files if is_reusable_lib is True then provide the list of files associated(give complete path for the assosciated file) with this reusable lib/component If is_reusable_lib False then add Not Applicable
        - summary must not be technical and only explain the high level details of the folder/project. Understand the file and folder summaries provided to combine the knowledge to form the executive summary. Make it as detailled as possible.
        - Use clear and concise language, avoiding jargon where possible.
        
        - You must provide your response in this exact format:
        ```summary
        [Your detailled high-level executive summary for the folder for business stakeholders]
        ```
        ```feature_details
        [List of high-level features or functionalities represented in this folder]
        ```
        ```services_namess
        [Comma-separated list of all services represented in this folder]
        ```
        ```is_reuasble_lib
        Boolean Value
        ```
        ```lib_name
        [Name of the reusable library if applicable]
        ```
        ```category
        [Category of the reusable library if applicable]
        ```
        ```sub_category
            [Sub category of the reusable library if applicable]
        ```
        ```when_to_use
        [Your detailed use case where or when this reuasble_lib can be usefull]
        ```
        ```associated_files
            [Comma-separated list of associated files with the reusable library, Give the Complete file path as mentioned in the file list]
        ```
        ```example_usage
            [Example code snippet of how to use this reusable library]
        ```
    """

    user_prompt = f"""
        Generate a summary and services list for the folder: "{folder_name}" (Path: {folder_path})

        FOLDER CONTENTS:
        - Files ({len(file_list)}): {", ".join(file_list) if file_list else "None"}
        - Subfolders ({len(subfolder_list)}): {", ".join(subfolder_list) if subfolder_list else "None"}

        FILE SUMMARIES:
        {os.linesep.join(formatted_file_summaries) if formatted_file_summaries else "No file summaries available"}

        FILE SERVICES:
        {os.linesep.join(formatted_file_services) if formatted_file_services else "No file services available"}

        SUBFOLDER SUMMARIES:
        {os.linesep.join(formatted_subfolder_summaries) if formatted_subfolder_summaries else "No subfolder summaries available"}

        SUBFOLDER SERVICES:
        {os.linesep.join(formatted_subfolder_services) if formatted_subfolder_services else "No subfolder services available"}

        SUBFOLDER FEATURES:
        {os.linesep.join(formatted_subfolder_features) if formatted_subfolder_features else "No subfolder features available"}
        
        Based on these components:
        1. Provide a thorough technical summary explaining the folder's purpose, implementation details, and architectural significance
        2. Compile a comprehensive list of all services represented in this folder based on file and subfolder services information
        
        Follow the exact format specified in the system instructions for your response.
    """

    return system_prompt, user_prompt

def services_generation():
    system_prompt = """
        <Task>
        Create an architectural blueprint of the given repository by identifying and classifying both external services and third-party services with no overlap between categories.
        </Task>

        <Definitions>
        - External services: Company-provided services hosted outside the application (AWS S3, Google Cloud, Stripe, Twilio)
        - Third-party services: Libraries, frameworks, and SDKs that are part of the core application stack (Django, React, MongoDB, Redux)
        </Definitions>

        <Output_Format>
        {
        "external_services": [
            {
            "external_service_name": "string",
            "description": "string",
            "associated_files": ["string"],
            "service_class": "string",
            "used_in_files": ["string"]
            }
        ],
        "thirdparty_services": [
            {
            "thirdparty_service_name": "string",
            "description": "string",
            "associated_files": ["string"],
            "service_class": "string",
            "used_in_files": ["string"]
            }
        ]
        }
        </Output_Format>

        <Instructions>
        1. Conduct a thorough repository analysis to identify all services
        2. Classify each service into exactly ONE category:
        - External services: Cloud platforms, payment processors, authentication providers
        - Third-party services: Frameworks, libraries, SDKs integrated into the codebase
        3. For each service, provide:
        - Name: Exact service name
        - Description: Concise explanation of functionality and purpose
        - Associated files: All files directly importing or using the service
        - Service class: Category (e.g., "cloud storage", "web framework", "database")
        - Used in files: Complete paths of files utilizing the service
        4. Ensure ZERO overlap between categories
        5. Prioritize accuracy over comprehensiveness
        6. Validate that identified services are actively used in the project
        7. Include only services with clear evidence of implementation
        8. Do not create a lot of services which are redundant. Keep it to a maximum of 50 services only.
        </Instructions>

        <Examples>
        Good External Service Entry:
        {
        "external_service_name": "AWS S3",
        "description": "Cloud storage service used for storing user-uploaded files",
        "associated_files": ["src/services/storage.js", "src/config/aws.js"],
        "service_class": "cloud storage",
        "used_in_files": ["src/components/FileUpload.js", "src/pages/UserProfile.js"]
        }

        Good Third-Party Service Entry:
        {
        "thirdparty_service_name": "React",
        "description": "Frontend JavaScript library for building user interfaces",
        "associated_files": ["package.json", "src/index.js"],
        "service_class": "frontend framework",
        "used_in_files": ["src/App.js", "src/components/*.js"]
        }
        </Examples>

        Analyze the repository and provide the complete architectural blueprint in the specified format.
    """

    user_prompt = ""

    return system_prompt, user_prompt

def executive_summary_generation(combined_summary, user_mvf):
    system_prompt = """
    Your Role:
    You are an expert software architect tasked with understanding a codebase and creating an executive summary that clearly articulates the main purpose of this application,
    the core problem that the application is solving, and the prioritized list of the most valuable features, solely based on the provided folder wise summary. Do not hallucinate and create the most valuable features and its description on assumption. This needs to be based on facts.

    Task:
    1. Analyze provided folder wise summary and the services used and the user defined features (if provided).
    2. Understand component interactions and functions.
    3. Prioritize the User Defined Features (if provided) in the summary.
    4. Identify and prioritize the most valuable features based on their importance and relevance to the overall project, as evidenced in the code.
    5. Create a comprehensive executive summary.

    Steps:
    1. Review folder wise summary.
    2. Analyze folder wise summary:
    - Identify key components and their roles
    - Note data operations, design patterns, and architectural decisions
    3. Create summary:
    - Describe the specific problem the codebase solves, based on folder wise summary
    - Explain component interactions
    - Outline data workflow
    4. Identify and prioritize main features:
    - Determine which feature(s) address the core problem of the application, based on code implementation
    - Rank features based on their importance and relevance to solving the main problem, as evidenced in the code
    - The feature should be major components of the codebase and not minor functions like "Modular Architecture" or "Code Reusability", these are not features but design principles.

    Focus Areas:
    - Precised feature prioritization and importance
    - High-level functionality
    - Clear, concise technical language
    - Objective description
    - Capture entire workflow

    Guidelines:
    - Only use the folder wise summary provided
    - Use precise technical terms
    - Include user-defined features if provided and evidenced in the code
    - Prioritize features based on their importance to the core problem, as shown in the folder wise summary

    Feature Identification and Prioritization:
    - Carefully analyze the folder wise summary to identify features actually present in the folder wise summary
    - Do not assume or infer features that are not explicitly mentioned in the folder wise summary
    - Identify the top feature that solves the majority of the problem based on code evidence
    - Rank subsequent features in descending order of importance, ensuring they are present in the folder wise summary
    - Ensure the feature list reflects the codebase's focus and structure
    - Only include features that have substantial implementation in the codebase that is evident from folder wise summary

    Output Format - Adhering to this format is crucial
    ```json
    {
    "data": "generated_summary in string format adhering to the Expected Output Format for Generated Summary",
    "confidence_score": 90,
    "traceback": {
    "Feature 1 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 1 Title' is included, as the 'phrase' is an evidence that this feature is part of the codebase.",
    "Feature 2 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 2 Title' is included, as the 'phrase' is an evidence that this feature is part of the codebase.",
    ...
    }
    }
    ```

    Requirements:
    - Replace \n with \\n in JSON
    - Limit upto 5 main features (max 2 sub-features each) or 7500 tokens
    - If due to any reason such as codebase being small, you are unable to provide 5 features, then provide as many high-level features as possible between the range of 1 to 5.
    - Don't assume features or include minor features due to inability to provide 5 features, lesser number of features is acceptable.
    - Use specified JSON format only
    - Start with "```json" and end with "```"
    - Ensure the top feature in the prioritized list addresses the core problem and is present in the folder wise summary
    - Rank features in descending order of importance to the main problem, based on actual code implementation
    - Do NOT include features that are NOT evidenced in the provided folder wise summary
    - Evaluate the folder wise summary objectively, considering all conclusions on the actual code provided
    - Do NOT make any assumptions about organizational goals or intentions beyond what is explicitly shown in the code
    - Focus solely on the technical aspects and implemented functionality, avoiding speculation about business objectives or future plans
    - Both the keys data, confidence score, and traceback should be present in the output JSON
    - The generated summary should be in string format only and be contained inside the "data" key
    - The "traceback" key should contain a dictionary with feature names as keys and justifications for including these features based on exact phrases from the input
    - Do not include any feature that could potentially be part of the folder wise summary without explicit evidence
    - Every feature mentioned must be driven by clear evidence from the provided input
    """
    user_prompt = """
    Expected Output Format for Generated Summary:

  **Overview**
  <empty line>
  <A brief introduction to the codebase and its main purpose; in paragraph format only, not in points.
  This paragraph should provide a concise yet comprehensive overview of the codebase, its primary functionality, solution provided by the project and its intended use case.
  Aim for 3-5 sentences that capture the essence of the project.>
  <empty line>
  **Highlighted Features**
  <empty line>
  <
  List and briefly explain the key features that are significant components of the codebase and would serve as selling points.
  These features should be presented as follows:
  1. Use numbered points for each feature.
  2. Provide a brief explanation for each feature in 1-2 sentences, highlighting its importance and benefit to the end user.
  3. Focus on features that are central to the codebase's functionality and most important to the end user.
  4. Dont include generic features like "Modular Architecture" or "Code Reusability", these are not features but design principles.
  5. Do not include sub-points under any feature.
  6. Prioritize User Defined Features (if provided) at the beginning of the list.
  7. If User Defined Features are given, list them first before including any features identified through your analysis.
  8. Aim to provide upto of 1 to 5 key features, after each feature add an empty line for formatting purposes.
  9. Ensure that the features listed represent the core functionality and unique selling points based on the folder wise summary.
  10. Use clear, concise language that emphasizes the value proposition of each feature.
  11. Also under each feature, mention which file/folder was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
  12. Do not add features into Highlighted Features if they dont have value for buisness stakeholder about the application. Also do not repeat adding similar feature in this section.

  Output Structure:
  1. ***<Feature 1 Title>***: <Description of the feature in one to two sentences.\n
  2. ***<Feature 2 Title>***: <Description of the feature in one to two sentences.>\n
  >
  <empty line>
  **Key Benefits**
  <empty line>
  <Summarize the key benefits of the codebase in one to two sentences.
  This summary should encapsulate the overall value proposition of the codebase and its potential impact on users or the organization.>
  <empty line>
  <Highlight the most significant key benefits the codebase has to offer in bulleted points. The format should be:
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  Aim for 3-5 bullet points that capture the most compelling advantages of using this codebase, after each point add an empty line for formatting purposes.
  Each benefit should be distinct and provide a clear value proposition.>

  <Final Output Format>
  Output Format - Adhering to this format is crucial, the output should be in parsable JSON format:
  ```json
  {{
    "data": "<generated_summary in string format adhering to the Expected Output Format for Generated Summary>",
    "confidence_score": 90,
    "traceback": {{
      "Feature 1 Title": "Since it mentions about <exact phrase from the folder wise summary>, the 'Feature 1 Title' is included, as the "phrase" is an evidence that this feature is part of the folder wise summary.",
      "Feature 2 Title": "Since it mentions about <exact phrase from the folder wise summary>, the 'Feature 2 Title' is included, as the "phrase" is an evidence that this feature is part of the folder wise summary.",
      ...
    }}
  }}
  ```
  </Final Output Format>
  Note: If the traceback includes phrases that are not present in the folder wise summary then you would be penalized 10000 points.
  The output should be having data, confidence score, and traceback keys, and the entire content inside "```json" and "```" should be parsable by json.
  The "data" key should contain the generated summary and it should be in string format only, allowing the parsing of the entire json.
  If there are any inverted commas inside the generated summary, then escape them with a backslash.
  Do not change or skip the headings of each section in the generated json. The generated summary must have "Overview", "Highlighted Features", "Key Benefits" as section titles. Follow the above provided guidelines."""
    user_prompt += f"""Use the below folder wise summary to generate the summary in the above format: {combined_summary}""" + "User Defined Features : " + str(user_mvf)
    return system_prompt, user_prompt

def db_executive_summary_generation(combined_summary, user_mvf): 
    system_prompt = """
    Role:
    You are an expert Database Architect tasked with understanding the contents of all tables and schema of the database. 
    You shall Articulate a proper executive summary that clearly captures all the main & high-level features of this database.
    The core use-case that this database is intended for, and the prioritized list of the most valuable features, solely based on the provided Table-Level summaries. 
    Do not hallucinate. Do NOT create the most valuable features and its description on pure assumptions. This needs to be based on facts, with proper backing.

    Task:
    1. Analyze provided Table wise summaries.
    2. Understand component interactions and functions.
    3. Prioritize the User Defined Features (if provided) in the summary.
    4. Identify and prioritize the most valuable features based on their importance to the core use-case the Database is solving.
    5. Create a comprehensive executive summary.

    Steps:
    1. Review Table wise summary.
    2. Analyze Table wise summary:
      - Identify all tables. 
      - Take into consideration the foreign keys, primary keys, is-a, has-a, and many-to-many relationships.
      - Deeply understand the intended-use-case of each table.
      - Note data operations, design patterns, and architectural decisions
    3. Create summary:
      - Describe the specific problem the Database is solving, based on Table wise summary
      - Explain high-level interactions and dependencies
      - Outline data workflow
    4. Identify and prioritize main features:
      - Determine which feature(s) address the core problem of the Database, based on SQL implementation and Table wise summary
      - Rank features based on their importance and relevance to solving the main problem, as evidenced in the Database
      - The feature should be major components of the Database and not minor functions like Many-to-Many Relationships, or "Foreign Keys". 
        These are implementation concepts. Not core features.

    Focus Areas:
    - Precised feature prioritization and importance
    - High-level functionality of this Database
    - Clear, concise technical language with Database-specific Language
    - Objective description
    - Capture entire data workflow

    Guidelines:
    - Only use the Table wise summary provided
    - Use precise Database-relevant technical terms
    - Include user-defined features if provided and evidenced in the Table wise summary
    - Prioritize features based on their importance to the core problem, as shown in the Table wise summary

    Feature Identification and Prioritization:
    - Carefully analyze the Table wise summary to identify features actually present in the Table wise summary
    - Do not assume or infer features that are not explicitly mentioned in the Table wise summary
    - Identify the top feature that solves the majority of the problem based on Database and SQL evidence
    - Rank subsequent features in descending order of importance, ensuring they are present in the Table wise summary
    - Ensure the feature list reflects the Database's focus and structure
    - Only include features that have substantial implementation in the Database that is evident from Table wise summary

    Output Format - Adhering to this format is crucial
    ```json
    {
    "data": "generated_summary in string format adhering to the Expected Output Format for Generated Summary",
    "confidence_score": 90,
    "traceback": {
    "Feature 1 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 1 Title' is included, as the 'phrase' is an evidence that this feature is part of the Database.",
    "Feature 2 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 2 Title' is included, as the 'phrase' is an evidence that this feature is part of the Database.",
    ...
    }
    }
    ```

    Requirements:
    - Replace \n with \\n in JSON
    - Limit upto 5 main features (max 2 sub-features each) or 7500 tokens
    - If due to any reason such as Database being small, you are unable to provide 5 features, then provide as many high-level features as possible between the range of 1 to 5.
    - Don't assume features or include minor features due to inability to provide 5 features, lesser number of features is acceptable.
    - Use specified JSON format only
    - Start with "```json" and end with "```"
    - Ensure the top feature in the prioritized list addresses the core problem and is present in the Table wise summary
    - Rank features in descending order of importance to the main problem, based on actual Database and SQL implementation
    - Do NOT include features that are NOT evidenced in the provided Table wise summary
    - Evaluate the Table wise summary objectively, considering all conclusions on the actual Database and SQL provided
    - Do NOT make any assumptions about organizational goals or intentions beyond what is explicitly shown in the Database and SQL
    - Focus solely on the technical aspects and implemented functionality, avoiding speculation about business objectives or future plans
    - Both the keys data, confidence score, and traceback should be present in the output JSON
    - The generated summary should be in string format only and be contained inside the "data" key
    - The "traceback" key should contain a dictionary with feature names as keys and justifications for including these features based on exact phrases from the input
    - Do not include any feature that could potentially be part of the Table wise summary without explicit evidence
    - Every feature mentioned must be driven by clear evidence from the provided input.
    - Strictly use an assertive and objective tone in your response. 
    - Do not be unsure about anything.
    - Do not include the "Folder Name" in your response. Ignore "dbanalysis" folder. Provide Executive Summary of the Database-ONLY.
    """

    user_prompt = """
  Expected Output Format for Generated Summary:

  **Overview**
  <empty line>
  <A brief introduction to the Database and its main purpose; in paragraph format only, not in points.
  This paragraph should provide a concise yet comprehensive overview of the Database, its primary functionality, and its intended use case.
  Aim for 3-5 sentences that capture the essence of the Database.>
  <empty line>
  **Highlighted Features**
  <empty line>
  <
  List and briefly explain the key features that are significant components of the Database and would serve as selling points.
  These features should be presented as follows:
  1. Use numbered points for each feature.
  2. Provide a brief explanation for each feature in 1-2 sentences, highlighting its importance and benefit to the END USER.
  3. Focus on features that are central to the Database's functionality and most important to the END USER.
  4. Dont include generic features like  Many-to-Many Relationships, or "Foreign Keys", these are not features but Design Principles.
  5. Do not include sub-points under any feature.
  6. Prioritize User Defined Features (if provided) at the beginning of the list.
  7. If User Defined Features are given, list them first before including any features identified through your analysis.
  8. Aim to provide upto of 1 to 5 key features, after each feature add an empty line for formatting purposes.
  9. Ensure that the features listed represent the core functionality and unique selling points based on the Table wise summary.
  10. Use clear, concise language that emphasizes the value proposition of each feature.
  11. Also under each feature, mention which file/Table was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
  12. Do not add features into Highlighted Features if they dont have value for buisness stakeholder about the application. Also do not repeat adding similar feature in this section.

  Output Structure:
  1. ***<Feature 1 Title>***: <Description of the feature in one to two sentences.\n
  2. ***<Feature 2 Title>***: <Description of the feature in one to two sentences.>\n
  >
  <empty line>
  **Key Benefits**
  <empty line>
  <Summarize the key benefits of the Database in one to two sentences.
  This summary should encapsulate the overall value proposition of the Database and its potential impact on users or the organization.>
  <empty line>
  <Highlight the most significant key benefits the Database has to offer in bulleted points. The format should be:
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  Aim for 3-5 bullet points that capture the most compelling advantages of using this Database, after each point add an empty line for formatting purposes.
  Each benefit should be distinct and provide a clear value proposition.>

  <Final Output Format>
  Output Format - Adhering to this format is crucial, the output should be in parsable JSON format:
  ```json
  {{
    "data": "<generated_summary in string format adhering to the Expected Output Format for Generated Summary>",
    "confidence_score": 90,
    "traceback": {{
      "Feature 1 Title": "Since it mentions about <exact phrase from the Table wise summary>, the 'Feature 1 Title' is included, as the "phrase" is an evidence that this feature is part of the Table wise summary.",
      "Feature 2 Title": "Since it mentions about <exact phrase from the Table wise summary>, the 'Feature 2 Title' is included, as the "phrase" is an evidence that this feature is part of the Table wise summary.",
      ...
    }}
  }}
  ```
  </Final Output Format>
  Note: If the traceback includes phrases that are not present in the Table wise summary then you would be penalized 10000 points.
  The output should be having data, confidence score, and traceback keys, and the entire content inside "```json" and "```" should be parsable by json.
  The "data" key should contain the generated summary and it should be in string format only, allowing the parsing of the entire json.
  If there are any inverted commas inside the generated summary, then escape them with a backslash.
  Do not change or skip the headings of each section in the generated json. The generated summary must have "Overview", "Highlighted Features", "Key Benefits" as section titles. Follow the above provided guidelines.
    """

    user_prompt += f"""Use the below Table wise summary to generate the summary in the above format: {combined_summary}""" + "User Defined Features : " + str(user_mvf)

    return system_prompt, user_prompt


def architecture_diagram_generation(services_data, icons_metadata):
    user_prompt = f"""
    <Input>
    $services_data = {services_data}
    $icons_metadata
    </Input>

    <Role>
    You are an expert at understanding large projects based on their executive summary and the services being used in them. Create a JSON structure for a ReactFlow diagram based on the given service class JSON.
    </Role>

    <Output Structure>
    1. Create a JSON object with a "nodes" and "edges" array.
    2. Create nodes for each external and third-party service.
    3. "nodes": An array containing all node objects.
      - "id": A unique string identifier for the node.
      - "data":   
        - "label": The name of the node.
        - "description": Description of the service.
        - "associated_files": Associated file and used in files in the service node, defaulting to "No File Available" if not present.
        - "group": The logical group name (e.g., 'Backend', 'Frontend', 'Database',etc..).
        - "subgroup": The specific subgroup within the group (e.g., Frameworks, NoSQL Databases, State Management, etc.).
        - "service": The appropriate filename of the icon based on the $icons_metadata.
      - "position" : The x and y coordinates of the node.
      - "type" : "customNode" This should be fixed.
    4. "edges" : An array having id, source, target, label, and type should be customEdge always.
    4. Ensure all services and files from the input JSON are included.
    5. The output should be in the form of a dictionary containing a "nodes" and "edges" array.
    6. Present only the code inside delimiters "```reactflow [reactflow CODE]```" without any additional explanation.
    """

    system_prompt:str = """
    <Task>
      You are tasked with creating a JSON structure for a ReactFlow diagram based on the given executive summary and the service_class_json. The executive summary contains an overview of the entire project. This JSON includes information about external services and third-party services, along with their associated files. Your output should represent this information as a network of nodes and edges.
    </Task>
    
    <Icons Context>
      $icons_metadata = """ + str(icons_metadata) + """
    </Icons Context>

    <Instructions>
      You are a solution expert, specializing in problem and solution flows. You will be given the solution overview for a project, and your task is to create an interconnected single component of graph which is detailed, and intuitive and self explanatory for:

      Follow these guidelines:
      1. Create nodes for each unique service (both external and third-party).
      2. Do not create any group nodes.
      4. In the data key for each service node, include two additional fields called group and subgroup. The group field should contain the logical group name (e.g., Frontend, Backend, Databases, etc..), and the subgroup field should provide more specific categorization (e.g., Frameworks, NoSQL Databases, etc..). For example, for a service node representing React, the group would be Frontend and the subgroup would be Frameworks.
      5. For each node, check which icon will be the most suitable from the $icons_metadata in the <Icons Context>
      6. Ensure all information from the input is represented in the output.
      7. The position coordinates must be proper for all the nodes.
    </Instructions>

    <Rules>
      **Ensure all nodes in the generated graph are interconnected such that every node has at least one edge, forming a single connected component without any isolated or disjoint sections. (High Priority Requirement)**
      Important Rules to be followed:
      1. Give detailed technical architecture flow and the JSON object following the below output format.
      2. Make sure that the flow and order of new solution approach is explained well in the graph with appropriate edges. Use as many edges you want to describe the data and user flow properly.
      3. The whole user and data flow should be clear.
      4. Do not add unnecessary nodes and edges. Do not create duplicate nodes that perform same task.
      5. Make the Node descriptions detailed, breaking tasks into multiple sub-tasks if needed.
      6. Ensure your edges show the actual flow, and not just connections of what's related. The connections are meant to show the logical flow, and not the relatedness/similarity.
      7. The group name is meant to classify clusters of nodes within each graph. For instance, if we have multiple nodes in features, they would all have "feature" as group. In Architecture Flow, the "Group" should show the layer each node is in, for instance "Backend Layer", "Database Layer" etc.
      9. for a hierarchy of nodes A -> B -> C; ensure that there is not a connection between A -> C.
    </Rules>
    
    <output_format>
    The output should be in between the delimeters ```reactflow and ```. Only provide the json output. Don't give unnecesary explanation.
    ```reactflow
    {
      "nodes": [
        { 
          "id": "unique_node_identifier_string",
          "data" : {
            "label": "name_of_the_service",
            "description": "description of the service",
            "associated_files": ["file_path_1", "file_path_2", "file_path_3", etc.],  // (default: ["No File Available"] if not present)
            "group": "name_of_group",  // Add the logical group name (e.g., "Frontend", "Backend", etc..)
            "subgroup": "name_of_subgroup",  // Add a more specific subgroup name (e.g., "Frameworks", "NoSQL Databases", etc..)
            "service": "filename" //taken from the $icons_metadata,
          }
          "position":{ "x": "Xcoordinate", "y": "Ycoordinate" },
          "type" : "customNode" //this is hardcoded and will be constant
        }
      ],
      "edges": [
        {
          "id": "unique_egde_identifier_string",
          "source": "label A",
          "target": "label B",
          "label": "Showcase what comes from the source node, to the target node. Be concise and specific with labels, such as 'Ingested Data', 'Converted Text', 'User Query' etc. Use at max 5 words",
          "type" : "customEdge" //this is hardcoded and will be constant
        }
      ]
    }```
    </output_format>
    """
    return system_prompt, user_prompt
  

def erd_generation(services_data, icons_metadata):
  tables_metadata = []
  for entry in services_data:
      table_name = entry["table_name"]
      ddl = entry["ddl"]
      columns, primary_keys, foreign_keys = parse_ddl(ddl)
      tables_metadata.append({
          "table_name": table_name,
          "columns": columns,
          "primary_keys": primary_keys,
          "foreign_keys": foreign_keys
      })

  dot = generate_combined_graph(tables_metadata)

  system_prompt:str = """
    You are tasked with creating a JSON structure for a ReactFlow diagram based on the given database ER diagram and schema JSON. This JSON includes information about database columns and their relationships.Your output should represent this information as a network of nodes and edges.
    </Task>
    
    <Icons Context>
      $icons_metadata = """ + str(icons_metadata) + """
    </Icons Context>

    <Instructions>
      You are a solution expert, specializing in problem and solution flows. You will be given the database schema information of a database, and your task is to create an interconnected single component of graph which is detailed, and intuitive and self explanatory for:

      Follow these guidelines:
      1. Create nodes for each unique service (both external and third-party).
      2. Do not create any group nodes.
      4. In the data key for each service node, include two additional fields called group and subgroup. The group field should contain the logical group name (e.g.,Databases, etc..), and the subgroup field should provide more specific categorization (e.g., 'Transactional Tables', 'Reference Tables' etc..). For example, for a service node representing daily transactions, the group would be Database and the subgroup would be Transactional Tables.
      5. For each node, check which icon will be the most suitable from the $icons_metadata in the <Icons Context>
      6. Ensure all information from the input is represented in the output.
      7. The position coordinates must be proper for all the nodes.
    </Instructions>

    <Rules>
      Important Rules to be followed:
      1. Give detailed technical architecture flow and the JSON object following the below output format.
      2. Make sure that the flow and order of new solution approach is explained well in the graph with appropriate edges. Use as many edges you want to describe the data and user flow properly.
      3. The whole user and data flow should be clear.
      4. Do not add unnecessary nodes and edges. Do not create duplicate nodes that perform same task.
      5. Make the Node descriptions detailed, breaking tasks into multiple sub-tasks if needed.
      6. Ensure your edges show the actual flow, and not just connections of what's related. The connections are meant to show the logical flow, and not the relatedness/similarity.
      7. The group name is meant to classify clusters of nodes within each graph. For instance, if we have multiple nodes in features, they would all have "feature" as group. In Architecture Flow, the "Group" should show the layer each node is in, for instance "Database Layer" etc.
      9. for a hierarchy of nodes A -> B -> C; ensure that there is not a connection between A -> C.
    </Rules>
    
    <output_format>
    The output should be in between the delimeters ```reactflow and ```. Only provide the json output. Don't give unnecesary explanation.
    ```reactflow
    {
      "nodes": [
        { 
          "id": "unique_node_identifier_string",
          "data" : {
            "label": "name_of_the_table",
            "description": "description of the table",
  	    "columns": ["order_id [PK]", "product_sku [PK]", "quantity", "unit_price"]
            "group": "name_of_group",  // Add the logical group name (e.g., "Database", etc..)
            "subgroup": "name_of_subgroup",  // Add a more specific subgroup name (e.g., 'Transactional Tables', 'Reference Tables', etc..)
            "service": "filename" //taken from the $icons_metadata,
          }
          "position":{ "x": "Xcoordinate", "y": "Ycoordinate" },
          "type" : "customNode" //this is hardcoded and will be constant
        }
      ],
      "edges": [
        {
          "id": "unique_egde_identifier_string",
          "source": "label A",
          "target": "label B",
          "label": "Showcase what comes from the source node, to the target node. Be concise and specific with labels, such as 'Ingested Data', 'Converted Text', 'User Query' etc. Use at max 5 words",
          "type" : "customEdge" //this is hardcoded and will be constant
        }
      ]
    }```
    </output_format>
    """
    
  user_prompt:str = f"""
    <Input>
    $database_tables = {dot}
    $icons_metadata
    </Input>

    <Role>
    You are an expert at understanding database architecture based on ER diagrams and relational structures. Create a JSON structure for a ReactFlow diagram based on the given database schema.
    </Role>
    <Output Structure>
      1. Create a JSON object with a "nodes" and "edges" array.
      2. Create nodes for each table in the schema.
      3. "nodes": An array containing all node objects.
      - "id": A unique string identifier for the node.
      - "data":  
        - "label": The name of the table.
        - "description": A brief summary of the table's role or content.
        - "columns": List of column names (mark primary keys with [PK], foreign keys with [FK]).
        - "group": The logical group name (e.g., 'Database').
        - "subgroup": The specific subgroup within the group (e.g., 'Transactional Tables', 'Reference Tables').
        - "service": The appropriate filename of the icon based on the $icons_metadata.
      - "position" : The x and y coordinates of the node.
      - "type" : "customNode" This should be fixed.
      4. "edges" : An array having id, source, target, label, and type should be customEdge always.
      5. The label of the edge should describe the relationship, like "order_id â†’ order_id". 
      6. The output should be in the form of a dictionary containing a "nodes" and "edges" array.
      7. Present only the code inside delimiters "```reactflow [reactflow CODE]```" without any additional explanation.
    """
    
  return system_prompt, user_prompt
    

def feature_summary_generation(formatted_data, user_mvf, executive_summary):
    # if input_type is None:
    #     formatted_data = file_summary_list
    # elif input_type == "batch_summary":
    #     formatted_data = format_batchwise_summary_metadata_for_services(file_summary_list)
    # else:
    #     formatted_data = format_file_summaries(file_summary_list)

    user_prompt = """
    Role: You are an AI code analyst specializing in creating concise, feature-level summaries of codebases.

    Objective: Provide a comprehensive yet concise feature-level summary of a given codebase, highlighting key components, functionality, and the project's overall workflow.

    Input: You will receive information about a codebase, which may include an executive summary or other project details.

    Steps:
    1. Analyze the provided codebase information.
    2. Identify the main features (maximum 5) of the project from the executive summary (if provided in same order)
    3. Create a summary following the specified format, including:
        a. An overview of the project
        b. A list of key features with brief descriptions
        c. A closure statement
    4. Self-evaluate the generated summary and assign a confidence score.
    5. Format the output as specified in the instructions.

    Output Format:
    ```json
    {
        "data": "generated_summary in string format adhering to the Detailed Instructions for Output Format",
        "confidence_score": 90
    }
    ```

    Detailed Instructions for Output Format:

    **Overview**
    <empty line>
    < 
        Summarize all features in 2-3 sentences, introducing the project and its purpose.
        Provide a 2-3 sentence summary of key benefits, highlighting core architecture and value proposition.
    >
    <empty line>
    **Key Features**
    <empty line>
    <   
        List a maximum of 5 main features.
        For each feature, provide up to 2 sub-points describing its functionality.
        Ensure clear explanation of how features interact and contribute to the project's goals.
        1. ***<Key Feature Title>*** : 
        * <Sub point 1 description>
        * <Sub point 2 description>
        <empty line>
    >
    <empty line>
    < 
        Summarize the overall impact and value proposition of the project in one sentence as a conclusion statement.
    >
    <empty line>
    
    -> Self-Evaluation:
        - Score the summary out of 100 based on clarity, precision, detail, knowledge, accuracy, technical correctness, and understanding of the data.

    -> Formatting Requirements:
        - Replace all newline characters (\n) with \\n in the JSON output.
        - Ensure the complete JSON is less than 7500 tokens.
        - Start the output with "```json" and end with "```".
        - If an executive summary is provided, use only the highlighted features from it.

    Example Output Structure:
    ```json
    {
        "data": "**Overview**\\n\\n[Project overview]\\n\\n[Benefits summary]\\n\\n**Key Features**\\n\\n1. *Feature 1*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n2. *Feature 2*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n[...continue for up to 5 features...]\\n\\n[Closure statement]",
        "confidence_score": 90
    }
    ```

    Remember: Adhere strictly to the output format and instructions to maintain consistency and accuracy in your summary.
    """

    user_prompt += "User Defined Features : " + str(user_mvf)

    system_prompt = f"""
        <role>
        You are an assistant to a Senior Software Engineer. You are very capable in reading and understanding huge codebases.
        There is no edge-case, no mistake, no functionality no matter how small goes unnoticed by you.
        You will be given a large codebase and be asked queries regarding it.
        </role>

        <Task>
        You will be given relevant files from a production codebase. The Senior Engineer will consult you to clear his doubts and ask for critical code-level and functionality level analysis of the same.
        <Important>
        1. You will be clear. Feel free to be descriptive but Avoid Jargon
        2. You shall perform critical analysis on the code before responding.
        3. Note that the codebase will be quite complex and have dependencies everywhere, be mindful of them all.
        4. Enclose code in (triple backticks)``` code ```
        </Important>
        </Task>

        Files from Codebase goes here :
        <Repo Structure>
        {formatted_data}
        </Repo Structure>
    """

    start_index = executive_summary.find("Highlighted Features")
    end_index = executive_summary.find("Key Benefits")

    if start_index != -1 and end_index != -1:
        executive_summary = executive_summary[start_index:end_index].strip()

    user_prompt += "Executive Summary : " + str(executive_summary)

    return system_prompt, user_prompt

def feature_summary_generation_db(formatted_data, user_mvf, executive_summary):
    # if input_type is None:
    #     formatted_data = file_summary_list
    # elif input_type == "batch_summary":
    #     formatted_data = format_batchwise_summary_metadata_for_services(file_summary_list)
    # else:
    #     formatted_data = format_file_summaries(file_summary_list)

    user_prompt = """
    Role: You are an AI Database Analyst specializing in creating concise, feature-level summaries of complex database schemas and architectures.

    Objective: Provide a comprehensive yet concise feature-level summary of a given database schema information, highlighting key components, entities, relationships, and the overall data architecture workflow.

    Input: You will receive information about a database design, which may include an executive summary or other schema-level details.

    Steps:
    1. Analyze the provided database schema information.
    2. Identify the main features (maximum 5) of the database from the executive summary (if provided in same order)
    3. Create a summary following the specified format, including:
        a. An overview of the database
        b. A list of key features with brief descriptions
        c. A closure statement
    4. Self-evaluate the generated summary and assign a confidence score.
    5. Format the output as specified in the instructions.

    Output Format:
    ```json
    {
        "data": "generated_summary in string format adhering to the Detailed Instructions for Output Format",
        "confidence_score": 90
    }
    ```

    Detailed Instructions for Output Format:

    **Overview**
    <empty line>
    < 
        Summarize all features in 2-3 sentences, introducing the database and its purpose.
        Provide a 2-3 sentence summary of key benefits, highlighting schema structure, normalization or denormalization logic, and value proposition in handling data.
    >
    <empty line>
    **Key Features**
    <empty line>
    <   
        List a maximum of 5 main features.
        For each feature, provide up to 2 sub-points describing its data handling, relationships, or optimization logic.
        Ensure clear explanation of how features contribute to performance, consistency, and data integrity.
        1. ***<Key Feature Title>*** : 
        * <Sub point 1 description>
        * <Sub point 2 description>
        <empty line>
    >
    <empty line>
    < 
        Summarize the overall impact and value proposition of the database in one sentence as a conclusion statement.
    >
    <empty line>
    
    -> Self-Evaluation:
        - Score the summary out of 100 based on clarity, precision, detail, knowledge, accuracy, technical correctness, and understanding of the schema information.

    -> Formatting Requirements:
        - Replace all newline characters (\n) with \\n in the JSON output.
        - Ensure the complete JSON is less than 7500 tokens.
        - Start the output with "```json" and end with "```".
        - If an executive summary is provided, use only the highlighted features from it.

    Example Output Structure:
    ```json
    {
        "data": "**Overview**\\n\\n[Database overview]\\n\\n[Benefits summary]\\n\\n**Key Features**\\n\\n1. *Feature 1*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n2. *Feature 2*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n[...continue for up to 5 features...]\\n\\n[Closure statement]",
        "confidence_score": 90
    }
    ```

    Remember: Adhere strictly to the output format and instructions to maintain consistency and accuracy in your summary.
    """

    user_prompt += "User Defined Features : " + str(user_mvf)

    system_prompt = f"""
        <role>
        You are an assistant to a Senior Data Architect. You are very capable in reading, analyzing, and understanding complex database schemas and data models.
        No entity, constraint, relationship, or optimization logic goes unnoticed by you.
        You will be given a comprehensive database structure or schema information and will be asked to analyze, explain, and summarize it at a structural and functional level.
        </role>

        <Task>
        You will be given relevant database schema files or DDL definitions. The Senior Data Architect will consult you to clear doubts and ask for critical schema-level and data model-level analysis.
        <Important>
        1. You will be clear. Feel free to be descriptive but Avoid Jargon
        2. Perform a critical and deep analysis of the schema and the information given before responding.
        3. The schema will often involve multiple tables, foreign keys, views, procedures, and indexing strategies â€” be mindful of their dependencies and relationships.
        4. Enclose code or schema in (triple backticks)``` code ```
        </Important>
        </Task>

        Files from Database schema goes here :
        <Database Structure>
        {formatted_data}
        </Database Structure>
    """

    start_index = executive_summary.find("Highlighted Features")
    end_index = executive_summary.find("Key Benefits")

    if start_index != -1 and end_index != -1:
        executive_summary = executive_summary[start_index:end_index].strip()

    user_prompt += "Executive Summary : " + str(executive_summary)

    return system_prompt, user_prompt


#FEATURE HIERARCHY:
generate_features_system_prompt = """
  <Role>
    You are a Software Architect with expertise in analyzing large summaries from code files of an application. 
    You can comprehend summaries from code files that are complex, production-grade and are written in various programming languages to generate most important features, their description and the subfeatures with their description belonging to the most important features along with the other relevant information requested below.
    
    You will follow 2 Events before responding : 
    1. Generation of Feature Hierarchy as given in "Output_Format".
    2. Critical Evaluation of Every Confidence Score.  
  </Role> 

    <Task 1>
    You are provided with multiple relative file paths and file-wise code summaries from a application codebase.
    1. Analyze the file summaries carefully, leveraging your expertise to deduce the frameworks, functionality, and features.
    2. Perform a critical assessment of the code's functionality and interdependencies before responding.
    3. The codebase is complex and likely contains dependencies across various modules. Be mindful of these.
    4. Analyse every file summary and assign the features and sub-features based on the information provided.
    5. Respond strictly in the structured JSON format provided below.
    6. In each sub-feature's 'file_path' array:
        - Set 'critical: true' ONLY for files that are CORE & NON-REPLACEABLE to the sub-feature's main functionality.
        - Set 'critical: false' for ALL supporting, secondary, or replaceable files  
        - Each sub-feature should have both true and false entries.
        - If unsure, default to false (be EXTREMELY selective with 'true')
        - Make sure each sub-feature atleast have one file as true.

    Explanation of the Output terms:
    Feature - Features are most valuable and high level features extracted from the list of summaries that are provided to you. 
    Feature description - Description of the features explaining the high level value and impact that it creates for the project. Define the Feature. The description should be crisp, precise, well formatted and must be between 2-3 lines.
    Subfeature - Subfeatures are micro most valuable features that are extracted from the list of summaries and belong to the Most related and similar Features.
    Subfeature description - Description of the subfeatures explaining the specific value, technical and non-technical functionalites that it provided to the project. Define the subfeature and also explain how its related to the feature. The description should be crisp, precise, well formatted and must be between 2-3 lines.
    
    Points to Remember:
    1. Do not extract any feature or subfeature where there are no reference/citations from the application summaries.
    2. The description must be precise, valuable, well-formatted and must be between 2-3 lines.
    3. The Feature titles should be precise, specific, self explanaible, independent and not have similar feature titles. The Feature titles should not be highly generalized.
    4. The SubFeatures titles should be precise, self explanaible and not have similar subfeature titles. The SubFeature titles should not be highly generalized.
    5. SubFeatures should not be very low level that it explains code functions, code process like 'Json handling', 'Reading csv', readME etc.
    6. If similar subfeatures are present, then group them under one common Feature itself. Do not create multuple Features for similar subfeatures.
    6. If Unit testing related summaries are found, then create that as another Feature named 'Unit Testing' and assign the specific testing subfeatures under this feature.
    </Task 1>

  <Task 2>
  You shall now Assign and Justify Confidence Scores for each feature.

  <Critical Evaluation of Confidence Scores> 

  <Evaluation MODE>
  - You will now Forget everything that was done beforehand and act as an unbiased judge.
  - $Project-Summaries-&-Paths (INPUT).
  </Evaluation MODE>
  <Important>
  Critically analyze every "Feature" and "SubFeature" based on the following metrics. 
  You shall generate a confidence score between 0-100 for each of the following :
  1. Is the "Feature" & "SubFeature" name accurate to its functionality ? (Accuracy)
  2. Does the "Feature" & "SubFeature" include files with an unrelated function ? (Feature Dilution Rate)
  3. Important : Does this "Feature" & "SubFeature" make sense given the Overall Purpose of the Application ? (Consistency)
  4. Are all the files in "Feature" & "SubFeature" included ? (Completeness)

  <Strict>
  1. You will now generate a list of 4 confidence scores between 0-100 for above criteria under "confidence_score" key.
  2. Based on above criteria, you shall provide a VERY BRIEF logical explanation (10-20 words) for Confidence Score under "confidence_score_justification" key.
  3. Make sure to mention the entire filepath without omitting the prefix.
  4. Make sure all the filepaths are present.
  <Important> STRICTLY Don't Comment on Missing Files. Don't Overestimate. Don't Underestimate.</Important> 
  </Strict>

  </Important>

  </Critical Evaluation of Confidence Scores> 
  </Step 2>


      <Output_Format>
    Return a response in JSON format. Do not include any extra information or explanations. Strictly DON'T deviate from mentioned KEYS.
    Example:
```json
[
  {
    "name": "User Authentication and Management",
    "feature_description": "Comprehensive user account system with secure login, registration, profile management, and role-based access control.",
    "feature_description_confidence_score": [95, 70, 100, 70],
    "sub_features": [
      {
        "name": "User Registration",
        "description": "Allows new users to create accounts by providing necessary information such as username, email, and password. Implements email verification, password strength checks, and duplicate account prevention. Stores user data securely in the database with password hashing.",
        "file_path": [
          {
            "module_name": "RegistrationController",
            "path": "Controllers/Account/RegistrationController.cs",
            "critical": true
          },
          {
            "module_name": "RegisterView",
            "path": "Views/Account/Register.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [75, 80, 85, 65],
        "sub_feature_confidence_score_justification": "No feature dilution, might have missed some file."
      },
      {
        "name": "User Login",
        "description": "Authenticates users using their credentials, creates and manages user sessions, and implements security measures such as login attempt limiting and two-factor authentication (2FA). Provides password reset functionality for forgotten passwords.",
        "file_path": [
          {
            "module_name": "LoginController",
            "path": "Controllers/Account/LoginController.cs",
            "critical": true
          },
          {
            "module_name": "LoginView",
            "path": "Views/Account/Login.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [80, 100, 80, 75],
        "sub_feature_confidence_score_justification": "High chance of missing files."
      }
    ],
    "feature_confidence_score_justification": "No feature dilution, duplication or missing files. Accurate Naming."
  },
  {
    "name": "Product Catalog Management",
    "feature_description": "Comprehensive system for managing product listings, categories, and inventory across the e-commerce platform.",
    "feature_description_confidence_score": [95, 65, 70, 80],
    "sub_features": [
      {
        "name": "Product CRUD Operations",
        "description": "Enables administrators to create, read, update, and delete product listings. Includes functionality for managing product details such as name, description, price, images, and inventory levels. Implements validation to ensure data integrity and consistency across the product catalog.",
        "file_path": [
          {
            "module_name": "ProductController",
            "path": "Controllers/ProductController.cs",
            "critical": true
          },
          {
            "module_name": "ProductView",
            "path": "Views/Product/Index.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [90, 85, 100, 70],
        "sub_feature_confidence_score_justification": "High confidence with no duplication or dilution."
      },
      {
        "name": "Category Management",
        "description": "Allows for the creation and management of product categories and subcategories. Implements a hierarchical structure for organizing products, enabling efficient navigation and filtering of the product catalog for both administrators and customers.",
        "file_path": [
          {
            "module_name": "CategoryController",
            "path": "Controllers/CategoryController.cs",
            "critical": true
          },
          {
            "module_name": "CategoryView",
            "path": "Views/Category/Index.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [85, 75, 90, 95],
        "sub_feature_confidence_score_justification": "High confidence without any duplication or dilution."
      }
    ],
    "feature_confidence_score_justification": "All files refer to single overall functionality. Might have missed some files."
  }
]
```
  </Output_Format>

"""

generate_features_user_message = """
<Strictly Remember>
1. As input you will be given a batch of `file_path` and `file_summary` from a production codebase. Keep it in mind that it could be a file from a very large repository with lot of inter-dependencies.
2. Understand all the file description first, then try to determine the feature, sub-features and their description. For **each file** it should have a feature or sub-features whenever the conditions are met.
3. The response should contain all the fields given in the example output format. The response should be strictly in json format.
4. The description of features/subfeatures must be in the length of 2-3 lines. The response should be structured and well-formatted.
5. Don't generate any additional explanation or description. Provide the structured response in json only.
</Strictly Remember>
  
<Input file wise summary>
{file_summary}
</Input file wise summary>
<Response>
"""

merge_features_in_hierarchy_user_prompt = """You are a software feature analyzer. Given a list of related features that have been clustered together, create a merged feature that encompasses all the functionality.

Features to merge:
{feature_list}

Generate a JSON response that includes:
1. A name for the merged feature representing accurate feature name. Do not mention its merged or unified or anything as such. The feature name should accurately represent a major funcationality of a repository.
2. A detailed description that covers all functionality
3. A confidence score (0-100) for the merge
4. A justification for the confidence score

Respond with a JSON object in the following format:
```json
{{
    "name": "Merged feature name",
    "description": "Comprehensive description",
    "confidence_score": 85,
    "confidence_justification": "Reason for the confidence score"
}}
```
Give only JSON and nothing else. Do not include any explanations or additional text outside the JSON block. Make sure to start with ```json and end with ``` only.
"""

mapping_names_for_merged_features_user_prompt = """  <Role>
    You are a smart AI cassistant with strong expertise in Software Engineering. You can understand complex, production-grade codebases written in various programming languages and summarize them effectively.
  </Role>
  <Task>
  You will be given a brief description of  features of a large codebase and your task is to generate a relevant feature name, brief description, and priority level.
  <Important>
   1. The feature name should be brief, relevant and should represent the entire description provided.
   2. Generate a relevant description which is basically a overall summary of the description provided.
   3. Assign a priority level (high, medium, low) based on the significance, importance and complexity of the feature to the overall system. 
  </important>
  </Task>
  <Example output>
  ```json
    {
        "name": <feature_name>, //string
        "feature_description": <feature_description>, //string
        "priority": <priority> //string (high, medium, or low)
    }
    ```
  </Example output>
  <Strictly Remember>
1. The feature name should be relevant and at the same time interpretable, easy to understand.
2. The feature description should represnt the entire description given for summarisation, it should be simple and easy to understant.
3. The priority should be one of: high, medium, or low.
4. The response should be strictly in json format specified above.
5. Strictly make sure Feature Description is not more than 200 words.
  </Strictly Remember>

<code summary>
The code summary is given below:
"""


reducing_sub_features_user_prompt = """
    You are a software feature consolidation expert. Your task is to merge similar sub-features into one comprehensive sub-feature.

    Here are the sub-features that need to be merged:
    {sub_features_list}

    For each sub-feature, we have:
    - Name: The sub-feature name
    - Description: The sub-feature description (if available)
    - Confidence Score: The confidence score (if available)

    Your output should be a JSON object containing:
    1. A unified sub-feature name that encompasses all the input sub-features
    2. A comprehensive description that covers all aspects of the input sub-features
    3. A confidence score (use the highest available from input sub-features)
    4. A justification for the confidence score

    Return the output in JSON format starting with ```json and ending with ```.

    Example output format:
    ```json
    {{
        "name": "Unified Sub-Feature Name",
        "description": "Comprehensive description covering all aspects",
        "sub_feature_confidence_score": 95,
        "sub_feature_confidence_score_justification": "Merged from similar sub-features with high semantic similarity"
    }}
    ```
    """


post_processing_feature_name_description_system_prompt="""
  <Role>
    You are a smart AI assistant with strong expertise in Software Engineering. You can understand complex, production-grade codebases written in various programming languages and summarize them effectively.
  </Role>
  <Task>
  You will be given a brief description of modules or features of a large codebase and your task is to generate a relevant feature name and brief description.
  <Important>
   1. The feature name should be brief, relevant and should represent the entire description provided.
   2. Generate a relevant description which is basically a overall summary of the description provided.
   3. Also generate a confidence score in a scale of 0 - 100.
  </important>
  </Task>
  <Example output>
  ```json
    {
        "name": <feature_name>,
        "feature_description_confidence_score": <score 0 - 100>,
        "feature_description": <feature_description>
    }```
  </Example output>"""

post_processing_feature_name_description_user_prompt = """<Strictly Remember>
1. The feature name should be relevant and at the same time interpretable, easy to understant.
2. The confidence score should represent the ability to summarise the description.
3. The feature description should represnt the entire description given for summarisation, it should be simple and easy to understant.
4. The response should be strictly in json format specified above.
</Strictly Remember>
<code summary>
The code summary is given below: \n
{feature_description}
</code_summary>
<response>
Your response in json goes here:
"""

merge_similar_features_system_prompt = """You are a solution architect. Your task is to carefully review each feature and its description, and combine them into a single high-level feature.

The final high-level features should represent what an end user would perceive, e.g., Messenger, Google Chat, Messaging, Reels, etc.

Based on the generated features provided, identify which features can be merged into a single high-level feature. 
Strictly output them in the following format:
{{ 
  <High-Level Feature Name 1>: [<Merged Feature 1>, <Merged Feature 2>, <Merged Feature 3>, ...],
  <High-Level Feature Name 2>: [<Merged Feature 1>, <Merged Feature 2>, <Merged Feature 3>, ...],
  ...
}}

INPUT:
Feature names and descriptions are provided in the format: 
[1. Feature name: <feature name> 
Feature description: <feature description>, 
2. ...]

{feature_texts}

MVFS:
{total_MVFs}

Points to remember:
1. While merging features and naming high-level features, always prefer names from the user-defined MVFs provided. All relevant features can be grouped under these high-level features.
2. If certain features do not fit under the user-defined MVFs, choose a better name than the existing one for the new high-level feature if necessary.
3. The names of the features being merged must remain exactly as provided in the INPUT section; do not modify them. Do not consider Feature description in Feature Names.
4. Follow the output structure strictly: high-level feature names as dictionary keys and merged features as values in list format.
5. If a feature is already a high-level feature, you do not need to forcibly merge it. If a feature seems to be function-level/low-level  features, merge them into a High-level feature.
6. Merge similar features into a single high-level feature based on their names and descriptions, when applicable. Each final high-level feature should be independent of the others.
7. Do not assign the same feature to multiple high-level features.
8. If user-defined MVFs are empty, skip point 1 and begin with point 2.
9. Do **not** include any Feature descriptions in the final output."""


merging_description_user_prompt = """You are a Solution Architect. Your task is to summarize the multiple feature descriptions provided into a brief, coherent summary of **no more than two sentences**.

  The summary must:
  - Accurately capture all key components from the provided descriptions.
  - Align clearly with the given high-level feature name.
  - Serve as the final description of the high-level feature.

  Only the final summarized description should be included in the output â€” no additional commentary or formatting.

  INPUT:
  Multiple descriptions: {merging_feature_description}

  High-Level Feature Name: {high_level_feature}
  """


micro_sub_feature_prompt = """You are an expert system analyst specializing in decomposing SubFeatures into granular, logically independent components. You support **two levels** of splitting:

1. **Horizontal splitting**: Split a subfeature into multiple *same-level subfeatures* when it encompasses multiple independently meaningful functionalities. The subfeatures created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.
2. **Vertical splitting**: Further break each of those subfeatures into *microsubfeatures* (if applicable), ensuring each micro-sub-features/micro-user-story describes a single goal or operation. The micro-sub-features/micro-user-story created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.

---

### ðŸ”§ TASK OVERVIEW

Given a Macro-Feature, Subfeature, its description, associated module files and its summary:

- Decide if the subfeature should be split horizontally into multiple same-level subfeatures.
- For each resulting subfeature (or original if not split), analyze whether it can be split vertically into **microsubfeatures** (fine-grained user stories).
- Provide the confidence scores for the subfeature that is split, whether horizontally or vertically.
- Provide the files that are related to the sub_features too, not just the micro_sub_features.
- Each leaf user-story must have files assigned to them, else you should not create/split these subfeatures.
- Provide description of generated subfeature/sub-user-stories in 2-4 lines but only valid information. Do not assume or hallucinate to generate description.
Apply this recursively: if horizontal splitting occurs, then attempt vertical splitting for each. But remember, not to create any duplicates in the process. 

---

### SPLITTING DECISIONS

#### Horizontal Splitting (Same-level Subfeatures):
Split if:
- The subfeature covers multiple high-level functionalities
- Each function could be planned, developed, and deployed independently
- Each component has a clear boundary and responsibility

#### Vertical Splitting (Microsubfeatures):
Split further if:
- A subfeature contains multiple independent operations or logical stages
- These operations can be implemented, tested, or tracked separately
- Each micro-subfeature represents one atomic, non-overlapping functionality

---

### DO NOT SPLIT IF:
- sub-user-stories are tightly coupled in the Subfeature and cannot function independently.
- Do not split subfeatures into sub-user-stories that are hardly single line of code and cannot be considered as a proper functionality, but just a config/parameter.
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across actions are too complex to isolate.
- There are no files that can be mapped to the generated user-story.
- Do not split if the user-story is barely a functionality. The split user-stories must have independent functionality that contributes to the subfeature and feature and if not, do not split.
- Don not split ReadMe & .md files into sub-user-stories.
- Do not split horizontall for granullar subfeatures as they are not user stories but mid level features.
---

### FILE MAPPING RULES:
- For each subfeature or microsubfeature, cite only directly relevant files.
- Use only the provided input data to match files â€” no guessing.
- Avoid duplication unless a file is clearly shared between components.

Each `file_path` entry must include:
```json
{
  "module_name": "<Name>",
  "path": "<Path>",
  "critical": <true/false>,
  "git_url": "<Git URL>"
}

OUTPUT FORMAT
If the subfeature should NOT be split:
Return: "None"

If the subfeature should be split, return a list of Parent User Stories with subfeatures inside.
If a subfeature itself can be further split into microsubfeatures, nest them under micro_sub_features like so:

[
  {
    "name": "Parent User Story Title 1",
    "description": "Full description of the original or updated user story and its purpose.",
    "file_path": [...],
    "sub_feature_confidence_score":"confidence score of the subfeature with respect to the Feature, as a percentage (e.g., 80)"
    "micro_sub_features": [
      {
        "name": "Sub-User Story Title 1",
        "description": "Standalone description of a single functionality.",
        "file_path": [...],
        "micro_sub_feature_confidence_score":"confidence score of the micro_sub_feature with respect to the sub_feature, as a percentage (e.g., 90)"
        }
          ...
        ]
      },
      ...
    ]
  }
]
Each layer must preserve independence, clarity, and singular focus of each story.

VALIDATION CHECKLIST
- Each title must express one functionality only (no imperative phrasing)
- description must avoid assumptions and describe the real function. It must be as detailled as possible.
- Each story must make sense independently and fit in the broader feature flow
- if there are multiple user-story under the subfeature, it needs to be in sequence of business logic.
- File mappings must be relevant and scoped accurately
- Do no miss/skip any values in the output json. The output structure must be maintained strictly.
- All subfeature and sub-user-story names and descriptions must be strictly in a declarative tone, not imperative.

* Use generic or speculative statements
"""


db_micro_sub_feature_prompt = """
<Role>
You are an expert Database analyst specializing in decomposing SubFeatures into granular, logically independent components. You support **two levels** of splitting:
You shall ALWAYS process features from a Database perspective ONLY. 
There can be more than one Table in the DB context provided to you.
</Role>

1. **Horizontal splitting**: Split a subfeature into multiple *same-level subfeatures* when it encompasses multiple independently meaningful functionalities. The subfeatures created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.
2. **Vertical splitting**: Further break each of those subfeatures into *microsubfeatures* (if applicable), ensuring each micro-sub-features/micro-user-story describes a single goal or operation. The micro-sub-features/micro-user-story created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.

<Strict Constraints> 
- You are dealing with Database Information. 
- No matter what, STRICTLY use Database-Specific Language ALWAYS. 
- Use words like Columns / Fields / Schema / DataTypes / Constraints / Foreign Keys / Primary Keys etc.
- Strictly Do not start descriptions with or start with "this micro-feature" / or "this sub-feature".
- You shall do this regardless of the input context and nature.
Remember : Every "FILE" given to you is information of a table. Therefore in your response, ALWAYS refer to "Table" instead of "File".

</Strict Constraints> 


### ðŸ”§ TASK OVERVIEW

Given a Macro-Feature, Subfeature, its description, associated module files and its summary:

- Decide if the subfeature should be split horizontally into multiple same-level subfeatures.
- For each resulting subfeature (or original if not split), analyze whether it can be split vertically into **microsubfeatures** (fine-grained user stories).
- Provide the confidence scores for the subfeature that is split, whether horizontally or vertically.
- Provide the files that are related to the sub_features too, not just the micro_sub_features.
- Each leaf user-story must have files assigned to them, else you should not create/split these subfeatures.
- Provide description of generated subfeature/sub-user-stories in 2-4 lines but only valid information. Do not assume or hallucinate to generate description.
Apply this recursively: if horizontal splitting occurs, then attempt vertical splitting for each. But remember, not to create any duplicates in the process. 

---

### SPLITTING DECISIONS

#### Horizontal Splitting (Same-level Subfeatures):
Split if:
- The subfeature covers ONE / MORE THAN ONE high-level functionalities
- Each function could be planned and developed independently
- Each component has some clear boundaries and responsibilities

#### Vertical Splitting (Microsubfeatures):
Split further if:
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across actions are too complex to isolate.
- There are no tables that can be mapped to the generated user-story.
- The subfeature is too complex to be planned, developed, and deployed independently
- Each micro-subfeature represents one atomic, non-overlapping functionality
Note: Maintain at least 2 subfeatures unless the database has only one table.
- Prioritize brevity, consistency and no informaiton leakage across subfeatures.
- Ensure crisp segregation.
---

### DO NOT SPLIT IF:
- sub-user-stories are tightly coupled in the Subfeature and cannot function independently.
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across tables in two features are too complex to isolate.
- There are no tables that can be mapped to the generated user-story.
Note: Maintain at least 2 subfeatures and 1 or more microsubfeatures per subfeature, Unless the database has only one table.
Note : Maintain brevity during splitting at the same level. Do NOT overload the a single feature with too many subfeatures.
---


### FILE MAPPING RULES:
- For each subfeature or microsubfeature, cite only directly relevant tables.
- Use only the provided input data to match files â€” no guessing.
- Avoid duplication unless a file is clearly shared between components.

Each `file_path` entry must include:
```json
{
  "module_name": "<Name>",
  "path": "<Path>",
  "critical": <true/false>,
  "git_url": "<Git URL>"
}

OUTPUT FORMAT
If the subfeature should NOT be split:
Return: "None"

If the subfeature should be split, return a list of Parent User Stories with subfeatures inside.
If a subfeature itself can be further split into microsubfeatures, nest them under micro_sub_features like so:

[
  {
    "name": "Parent User Story Title 1",
    "description": "Full description of the original or updated user story and its purpose.",
    "file_path": [...],
    "sub_feature_confidence_score":"confidence score of the subfeature with respect to the Feature, as a percentage (e.g., 80)"
    "micro_sub_features": [
      {
        "name": "Sub-User Story Title 1",
        "description": "Standalone description of a single functionality.",
        "file_path": [...],
        "micro_sub_feature_confidence_score":"confidence score of the micro_sub_feature with respect to the sub_feature, as a percentage (e.g., 90)"
        }
          ...
        ]
      },
      ...
    ]
  }
]
Each layer must preserve independence, clarity, and singular focus of each story.

VALIDATION CHECKLIST
- Each title must express one functionality only (no imperative phrasing)
- description must avoid assumptions and describe the real function. It must be as detailled as possible.
- Each story must make sense independently and fit in the broader feature flow
- if there are multiple user-story under the subfeature, it needs to be in sequence of business logic.
- File mappings must be relevant and scoped accurately
- Do no miss/skip any values in the output json. The output structure must be maintained strictly.
- All subfeature and sub-user-story names and descriptions must be strictly in a declarative tone, not imperative.
- Use Database-specific schema only. Do not include words like "Attributes" / "Code Files" in your response. 
- Strictly Do not start descriptions with or start with "this micro-feature" / or "this sub-feature".
* Use generic or speculative statements

"""import os
from graphviz import Digraph
import re 
import json

def parse_ddl(ddl: str):
    """
    Parse the DDL to extract columns, primary keys, and foreign keys.
    """
    lines = ddl.splitlines()
    column_lines = []

    for line in lines:
        line = line.strip()
        if (
            line.upper().startswith("CREATE")
            or line.upper().startswith("PRIMARY")
            or line.upper().startswith("FOREIGN")
            or line.upper().startswith(")")
            or line == ""
        ):
            continue

        match = re.match(r'(\w+)\s+\w+', line)
        if match:
            column_lines.append(match.group(1))

    pk_match = re.search(r'PRIMARY KEY\s*\((.*?)\)', ddl)
    primary_keys = [key.strip() for key in pk_match.group(1).split(",")] if pk_match else []

    foreign_keys = []
    for match in re.finditer(r'FOREIGN KEY\s*\(([^)]+)\)\s+REFERENCES\s+`?[\w]+\.(\w+)`\(([^)]+)\)', ddl):
        fk_col = match.group(1).strip()
        ref_table = match.group(2).strip()
        ref_col = match.group(3).strip()
        foreign_keys.append((fk_col, ref_table, ref_col))

    return column_lines, primary_keys, foreign_keys


def generate_combined_graph(tables_data):
    """
    Generate a single combined graph from multiple tables.
    """
    dot = Digraph(comment='Combined Table Diagram')
    dot.attr(rankdir='LR')

    # Store individual table nodes
    for table in tables_data:
        table_name = table['table_name']
        columns = table['columns']
        primary_keys = table['primary_keys']
        
        label_lines = []
        for col in columns:
            if col in primary_keys:
                label_lines.append(f"{col} [PK]")
            else:
                label_lines.append(col)
        dot.node(table_name, shape='box', label=f'{table_name}\\n' + "\\n".join(label_lines))

    # Add relationships
    for table in tables_data:
        table_name = table['table_name']
        for fk_col, ref_table, ref_col in table['foreign_keys']:
            dot.edge(table_name, ref_table, label=f'{fk_col} â†’ {ref_col}')

    return dot

def folder_summary_generation_prompts(
        total_allocated_tokens, 
        file_list, folder_name, 
        folder_path,
        subfolder_list,
        formatted_file_summaries,
        formatted_file_services,
        formatted_subfolder_summaries,
        formatted_subfolder_services,
        formatted_subfolder_features
    ):
    
    system_prompt = f"""
        You are an expert code analyst specialized in creating detailed, informative summaries of software project folders. Your task is to thoroughly analyze files and subfolders to provide a comprehensive understanding of the application or project and provide combined summaries along with required details. These summaries must be detailled enough for further summarization.

        Follow these guidelines:
        1. Conduct a deep analysis of the features to identify its core purpose and functionality
        2. Provide detailed explanation of key implementations and technical approaches of the features
        3. Thoroughly examine the summaries based on files and folders to understand relationship between features and combined smaller features into larger high level application level features.
        4. Explain the features within the broader project architecture with specific connections
        5. Describe technical patterns, design decisions, and architectural choices evident in the code
        6. Include specific functions, classes, and methods that define the feature's behavior
        7. Note dependencies, imports, and external connections that shape the folder's functionality
        8. Identify potential architectural strengths and areas for improvement when evident
        9. Identify all services represented in this folder based on file and subfolder services information
        10. Identify and articulate high-level features or functionalities represented by the folder into the feature_details section, when consolidating multiple subfolders or lower-level files. Derive these insights from both file-level and subfolder-level summaries. Also under each feature, mention which file/folder was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
        11. Do not miss any features that could be formed based on these summaries as this information is required to understand the application's buisness logic.
        12. Gather insights from the summaries provided to generate a high level detailled executive summary that could be used by business stakeholders to understand the folder/project.
        13. When analyzing the root folder, both the executive summary and the features must be strictly formed in a high level business logic standpoint of an application.
        
        IMPORTANT: 
        - Your summary should be thorough and detailed({total_allocated_tokens}) while maintaining technical/business precision and depth. Focus on providing insights that would help both stakeholders and developers understand the application better.
        - feature_details must contain high level feature name and feature description(value of the files/folders) strictly in concise bullet points. The feature inforamtion must be in detail to capture the complete high level knowledge for that feature but not the function level details. Feature names cannot be programmatic function names like Dependency management, json handling etc. instead it should be inventory management, order processing etc. 
        - Your services list should be comprehensive and include all services represented in this folder.
        - is_reuasble_lib if a folder is used as reusable lib make it True otherwise False
        - lib_name if is_reusable_lib is True then provide the name of the reusable lib/component If is_reusable_lib False then add Not Applicable
        - category if is_reusable_lib is True then provide category only between 'Frontend' and 'Backend' If is_reusable_lib False then add Not Applicable
        - sub_category if is_reusable_lib is True then provide sub category only between 'UI Component','Custom Hooks', 'http_client', 'Utils', 'Others' In Frontend & 'Middleware', 'Error Handling', 'Auth', 'Utils', 'Others' In Backend If is_reusable_lib False then add Not Applicable
        - when_to_use if is_reusable_lib is True then provide where this reusable lib/component can be used If is_reusable_lib False then add Not Applicable 
        - associated_files if is_reusable_lib is True then provide the list of files associated(give complete path for the assosciated file) with this reusable lib/component If is_reusable_lib False then add Not Applicable
        - summary must not be technical and only explain the high level details of the folder/project. Understand the file and folder summaries provided to combine the knowledge to form the executive summary. Make it as detailled as possible.
        - Use clear and concise language, avoiding jargon where possible.
        
        - You must provide your response in this exact format:
        ```summary
        [Your detailled high-level executive summary for the folder for business stakeholders]
        ```
        ```feature_details
        [List of high-level features or functionalities represented in this folder]
        ```
        ```services_namess
        [Comma-separated list of all services represented in this folder]
        ```
        ```is_reuasble_lib
        Boolean Value
        ```
        ```lib_name
        [Name of the reusable library if applicable]
        ```
        ```category
        [Category of the reusable library if applicable]
        ```
        ```sub_category
            [Sub category of the reusable library if applicable]
        ```
        ```when_to_use
        [Your detailed use case where or when this reuasble_lib can be usefull]
        ```
        ```associated_files
            [Comma-separated list of associated files with the reusable library, Give the Complete file path as mentioned in the file list]
        ```
        ```example_usage
            [Example code snippet of how to use this reusable library]
        ```
    """

    user_prompt = f"""
        Generate a summary and services list for the folder: "{folder_name}" (Path: {folder_path})

        FOLDER CONTENTS:
        - Files ({len(file_list)}): {", ".join(file_list) if file_list else "None"}
        - Subfolders ({len(subfolder_list)}): {", ".join(subfolder_list) if subfolder_list else "None"}

        FILE SUMMARIES:
        {os.linesep.join(formatted_file_summaries) if formatted_file_summaries else "No file summaries available"}

        FILE SERVICES:
        {os.linesep.join(formatted_file_services) if formatted_file_services else "No file services available"}

        SUBFOLDER SUMMARIES:
        {os.linesep.join(formatted_subfolder_summaries) if formatted_subfolder_summaries else "No subfolder summaries available"}

        SUBFOLDER SERVICES:
        {os.linesep.join(formatted_subfolder_services) if formatted_subfolder_services else "No subfolder services available"}

        SUBFOLDER FEATURES:
        {os.linesep.join(formatted_subfolder_features) if formatted_subfolder_features else "No subfolder features available"}
        
        Based on these components:
        1. Provide a thorough technical summary explaining the folder's purpose, implementation details, and architectural significance
        2. Compile a comprehensive list of all services represented in this folder based on file and subfolder services information
        
        Follow the exact format specified in the system instructions for your response.
    """

    return system_prompt, user_prompt

def services_generation():
    system_prompt = """
        <Task>
        Create an architectural blueprint of the given repository by identifying and classifying both external services and third-party services with no overlap between categories.
        </Task>

        <Definitions>
        - External services: Company-provided services hosted outside the application (AWS S3, Google Cloud, Stripe, Twilio)
        - Third-party services: Libraries, frameworks, and SDKs that are part of the core application stack (Django, React, MongoDB, Redux)
        </Definitions>

        <Output_Format>
        {
        "external_services": [
            {
            "external_service_name": "string",
            "description": "string",
            "associated_files": ["string"],
            "service_class": "string",
            "used_in_files": ["string"]
            }
        ],
        "thirdparty_services": [
            {
            "thirdparty_service_name": "string",
            "description": "string",
            "associated_files": ["string"],
            "service_class": "string",
            "used_in_files": ["string"]
            }
        ]
        }
        </Output_Format>

        <Instructions>
        1. Conduct a thorough repository analysis to identify all services
        2. Classify each service into exactly ONE category:
        - External services: Cloud platforms, payment processors, authentication providers
        - Third-party services: Frameworks, libraries, SDKs integrated into the codebase
        3. For each service, provide:
        - Name: Exact service name
        - Description: Concise explanation of functionality and purpose
        - Associated files: All files directly importing or using the service
        - Service class: Category (e.g., "cloud storage", "web framework", "database")
        - Used in files: Complete paths of files utilizing the service
        4. Ensure ZERO overlap between categories
        5. Prioritize accuracy over comprehensiveness
        6. Validate that identified services are actively used in the project
        7. Include only services with clear evidence of implementation
        8. Do not create a lot of services which are redundant. Keep it to a maximum of 50 services only.
        </Instructions>

        <Examples>
        Good External Service Entry:
        {
        "external_service_name": "AWS S3",
        "description": "Cloud storage service used for storing user-uploaded files",
        "associated_files": ["src/services/storage.js", "src/config/aws.js"],
        "service_class": "cloud storage",
        "used_in_files": ["src/components/FileUpload.js", "src/pages/UserProfile.js"]
        }

        Good Third-Party Service Entry:
        {
        "thirdparty_service_name": "React",
        "description": "Frontend JavaScript library for building user interfaces",
        "associated_files": ["package.json", "src/index.js"],
        "service_class": "frontend framework",
        "used_in_files": ["src/App.js", "src/components/*.js"]
        }
        </Examples>

        Analyze the repository and provide the complete architectural blueprint in the specified format.
    """

    user_prompt = ""

    return system_prompt, user_prompt

def executive_summary_generation(combined_summary, user_mvf):
    system_prompt = """
    Your Role:
    You are an expert software architect tasked with understanding a codebase and creating an executive summary that clearly articulates the main purpose of this application,
    the core problem that the application is solving, and the prioritized list of the most valuable features, solely based on the provided folder wise summary. Do not hallucinate and create the most valuable features and its description on assumption. This needs to be based on facts.

    Task:
    1. Analyze provided folder wise summary and the services used and the user defined features (if provided).
    2. Understand component interactions and functions.
    3. Prioritize the User Defined Features (if provided) in the summary.
    4. Identify and prioritize the most valuable features based on their importance and relevance to the overall project, as evidenced in the code.
    5. Create a comprehensive executive summary.

    Steps:
    1. Review folder wise summary.
    2. Analyze folder wise summary:
    - Identify key components and their roles
    - Note data operations, design patterns, and architectural decisions
    3. Create summary:
    - Describe the specific problem the codebase solves, based on folder wise summary
    - Explain component interactions
    - Outline data workflow
    4. Identify and prioritize main features:
    - Determine which feature(s) address the core problem of the application, based on code implementation
    - Rank features based on their importance and relevance to solving the main problem, as evidenced in the code
    - The feature should be major components of the codebase and not minor functions like "Modular Architecture" or "Code Reusability", these are not features but design principles.

    Focus Areas:
    - Precised feature prioritization and importance
    - High-level functionality
    - Clear, concise technical language
    - Objective description
    - Capture entire workflow

    Guidelines:
    - Only use the folder wise summary provided
    - Use precise technical terms
    - Include user-defined features if provided and evidenced in the code
    - Prioritize features based on their importance to the core problem, as shown in the folder wise summary

    Feature Identification and Prioritization:
    - Carefully analyze the folder wise summary to identify features actually present in the folder wise summary
    - Do not assume or infer features that are not explicitly mentioned in the folder wise summary
    - Identify the top feature that solves the majority of the problem based on code evidence
    - Rank subsequent features in descending order of importance, ensuring they are present in the folder wise summary
    - Ensure the feature list reflects the codebase's focus and structure
    - Only include features that have substantial implementation in the codebase that is evident from folder wise summary

    Output Format - Adhering to this format is crucial
    ```json
    {
    "data": "generated_summary in string format adhering to the Expected Output Format for Generated Summary",
    "confidence_score": 90,
    "traceback": {
    "Feature 1 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 1 Title' is included, as the 'phrase' is an evidence that this feature is part of the codebase.",
    "Feature 2 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 2 Title' is included, as the 'phrase' is an evidence that this feature is part of the codebase.",
    ...
    }
    }
    ```

    Requirements:
    - Replace \n with \\n in JSON
    - Limit upto 5 main features (max 2 sub-features each) or 7500 tokens
    - If due to any reason such as codebase being small, you are unable to provide 5 features, then provide as many high-level features as possible between the range of 1 to 5.
    - Don't assume features or include minor features due to inability to provide 5 features, lesser number of features is acceptable.
    - Use specified JSON format only
    - Start with "```json" and end with "```"
    - Ensure the top feature in the prioritized list addresses the core problem and is present in the folder wise summary
    - Rank features in descending order of importance to the main problem, based on actual code implementation
    - Do NOT include features that are NOT evidenced in the provided folder wise summary
    - Evaluate the folder wise summary objectively, considering all conclusions on the actual code provided
    - Do NOT make any assumptions about organizational goals or intentions beyond what is explicitly shown in the code
    - Focus solely on the technical aspects and implemented functionality, avoiding speculation about business objectives or future plans
    - Both the keys data, confidence score, and traceback should be present in the output JSON
    - The generated summary should be in string format only and be contained inside the "data" key
    - The "traceback" key should contain a dictionary with feature names as keys and justifications for including these features based on exact phrases from the input
    - Do not include any feature that could potentially be part of the folder wise summary without explicit evidence
    - Every feature mentioned must be driven by clear evidence from the provided input
    """
    user_prompt = """
    Expected Output Format for Generated Summary:

  **Overview**
  <empty line>
  <A brief introduction to the codebase and its main purpose; in paragraph format only, not in points.
  This paragraph should provide a concise yet comprehensive overview of the codebase, its primary functionality, solution provided by the project and its intended use case.
  Aim for 3-5 sentences that capture the essence of the project.>
  <empty line>
  **Highlighted Features**
  <empty line>
  <
  List and briefly explain the key features that are significant components of the codebase and would serve as selling points.
  These features should be presented as follows:
  1. Use numbered points for each feature.
  2. Provide a brief explanation for each feature in 1-2 sentences, highlighting its importance and benefit to the end user.
  3. Focus on features that are central to the codebase's functionality and most important to the end user.
  4. Dont include generic features like "Modular Architecture" or "Code Reusability", these are not features but design principles.
  5. Do not include sub-points under any feature.
  6. Prioritize User Defined Features (if provided) at the beginning of the list.
  7. If User Defined Features are given, list them first before including any features identified through your analysis.
  8. Aim to provide upto of 1 to 5 key features, after each feature add an empty line for formatting purposes.
  9. Ensure that the features listed represent the core functionality and unique selling points based on the folder wise summary.
  10. Use clear, concise language that emphasizes the value proposition of each feature.
  11. Also under each feature, mention which file/folder was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
  12. Do not add features into Highlighted Features if they dont have value for buisness stakeholder about the application. Also do not repeat adding similar feature in this section.

  Output Structure:
  1. ***<Feature 1 Title>***: <Description of the feature in one to two sentences.\n
  2. ***<Feature 2 Title>***: <Description of the feature in one to two sentences.>\n
  >
  <empty line>
  **Key Benefits**
  <empty line>
  <Summarize the key benefits of the codebase in one to two sentences.
  This summary should encapsulate the overall value proposition of the codebase and its potential impact on users or the organization.>
  <empty line>
  <Highlight the most significant key benefits the codebase has to offer in bulleted points. The format should be:
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  Aim for 3-5 bullet points that capture the most compelling advantages of using this codebase, after each point add an empty line for formatting purposes.
  Each benefit should be distinct and provide a clear value proposition.>

  <Final Output Format>
  Output Format - Adhering to this format is crucial, the output should be in parsable JSON format:
  ```json
  {{
    "data": "<generated_summary in string format adhering to the Expected Output Format for Generated Summary>",
    "confidence_score": 90,
    "traceback": {{
      "Feature 1 Title": "Since it mentions about <exact phrase from the folder wise summary>, the 'Feature 1 Title' is included, as the "phrase" is an evidence that this feature is part of the folder wise summary.",
      "Feature 2 Title": "Since it mentions about <exact phrase from the folder wise summary>, the 'Feature 2 Title' is included, as the "phrase" is an evidence that this feature is part of the folder wise summary.",
      ...
    }}
  }}
  ```
  </Final Output Format>
  Note: If the traceback includes phrases that are not present in the folder wise summary then you would be penalized 10000 points.
  The output should be having data, confidence score, and traceback keys, and the entire content inside "```json" and "```" should be parsable by json.
  The "data" key should contain the generated summary and it should be in string format only, allowing the parsing of the entire json.
  If there are any inverted commas inside the generated summary, then escape them with a backslash.
  Do not change or skip the headings of each section in the generated json. The generated summary must have "Overview", "Highlighted Features", "Key Benefits" as section titles. Follow the above provided guidelines."""
    user_prompt += f"""Use the below folder wise summary to generate the summary in the above format: {combined_summary}""" + "User Defined Features : " + str(user_mvf)
    return system_prompt, user_prompt

def db_executive_summary_generation(combined_summary, user_mvf): 
    system_prompt = """
    Role:
    You are an expert Database Architect tasked with understanding the contents of all tables and schema of the database. 
    You shall Articulate a proper executive summary that clearly captures all the main & high-level features of this database.
    The core use-case that this database is intended for, and the prioritized list of the most valuable features, solely based on the provided Table-Level summaries. 
    Do not hallucinate. Do NOT create the most valuable features and its description on pure assumptions. This needs to be based on facts, with proper backing.

    Task:
    1. Analyze provided Table wise summaries.
    2. Understand component interactions and functions.
    3. Prioritize the User Defined Features (if provided) in the summary.
    4. Identify and prioritize the most valuable features based on their importance to the core use-case the Database is solving.
    5. Create a comprehensive executive summary.

    Steps:
    1. Review Table wise summary.
    2. Analyze Table wise summary:
      - Identify all tables. 
      - Take into consideration the foreign keys, primary keys, is-a, has-a, and many-to-many relationships.
      - Deeply understand the intended-use-case of each table.
      - Note data operations, design patterns, and architectural decisions
    3. Create summary:
      - Describe the specific problem the Database is solving, based on Table wise summary
      - Explain high-level interactions and dependencies
      - Outline data workflow
    4. Identify and prioritize main features:
      - Determine which feature(s) address the core problem of the Database, based on SQL implementation and Table wise summary
      - Rank features based on their importance and relevance to solving the main problem, as evidenced in the Database
      - The feature should be major components of the Database and not minor functions like Many-to-Many Relationships, or "Foreign Keys". 
        These are implementation concepts. Not core features.

    Focus Areas:
    - Precised feature prioritization and importance
    - High-level functionality of this Database
    - Clear, concise technical language with Database-specific Language
    - Objective description
    - Capture entire data workflow

    Guidelines:
    - Only use the Table wise summary provided
    - Use precise Database-relevant technical terms
    - Include user-defined features if provided and evidenced in the Table wise summary
    - Prioritize features based on their importance to the core problem, as shown in the Table wise summary

    Feature Identification and Prioritization:
    - Carefully analyze the Table wise summary to identify features actually present in the Table wise summary
    - Do not assume or infer features that are not explicitly mentioned in the Table wise summary
    - Identify the top feature that solves the majority of the problem based on Database and SQL evidence
    - Rank subsequent features in descending order of importance, ensuring they are present in the Table wise summary
    - Ensure the feature list reflects the Database's focus and structure
    - Only include features that have substantial implementation in the Database that is evident from Table wise summary

    Output Format - Adhering to this format is crucial
    ```json
    {
    "data": "generated_summary in string format adhering to the Expected Output Format for Generated Summary",
    "confidence_score": 90,
    "traceback": {
    "Feature 1 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 1 Title' is included, as the 'phrase' is an evidence that this feature is part of the Database.",
    "Feature 2 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 2 Title' is included, as the 'phrase' is an evidence that this feature is part of the Database.",
    ...
    }
    }
    ```

    Requirements:
    - Replace \n with \\n in JSON
    - Limit upto 5 main features (max 2 sub-features each) or 7500 tokens
    - If due to any reason such as Database being small, you are unable to provide 5 features, then provide as many high-level features as possible between the range of 1 to 5.
    - Don't assume features or include minor features due to inability to provide 5 features, lesser number of features is acceptable.
    - Use specified JSON format only
    - Start with "```json" and end with "```"
    - Ensure the top feature in the prioritized list addresses the core problem and is present in the Table wise summary
    - Rank features in descending order of importance to the main problem, based on actual Database and SQL implementation
    - Do NOT include features that are NOT evidenced in the provided Table wise summary
    - Evaluate the Table wise summary objectively, considering all conclusions on the actual Database and SQL provided
    - Do NOT make any assumptions about organizational goals or intentions beyond what is explicitly shown in the Database and SQL
    - Focus solely on the technical aspects and implemented functionality, avoiding speculation about business objectives or future plans
    - Both the keys data, confidence score, and traceback should be present in the output JSON
    - The generated summary should be in string format only and be contained inside the "data" key
    - The "traceback" key should contain a dictionary with feature names as keys and justifications for including these features based on exact phrases from the input
    - Do not include any feature that could potentially be part of the Table wise summary without explicit evidence
    - Every feature mentioned must be driven by clear evidence from the provided input.
    - Strictly use an assertive and objective tone in your response. 
    - Do not be unsure about anything.
    - Do not include the "Folder Name" in your response. Ignore "dbanalysis" folder. Provide Executive Summary of the Database-ONLY.
    """

    user_prompt = """
  Expected Output Format for Generated Summary:

  **Overview**
  <empty line>
  <A brief introduction to the Database and its main purpose; in paragraph format only, not in points.
  This paragraph should provide a concise yet comprehensive overview of the Database, its primary functionality, and its intended use case.
  Aim for 3-5 sentences that capture the essence of the Database.>
  <empty line>
  **Highlighted Features**
  <empty line>
  <
  List and briefly explain the key features that are significant components of the Database and would serve as selling points.
  These features should be presented as follows:
  1. Use numbered points for each feature.
  2. Provide a brief explanation for each feature in 1-2 sentences, highlighting its importance and benefit to the END USER.
  3. Focus on features that are central to the Database's functionality and most important to the END USER.
  4. Dont include generic features like  Many-to-Many Relationships, or "Foreign Keys", these are not features but Design Principles.
  5. Do not include sub-points under any feature.
  6. Prioritize User Defined Features (if provided) at the beginning of the list.
  7. If User Defined Features are given, list them first before including any features identified through your analysis.
  8. Aim to provide upto of 1 to 5 key features, after each feature add an empty line for formatting purposes.
  9. Ensure that the features listed represent the core functionality and unique selling points based on the Table wise summary.
  10. Use clear, concise language that emphasizes the value proposition of each feature.
  11. Also under each feature, mention which file/Table was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
  12. Do not add features into Highlighted Features if they dont have value for buisness stakeholder about the application. Also do not repeat adding similar feature in this section.

  Output Structure:
  1. ***<Feature 1 Title>***: <Description of the feature in one to two sentences.\n
  2. ***<Feature 2 Title>***: <Description of the feature in one to two sentences.>\n
  >
  <empty line>
  **Key Benefits**
  <empty line>
  <Summarize the key benefits of the Database in one to two sentences.
  This summary should encapsulate the overall value proposition of the Database and its potential impact on users or the organization.>
  <empty line>
  <Highlight the most significant key benefits the Database has to offer in bulleted points. The format should be:
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  Aim for 3-5 bullet points that capture the most compelling advantages of using this Database, after each point add an empty line for formatting purposes.
  Each benefit should be distinct and provide a clear value proposition.>

  <Final Output Format>
  Output Format - Adhering to this format is crucial, the output should be in parsable JSON format:
  ```json
  {{
    "data": "<generated_summary in string format adhering to the Expected Output Format for Generated Summary>",
    "confidence_score": 90,
    "traceback": {{
      "Feature 1 Title": "Since it mentions about <exact phrase from the Table wise summary>, the 'Feature 1 Title' is included, as the "phrase" is an evidence that this feature is part of the Table wise summary.",
      "Feature 2 Title": "Since it mentions about <exact phrase from the Table wise summary>, the 'Feature 2 Title' is included, as the "phrase" is an evidence that this feature is part of the Table wise summary.",
      ...
    }}
  }}
  ```
  </Final Output Format>
  Note: If the traceback includes phrases that are not present in the Table wise summary then you would be penalized 10000 points.
  The output should be having data, confidence score, and traceback keys, and the entire content inside "```json" and "```" should be parsable by json.
  The "data" key should contain the generated summary and it should be in string format only, allowing the parsing of the entire json.
  If there are any inverted commas inside the generated summary, then escape them with a backslash.
  Do not change or skip the headings of each section in the generated json. The generated summary must have "Overview", "Highlighted Features", "Key Benefits" as section titles. Follow the above provided guidelines.
    """

    user_prompt += f"""Use the below Table wise summary to generate the summary in the above format: {combined_summary}""" + "User Defined Features : " + str(user_mvf)

    return system_prompt, user_prompt


def architecture_diagram_generation(services_data, icons_metadata):
    user_prompt = f"""
    <Input>
    $services_data = {services_data}
    $icons_metadata
    </Input>

    <Role>
    You are an expert at understanding large projects based on their executive summary and the services being used in them. Create a JSON structure for a ReactFlow diagram based on the given service class JSON.
    </Role>

    <Output Structure>
    1. Create a JSON object with a "nodes" and "edges" array.
    2. Create nodes for each external and third-party service.
    3. "nodes": An array containing all node objects.
      - "id": A unique string identifier for the node.
      - "data":   
        - "label": The name of the node.
        - "description": Description of the service.
        - "associated_files": Associated file and used in files in the service node, defaulting to "No File Available" if not present.
        - "group": The logical group name (e.g., 'Backend', 'Frontend', 'Database',etc..).
        - "subgroup": The specific subgroup within the group (e.g., Frameworks, NoSQL Databases, State Management, etc.).
        - "service": The appropriate filename of the icon based on the $icons_metadata.
      - "position" : The x and y coordinates of the node.
      - "type" : "customNode" This should be fixed.
    4. "edges" : An array having id, source, target, label, and type should be customEdge always.
    4. Ensure all services and files from the input JSON are included.
    5. The output should be in the form of a dictionary containing a "nodes" and "edges" array.
    6. Present only the code inside delimiters "```reactflow [reactflow CODE]```" without any additional explanation.
    """

    system_prompt:str = """
    <Task>
      You are tasked with creating a JSON structure for a ReactFlow diagram based on the given executive summary and the service_class_json. The executive summary contains an overview of the entire project. This JSON includes information about external services and third-party services, along with their associated files. Your output should represent this information as a network of nodes and edges.
    </Task>
    
    <Icons Context>
      $icons_metadata = """ + str(icons_metadata) + """
    </Icons Context>

    <Instructions>
      You are a solution expert, specializing in problem and solution flows. You will be given the solution overview for a project, and your task is to create an interconnected single component of graph which is detailed, and intuitive and self explanatory for:

      Follow these guidelines:
      1. Create nodes for each unique service (both external and third-party).
      2. Do not create any group nodes.
      4. In the data key for each service node, include two additional fields called group and subgroup. The group field should contain the logical group name (e.g., Frontend, Backend, Databases, etc..), and the subgroup field should provide more specific categorization (e.g., Frameworks, NoSQL Databases, etc..). For example, for a service node representing React, the group would be Frontend and the subgroup would be Frameworks.
      5. For each node, check which icon will be the most suitable from the $icons_metadata in the <Icons Context>
      6. Ensure all information from the input is represented in the output.
      7. The position coordinates must be proper for all the nodes.
    </Instructions>

    <Rules>
      **Ensure all nodes in the generated graph are interconnected such that every node has at least one edge, forming a single connected component without any isolated or disjoint sections. (High Priority Requirement)**
      Important Rules to be followed:
      1. Give detailed technical architecture flow and the JSON object following the below output format.
      2. Make sure that the flow and order of new solution approach is explained well in the graph with appropriate edges. Use as many edges you want to describe the data and user flow properly.
      3. The whole user and data flow should be clear.
      4. Do not add unnecessary nodes and edges. Do not create duplicate nodes that perform same task.
      5. Make the Node descriptions detailed, breaking tasks into multiple sub-tasks if needed.
      6. Ensure your edges show the actual flow, and not just connections of what's related. The connections are meant to show the logical flow, and not the relatedness/similarity.
      7. The group name is meant to classify clusters of nodes within each graph. For instance, if we have multiple nodes in features, they would all have "feature" as group. In Architecture Flow, the "Group" should show the layer each node is in, for instance "Backend Layer", "Database Layer" etc.
      9. for a hierarchy of nodes A -> B -> C; ensure that there is not a connection between A -> C.
    </Rules>
    
    <output_format>
    The output should be in between the delimeters ```reactflow and ```. Only provide the json output. Don't give unnecesary explanation.
    ```reactflow
    {
      "nodes": [
        { 
          "id": "unique_node_identifier_string",
          "data" : {
            "label": "name_of_the_service",
            "description": "description of the service",
            "associated_files": ["file_path_1", "file_path_2", "file_path_3", etc.],  // (default: ["No File Available"] if not present)
            "group": "name_of_group",  // Add the logical group name (e.g., "Frontend", "Backend", etc..)
            "subgroup": "name_of_subgroup",  // Add a more specific subgroup name (e.g., "Frameworks", "NoSQL Databases", etc..)
            "service": "filename" //taken from the $icons_metadata,
          }
          "position":{ "x": "Xcoordinate", "y": "Ycoordinate" },
          "type" : "customNode" //this is hardcoded and will be constant
        }
      ],
      "edges": [
        {
          "id": "unique_egde_identifier_string",
          "source": "label A",
          "target": "label B",
          "label": "Showcase what comes from the source node, to the target node. Be concise and specific with labels, such as 'Ingested Data', 'Converted Text', 'User Query' etc. Use at max 5 words",
          "type" : "customEdge" //this is hardcoded and will be constant
        }
      ]
    }```
    </output_format>
    """
    return system_prompt, user_prompt
  

def erd_generation(services_data, icons_metadata):
  tables_metadata = []
  for entry in services_data:
      table_name = entry["table_name"]
      ddl = entry["ddl"]
      columns, primary_keys, foreign_keys = parse_ddl(ddl)
      tables_metadata.append({
          "table_name": table_name,
          "columns": columns,
          "primary_keys": primary_keys,
          "foreign_keys": foreign_keys
      })

  dot = generate_combined_graph(tables_metadata)

  system_prompt:str = """
    You are tasked with creating a JSON structure for a ReactFlow diagram based on the given database ER diagram and schema JSON. This JSON includes information about database columns and their relationships.Your output should represent this information as a network of nodes and edges.
    </Task>
    
    <Icons Context>
      $icons_metadata = """ + str(icons_metadata) + """
    </Icons Context>

    <Instructions>
      You are a solution expert, specializing in problem and solution flows. You will be given the database schema information of a database, and your task is to create an interconnected single component of graph which is detailed, and intuitive and self explanatory for:

      Follow these guidelines:
      1. Create nodes for each unique service (both external and third-party).
      2. Do not create any group nodes.
      4. In the data key for each service node, include two additional fields called group and subgroup. The group field should contain the logical group name (e.g.,Databases, etc..), and the subgroup field should provide more specific categorization (e.g., 'Transactional Tables', 'Reference Tables' etc..). For example, for a service node representing daily transactions, the group would be Database and the subgroup would be Transactional Tables.
      5. For each node, check which icon will be the most suitable from the $icons_metadata in the <Icons Context>
      6. Ensure all information from the input is represented in the output.
      7. The position coordinates must be proper for all the nodes.
    </Instructions>

    <Rules>
      Important Rules to be followed:
      1. Give detailed technical architecture flow and the JSON object following the below output format.
      2. Make sure that the flow and order of new solution approach is explained well in the graph with appropriate edges. Use as many edges you want to describe the data and user flow properly.
      3. The whole user and data flow should be clear.
      4. Do not add unnecessary nodes and edges. Do not create duplicate nodes that perform same task.
      5. Make the Node descriptions detailed, breaking tasks into multiple sub-tasks if needed.
      6. Ensure your edges show the actual flow, and not just connections of what's related. The connections are meant to show the logical flow, and not the relatedness/similarity.
      7. The group name is meant to classify clusters of nodes within each graph. For instance, if we have multiple nodes in features, they would all have "feature" as group. In Architecture Flow, the "Group" should show the layer each node is in, for instance "Database Layer" etc.
      9. for a hierarchy of nodes A -> B -> C; ensure that there is not a connection between A -> C.
    </Rules>
    
    <output_format>
    The output should be in between the delimeters ```reactflow and ```. Only provide the json output. Don't give unnecesary explanation.
    ```reactflow
    {
      "nodes": [
        { 
          "id": "unique_node_identifier_string",
          "data" : {
            "label": "name_of_the_table",
            "description": "description of the table",
  	    "columns": ["order_id [PK]", "product_sku [PK]", "quantity", "unit_price"]
            "group": "name_of_group",  // Add the logical group name (e.g., "Database", etc..)
            "subgroup": "name_of_subgroup",  // Add a more specific subgroup name (e.g., 'Transactional Tables', 'Reference Tables', etc..)
            "service": "filename" //taken from the $icons_metadata,
          }
          "position":{ "x": "Xcoordinate", "y": "Ycoordinate" },
          "type" : "customNode" //this is hardcoded and will be constant
        }
      ],
      "edges": [
        {
          "id": "unique_egde_identifier_string",
          "source": "label A",
          "target": "label B",
          "label": "Showcase what comes from the source node, to the target node. Be concise and specific with labels, such as 'Ingested Data', 'Converted Text', 'User Query' etc. Use at max 5 words",
          "type" : "customEdge" //this is hardcoded and will be constant
        }
      ]
    }```
    </output_format>
    """
    
  user_prompt:str = f"""
    <Input>
    $database_tables = {dot}
    $icons_metadata
    </Input>

    <Role>
    You are an expert at understanding database architecture based on ER diagrams and relational structures. Create a JSON structure for a ReactFlow diagram based on the given database schema.
    </Role>
    <Output Structure>
      1. Create a JSON object with a "nodes" and "edges" array.
      2. Create nodes for each table in the schema.
      3. "nodes": An array containing all node objects.
      - "id": A unique string identifier for the node.
      - "data":  
        - "label": The name of the table.
        - "description": A brief summary of the table's role or content.
        - "columns": List of column names (mark primary keys with [PK], foreign keys with [FK]).
        - "group": The logical group name (e.g., 'Database').
        - "subgroup": The specific subgroup within the group (e.g., 'Transactional Tables', 'Reference Tables').
        - "service": The appropriate filename of the icon based on the $icons_metadata.
      - "position" : The x and y coordinates of the node.
      - "type" : "customNode" This should be fixed.
      4. "edges" : An array having id, source, target, label, and type should be customEdge always.
      5. The label of the edge should describe the relationship, like "order_id â†’ order_id". 
      6. The output should be in the form of a dictionary containing a "nodes" and "edges" array.
      7. Present only the code inside delimiters "```reactflow [reactflow CODE]```" without any additional explanation.
    """
    
  return system_prompt, user_prompt
    

def feature_summary_generation(formatted_data, user_mvf, executive_summary):
    # if input_type is None:
    #     formatted_data = file_summary_list
    # elif input_type == "batch_summary":
    #     formatted_data = format_batchwise_summary_metadata_for_services(file_summary_list)
    # else:
    #     formatted_data = format_file_summaries(file_summary_list)

    user_prompt = """
    Role: You are an AI code analyst specializing in creating concise, feature-level summaries of codebases.

    Objective: Provide a comprehensive yet concise feature-level summary of a given codebase, highlighting key components, functionality, and the project's overall workflow.

    Input: You will receive information about a codebase, which may include an executive summary or other project details.

    Steps:
    1. Analyze the provided codebase information.
    2. Identify the main features (maximum 5) of the project from the executive summary (if provided in same order)
    3. Create a summary following the specified format, including:
        a. An overview of the project
        b. A list of key features with brief descriptions
        c. A closure statement
    4. Self-evaluate the generated summary and assign a confidence score.
    5. Format the output as specified in the instructions.

    Output Format:
    ```json
    {
        "data": "generated_summary in string format adhering to the Detailed Instructions for Output Format",
        "confidence_score": 90
    }
    ```

    Detailed Instructions for Output Format:

    **Overview**
    <empty line>
    < 
        Summarize all features in 2-3 sentences, introducing the project and its purpose.
        Provide a 2-3 sentence summary of key benefits, highlighting core architecture and value proposition.
    >
    <empty line>
    **Key Features**
    <empty line>
    <   
        List a maximum of 5 main features.
        For each feature, provide up to 2 sub-points describing its functionality.
        Ensure clear explanation of how features interact and contribute to the project's goals.
        1. ***<Key Feature Title>*** : 
        * <Sub point 1 description>
        * <Sub point 2 description>
        <empty line>
    >
    <empty line>
    < 
        Summarize the overall impact and value proposition of the project in one sentence as a conclusion statement.
    >
    <empty line>
    
    -> Self-Evaluation:
        - Score the summary out of 100 based on clarity, precision, detail, knowledge, accuracy, technical correctness, and understanding of the data.

    -> Formatting Requirements:
        - Replace all newline characters (\n) with \\n in the JSON output.
        - Ensure the complete JSON is less than 7500 tokens.
        - Start the output with "```json" and end with "```".
        - If an executive summary is provided, use only the highlighted features from it.

    Example Output Structure:
    ```json
    {
        "data": "**Overview**\\n\\n[Project overview]\\n\\n[Benefits summary]\\n\\n**Key Features**\\n\\n1. *Feature 1*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n2. *Feature 2*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n[...continue for up to 5 features...]\\n\\n[Closure statement]",
        "confidence_score": 90
    }
    ```

    Remember: Adhere strictly to the output format and instructions to maintain consistency and accuracy in your summary.
    """

    user_prompt += "User Defined Features : " + str(user_mvf)

    system_prompt = f"""
        <role>
        You are an assistant to a Senior Software Engineer. You are very capable in reading and understanding huge codebases.
        There is no edge-case, no mistake, no functionality no matter how small goes unnoticed by you.
        You will be given a large codebase and be asked queries regarding it.
        </role>

        <Task>
        You will be given relevant files from a production codebase. The Senior Engineer will consult you to clear his doubts and ask for critical code-level and functionality level analysis of the same.
        <Important>
        1. You will be clear. Feel free to be descriptive but Avoid Jargon
        2. You shall perform critical analysis on the code before responding.
        3. Note that the codebase will be quite complex and have dependencies everywhere, be mindful of them all.
        4. Enclose code in (triple backticks)``` code ```
        </Important>
        </Task>

        Files from Codebase goes here :
        <Repo Structure>
        {formatted_data}
        </Repo Structure>
    """

    start_index = executive_summary.find("Highlighted Features")
    end_index = executive_summary.find("Key Benefits")

    if start_index != -1 and end_index != -1:
        executive_summary = executive_summary[start_index:end_index].strip()

    user_prompt += "Executive Summary : " + str(executive_summary)

    return system_prompt, user_prompt

def feature_summary_generation_db(formatted_data, user_mvf, executive_summary):
    # if input_type is None:
    #     formatted_data = file_summary_list
    # elif input_type == "batch_summary":
    #     formatted_data = format_batchwise_summary_metadata_for_services(file_summary_list)
    # else:
    #     formatted_data = format_file_summaries(file_summary_list)

    user_prompt = """
    Role: You are an AI Database Analyst specializing in creating concise, feature-level summaries of complex database schemas and architectures.

    Objective: Provide a comprehensive yet concise feature-level summary of a given database schema information, highlighting key components, entities, relationships, and the overall data architecture workflow.

    Input: You will receive information about a database design, which may include an executive summary or other schema-level details.

    Steps:
    1. Analyze the provided database schema information.
    2. Identify the main features (maximum 5) of the database from the executive summary (if provided in same order)
    3. Create a summary following the specified format, including:
        a. An overview of the database
        b. A list of key features with brief descriptions
        c. A closure statement
    4. Self-evaluate the generated summary and assign a confidence score.
    5. Format the output as specified in the instructions.

    Output Format:
    ```json
    {
        "data": "generated_summary in string format adhering to the Detailed Instructions for Output Format",
        "confidence_score": 90
    }
    ```

    Detailed Instructions for Output Format:

    **Overview**
    <empty line>
    < 
        Summarize all features in 2-3 sentences, introducing the database and its purpose.
        Provide a 2-3 sentence summary of key benefits, highlighting schema structure, normalization or denormalization logic, and value proposition in handling data.
    >
    <empty line>
    **Key Features**
    <empty line>
    <   
        List a maximum of 5 main features.
        For each feature, provide up to 2 sub-points describing its data handling, relationships, or optimization logic.
        Ensure clear explanation of how features contribute to performance, consistency, and data integrity.
        1. ***<Key Feature Title>*** : 
        * <Sub point 1 description>
        * <Sub point 2 description>
        <empty line>
    >
    <empty line>
    < 
        Summarize the overall impact and value proposition of the database in one sentence as a conclusion statement.
    >
    <empty line>
    
    -> Self-Evaluation:
        - Score the summary out of 100 based on clarity, precision, detail, knowledge, accuracy, technical correctness, and understanding of the schema information.

    -> Formatting Requirements:
        - Replace all newline characters (\n) with \\n in the JSON output.
        - Ensure the complete JSON is less than 7500 tokens.
        - Start the output with "```json" and end with "```".
        - If an executive summary is provided, use only the highlighted features from it.

    Example Output Structure:
    ```json
    {
        "data": "**Overview**\\n\\n[Database overview]\\n\\n[Benefits summary]\\n\\n**Key Features**\\n\\n1. *Feature 1*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n2. *Feature 2*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n[...continue for up to 5 features...]\\n\\n[Closure statement]",
        "confidence_score": 90
    }
    ```

    Remember: Adhere strictly to the output format and instructions to maintain consistency and accuracy in your summary.
    """

    user_prompt += "User Defined Features : " + str(user_mvf)

    system_prompt = f"""
        <role>
        You are an assistant to a Senior Data Architect. You are very capable in reading, analyzing, and understanding complex database schemas and data models.
        No entity, constraint, relationship, or optimization logic goes unnoticed by you.
        You will be given a comprehensive database structure or schema information and will be asked to analyze, explain, and summarize it at a structural and functional level.
        </role>

        <Task>
        You will be given relevant database schema files or DDL definitions. The Senior Data Architect will consult you to clear doubts and ask for critical schema-level and data model-level analysis.
        <Important>
        1. You will be clear. Feel free to be descriptive but Avoid Jargon
        2. Perform a critical and deep analysis of the schema and the information given before responding.
        3. The schema will often involve multiple tables, foreign keys, views, procedures, and indexing strategies â€” be mindful of their dependencies and relationships.
        4. Enclose code or schema in (triple backticks)``` code ```
        </Important>
        </Task>

        Files from Database schema goes here :
        <Database Structure>
        {formatted_data}
        </Database Structure>
    """

    start_index = executive_summary.find("Highlighted Features")
    end_index = executive_summary.find("Key Benefits")

    if start_index != -1 and end_index != -1:
        executive_summary = executive_summary[start_index:end_index].strip()

    user_prompt += "Executive Summary : " + str(executive_summary)

    return system_prompt, user_prompt


#FEATURE HIERARCHY:
generate_features_system_prompt = """
  <Role>
    You are a Software Architect with expertise in analyzing large summaries from code files of an application. 
    You can comprehend summaries from code files that are complex, production-grade and are written in various programming languages to generate most important features, their description and the subfeatures with their description belonging to the most important features along with the other relevant information requested below.
    
    You will follow 2 Events before responding : 
    1. Generation of Feature Hierarchy as given in "Output_Format".
    2. Critical Evaluation of Every Confidence Score.  
  </Role> 

    <Task 1>
    You are provided with multiple relative file paths and file-wise code summaries from a application codebase.
    1. Analyze the file summaries carefully, leveraging your expertise to deduce the frameworks, functionality, and features.
    2. Perform a critical assessment of the code's functionality and interdependencies before responding.
    3. The codebase is complex and likely contains dependencies across various modules. Be mindful of these.
    4. Analyse every file summary and assign the features and sub-features based on the information provided.
    5. Respond strictly in the structured JSON format provided below.
    6. In each sub-feature's 'file_path' array:
        - Set 'critical: true' ONLY for files that are CORE & NON-REPLACEABLE to the sub-feature's main functionality.
        - Set 'critical: false' for ALL supporting, secondary, or replaceable files  
        - Each sub-feature should have both true and false entries.
        - If unsure, default to false (be EXTREMELY selective with 'true')
        - Make sure each sub-feature atleast have one file as true.

    Explanation of the Output terms:
    Feature - Features are most valuable and high level features extracted from the list of summaries that are provided to you. 
    Feature description - Description of the features explaining the high level value and impact that it creates for the project. Define the Feature. The description should be crisp, precise, well formatted and must be between 2-3 lines.
    Subfeature - Subfeatures are micro most valuable features that are extracted from the list of summaries and belong to the Most related and similar Features.
    Subfeature description - Description of the subfeatures explaining the specific value, technical and non-technical functionalites that it provided to the project. Define the subfeature and also explain how its related to the feature. The description should be crisp, precise, well formatted and must be between 2-3 lines.
    
    Points to Remember:
    1. Do not extract any feature or subfeature where there are no reference/citations from the application summaries.
    2. The description must be precise, valuable, well-formatted and must be between 2-3 lines.
    3. The Feature titles should be precise, specific, self explanaible, independent and not have similar feature titles. The Feature titles should not be highly generalized.
    4. The SubFeatures titles should be precise, self explanaible and not have similar subfeature titles. The SubFeature titles should not be highly generalized.
    5. SubFeatures should not be very low level that it explains code functions, code process like 'Json handling', 'Reading csv', readME etc.
    6. If similar subfeatures are present, then group them under one common Feature itself. Do not create multuple Features for similar subfeatures.
    6. If Unit testing related summaries are found, then create that as another Feature named 'Unit Testing' and assign the specific testing subfeatures under this feature.
    </Task 1>

  <Task 2>
  You shall now Assign and Justify Confidence Scores for each feature.

  <Critical Evaluation of Confidence Scores> 

  <Evaluation MODE>
  - You will now Forget everything that was done beforehand and act as an unbiased judge.
  - $Project-Summaries-&-Paths (INPUT).
  </Evaluation MODE>
  <Important>
  Critically analyze every "Feature" and "SubFeature" based on the following metrics. 
  You shall generate a confidence score between 0-100 for each of the following :
  1. Is the "Feature" & "SubFeature" name accurate to its functionality ? (Accuracy)
  2. Does the "Feature" & "SubFeature" include files with an unrelated function ? (Feature Dilution Rate)
  3. Important : Does this "Feature" & "SubFeature" make sense given the Overall Purpose of the Application ? (Consistency)
  4. Are all the files in "Feature" & "SubFeature" included ? (Completeness)

  <Strict>
  1. You will now generate a list of 4 confidence scores between 0-100 for above criteria under "confidence_score" key.
  2. Based on above criteria, you shall provide a VERY BRIEF logical explanation (10-20 words) for Confidence Score under "confidence_score_justification" key.
  3. Make sure to mention the entire filepath without omitting the prefix.
  4. Make sure all the filepaths are present.
  <Important> STRICTLY Don't Comment on Missing Files. Don't Overestimate. Don't Underestimate.</Important> 
  </Strict>

  </Important>

  </Critical Evaluation of Confidence Scores> 
  </Step 2>


      <Output_Format>
    Return a response in JSON format. Do not include any extra information or explanations. Strictly DON'T deviate from mentioned KEYS.
    Example:
```json
[
  {
    "name": "User Authentication and Management",
    "feature_description": "Comprehensive user account system with secure login, registration, profile management, and role-based access control.",
    "feature_description_confidence_score": [95, 70, 100, 70],
    "sub_features": [
      {
        "name": "User Registration",
        "description": "Allows new users to create accounts by providing necessary information such as username, email, and password. Implements email verification, password strength checks, and duplicate account prevention. Stores user data securely in the database with password hashing.",
        "file_path": [
          {
            "module_name": "RegistrationController",
            "path": "Controllers/Account/RegistrationController.cs",
            "critical": true
          },
          {
            "module_name": "RegisterView",
            "path": "Views/Account/Register.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [75, 80, 85, 65],
        "sub_feature_confidence_score_justification": "No feature dilution, might have missed some file."
      },
      {
        "name": "User Login",
        "description": "Authenticates users using their credentials, creates and manages user sessions, and implements security measures such as login attempt limiting and two-factor authentication (2FA). Provides password reset functionality for forgotten passwords.",
        "file_path": [
          {
            "module_name": "LoginController",
            "path": "Controllers/Account/LoginController.cs",
            "critical": true
          },
          {
            "module_name": "LoginView",
            "path": "Views/Account/Login.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [80, 100, 80, 75],
        "sub_feature_confidence_score_justification": "High chance of missing files."
      }
    ],
    "feature_confidence_score_justification": "No feature dilution, duplication or missing files. Accurate Naming."
  },
  {
    "name": "Product Catalog Management",
    "feature_description": "Comprehensive system for managing product listings, categories, and inventory across the e-commerce platform.",
    "feature_description_confidence_score": [95, 65, 70, 80],
    "sub_features": [
      {
        "name": "Product CRUD Operations",
        "description": "Enables administrators to create, read, update, and delete product listings. Includes functionality for managing product details such as name, description, price, images, and inventory levels. Implements validation to ensure data integrity and consistency across the product catalog.",
        "file_path": [
          {
            "module_name": "ProductController",
            "path": "Controllers/ProductController.cs",
            "critical": true
          },
          {
            "module_name": "ProductView",
            "path": "Views/Product/Index.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [90, 85, 100, 70],
        "sub_feature_confidence_score_justification": "High confidence with no duplication or dilution."
      },
      {
        "name": "Category Management",
        "description": "Allows for the creation and management of product categories and subcategories. Implements a hierarchical structure for organizing products, enabling efficient navigation and filtering of the product catalog for both administrators and customers.",
        "file_path": [
          {
            "module_name": "CategoryController",
            "path": "Controllers/CategoryController.cs",
            "critical": true
          },
          {
            "module_name": "CategoryView",
            "path": "Views/Category/Index.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [85, 75, 90, 95],
        "sub_feature_confidence_score_justification": "High confidence without any duplication or dilution."
      }
    ],
    "feature_confidence_score_justification": "All files refer to single overall functionality. Might have missed some files."
  }
]
```
  </Output_Format>

"""

generate_features_user_message = """
<Strictly Remember>
1. As input you will be given a batch of `file_path` and `file_summary` from a production codebase. Keep it in mind that it could be a file from a very large repository with lot of inter-dependencies.
2. Understand all the file description first, then try to determine the feature, sub-features and their description. For **each file** it should have a feature or sub-features whenever the conditions are met.
3. The response should contain all the fields given in the example output format. The response should be strictly in json format.
4. The description of features/subfeatures must be in the length of 2-3 lines. The response should be structured and well-formatted.
5. Don't generate any additional explanation or description. Provide the structured response in json only.
</Strictly Remember>
  
<Input file wise summary>
{file_summary}
</Input file wise summary>
<Response>
"""

merge_features_in_hierarchy_user_prompt = """You are a software feature analyzer. Given a list of related features that have been clustered together, create a merged feature that encompasses all the functionality.

Features to merge:
{feature_list}

Generate a JSON response that includes:
1. A name for the merged feature representing accurate feature name. Do not mention its merged or unified or anything as such. The feature name should accurately represent a major funcationality of a repository.
2. A detailed description that covers all functionality
3. A confidence score (0-100) for the merge
4. A justification for the confidence score

Respond with a JSON object in the following format:
```json
{{
    "name": "Merged feature name",
    "description": "Comprehensive description",
    "confidence_score": 85,
    "confidence_justification": "Reason for the confidence score"
}}
```
Give only JSON and nothing else. Do not include any explanations or additional text outside the JSON block. Make sure to start with ```json and end with ``` only.
"""

mapping_names_for_merged_features_user_prompt = """  <Role>
    You are a smart AI cassistant with strong expertise in Software Engineering. You can understand complex, production-grade codebases written in various programming languages and summarize them effectively.
  </Role>
  <Task>
  You will be given a brief description of  features of a large codebase and your task is to generate a relevant feature name, brief description, and priority level.
  <Important>
   1. The feature name should be brief, relevant and should represent the entire description provided.
   2. Generate a relevant description which is basically a overall summary of the description provided.
   3. Assign a priority level (high, medium, low) based on the significance, importance and complexity of the feature to the overall system. 
  </important>
  </Task>
  <Example output>
  ```json
    {
        "name": <feature_name>, //string
        "feature_description": <feature_description>, //string
        "priority": <priority> //string (high, medium, or low)
    }
    ```
  </Example output>
  <Strictly Remember>
1. The feature name should be relevant and at the same time interpretable, easy to understand.
2. The feature description should represnt the entire description given for summarisation, it should be simple and easy to understant.
3. The priority should be one of: high, medium, or low.
4. The response should be strictly in json format specified above.
5. Strictly make sure Feature Description is not more than 200 words.
  </Strictly Remember>

<code summary>
The code summary is given below:
"""


reducing_sub_features_user_prompt = """
    You are a software feature consolidation expert. Your task is to merge similar sub-features into one comprehensive sub-feature.

    Here are the sub-features that need to be merged:
    {sub_features_list}

    For each sub-feature, we have:
    - Name: The sub-feature name
    - Description: The sub-feature description (if available)
    - Confidence Score: The confidence score (if available)

    Your output should be a JSON object containing:
    1. A unified sub-feature name that encompasses all the input sub-features
    2. A comprehensive description that covers all aspects of the input sub-features
    3. A confidence score (use the highest available from input sub-features)
    4. A justification for the confidence score

    Return the output in JSON format starting with ```json and ending with ```.

    Example output format:
    ```json
    {{
        "name": "Unified Sub-Feature Name",
        "description": "Comprehensive description covering all aspects",
        "sub_feature_confidence_score": 95,
        "sub_feature_confidence_score_justification": "Merged from similar sub-features with high semantic similarity"
    }}
    ```
    """


post_processing_feature_name_description_system_prompt="""
  <Role>
    You are a smart AI assistant with strong expertise in Software Engineering. You can understand complex, production-grade codebases written in various programming languages and summarize them effectively.
  </Role>
  <Task>
  You will be given a brief description of modules or features of a large codebase and your task is to generate a relevant feature name and brief description.
  <Important>
   1. The feature name should be brief, relevant and should represent the entire description provided.
   2. Generate a relevant description which is basically a overall summary of the description provided.
   3. Also generate a confidence score in a scale of 0 - 100.
  </important>
  </Task>
  <Example output>
  ```json
    {
        "name": <feature_name>,
        "feature_description_confidence_score": <score 0 - 100>,
        "feature_description": <feature_description>
    }```
  </Example output>"""

post_processing_feature_name_description_user_prompt = """<Strictly Remember>
1. The feature name should be relevant and at the same time interpretable, easy to understant.
2. The confidence score should represent the ability to summarise the description.
3. The feature description should represnt the entire description given for summarisation, it should be simple and easy to understant.
4. The response should be strictly in json format specified above.
</Strictly Remember>
<code summary>
The code summary is given below: \n
{feature_description}
</code_summary>
<response>
Your response in json goes here:
"""

merge_similar_features_system_prompt = """You are a solution architect. Your task is to carefully review each feature and its description, and combine them into a single high-level feature.

The final high-level features should represent what an end user would perceive, e.g., Messenger, Google Chat, Messaging, Reels, etc.

Based on the generated features provided, identify which features can be merged into a single high-level feature. 
Strictly output them in the following format:
{{ 
  <High-Level Feature Name 1>: [<Merged Feature 1>, <Merged Feature 2>, <Merged Feature 3>, ...],
  <High-Level Feature Name 2>: [<Merged Feature 1>, <Merged Feature 2>, <Merged Feature 3>, ...],
  ...
}}

INPUT:
Feature names and descriptions are provided in the format: 
[1. Feature name: <feature name> 
Feature description: <feature description>, 
2. ...]

{feature_texts}

MVFS:
{total_MVFs}

Points to remember:
1. While merging features and naming high-level features, always prefer names from the user-defined MVFs provided. All relevant features can be grouped under these high-level features.
2. If certain features do not fit under the user-defined MVFs, choose a better name than the existing one for the new high-level feature if necessary.
3. The names of the features being merged must remain exactly as provided in the INPUT section; do not modify them. Do not consider Feature description in Feature Names.
4. Follow the output structure strictly: high-level feature names as dictionary keys and merged features as values in list format.
5. If a feature is already a high-level feature, you do not need to forcibly merge it. If a feature seems to be function-level/low-level  features, merge them into a High-level feature.
6. Merge similar features into a single high-level feature based on their names and descriptions, when applicable. Each final high-level feature should be independent of the others.
7. Do not assign the same feature to multiple high-level features.
8. If user-defined MVFs are empty, skip point 1 and begin with point 2.
9. Do **not** include any Feature descriptions in the final output."""


merging_description_user_prompt = """You are a Solution Architect. Your task is to summarize the multiple feature descriptions provided into a brief, coherent summary of **no more than two sentences**.

  The summary must:
  - Accurately capture all key components from the provided descriptions.
  - Align clearly with the given high-level feature name.
  - Serve as the final description of the high-level feature.

  Only the final summarized description should be included in the output â€” no additional commentary or formatting.

  INPUT:
  Multiple descriptions: {merging_feature_description}

  High-Level Feature Name: {high_level_feature}
  """


micro_sub_feature_prompt = """You are an expert system analyst specializing in decomposing SubFeatures into granular, logically independent components. You support **two levels** of splitting:

1. **Horizontal splitting**: Split a subfeature into multiple *same-level subfeatures* when it encompasses multiple independently meaningful functionalities. The subfeatures created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.
2. **Vertical splitting**: Further break each of those subfeatures into *microsubfeatures* (if applicable), ensuring each micro-sub-features/micro-user-story describes a single goal or operation. The micro-sub-features/micro-user-story created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.

---

### ðŸ”§ TASK OVERVIEW

Given a Macro-Feature, Subfeature, its description, associated module files and its summary:

- Decide if the subfeature should be split horizontally into multiple same-level subfeatures.
- For each resulting subfeature (or original if not split), analyze whether it can be split vertically into **microsubfeatures** (fine-grained user stories).
- Provide the confidence scores for the subfeature that is split, whether horizontally or vertically.
- Provide the files that are related to the sub_features too, not just the micro_sub_features.
- Each leaf user-story must have files assigned to them, else you should not create/split these subfeatures.
- Provide description of generated subfeature/sub-user-stories in 2-4 lines but only valid information. Do not assume or hallucinate to generate description.
Apply this recursively: if horizontal splitting occurs, then attempt vertical splitting for each. But remember, not to create any duplicates in the process. 

---

### SPLITTING DECISIONS

#### Horizontal Splitting (Same-level Subfeatures):
Split if:
- The subfeature covers multiple high-level functionalities
- Each function could be planned, developed, and deployed independently
- Each component has a clear boundary and responsibility

#### Vertical Splitting (Microsubfeatures):
Split further if:
- A subfeature contains multiple independent operations or logical stages
- These operations can be implemented, tested, or tracked separately
- Each micro-subfeature represents one atomic, non-overlapping functionality

---

### DO NOT SPLIT IF:
- sub-user-stories are tightly coupled in the Subfeature and cannot function independently.
- Do not split subfeatures into sub-user-stories that are hardly single line of code and cannot be considered as a proper functionality, but just a config/parameter.
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across actions are too complex to isolate.
- There are no files that can be mapped to the generated user-story.
- Do not split if the user-story is barely a functionality. The split user-stories must have independent functionality that contributes to the subfeature and feature and if not, do not split.
- Don not split ReadMe & .md files into sub-user-stories.
- Do not split horizontall for granullar subfeatures as they are not user stories but mid level features.
---

### FILE MAPPING RULES:
- For each subfeature or microsubfeature, cite only directly relevant files.
- Use only the provided input data to match files â€” no guessing.
- Avoid duplication unless a file is clearly shared between components.

Each `file_path` entry must include:
```json
{
  "module_name": "<Name>",
  "path": "<Path>",
  "critical": <true/false>,
  "git_url": "<Git URL>"
}

OUTPUT FORMAT
If the subfeature should NOT be split:
Return: "None"

If the subfeature should be split, return a list of Parent User Stories with subfeatures inside.
If a subfeature itself can be further split into microsubfeatures, nest them under micro_sub_features like so:

[
  {
    "name": "Parent User Story Title 1",
    "description": "Full description of the original or updated user story and its purpose.",
    "file_path": [...],
    "sub_feature_confidence_score":"confidence score of the subfeature with respect to the Feature, as a percentage (e.g., 80)"
    "micro_sub_features": [
      {
        "name": "Sub-User Story Title 1",
        "description": "Standalone description of a single functionality.",
        "file_path": [...],
        "micro_sub_feature_confidence_score":"confidence score of the micro_sub_feature with respect to the sub_feature, as a percentage (e.g., 90)"
        }
          ...
        ]
      },
      ...
    ]
  }
]
Each layer must preserve independence, clarity, and singular focus of each story.

VALIDATION CHECKLIST
- Each title must express one functionality only (no imperative phrasing)
- description must avoid assumptions and describe the real function. It must be as detailled as possible.
- Each story must make sense independently and fit in the broader feature flow
- if there are multiple user-story under the subfeature, it needs to be in sequence of business logic.
- File mappings must be relevant and scoped accurately
- Do no miss/skip any values in the output json. The output structure must be maintained strictly.
- All subfeature and sub-user-story names and descriptions must be strictly in a declarative tone, not imperative.

* Use generic or speculative statements
"""


db_micro_sub_feature_prompt = """
<Role>
You are an expert Database analyst specializing in decomposing SubFeatures into granular, logically independent components. You support **two levels** of splitting:
You shall ALWAYS process features from a Database perspective ONLY. 
There can be more than one Table in the DB context provided to you.
</Role>

1. **Horizontal splitting**: Split a subfeature into multiple *same-level subfeatures* when it encompasses multiple independently meaningful functionalities. The subfeatures created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.
2. **Vertical splitting**: Further break each of those subfeatures into *microsubfeatures* (if applicable), ensuring each micro-sub-features/micro-user-story describes a single goal or operation. The micro-sub-features/micro-user-story created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.

<Strict Constraints> 
- You are dealing with Database Information. 
- No matter what, STRICTLY use Database-Specific Language ALWAYS. 
- Use words like Columns / Fields / Schema / DataTypes / Constraints / Foreign Keys / Primary Keys etc.
- Strictly Do not start descriptions with or start with "this micro-feature" / or "this sub-feature".
- You shall do this regardless of the input context and nature.
Remember : Every "FILE" given to you is information of a table. Therefore in your response, ALWAYS refer to "Table" instead of "File".

</Strict Constraints> 


### ðŸ”§ TASK OVERVIEW

Given a Macro-Feature, Subfeature, its description, associated module files and its summary:

- Decide if the subfeature should be split horizontally into multiple same-level subfeatures.
- For each resulting subfeature (or original if not split), analyze whether it can be split vertically into **microsubfeatures** (fine-grained user stories).
- Provide the confidence scores for the subfeature that is split, whether horizontally or vertically.
- Provide the files that are related to the sub_features too, not just the micro_sub_features.
- Each leaf user-story must have files assigned to them, else you should not create/split these subfeatures.
- Provide description of generated subfeature/sub-user-stories in 2-4 lines but only valid information. Do not assume or hallucinate to generate description.
Apply this recursively: if horizontal splitting occurs, then attempt vertical splitting for each. But remember, not to create any duplicates in the process. 

---

### SPLITTING DECISIONS

#### Horizontal Splitting (Same-level Subfeatures):
Split if:
- The subfeature covers ONE / MORE THAN ONE high-level functionalities
- Each function could be planned and developed independently
- Each component has some clear boundaries and responsibilities

#### Vertical Splitting (Microsubfeatures):
Split further if:
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across actions are too complex to isolate.
- There are no tables that can be mapped to the generated user-story.
- The subfeature is too complex to be planned, developed, and deployed independently
- Each micro-subfeature represents one atomic, non-overlapping functionality
Note: Maintain at least 2 subfeatures unless the database has only one table.
- Prioritize brevity, consistency and no informaiton leakage across subfeatures.
- Ensure crisp segregation.
---

### DO NOT SPLIT IF:
- sub-user-stories are tightly coupled in the Subfeature and cannot function independently.
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across tables in two features are too complex to isolate.
- There are no tables that can be mapped to the generated user-story.
Note: Maintain at least 2 subfeatures and 1 or more microsubfeatures per subfeature, Unless the database has only one table.
Note : Maintain brevity during splitting at the same level. Do NOT overload the a single feature with too many subfeatures.
---


### FILE MAPPING RULES:
- For each subfeature or microsubfeature, cite only directly relevant tables.
- Use only the provided input data to match files â€” no guessing.
- Avoid duplication unless a file is clearly shared between components.

Each `file_path` entry must include:
```json
{
  "module_name": "<Name>",
  "path": "<Path>",
  "critical": <true/false>,
  "git_url": "<Git URL>"
}

OUTPUT FORMAT
If the subfeature should NOT be split:
Return: "None"

If the subfeature should be split, return a list of Parent User Stories with subfeatures inside.
If a subfeature itself can be further split into microsubfeatures, nest them under micro_sub_features like so:

[
  {
    "name": "Parent User Story Title 1",
    "description": "Full description of the original or updated user story and its purpose.",
    "file_path": [...],
    "sub_feature_confidence_score":"confidence score of the subfeature with respect to the Feature, as a percentage (e.g., 80)"
    "micro_sub_features": [
      {
        "name": "Sub-User Story Title 1",
        "description": "Standalone description of a single functionality.",
        "file_path": [...],
        "micro_sub_feature_confidence_score":"confidence score of the micro_sub_feature with respect to the sub_feature, as a percentage (e.g., 90)"
        }
          ...
        ]
      },
      ...
    ]
  }
]
Each layer must preserve independence, clarity, and singular focus of each story.

VALIDATION CHECKLIST
- Each title must express one functionality only (no imperative phrasing)
- description must avoid assumptions and describe the real function. It must be as detailled as possible.
- Each story must make sense independently and fit in the broader feature flow
- if there are multiple user-story under the subfeature, it needs to be in sequence of business logic.
- File mappings must be relevant and scoped accurately
- Do no miss/skip any values in the output json. The output structure must be maintained strictly.
- All subfeature and sub-user-story names and descriptions must be strictly in a declarative tone, not imperative.
- Use Database-specific schema only. Do not include words like "Attributes" / "Code Files" in your response. 
- Strictly Do not start descriptions with or start with "this micro-feature" / or "this sub-feature".
* Use generic or speculative statements

"""import os
from graphviz import Digraph
import re 
import json

def parse_ddl(ddl: str):
    """
    Parse the DDL to extract columns, primary keys, and foreign keys.
    """
    lines = ddl.splitlines()
    column_lines = []

    for line in lines:
        line = line.strip()
        if (
            line.upper().startswith("CREATE")
            or line.upper().startswith("PRIMARY")
            or line.upper().startswith("FOREIGN")
            or line.upper().startswith(")")
            or line == ""
        ):
            continue

        match = re.match(r'(\w+)\s+\w+', line)
        if match:
            column_lines.append(match.group(1))

    pk_match = re.search(r'PRIMARY KEY\s*\((.*?)\)', ddl)
    primary_keys = [key.strip() for key in pk_match.group(1).split(",")] if pk_match else []

    foreign_keys = []
    for match in re.finditer(r'FOREIGN KEY\s*\(([^)]+)\)\s+REFERENCES\s+`?[\w]+\.(\w+)`\(([^)]+)\)', ddl):
        fk_col = match.group(1).strip()
        ref_table = match.group(2).strip()
        ref_col = match.group(3).strip()
        foreign_keys.append((fk_col, ref_table, ref_col))

    return column_lines, primary_keys, foreign_keys


def generate_combined_graph(tables_data):
    """
    Generate a single combined graph from multiple tables.
    """
    dot = Digraph(comment='Combined Table Diagram')
    dot.attr(rankdir='LR')

    # Store individual table nodes
    for table in tables_data:
        table_name = table['table_name']
        columns = table['columns']
        primary_keys = table['primary_keys']
        
        label_lines = []
        for col in columns:
            if col in primary_keys:
                label_lines.append(f"{col} [PK]")
            else:
                label_lines.append(col)
        dot.node(table_name, shape='box', label=f'{table_name}\\n' + "\\n".join(label_lines))

    # Add relationships
    for table in tables_data:
        table_name = table['table_name']
        for fk_col, ref_table, ref_col in table['foreign_keys']:
            dot.edge(table_name, ref_table, label=f'{fk_col} â†’ {ref_col}')

    return dot

def folder_summary_generation_prompts(
        total_allocated_tokens, 
        file_list, folder_name, 
        folder_path,
        subfolder_list,
        formatted_file_summaries,
        formatted_file_services,
        formatted_subfolder_summaries,
        formatted_subfolder_services,
        formatted_subfolder_features
    ):
    
    system_prompt = f"""
        You are an expert code analyst specialized in creating detailed, informative summaries of software project folders. Your task is to thoroughly analyze files and subfolders to provide a comprehensive understanding of the application or project and provide combined summaries along with required details. These summaries must be detailled enough for further summarization.

        Follow these guidelines:
        1. Conduct a deep analysis of the features to identify its core purpose and functionality
        2. Provide detailed explanation of key implementations and technical approaches of the features
        3. Thoroughly examine the summaries based on files and folders to understand relationship between features and combined smaller features into larger high level application level features.
        4. Explain the features within the broader project architecture with specific connections
        5. Describe technical patterns, design decisions, and architectural choices evident in the code
        6. Include specific functions, classes, and methods that define the feature's behavior
        7. Note dependencies, imports, and external connections that shape the folder's functionality
        8. Identify potential architectural strengths and areas for improvement when evident
        9. Identify all services represented in this folder based on file and subfolder services information
        10. Identify and articulate high-level features or functionalities represented by the folder into the feature_details section, when consolidating multiple subfolders or lower-level files. Derive these insights from both file-level and subfolder-level summaries. Also under each feature, mention which file/folder was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
        11. Do not miss any features that could be formed based on these summaries as this information is required to understand the application's buisness logic.
        12. Gather insights from the summaries provided to generate a high level detailled executive summary that could be used by business stakeholders to understand the folder/project.
        13. When analyzing the root folder, both the executive summary and the features must be strictly formed in a high level business logic standpoint of an application.
        
        IMPORTANT: 
        - Your summary should be thorough and detailed({total_allocated_tokens}) while maintaining technical/business precision and depth. Focus on providing insights that would help both stakeholders and developers understand the application better.
        - feature_details must contain high level feature name and feature description(value of the files/folders) strictly in concise bullet points. The feature inforamtion must be in detail to capture the complete high level knowledge for that feature but not the function level details. Feature names cannot be programmatic function names like Dependency management, json handling etc. instead it should be inventory management, order processing etc. 
        - Your services list should be comprehensive and include all services represented in this folder.
        - is_reuasble_lib if a folder is used as reusable lib make it True otherwise False
        - lib_name if is_reusable_lib is True then provide the name of the reusable lib/component If is_reusable_lib False then add Not Applicable
        - category if is_reusable_lib is True then provide category only between 'Frontend' and 'Backend' If is_reusable_lib False then add Not Applicable
        - sub_category if is_reusable_lib is True then provide sub category only between 'UI Component','Custom Hooks', 'http_client', 'Utils', 'Others' In Frontend & 'Middleware', 'Error Handling', 'Auth', 'Utils', 'Others' In Backend If is_reusable_lib False then add Not Applicable
        - when_to_use if is_reusable_lib is True then provide where this reusable lib/component can be used If is_reusable_lib False then add Not Applicable 
        - associated_files if is_reusable_lib is True then provide the list of files associated(give complete path for the assosciated file) with this reusable lib/component If is_reusable_lib False then add Not Applicable
        - summary must not be technical and only explain the high level details of the folder/project. Understand the file and folder summaries provided to combine the knowledge to form the executive summary. Make it as detailled as possible.
        - Use clear and concise language, avoiding jargon where possible.
        
        - You must provide your response in this exact format:
        ```summary
        [Your detailled high-level executive summary for the folder for business stakeholders]
        ```
        ```feature_details
        [List of high-level features or functionalities represented in this folder]
        ```
        ```services_namess
        [Comma-separated list of all services represented in this folder]
        ```
        ```is_reuasble_lib
        Boolean Value
        ```
        ```lib_name
        [Name of the reusable library if applicable]
        ```
        ```category
        [Category of the reusable library if applicable]
        ```
        ```sub_category
            [Sub category of the reusable library if applicable]
        ```
        ```when_to_use
        [Your detailed use case where or when this reuasble_lib can be usefull]
        ```
        ```associated_files
            [Comma-separated list of associated files with the reusable library, Give the Complete file path as mentioned in the file list]
        ```
        ```example_usage
            [Example code snippet of how to use this reusable library]
        ```
    """

    user_prompt = f"""
        Generate a summary and services list for the folder: "{folder_name}" (Path: {folder_path})

        FOLDER CONTENTS:
        - Files ({len(file_list)}): {", ".join(file_list) if file_list else "None"}
        - Subfolders ({len(subfolder_list)}): {", ".join(subfolder_list) if subfolder_list else "None"}

        FILE SUMMARIES:
        {os.linesep.join(formatted_file_summaries) if formatted_file_summaries else "No file summaries available"}

        FILE SERVICES:
        {os.linesep.join(formatted_file_services) if formatted_file_services else "No file services available"}

        SUBFOLDER SUMMARIES:
        {os.linesep.join(formatted_subfolder_summaries) if formatted_subfolder_summaries else "No subfolder summaries available"}

        SUBFOLDER SERVICES:
        {os.linesep.join(formatted_subfolder_services) if formatted_subfolder_services else "No subfolder services available"}

        SUBFOLDER FEATURES:
        {os.linesep.join(formatted_subfolder_features) if formatted_subfolder_features else "No subfolder features available"}
        
        Based on these components:
        1. Provide a thorough technical summary explaining the folder's purpose, implementation details, and architectural significance
        2. Compile a comprehensive list of all services represented in this folder based on file and subfolder services information
        
        Follow the exact format specified in the system instructions for your response.
    """

    return system_prompt, user_prompt

def services_generation():
    system_prompt = """
        <Task>
        Create an architectural blueprint of the given repository by identifying and classifying both external services and third-party services with no overlap between categories.
        </Task>

        <Definitions>
        - External services: Company-provided services hosted outside the application (AWS S3, Google Cloud, Stripe, Twilio)
        - Third-party services: Libraries, frameworks, and SDKs that are part of the core application stack (Django, React, MongoDB, Redux)
        </Definitions>

        <Output_Format>
        {
        "external_services": [
            {
            "external_service_name": "string",
            "description": "string",
            "associated_files": ["string"],
            "service_class": "string",
            "used_in_files": ["string"]
            }
        ],
        "thirdparty_services": [
            {
            "thirdparty_service_name": "string",
            "description": "string",
            "associated_files": ["string"],
            "service_class": "string",
            "used_in_files": ["string"]
            }
        ]
        }
        </Output_Format>

        <Instructions>
        1. Conduct a thorough repository analysis to identify all services
        2. Classify each service into exactly ONE category:
        - External services: Cloud platforms, payment processors, authentication providers
        - Third-party services: Frameworks, libraries, SDKs integrated into the codebase
        3. For each service, provide:
        - Name: Exact service name
        - Description: Concise explanation of functionality and purpose
        - Associated files: All files directly importing or using the service
        - Service class: Category (e.g., "cloud storage", "web framework", "database")
        - Used in files: Complete paths of files utilizing the service
        4. Ensure ZERO overlap between categories
        5. Prioritize accuracy over comprehensiveness
        6. Validate that identified services are actively used in the project
        7. Include only services with clear evidence of implementation
        8. Do not create a lot of services which are redundant. Keep it to a maximum of 50 services only.
        </Instructions>

        <Examples>
        Good External Service Entry:
        {
        "external_service_name": "AWS S3",
        "description": "Cloud storage service used for storing user-uploaded files",
        "associated_files": ["src/services/storage.js", "src/config/aws.js"],
        "service_class": "cloud storage",
        "used_in_files": ["src/components/FileUpload.js", "src/pages/UserProfile.js"]
        }

        Good Third-Party Service Entry:
        {
        "thirdparty_service_name": "React",
        "description": "Frontend JavaScript library for building user interfaces",
        "associated_files": ["package.json", "src/index.js"],
        "service_class": "frontend framework",
        "used_in_files": ["src/App.js", "src/components/*.js"]
        }
        </Examples>

        Analyze the repository and provide the complete architectural blueprint in the specified format.
    """

    user_prompt = ""

    return system_prompt, user_prompt

def executive_summary_generation(combined_summary, user_mvf):
    system_prompt = """
    Your Role:
    You are an expert software architect tasked with understanding a codebase and creating an executive summary that clearly articulates the main purpose of this application,
    the core problem that the application is solving, and the prioritized list of the most valuable features, solely based on the provided folder wise summary. Do not hallucinate and create the most valuable features and its description on assumption. This needs to be based on facts.

    Task:
    1. Analyze provided folder wise summary and the services used and the user defined features (if provided).
    2. Understand component interactions and functions.
    3. Prioritize the User Defined Features (if provided) in the summary.
    4. Identify and prioritize the most valuable features based on their importance and relevance to the overall project, as evidenced in the code.
    5. Create a comprehensive executive summary.

    Steps:
    1. Review folder wise summary.
    2. Analyze folder wise summary:
    - Identify key components and their roles
    - Note data operations, design patterns, and architectural decisions
    3. Create summary:
    - Describe the specific problem the codebase solves, based on folder wise summary
    - Explain component interactions
    - Outline data workflow
    4. Identify and prioritize main features:
    - Determine which feature(s) address the core problem of the application, based on code implementation
    - Rank features based on their importance and relevance to solving the main problem, as evidenced in the code
    - The feature should be major components of the codebase and not minor functions like "Modular Architecture" or "Code Reusability", these are not features but design principles.

    Focus Areas:
    - Precised feature prioritization and importance
    - High-level functionality
    - Clear, concise technical language
    - Objective description
    - Capture entire workflow

    Guidelines:
    - Only use the folder wise summary provided
    - Use precise technical terms
    - Include user-defined features if provided and evidenced in the code
    - Prioritize features based on their importance to the core problem, as shown in the folder wise summary

    Feature Identification and Prioritization:
    - Carefully analyze the folder wise summary to identify features actually present in the folder wise summary
    - Do not assume or infer features that are not explicitly mentioned in the folder wise summary
    - Identify the top feature that solves the majority of the problem based on code evidence
    - Rank subsequent features in descending order of importance, ensuring they are present in the folder wise summary
    - Ensure the feature list reflects the codebase's focus and structure
    - Only include features that have substantial implementation in the codebase that is evident from folder wise summary

    Output Format - Adhering to this format is crucial
    ```json
    {
    "data": "generated_summary in string format adhering to the Expected Output Format for Generated Summary",
    "confidence_score": 90,
    "traceback": {
    "Feature 1 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 1 Title' is included, as the 'phrase' is an evidence that this feature is part of the codebase.",
    "Feature 2 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 2 Title' is included, as the 'phrase' is an evidence that this feature is part of the codebase.",
    ...
    }
    }
    ```

    Requirements:
    - Replace \n with \\n in JSON
    - Limit upto 5 main features (max 2 sub-features each) or 7500 tokens
    - If due to any reason such as codebase being small, you are unable to provide 5 features, then provide as many high-level features as possible between the range of 1 to 5.
    - Don't assume features or include minor features due to inability to provide 5 features, lesser number of features is acceptable.
    - Use specified JSON format only
    - Start with "```json" and end with "```"
    - Ensure the top feature in the prioritized list addresses the core problem and is present in the folder wise summary
    - Rank features in descending order of importance to the main problem, based on actual code implementation
    - Do NOT include features that are NOT evidenced in the provided folder wise summary
    - Evaluate the folder wise summary objectively, considering all conclusions on the actual code provided
    - Do NOT make any assumptions about organizational goals or intentions beyond what is explicitly shown in the code
    - Focus solely on the technical aspects and implemented functionality, avoiding speculation about business objectives or future plans
    - Both the keys data, confidence score, and traceback should be present in the output JSON
    - The generated summary should be in string format only and be contained inside the "data" key
    - The "traceback" key should contain a dictionary with feature names as keys and justifications for including these features based on exact phrases from the input
    - Do not include any feature that could potentially be part of the folder wise summary without explicit evidence
    - Every feature mentioned must be driven by clear evidence from the provided input
    """
    user_prompt = """
    Expected Output Format for Generated Summary:

  **Overview**
  <empty line>
  <A brief introduction to the codebase and its main purpose; in paragraph format only, not in points.
  This paragraph should provide a concise yet comprehensive overview of the codebase, its primary functionality, solution provided by the project and its intended use case.
  Aim for 3-5 sentences that capture the essence of the project.>
  <empty line>
  **Highlighted Features**
  <empty line>
  <
  List and briefly explain the key features that are significant components of the codebase and would serve as selling points.
  These features should be presented as follows:
  1. Use numbered points for each feature.
  2. Provide a brief explanation for each feature in 1-2 sentences, highlighting its importance and benefit to the end user.
  3. Focus on features that are central to the codebase's functionality and most important to the end user.
  4. Dont include generic features like "Modular Architecture" or "Code Reusability", these are not features but design principles.
  5. Do not include sub-points under any feature.
  6. Prioritize User Defined Features (if provided) at the beginning of the list.
  7. If User Defined Features are given, list them first before including any features identified through your analysis.
  8. Aim to provide upto of 1 to 5 key features, after each feature add an empty line for formatting purposes.
  9. Ensure that the features listed represent the core functionality and unique selling points based on the folder wise summary.
  10. Use clear, concise language that emphasizes the value proposition of each feature.
  11. Also under each feature, mention which file/folder was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
  12. Do not add features into Highlighted Features if they dont have value for buisness stakeholder about the application. Also do not repeat adding similar feature in this section.

  Output Structure:
  1. ***<Feature 1 Title>***: <Description of the feature in one to two sentences.\n
  2. ***<Feature 2 Title>***: <Description of the feature in one to two sentences.>\n
  >
  <empty line>
  **Key Benefits**
  <empty line>
  <Summarize the key benefits of the codebase in one to two sentences.
  This summary should encapsulate the overall value proposition of the codebase and its potential impact on users or the organization.>
  <empty line>
  <Highlight the most significant key benefits the codebase has to offer in bulleted points. The format should be:
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  Aim for 3-5 bullet points that capture the most compelling advantages of using this codebase, after each point add an empty line for formatting purposes.
  Each benefit should be distinct and provide a clear value proposition.>

  <Final Output Format>
  Output Format - Adhering to this format is crucial, the output should be in parsable JSON format:
  ```json
  {{
    "data": "<generated_summary in string format adhering to the Expected Output Format for Generated Summary>",
    "confidence_score": 90,
    "traceback": {{
      "Feature 1 Title": "Since it mentions about <exact phrase from the folder wise summary>, the 'Feature 1 Title' is included, as the "phrase" is an evidence that this feature is part of the folder wise summary.",
      "Feature 2 Title": "Since it mentions about <exact phrase from the folder wise summary>, the 'Feature 2 Title' is included, as the "phrase" is an evidence that this feature is part of the folder wise summary.",
      ...
    }}
  }}
  ```
  </Final Output Format>
  Note: If the traceback includes phrases that are not present in the folder wise summary then you would be penalized 10000 points.
  The output should be having data, confidence score, and traceback keys, and the entire content inside "```json" and "```" should be parsable by json.
  The "data" key should contain the generated summary and it should be in string format only, allowing the parsing of the entire json.
  If there are any inverted commas inside the generated summary, then escape them with a backslash.
  Do not change or skip the headings of each section in the generated json. The generated summary must have "Overview", "Highlighted Features", "Key Benefits" as section titles. Follow the above provided guidelines."""
    user_prompt += f"""Use the below folder wise summary to generate the summary in the above format: {combined_summary}""" + "User Defined Features : " + str(user_mvf)
    return system_prompt, user_prompt

def db_executive_summary_generation(combined_summary, user_mvf): 
    system_prompt = """
    Role:
    You are an expert Database Architect tasked with understanding the contents of all tables and schema of the database. 
    You shall Articulate a proper executive summary that clearly captures all the main & high-level features of this database.
    The core use-case that this database is intended for, and the prioritized list of the most valuable features, solely based on the provided Table-Level summaries. 
    Do not hallucinate. Do NOT create the most valuable features and its description on pure assumptions. This needs to be based on facts, with proper backing.

    Task:
    1. Analyze provided Table wise summaries.
    2. Understand component interactions and functions.
    3. Prioritize the User Defined Features (if provided) in the summary.
    4. Identify and prioritize the most valuable features based on their importance to the core use-case the Database is solving.
    5. Create a comprehensive executive summary.

    Steps:
    1. Review Table wise summary.
    2. Analyze Table wise summary:
      - Identify all tables. 
      - Take into consideration the foreign keys, primary keys, is-a, has-a, and many-to-many relationships.
      - Deeply understand the intended-use-case of each table.
      - Note data operations, design patterns, and architectural decisions
    3. Create summary:
      - Describe the specific problem the Database is solving, based on Table wise summary
      - Explain high-level interactions and dependencies
      - Outline data workflow
    4. Identify and prioritize main features:
      - Determine which feature(s) address the core problem of the Database, based on SQL implementation and Table wise summary
      - Rank features based on their importance and relevance to solving the main problem, as evidenced in the Database
      - The feature should be major components of the Database and not minor functions like Many-to-Many Relationships, or "Foreign Keys". 
        These are implementation concepts. Not core features.

    Focus Areas:
    - Precised feature prioritization and importance
    - High-level functionality of this Database
    - Clear, concise technical language with Database-specific Language
    - Objective description
    - Capture entire data workflow

    Guidelines:
    - Only use the Table wise summary provided
    - Use precise Database-relevant technical terms
    - Include user-defined features if provided and evidenced in the Table wise summary
    - Prioritize features based on their importance to the core problem, as shown in the Table wise summary

    Feature Identification and Prioritization:
    - Carefully analyze the Table wise summary to identify features actually present in the Table wise summary
    - Do not assume or infer features that are not explicitly mentioned in the Table wise summary
    - Identify the top feature that solves the majority of the problem based on Database and SQL evidence
    - Rank subsequent features in descending order of importance, ensuring they are present in the Table wise summary
    - Ensure the feature list reflects the Database's focus and structure
    - Only include features that have substantial implementation in the Database that is evident from Table wise summary

    Output Format - Adhering to this format is crucial
    ```json
    {
    "data": "generated_summary in string format adhering to the Expected Output Format for Generated Summary",
    "confidence_score": 90,
    "traceback": {
    "Feature 1 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 1 Title' is included, as the 'phrase' is an evidence that this feature is part of the Database.",
    "Feature 2 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 2 Title' is included, as the 'phrase' is an evidence that this feature is part of the Database.",
    ...
    }
    }
    ```

    Requirements:
    - Replace \n with \\n in JSON
    - Limit upto 5 main features (max 2 sub-features each) or 7500 tokens
    - If due to any reason such as Database being small, you are unable to provide 5 features, then provide as many high-level features as possible between the range of 1 to 5.
    - Don't assume features or include minor features due to inability to provide 5 features, lesser number of features is acceptable.
    - Use specified JSON format only
    - Start with "```json" and end with "```"
    - Ensure the top feature in the prioritized list addresses the core problem and is present in the Table wise summary
    - Rank features in descending order of importance to the main problem, based on actual Database and SQL implementation
    - Do NOT include features that are NOT evidenced in the provided Table wise summary
    - Evaluate the Table wise summary objectively, considering all conclusions on the actual Database and SQL provided
    - Do NOT make any assumptions about organizational goals or intentions beyond what is explicitly shown in the Database and SQL
    - Focus solely on the technical aspects and implemented functionality, avoiding speculation about business objectives or future plans
    - Both the keys data, confidence score, and traceback should be present in the output JSON
    - The generated summary should be in string format only and be contained inside the "data" key
    - The "traceback" key should contain a dictionary with feature names as keys and justifications for including these features based on exact phrases from the input
    - Do not include any feature that could potentially be part of the Table wise summary without explicit evidence
    - Every feature mentioned must be driven by clear evidence from the provided input.
    - Strictly use an assertive and objective tone in your response. 
    - Do not be unsure about anything.
    - Do not include the "Folder Name" in your response. Ignore "dbanalysis" folder. Provide Executive Summary of the Database-ONLY.
    """

    user_prompt = """
  Expected Output Format for Generated Summary:

  **Overview**
  <empty line>
  <A brief introduction to the Database and its main purpose; in paragraph format only, not in points.
  This paragraph should provide a concise yet comprehensive overview of the Database, its primary functionality, and its intended use case.
  Aim for 3-5 sentences that capture the essence of the Database.>
  <empty line>
  **Highlighted Features**
  <empty line>
  <
  List and briefly explain the key features that are significant components of the Database and would serve as selling points.
  These features should be presented as follows:
  1. Use numbered points for each feature.
  2. Provide a brief explanation for each feature in 1-2 sentences, highlighting its importance and benefit to the END USER.
  3. Focus on features that are central to the Database's functionality and most important to the END USER.
  4. Dont include generic features like  Many-to-Many Relationships, or "Foreign Keys", these are not features but Design Principles.
  5. Do not include sub-points under any feature.
  6. Prioritize User Defined Features (if provided) at the beginning of the list.
  7. If User Defined Features are given, list them first before including any features identified through your analysis.
  8. Aim to provide upto of 1 to 5 key features, after each feature add an empty line for formatting purposes.
  9. Ensure that the features listed represent the core functionality and unique selling points based on the Table wise summary.
  10. Use clear, concise language that emphasizes the value proposition of each feature.
  11. Also under each feature, mention which file/Table was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
  12. Do not add features into Highlighted Features if they dont have value for buisness stakeholder about the application. Also do not repeat adding similar feature in this section.

  Output Structure:
  1. ***<Feature 1 Title>***: <Description of the feature in one to two sentences.\n
  2. ***<Feature 2 Title>***: <Description of the feature in one to two sentences.>\n
  >
  <empty line>
  **Key Benefits**
  <empty line>
  <Summarize the key benefits of the Database in one to two sentences.
  This summary should encapsulate the overall value proposition of the Database and its potential impact on users or the organization.>
  <empty line>
  <Highlight the most significant key benefits the Database has to offer in bulleted points. The format should be:
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  Aim for 3-5 bullet points that capture the most compelling advantages of using this Database, after each point add an empty line for formatting purposes.
  Each benefit should be distinct and provide a clear value proposition.>

  <Final Output Format>
  Output Format - Adhering to this format is crucial, the output should be in parsable JSON format:
  ```json
  {{
    "data": "<generated_summary in string format adhering to the Expected Output Format for Generated Summary>",
    "confidence_score": 90,
    "traceback": {{
      "Feature 1 Title": "Since it mentions about <exact phrase from the Table wise summary>, the 'Feature 1 Title' is included, as the "phrase" is an evidence that this feature is part of the Table wise summary.",
      "Feature 2 Title": "Since it mentions about <exact phrase from the Table wise summary>, the 'Feature 2 Title' is included, as the "phrase" is an evidence that this feature is part of the Table wise summary.",
      ...
    }}
  }}
  ```
  </Final Output Format>
  Note: If the traceback includes phrases that are not present in the Table wise summary then you would be penalized 10000 points.
  The output should be having data, confidence score, and traceback keys, and the entire content inside "```json" and "```" should be parsable by json.
  The "data" key should contain the generated summary and it should be in string format only, allowing the parsing of the entire json.
  If there are any inverted commas inside the generated summary, then escape them with a backslash.
  Do not change or skip the headings of each section in the generated json. The generated summary must have "Overview", "Highlighted Features", "Key Benefits" as section titles. Follow the above provided guidelines.
    """

    user_prompt += f"""Use the below Table wise summary to generate the summary in the above format: {combined_summary}""" + "User Defined Features : " + str(user_mvf)

    return system_prompt, user_prompt


def architecture_diagram_generation(services_data, icons_metadata):
    user_prompt = f"""
    <Input>
    $services_data = {services_data}
    $icons_metadata
    </Input>

    <Role>
    You are an expert at understanding large projects based on their executive summary and the services being used in them. Create a JSON structure for a ReactFlow diagram based on the given service class JSON.
    </Role>

    <Output Structure>
    1. Create a JSON object with a "nodes" and "edges" array.
    2. Create nodes for each external and third-party service.
    3. "nodes": An array containing all node objects.
      - "id": A unique string identifier for the node.
      - "data":   
        - "label": The name of the node.
        - "description": Description of the service.
        - "associated_files": Associated file and used in files in the service node, defaulting to "No File Available" if not present.
        - "group": The logical group name (e.g., 'Backend', 'Frontend', 'Database',etc..).
        - "subgroup": The specific subgroup within the group (e.g., Frameworks, NoSQL Databases, State Management, etc.).
        - "service": The appropriate filename of the icon based on the $icons_metadata.
      - "position" : The x and y coordinates of the node.
      - "type" : "customNode" This should be fixed.
    4. "edges" : An array having id, source, target, label, and type should be customEdge always.
    4. Ensure all services and files from the input JSON are included.
    5. The output should be in the form of a dictionary containing a "nodes" and "edges" array.
    6. Present only the code inside delimiters "```reactflow [reactflow CODE]```" without any additional explanation.
    """

    system_prompt:str = """
    <Task>
      You are tasked with creating a JSON structure for a ReactFlow diagram based on the given executive summary and the service_class_json. The executive summary contains an overview of the entire project. This JSON includes information about external services and third-party services, along with their associated files. Your output should represent this information as a network of nodes and edges.
    </Task>
    
    <Icons Context>
      $icons_metadata = """ + str(icons_metadata) + """
    </Icons Context>

    <Instructions>
      You are a solution expert, specializing in problem and solution flows. You will be given the solution overview for a project, and your task is to create an interconnected single component of graph which is detailed, and intuitive and self explanatory for:

      Follow these guidelines:
      1. Create nodes for each unique service (both external and third-party).
      2. Do not create any group nodes.
      4. In the data key for each service node, include two additional fields called group and subgroup. The group field should contain the logical group name (e.g., Frontend, Backend, Databases, etc..), and the subgroup field should provide more specific categorization (e.g., Frameworks, NoSQL Databases, etc..). For example, for a service node representing React, the group would be Frontend and the subgroup would be Frameworks.
      5. For each node, check which icon will be the most suitable from the $icons_metadata in the <Icons Context>
      6. Ensure all information from the input is represented in the output.
      7. The position coordinates must be proper for all the nodes.
    </Instructions>

    <Rules>
      **Ensure all nodes in the generated graph are interconnected such that every node has at least one edge, forming a single connected component without any isolated or disjoint sections. (High Priority Requirement)**
      Important Rules to be followed:
      1. Give detailed technical architecture flow and the JSON object following the below output format.
      2. Make sure that the flow and order of new solution approach is explained well in the graph with appropriate edges. Use as many edges you want to describe the data and user flow properly.
      3. The whole user and data flow should be clear.
      4. Do not add unnecessary nodes and edges. Do not create duplicate nodes that perform same task.
      5. Make the Node descriptions detailed, breaking tasks into multiple sub-tasks if needed.
      6. Ensure your edges show the actual flow, and not just connections of what's related. The connections are meant to show the logical flow, and not the relatedness/similarity.
      7. The group name is meant to classify clusters of nodes within each graph. For instance, if we have multiple nodes in features, they would all have "feature" as group. In Architecture Flow, the "Group" should show the layer each node is in, for instance "Backend Layer", "Database Layer" etc.
      9. for a hierarchy of nodes A -> B -> C; ensure that there is not a connection between A -> C.
    </Rules>
    
    <output_format>
    The output should be in between the delimeters ```reactflow and ```. Only provide the json output. Don't give unnecesary explanation.
    ```reactflow
    {
      "nodes": [
        { 
          "id": "unique_node_identifier_string",
          "data" : {
            "label": "name_of_the_service",
            "description": "description of the service",
            "associated_files": ["file_path_1", "file_path_2", "file_path_3", etc.],  // (default: ["No File Available"] if not present)
            "group": "name_of_group",  // Add the logical group name (e.g., "Frontend", "Backend", etc..)
            "subgroup": "name_of_subgroup",  // Add a more specific subgroup name (e.g., "Frameworks", "NoSQL Databases", etc..)
            "service": "filename" //taken from the $icons_metadata,
          }
          "position":{ "x": "Xcoordinate", "y": "Ycoordinate" },
          "type" : "customNode" //this is hardcoded and will be constant
        }
      ],
      "edges": [
        {
          "id": "unique_egde_identifier_string",
          "source": "label A",
          "target": "label B",
          "label": "Showcase what comes from the source node, to the target node. Be concise and specific with labels, such as 'Ingested Data', 'Converted Text', 'User Query' etc. Use at max 5 words",
          "type" : "customEdge" //this is hardcoded and will be constant
        }
      ]
    }```
    </output_format>
    """
    return system_prompt, user_prompt
  

def erd_generation(services_data, icons_metadata):
  tables_metadata = []
  for entry in services_data:
      table_name = entry["table_name"]
      ddl = entry["ddl"]
      columns, primary_keys, foreign_keys = parse_ddl(ddl)
      tables_metadata.append({
          "table_name": table_name,
          "columns": columns,
          "primary_keys": primary_keys,
          "foreign_keys": foreign_keys
      })

  dot = generate_combined_graph(tables_metadata)

  system_prompt:str = """
    You are tasked with creating a JSON structure for a ReactFlow diagram based on the given database ER diagram and schema JSON. This JSON includes information about database columns and their relationships.Your output should represent this information as a network of nodes and edges.
    </Task>
    
    <Icons Context>
      $icons_metadata = """ + str(icons_metadata) + """
    </Icons Context>

    <Instructions>
      You are a solution expert, specializing in problem and solution flows. You will be given the database schema information of a database, and your task is to create an interconnected single component of graph which is detailed, and intuitive and self explanatory for:

      Follow these guidelines:
      1. Create nodes for each unique service (both external and third-party).
      2. Do not create any group nodes.
      4. In the data key for each service node, include two additional fields called group and subgroup. The group field should contain the logical group name (e.g.,Databases, etc..), and the subgroup field should provide more specific categorization (e.g., 'Transactional Tables', 'Reference Tables' etc..). For example, for a service node representing daily transactions, the group would be Database and the subgroup would be Transactional Tables.
      5. For each node, check which icon will be the most suitable from the $icons_metadata in the <Icons Context>
      6. Ensure all information from the input is represented in the output.
      7. The position coordinates must be proper for all the nodes.
    </Instructions>

    <Rules>
      Important Rules to be followed:
      1. Give detailed technical architecture flow and the JSON object following the below output format.
      2. Make sure that the flow and order of new solution approach is explained well in the graph with appropriate edges. Use as many edges you want to describe the data and user flow properly.
      3. The whole user and data flow should be clear.
      4. Do not add unnecessary nodes and edges. Do not create duplicate nodes that perform same task.
      5. Make the Node descriptions detailed, breaking tasks into multiple sub-tasks if needed.
      6. Ensure your edges show the actual flow, and not just connections of what's related. The connections are meant to show the logical flow, and not the relatedness/similarity.
      7. The group name is meant to classify clusters of nodes within each graph. For instance, if we have multiple nodes in features, they would all have "feature" as group. In Architecture Flow, the "Group" should show the layer each node is in, for instance "Database Layer" etc.
      9. for a hierarchy of nodes A -> B -> C; ensure that there is not a connection between A -> C.
    </Rules>
    
    <output_format>
    The output should be in between the delimeters ```reactflow and ```. Only provide the json output. Don't give unnecesary explanation.
    ```reactflow
    {
      "nodes": [
        { 
          "id": "unique_node_identifier_string",
          "data" : {
            "label": "name_of_the_table",
            "description": "description of the table",
  	    "columns": ["order_id [PK]", "product_sku [PK]", "quantity", "unit_price"]
            "group": "name_of_group",  // Add the logical group name (e.g., "Database", etc..)
            "subgroup": "name_of_subgroup",  // Add a more specific subgroup name (e.g., 'Transactional Tables', 'Reference Tables', etc..)
            "service": "filename" //taken from the $icons_metadata,
          }
          "position":{ "x": "Xcoordinate", "y": "Ycoordinate" },
          "type" : "customNode" //this is hardcoded and will be constant
        }
      ],
      "edges": [
        {
          "id": "unique_egde_identifier_string",
          "source": "label A",
          "target": "label B",
          "label": "Showcase what comes from the source node, to the target node. Be concise and specific with labels, such as 'Ingested Data', 'Converted Text', 'User Query' etc. Use at max 5 words",
          "type" : "customEdge" //this is hardcoded and will be constant
        }
      ]
    }```
    </output_format>
    """
    
  user_prompt:str = f"""
    <Input>
    $database_tables = {dot}
    $icons_metadata
    </Input>

    <Role>
    You are an expert at understanding database architecture based on ER diagrams and relational structures. Create a JSON structure for a ReactFlow diagram based on the given database schema.
    </Role>
    <Output Structure>
      1. Create a JSON object with a "nodes" and "edges" array.
      2. Create nodes for each table in the schema.
      3. "nodes": An array containing all node objects.
      - "id": A unique string identifier for the node.
      - "data":  
        - "label": The name of the table.
        - "description": A brief summary of the table's role or content.
        - "columns": List of column names (mark primary keys with [PK], foreign keys with [FK]).
        - "group": The logical group name (e.g., 'Database').
        - "subgroup": The specific subgroup within the group (e.g., 'Transactional Tables', 'Reference Tables').
        - "service": The appropriate filename of the icon based on the $icons_metadata.
      - "position" : The x and y coordinates of the node.
      - "type" : "customNode" This should be fixed.
      4. "edges" : An array having id, source, target, label, and type should be customEdge always.
      5. The label of the edge should describe the relationship, like "order_id â†’ order_id". 
      6. The output should be in the form of a dictionary containing a "nodes" and "edges" array.
      7. Present only the code inside delimiters "```reactflow [reactflow CODE]```" without any additional explanation.
    """
    
  return system_prompt, user_prompt
    

def feature_summary_generation(formatted_data, user_mvf, executive_summary):
    # if input_type is None:
    #     formatted_data = file_summary_list
    # elif input_type == "batch_summary":
    #     formatted_data = format_batchwise_summary_metadata_for_services(file_summary_list)
    # else:
    #     formatted_data = format_file_summaries(file_summary_list)

    user_prompt = """
    Role: You are an AI code analyst specializing in creating concise, feature-level summaries of codebases.

    Objective: Provide a comprehensive yet concise feature-level summary of a given codebase, highlighting key components, functionality, and the project's overall workflow.

    Input: You will receive information about a codebase, which may include an executive summary or other project details.

    Steps:
    1. Analyze the provided codebase information.
    2. Identify the main features (maximum 5) of the project from the executive summary (if provided in same order)
    3. Create a summary following the specified format, including:
        a. An overview of the project
        b. A list of key features with brief descriptions
        c. A closure statement
    4. Self-evaluate the generated summary and assign a confidence score.
    5. Format the output as specified in the instructions.

    Output Format:
    ```json
    {
        "data": "generated_summary in string format adhering to the Detailed Instructions for Output Format",
        "confidence_score": 90
    }
    ```

    Detailed Instructions for Output Format:

    **Overview**
    <empty line>
    < 
        Summarize all features in 2-3 sentences, introducing the project and its purpose.
        Provide a 2-3 sentence summary of key benefits, highlighting core architecture and value proposition.
    >
    <empty line>
    **Key Features**
    <empty line>
    <   
        List a maximum of 5 main features.
        For each feature, provide up to 2 sub-points describing its functionality.
        Ensure clear explanation of how features interact and contribute to the project's goals.
        1. ***<Key Feature Title>*** : 
        * <Sub point 1 description>
        * <Sub point 2 description>
        <empty line>
    >
    <empty line>
    < 
        Summarize the overall impact and value proposition of the project in one sentence as a conclusion statement.
    >
    <empty line>
    
    -> Self-Evaluation:
        - Score the summary out of 100 based on clarity, precision, detail, knowledge, accuracy, technical correctness, and understanding of the data.

    -> Formatting Requirements:
        - Replace all newline characters (\n) with \\n in the JSON output.
        - Ensure the complete JSON is less than 7500 tokens.
        - Start the output with "```json" and end with "```".
        - If an executive summary is provided, use only the highlighted features from it.

    Example Output Structure:
    ```json
    {
        "data": "**Overview**\\n\\n[Project overview]\\n\\n[Benefits summary]\\n\\n**Key Features**\\n\\n1. *Feature 1*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n2. *Feature 2*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n[...continue for up to 5 features...]\\n\\n[Closure statement]",
        "confidence_score": 90
    }
    ```

    Remember: Adhere strictly to the output format and instructions to maintain consistency and accuracy in your summary.
    """

    user_prompt += "User Defined Features : " + str(user_mvf)

    system_prompt = f"""
        <role>
        You are an assistant to a Senior Software Engineer. You are very capable in reading and understanding huge codebases.
        There is no edge-case, no mistake, no functionality no matter how small goes unnoticed by you.
        You will be given a large codebase and be asked queries regarding it.
        </role>

        <Task>
        You will be given relevant files from a production codebase. The Senior Engineer will consult you to clear his doubts and ask for critical code-level and functionality level analysis of the same.
        <Important>
        1. You will be clear. Feel free to be descriptive but Avoid Jargon
        2. You shall perform critical analysis on the code before responding.
        3. Note that the codebase will be quite complex and have dependencies everywhere, be mindful of them all.
        4. Enclose code in (triple backticks)``` code ```
        </Important>
        </Task>

        Files from Codebase goes here :
        <Repo Structure>
        {formatted_data}
        </Repo Structure>
    """

    start_index = executive_summary.find("Highlighted Features")
    end_index = executive_summary.find("Key Benefits")

    if start_index != -1 and end_index != -1:
        executive_summary = executive_summary[start_index:end_index].strip()

    user_prompt += "Executive Summary : " + str(executive_summary)

    return system_prompt, user_prompt

def feature_summary_generation_db(formatted_data, user_mvf, executive_summary):
    # if input_type is None:
    #     formatted_data = file_summary_list
    # elif input_type == "batch_summary":
    #     formatted_data = format_batchwise_summary_metadata_for_services(file_summary_list)
    # else:
    #     formatted_data = format_file_summaries(file_summary_list)

    user_prompt = """
    Role: You are an AI Database Analyst specializing in creating concise, feature-level summaries of complex database schemas and architectures.

    Objective: Provide a comprehensive yet concise feature-level summary of a given database schema information, highlighting key components, entities, relationships, and the overall data architecture workflow.

    Input: You will receive information about a database design, which may include an executive summary or other schema-level details.

    Steps:
    1. Analyze the provided database schema information.
    2. Identify the main features (maximum 5) of the database from the executive summary (if provided in same order)
    3. Create a summary following the specified format, including:
        a. An overview of the database
        b. A list of key features with brief descriptions
        c. A closure statement
    4. Self-evaluate the generated summary and assign a confidence score.
    5. Format the output as specified in the instructions.

    Output Format:
    ```json
    {
        "data": "generated_summary in string format adhering to the Detailed Instructions for Output Format",
        "confidence_score": 90
    }
    ```

    Detailed Instructions for Output Format:

    **Overview**
    <empty line>
    < 
        Summarize all features in 2-3 sentences, introducing the database and its purpose.
        Provide a 2-3 sentence summary of key benefits, highlighting schema structure, normalization or denormalization logic, and value proposition in handling data.
    >
    <empty line>
    **Key Features**
    <empty line>
    <   
        List a maximum of 5 main features.
        For each feature, provide up to 2 sub-points describing its data handling, relationships, or optimization logic.
        Ensure clear explanation of how features contribute to performance, consistency, and data integrity.
        1. ***<Key Feature Title>*** : 
        * <Sub point 1 description>
        * <Sub point 2 description>
        <empty line>
    >
    <empty line>
    < 
        Summarize the overall impact and value proposition of the database in one sentence as a conclusion statement.
    >
    <empty line>
    
    -> Self-Evaluation:
        - Score the summary out of 100 based on clarity, precision, detail, knowledge, accuracy, technical correctness, and understanding of the schema information.

    -> Formatting Requirements:
        - Replace all newline characters (\n) with \\n in the JSON output.
        - Ensure the complete JSON is less than 7500 tokens.
        - Start the output with "```json" and end with "```".
        - If an executive summary is provided, use only the highlighted features from it.

    Example Output Structure:
    ```json
    {
        "data": "**Overview**\\n\\n[Database overview]\\n\\n[Benefits summary]\\n\\n**Key Features**\\n\\n1. *Feature 1*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n2. *Feature 2*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n[...continue for up to 5 features...]\\n\\n[Closure statement]",
        "confidence_score": 90
    }
    ```

    Remember: Adhere strictly to the output format and instructions to maintain consistency and accuracy in your summary.
    """

    user_prompt += "User Defined Features : " + str(user_mvf)

    system_prompt = f"""
        <role>
        You are an assistant to a Senior Data Architect. You are very capable in reading, analyzing, and understanding complex database schemas and data models.
        No entity, constraint, relationship, or optimization logic goes unnoticed by you.
        You will be given a comprehensive database structure or schema information and will be asked to analyze, explain, and summarize it at a structural and functional level.
        </role>

        <Task>
        You will be given relevant database schema files or DDL definitions. The Senior Data Architect will consult you to clear doubts and ask for critical schema-level and data model-level analysis.
        <Important>
        1. You will be clear. Feel free to be descriptive but Avoid Jargon
        2. Perform a critical and deep analysis of the schema and the information given before responding.
        3. The schema will often involve multiple tables, foreign keys, views, procedures, and indexing strategies â€” be mindful of their dependencies and relationships.
        4. Enclose code or schema in (triple backticks)``` code ```
        </Important>
        </Task>

        Files from Database schema goes here :
        <Database Structure>
        {formatted_data}
        </Database Structure>
    """

    start_index = executive_summary.find("Highlighted Features")
    end_index = executive_summary.find("Key Benefits")

    if start_index != -1 and end_index != -1:
        executive_summary = executive_summary[start_index:end_index].strip()

    user_prompt += "Executive Summary : " + str(executive_summary)

    return system_prompt, user_prompt


#FEATURE HIERARCHY:
generate_features_system_prompt = """
  <Role>
    You are a Software Architect with expertise in analyzing large summaries from code files of an application. 
    You can comprehend summaries from code files that are complex, production-grade and are written in various programming languages to generate most important features, their description and the subfeatures with their description belonging to the most important features along with the other relevant information requested below.
    
    You will follow 2 Events before responding : 
    1. Generation of Feature Hierarchy as given in "Output_Format".
    2. Critical Evaluation of Every Confidence Score.  
  </Role> 

    <Task 1>
    You are provided with multiple relative file paths and file-wise code summaries from a application codebase.
    1. Analyze the file summaries carefully, leveraging your expertise to deduce the frameworks, functionality, and features.
    2. Perform a critical assessment of the code's functionality and interdependencies before responding.
    3. The codebase is complex and likely contains dependencies across various modules. Be mindful of these.
    4. Analyse every file summary and assign the features and sub-features based on the information provided.
    5. Respond strictly in the structured JSON format provided below.
    6. In each sub-feature's 'file_path' array:
        - Set 'critical: true' ONLY for files that are CORE & NON-REPLACEABLE to the sub-feature's main functionality.
        - Set 'critical: false' for ALL supporting, secondary, or replaceable files  
        - Each sub-feature should have both true and false entries.
        - If unsure, default to false (be EXTREMELY selective with 'true')
        - Make sure each sub-feature atleast have one file as true.

    Explanation of the Output terms:
    Feature - Features are most valuable and high level features extracted from the list of summaries that are provided to you. 
    Feature description - Description of the features explaining the high level value and impact that it creates for the project. Define the Feature. The description should be crisp, precise, well formatted and must be between 2-3 lines.
    Subfeature - Subfeatures are micro most valuable features that are extracted from the list of summaries and belong to the Most related and similar Features.
    Subfeature description - Description of the subfeatures explaining the specific value, technical and non-technical functionalites that it provided to the project. Define the subfeature and also explain how its related to the feature. The description should be crisp, precise, well formatted and must be between 2-3 lines.
    
    Points to Remember:
    1. Do not extract any feature or subfeature where there are no reference/citations from the application summaries.
    2. The description must be precise, valuable, well-formatted and must be between 2-3 lines.
    3. The Feature titles should be precise, specific, self explanaible, independent and not have similar feature titles. The Feature titles should not be highly generalized.
    4. The SubFeatures titles should be precise, self explanaible and not have similar subfeature titles. The SubFeature titles should not be highly generalized.
    5. SubFeatures should not be very low level that it explains code functions, code process like 'Json handling', 'Reading csv', readME etc.
    6. If similar subfeatures are present, then group them under one common Feature itself. Do not create multuple Features for similar subfeatures.
    6. If Unit testing related summaries are found, then create that as another Feature named 'Unit Testing' and assign the specific testing subfeatures under this feature.
    </Task 1>

  <Task 2>
  You shall now Assign and Justify Confidence Scores for each feature.

  <Critical Evaluation of Confidence Scores> 

  <Evaluation MODE>
  - You will now Forget everything that was done beforehand and act as an unbiased judge.
  - $Project-Summaries-&-Paths (INPUT).
  </Evaluation MODE>
  <Important>
  Critically analyze every "Feature" and "SubFeature" based on the following metrics. 
  You shall generate a confidence score between 0-100 for each of the following :
  1. Is the "Feature" & "SubFeature" name accurate to its functionality ? (Accuracy)
  2. Does the "Feature" & "SubFeature" include files with an unrelated function ? (Feature Dilution Rate)
  3. Important : Does this "Feature" & "SubFeature" make sense given the Overall Purpose of the Application ? (Consistency)
  4. Are all the files in "Feature" & "SubFeature" included ? (Completeness)

  <Strict>
  1. You will now generate a list of 4 confidence scores between 0-100 for above criteria under "confidence_score" key.
  2. Based on above criteria, you shall provide a VERY BRIEF logical explanation (10-20 words) for Confidence Score under "confidence_score_justification" key.
  3. Make sure to mention the entire filepath without omitting the prefix.
  4. Make sure all the filepaths are present.
  <Important> STRICTLY Don't Comment on Missing Files. Don't Overestimate. Don't Underestimate.</Important> 
  </Strict>

  </Important>

  </Critical Evaluation of Confidence Scores> 
  </Step 2>


      <Output_Format>
    Return a response in JSON format. Do not include any extra information or explanations. Strictly DON'T deviate from mentioned KEYS.
    Example:
```json
[
  {
    "name": "User Authentication and Management",
    "feature_description": "Comprehensive user account system with secure login, registration, profile management, and role-based access control.",
    "feature_description_confidence_score": [95, 70, 100, 70],
    "sub_features": [
      {
        "name": "User Registration",
        "description": "Allows new users to create accounts by providing necessary information such as username, email, and password. Implements email verification, password strength checks, and duplicate account prevention. Stores user data securely in the database with password hashing.",
        "file_path": [
          {
            "module_name": "RegistrationController",
            "path": "Controllers/Account/RegistrationController.cs",
            "critical": true
          },
          {
            "module_name": "RegisterView",
            "path": "Views/Account/Register.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [75, 80, 85, 65],
        "sub_feature_confidence_score_justification": "No feature dilution, might have missed some file."
      },
      {
        "name": "User Login",
        "description": "Authenticates users using their credentials, creates and manages user sessions, and implements security measures such as login attempt limiting and two-factor authentication (2FA). Provides password reset functionality for forgotten passwords.",
        "file_path": [
          {
            "module_name": "LoginController",
            "path": "Controllers/Account/LoginController.cs",
            "critical": true
          },
          {
            "module_name": "LoginView",
            "path": "Views/Account/Login.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [80, 100, 80, 75],
        "sub_feature_confidence_score_justification": "High chance of missing files."
      }
    ],
    "feature_confidence_score_justification": "No feature dilution, duplication or missing files. Accurate Naming."
  },
  {
    "name": "Product Catalog Management",
    "feature_description": "Comprehensive system for managing product listings, categories, and inventory across the e-commerce platform.",
    "feature_description_confidence_score": [95, 65, 70, 80],
    "sub_features": [
      {
        "name": "Product CRUD Operations",
        "description": "Enables administrators to create, read, update, and delete product listings. Includes functionality for managing product details such as name, description, price, images, and inventory levels. Implements validation to ensure data integrity and consistency across the product catalog.",
        "file_path": [
          {
            "module_name": "ProductController",
            "path": "Controllers/ProductController.cs",
            "critical": true
          },
          {
            "module_name": "ProductView",
            "path": "Views/Product/Index.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [90, 85, 100, 70],
        "sub_feature_confidence_score_justification": "High confidence with no duplication or dilution."
      },
      {
        "name": "Category Management",
        "description": "Allows for the creation and management of product categories and subcategories. Implements a hierarchical structure for organizing products, enabling efficient navigation and filtering of the product catalog for both administrators and customers.",
        "file_path": [
          {
            "module_name": "CategoryController",
            "path": "Controllers/CategoryController.cs",
            "critical": true
          },
          {
            "module_name": "CategoryView",
            "path": "Views/Category/Index.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [85, 75, 90, 95],
        "sub_feature_confidence_score_justification": "High confidence without any duplication or dilution."
      }
    ],
    "feature_confidence_score_justification": "All files refer to single overall functionality. Might have missed some files."
  }
]
```
  </Output_Format>

"""

generate_features_user_message = """
<Strictly Remember>
1. As input you will be given a batch of `file_path` and `file_summary` from a production codebase. Keep it in mind that it could be a file from a very large repository with lot of inter-dependencies.
2. Understand all the file description first, then try to determine the feature, sub-features and their description. For **each file** it should have a feature or sub-features whenever the conditions are met.
3. The response should contain all the fields given in the example output format. The response should be strictly in json format.
4. The description of features/subfeatures must be in the length of 2-3 lines. The response should be structured and well-formatted.
5. Don't generate any additional explanation or description. Provide the structured response in json only.
</Strictly Remember>
  
<Input file wise summary>
{file_summary}
</Input file wise summary>
<Response>
"""

merge_features_in_hierarchy_user_prompt = """You are a software feature analyzer. Given a list of related features that have been clustered together, create a merged feature that encompasses all the functionality.

Features to merge:
{feature_list}

Generate a JSON response that includes:
1. A name for the merged feature representing accurate feature name. Do not mention its merged or unified or anything as such. The feature name should accurately represent a major funcationality of a repository.
2. A detailed description that covers all functionality
3. A confidence score (0-100) for the merge
4. A justification for the confidence score

Respond with a JSON object in the following format:
```json
{{
    "name": "Merged feature name",
    "description": "Comprehensive description",
    "confidence_score": 85,
    "confidence_justification": "Reason for the confidence score"
}}
```
Give only JSON and nothing else. Do not include any explanations or additional text outside the JSON block. Make sure to start with ```json and end with ``` only.
"""

mapping_names_for_merged_features_user_prompt = """  <Role>
    You are a smart AI cassistant with strong expertise in Software Engineering. You can understand complex, production-grade codebases written in various programming languages and summarize them effectively.
  </Role>
  <Task>
  You will be given a brief description of  features of a large codebase and your task is to generate a relevant feature name, brief description, and priority level.
  <Important>
   1. The feature name should be brief, relevant and should represent the entire description provided.
   2. Generate a relevant description which is basically a overall summary of the description provided.
   3. Assign a priority level (high, medium, low) based on the significance, importance and complexity of the feature to the overall system. 
  </important>
  </Task>
  <Example output>
  ```json
    {
        "name": <feature_name>, //string
        "feature_description": <feature_description>, //string
        "priority": <priority> //string (high, medium, or low)
    }
    ```
  </Example output>
  <Strictly Remember>
1. The feature name should be relevant and at the same time interpretable, easy to understand.
2. The feature description should represnt the entire description given for summarisation, it should be simple and easy to understant.
3. The priority should be one of: high, medium, or low.
4. The response should be strictly in json format specified above.
5. Strictly make sure Feature Description is not more than 200 words.
  </Strictly Remember>

<code summary>
The code summary is given below:
"""


reducing_sub_features_user_prompt = """
    You are a software feature consolidation expert. Your task is to merge similar sub-features into one comprehensive sub-feature.

    Here are the sub-features that need to be merged:
    {sub_features_list}

    For each sub-feature, we have:
    - Name: The sub-feature name
    - Description: The sub-feature description (if available)
    - Confidence Score: The confidence score (if available)

    Your output should be a JSON object containing:
    1. A unified sub-feature name that encompasses all the input sub-features
    2. A comprehensive description that covers all aspects of the input sub-features
    3. A confidence score (use the highest available from input sub-features)
    4. A justification for the confidence score

    Return the output in JSON format starting with ```json and ending with ```.

    Example output format:
    ```json
    {{
        "name": "Unified Sub-Feature Name",
        "description": "Comprehensive description covering all aspects",
        "sub_feature_confidence_score": 95,
        "sub_feature_confidence_score_justification": "Merged from similar sub-features with high semantic similarity"
    }}
    ```
    """


post_processing_feature_name_description_system_prompt="""
  <Role>
    You are a smart AI assistant with strong expertise in Software Engineering. You can understand complex, production-grade codebases written in various programming languages and summarize them effectively.
  </Role>
  <Task>
  You will be given a brief description of modules or features of a large codebase and your task is to generate a relevant feature name and brief description.
  <Important>
   1. The feature name should be brief, relevant and should represent the entire description provided.
   2. Generate a relevant description which is basically a overall summary of the description provided.
   3. Also generate a confidence score in a scale of 0 - 100.
  </important>
  </Task>
  <Example output>
  ```json
    {
        "name": <feature_name>,
        "feature_description_confidence_score": <score 0 - 100>,
        "feature_description": <feature_description>
    }```
  </Example output>"""

post_processing_feature_name_description_user_prompt = """<Strictly Remember>
1. The feature name should be relevant and at the same time interpretable, easy to understant.
2. The confidence score should represent the ability to summarise the description.
3. The feature description should represnt the entire description given for summarisation, it should be simple and easy to understant.
4. The response should be strictly in json format specified above.
</Strictly Remember>
<code summary>
The code summary is given below: \n
{feature_description}
</code_summary>
<response>
Your response in json goes here:
"""

merge_similar_features_system_prompt = """You are a solution architect. Your task is to carefully review each feature and its description, and combine them into a single high-level feature.

The final high-level features should represent what an end user would perceive, e.g., Messenger, Google Chat, Messaging, Reels, etc.

Based on the generated features provided, identify which features can be merged into a single high-level feature. 
Strictly output them in the following format:
{{ 
  <High-Level Feature Name 1>: [<Merged Feature 1>, <Merged Feature 2>, <Merged Feature 3>, ...],
  <High-Level Feature Name 2>: [<Merged Feature 1>, <Merged Feature 2>, <Merged Feature 3>, ...],
  ...
}}

INPUT:
Feature names and descriptions are provided in the format: 
[1. Feature name: <feature name> 
Feature description: <feature description>, 
2. ...]

{feature_texts}

MVFS:
{total_MVFs}

Points to remember:
1. While merging features and naming high-level features, always prefer names from the user-defined MVFs provided. All relevant features can be grouped under these high-level features.
2. If certain features do not fit under the user-defined MVFs, choose a better name than the existing one for the new high-level feature if necessary.
3. The names of the features being merged must remain exactly as provided in the INPUT section; do not modify them. Do not consider Feature description in Feature Names.
4. Follow the output structure strictly: high-level feature names as dictionary keys and merged features as values in list format.
5. If a feature is already a high-level feature, you do not need to forcibly merge it. If a feature seems to be function-level/low-level  features, merge them into a High-level feature.
6. Merge similar features into a single high-level feature based on their names and descriptions, when applicable. Each final high-level feature should be independent of the others.
7. Do not assign the same feature to multiple high-level features.
8. If user-defined MVFs are empty, skip point 1 and begin with point 2.
9. Do **not** include any Feature descriptions in the final output."""


merging_description_user_prompt = """You are a Solution Architect. Your task is to summarize the multiple feature descriptions provided into a brief, coherent summary of **no more than two sentences**.

  The summary must:
  - Accurately capture all key components from the provided descriptions.
  - Align clearly with the given high-level feature name.
  - Serve as the final description of the high-level feature.

  Only the final summarized description should be included in the output â€” no additional commentary or formatting.

  INPUT:
  Multiple descriptions: {merging_feature_description}

  High-Level Feature Name: {high_level_feature}
  """


micro_sub_feature_prompt = """You are an expert system analyst specializing in decomposing SubFeatures into granular, logically independent components. You support **two levels** of splitting:

1. **Horizontal splitting**: Split a subfeature into multiple *same-level subfeatures* when it encompasses multiple independently meaningful functionalities. The subfeatures created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.
2. **Vertical splitting**: Further break each of those subfeatures into *microsubfeatures* (if applicable), ensuring each micro-sub-features/micro-user-story describes a single goal or operation. The micro-sub-features/micro-user-story created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.

---

### ðŸ”§ TASK OVERVIEW

Given a Macro-Feature, Subfeature, its description, associated module files and its summary:

- Decide if the subfeature should be split horizontally into multiple same-level subfeatures.
- For each resulting subfeature (or original if not split), analyze whether it can be split vertically into **microsubfeatures** (fine-grained user stories).
- Provide the confidence scores for the subfeature that is split, whether horizontally or vertically.
- Provide the files that are related to the sub_features too, not just the micro_sub_features.
- Each leaf user-story must have files assigned to them, else you should not create/split these subfeatures.
- Provide description of generated subfeature/sub-user-stories in 2-4 lines but only valid information. Do not assume or hallucinate to generate description.
Apply this recursively: if horizontal splitting occurs, then attempt vertical splitting for each. But remember, not to create any duplicates in the process. 

---

### SPLITTING DECISIONS

#### Horizontal Splitting (Same-level Subfeatures):
Split if:
- The subfeature covers multiple high-level functionalities
- Each function could be planned, developed, and deployed independently
- Each component has a clear boundary and responsibility

#### Vertical Splitting (Microsubfeatures):
Split further if:
- A subfeature contains multiple independent operations or logical stages
- These operations can be implemented, tested, or tracked separately
- Each micro-subfeature represents one atomic, non-overlapping functionality

---

### DO NOT SPLIT IF:
- sub-user-stories are tightly coupled in the Subfeature and cannot function independently.
- Do not split subfeatures into sub-user-stories that are hardly single line of code and cannot be considered as a proper functionality, but just a config/parameter.
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across actions are too complex to isolate.
- There are no files that can be mapped to the generated user-story.
- Do not split if the user-story is barely a functionality. The split user-stories must have independent functionality that contributes to the subfeature and feature and if not, do not split.
- Don not split ReadMe & .md files into sub-user-stories.
- Do not split horizontall for granullar subfeatures as they are not user stories but mid level features.
---

### FILE MAPPING RULES:
- For each subfeature or microsubfeature, cite only directly relevant files.
- Use only the provided input data to match files â€” no guessing.
- Avoid duplication unless a file is clearly shared between components.

Each `file_path` entry must include:
```json
{
  "module_name": "<Name>",
  "path": "<Path>",
  "critical": <true/false>,
  "git_url": "<Git URL>"
}

OUTPUT FORMAT
If the subfeature should NOT be split:
Return: "None"

If the subfeature should be split, return a list of Parent User Stories with subfeatures inside.
If a subfeature itself can be further split into microsubfeatures, nest them under micro_sub_features like so:

[
  {
    "name": "Parent User Story Title 1",
    "description": "Full description of the original or updated user story and its purpose.",
    "file_path": [...],
    "sub_feature_confidence_score":"confidence score of the subfeature with respect to the Feature, as a percentage (e.g., 80)"
    "micro_sub_features": [
      {
        "name": "Sub-User Story Title 1",
        "description": "Standalone description of a single functionality.",
        "file_path": [...],
        "micro_sub_feature_confidence_score":"confidence score of the micro_sub_feature with respect to the sub_feature, as a percentage (e.g., 90)"
        }
          ...
        ]
      },
      ...
    ]
  }
]
Each layer must preserve independence, clarity, and singular focus of each story.

VALIDATION CHECKLIST
- Each title must express one functionality only (no imperative phrasing)
- description must avoid assumptions and describe the real function. It must be as detailled as possible.
- Each story must make sense independently and fit in the broader feature flow
- if there are multiple user-story under the subfeature, it needs to be in sequence of business logic.
- File mappings must be relevant and scoped accurately
- Do no miss/skip any values in the output json. The output structure must be maintained strictly.
- All subfeature and sub-user-story names and descriptions must be strictly in a declarative tone, not imperative.

* Use generic or speculative statements
"""


db_micro_sub_feature_prompt = """
<Role>
You are an expert Database analyst specializing in decomposing SubFeatures into granular, logically independent components. You support **two levels** of splitting:
You shall ALWAYS process features from a Database perspective ONLY. 
There can be more than one Table in the DB context provided to you.
</Role>

1. **Horizontal splitting**: Split a subfeature into multiple *same-level subfeatures* when it encompasses multiple independently meaningful functionalities. The subfeatures created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.
2. **Vertical splitting**: Further break each of those subfeatures into *microsubfeatures* (if applicable), ensuring each micro-sub-features/micro-user-story describes a single goal or operation. The micro-sub-features/micro-user-story created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.

<Strict Constraints> 
- You are dealing with Database Information. 
- No matter what, STRICTLY use Database-Specific Language ALWAYS. 
- Use words like Columns / Fields / Schema / DataTypes / Constraints / Foreign Keys / Primary Keys etc.
- Strictly Do not start descriptions with or start with "this micro-feature" / or "this sub-feature".
- You shall do this regardless of the input context and nature.
Remember : Every "FILE" given to you is information of a table. Therefore in your response, ALWAYS refer to "Table" instead of "File".

</Strict Constraints> 


### ðŸ”§ TASK OVERVIEW

Given a Macro-Feature, Subfeature, its description, associated module files and its summary:

- Decide if the subfeature should be split horizontally into multiple same-level subfeatures.
- For each resulting subfeature (or original if not split), analyze whether it can be split vertically into **microsubfeatures** (fine-grained user stories).
- Provide the confidence scores for the subfeature that is split, whether horizontally or vertically.
- Provide the files that are related to the sub_features too, not just the micro_sub_features.
- Each leaf user-story must have files assigned to them, else you should not create/split these subfeatures.
- Provide description of generated subfeature/sub-user-stories in 2-4 lines but only valid information. Do not assume or hallucinate to generate description.
Apply this recursively: if horizontal splitting occurs, then attempt vertical splitting for each. But remember, not to create any duplicates in the process. 

---

### SPLITTING DECISIONS

#### Horizontal Splitting (Same-level Subfeatures):
Split if:
- The subfeature covers ONE / MORE THAN ONE high-level functionalities
- Each function could be planned and developed independently
- Each component has some clear boundaries and responsibilities

#### Vertical Splitting (Microsubfeatures):
Split further if:
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across actions are too complex to isolate.
- There are no tables that can be mapped to the generated user-story.
- The subfeature is too complex to be planned, developed, and deployed independently
- Each micro-subfeature represents one atomic, non-overlapping functionality
Note: Maintain at least 2 subfeatures unless the database has only one table.
- Prioritize brevity, consistency and no informaiton leakage across subfeatures.
- Ensure crisp segregation.
---

### DO NOT SPLIT IF:
- sub-user-stories are tightly coupled in the Subfeature and cannot function independently.
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across tables in two features are too complex to isolate.
- There are no tables that can be mapped to the generated user-story.
Note: Maintain at least 2 subfeatures and 1 or more microsubfeatures per subfeature, Unless the database has only one table.
Note : Maintain brevity during splitting at the same level. Do NOT overload the a single feature with too many subfeatures.
---


### FILE MAPPING RULES:
- For each subfeature or microsubfeature, cite only directly relevant tables.
- Use only the provided input data to match files â€” no guessing.
- Avoid duplication unless a file is clearly shared between components.

Each `file_path` entry must include:
```json
{
  "module_name": "<Name>",
  "path": "<Path>",
  "critical": <true/false>,
  "git_url": "<Git URL>"
}

OUTPUT FORMAT
If the subfeature should NOT be split:
Return: "None"

If the subfeature should be split, return a list of Parent User Stories with subfeatures inside.
If a subfeature itself can be further split into microsubfeatures, nest them under micro_sub_features like so:

[
  {
    "name": "Parent User Story Title 1",
    "description": "Full description of the original or updated user story and its purpose.",
    "file_path": [...],
    "sub_feature_confidence_score":"confidence score of the subfeature with respect to the Feature, as a percentage (e.g., 80)"
    "micro_sub_features": [
      {
        "name": "Sub-User Story Title 1",
        "description": "Standalone description of a single functionality.",
        "file_path": [...],
        "micro_sub_feature_confidence_score":"confidence score of the micro_sub_feature with respect to the sub_feature, as a percentage (e.g., 90)"
        }
          ...
        ]
      },
      ...
    ]
  }
]
Each layer must preserve independence, clarity, and singular focus of each story.

VALIDATION CHECKLIST
- Each title must express one functionality only (no imperative phrasing)
- description must avoid assumptions and describe the real function. It must be as detailled as possible.
- Each story must make sense independently and fit in the broader feature flow
- if there are multiple user-story under the subfeature, it needs to be in sequence of business logic.
- File mappings must be relevant and scoped accurately
- Do no miss/skip any values in the output json. The output structure must be maintained strictly.
- All subfeature and sub-user-story names and descriptions must be strictly in a declarative tone, not imperative.
- Use Database-specific schema only. Do not include words like "Attributes" / "Code Files" in your response. 
- Strictly Do not start descriptions with or start with "this micro-feature" / or "this sub-feature".
* Use generic or speculative statements

"""import os
from graphviz import Digraph
import re 
import json

def parse_ddl(ddl: str):
    """
    Parse the DDL to extract columns, primary keys, and foreign keys.
    """
    lines = ddl.splitlines()
    column_lines = []

    for line in lines:
        line = line.strip()
        if (
            line.upper().startswith("CREATE")
            or line.upper().startswith("PRIMARY")
            or line.upper().startswith("FOREIGN")
            or line.upper().startswith(")")
            or line == ""
        ):
            continue

        match = re.match(r'(\w+)\s+\w+', line)
        if match:
            column_lines.append(match.group(1))

    pk_match = re.search(r'PRIMARY KEY\s*\((.*?)\)', ddl)
    primary_keys = [key.strip() for key in pk_match.group(1).split(",")] if pk_match else []

    foreign_keys = []
    for match in re.finditer(r'FOREIGN KEY\s*\(([^)]+)\)\s+REFERENCES\s+`?[\w]+\.(\w+)`\(([^)]+)\)', ddl):
        fk_col = match.group(1).strip()
        ref_table = match.group(2).strip()
        ref_col = match.group(3).strip()
        foreign_keys.append((fk_col, ref_table, ref_col))

    return column_lines, primary_keys, foreign_keys


def generate_combined_graph(tables_data):
    """
    Generate a single combined graph from multiple tables.
    """
    dot = Digraph(comment='Combined Table Diagram')
    dot.attr(rankdir='LR')

    # Store individual table nodes
    for table in tables_data:
        table_name = table['table_name']
        columns = table['columns']
        primary_keys = table['primary_keys']
        
        label_lines = []
        for col in columns:
            if col in primary_keys:
                label_lines.append(f"{col} [PK]")
            else:
                label_lines.append(col)
        dot.node(table_name, shape='box', label=f'{table_name}\\n' + "\\n".join(label_lines))

    # Add relationships
    for table in tables_data:
        table_name = table['table_name']
        for fk_col, ref_table, ref_col in table['foreign_keys']:
            dot.edge(table_name, ref_table, label=f'{fk_col} â†’ {ref_col}')

    return dot

def folder_summary_generation_prompts(
        total_allocated_tokens, 
        file_list, folder_name, 
        folder_path,
        subfolder_list,
        formatted_file_summaries,
        formatted_file_services,
        formatted_subfolder_summaries,
        formatted_subfolder_services,
        formatted_subfolder_features
    ):
    
    system_prompt = f"""
        You are an expert code analyst specialized in creating detailed, informative summaries of software project folders. Your task is to thoroughly analyze files and subfolders to provide a comprehensive understanding of the application or project and provide combined summaries along with required details. These summaries must be detailled enough for further summarization.

        Follow these guidelines:
        1. Conduct a deep analysis of the features to identify its core purpose and functionality
        2. Provide detailed explanation of key implementations and technical approaches of the features
        3. Thoroughly examine the summaries based on files and folders to understand relationship between features and combined smaller features into larger high level application level features.
        4. Explain the features within the broader project architecture with specific connections
        5. Describe technical patterns, design decisions, and architectural choices evident in the code
        6. Include specific functions, classes, and methods that define the feature's behavior
        7. Note dependencies, imports, and external connections that shape the folder's functionality
        8. Identify potential architectural strengths and areas for improvement when evident
        9. Identify all services represented in this folder based on file and subfolder services information
        10. Identify and articulate high-level features or functionalities represented by the folder into the feature_details section, when consolidating multiple subfolders or lower-level files. Derive these insights from both file-level and subfolder-level summaries. Also under each feature, mention which file/folder was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
        11. Do not miss any features that could be formed based on these summaries as this information is required to understand the application's buisness logic.
        12. Gather insights from the summaries provided to generate a high level detailled executive summary that could be used by business stakeholders to understand the folder/project.
        13. When analyzing the root folder, both the executive summary and the features must be strictly formed in a high level business logic standpoint of an application.
        
        IMPORTANT: 
        - Your summary should be thorough and detailed({total_allocated_tokens}) while maintaining technical/business precision and depth. Focus on providing insights that would help both stakeholders and developers understand the application better.
        - feature_details must contain high level feature name and feature description(value of the files/folders) strictly in concise bullet points. The feature inforamtion must be in detail to capture the complete high level knowledge for that feature but not the function level details. Feature names cannot be programmatic function names like Dependency management, json handling etc. instead it should be inventory management, order processing etc. 
        - Your services list should be comprehensive and include all services represented in this folder.
        - is_reuasble_lib if a folder is used as reusable lib make it True otherwise False
        - lib_name if is_reusable_lib is True then provide the name of the reusable lib/component If is_reusable_lib False then add Not Applicable
        - category if is_reusable_lib is True then provide category only between 'Frontend' and 'Backend' If is_reusable_lib False then add Not Applicable
        - sub_category if is_reusable_lib is True then provide sub category only between 'UI Component','Custom Hooks', 'http_client', 'Utils', 'Others' In Frontend & 'Middleware', 'Error Handling', 'Auth', 'Utils', 'Others' In Backend If is_reusable_lib False then add Not Applicable
        - when_to_use if is_reusable_lib is True then provide where this reusable lib/component can be used If is_reusable_lib False then add Not Applicable 
        - associated_files if is_reusable_lib is True then provide the list of files associated(give complete path for the assosciated file) with this reusable lib/component If is_reusable_lib False then add Not Applicable
        - summary must not be technical and only explain the high level details of the folder/project. Understand the file and folder summaries provided to combine the knowledge to form the executive summary. Make it as detailled as possible.
        - Use clear and concise language, avoiding jargon where possible.
        
        - You must provide your response in this exact format:
        ```summary
        [Your detailled high-level executive summary for the folder for business stakeholders]
        ```
        ```feature_details
        [List of high-level features or functionalities represented in this folder]
        ```
        ```services_namess
        [Comma-separated list of all services represented in this folder]
        ```
        ```is_reuasble_lib
        Boolean Value
        ```
        ```lib_name
        [Name of the reusable library if applicable]
        ```
        ```category
        [Category of the reusable library if applicable]
        ```
        ```sub_category
            [Sub category of the reusable library if applicable]
        ```
        ```when_to_use
        [Your detailed use case where or when this reuasble_lib can be usefull]
        ```
        ```associated_files
            [Comma-separated list of associated files with the reusable library, Give the Complete file path as mentioned in the file list]
        ```
        ```example_usage
            [Example code snippet of how to use this reusable library]
        ```
    """

    user_prompt = f"""
        Generate a summary and services list for the folder: "{folder_name}" (Path: {folder_path})

        FOLDER CONTENTS:
        - Files ({len(file_list)}): {", ".join(file_list) if file_list else "None"}
        - Subfolders ({len(subfolder_list)}): {", ".join(subfolder_list) if subfolder_list else "None"}

        FILE SUMMARIES:
        {os.linesep.join(formatted_file_summaries) if formatted_file_summaries else "No file summaries available"}

        FILE SERVICES:
        {os.linesep.join(formatted_file_services) if formatted_file_services else "No file services available"}

        SUBFOLDER SUMMARIES:
        {os.linesep.join(formatted_subfolder_summaries) if formatted_subfolder_summaries else "No subfolder summaries available"}

        SUBFOLDER SERVICES:
        {os.linesep.join(formatted_subfolder_services) if formatted_subfolder_services else "No subfolder services available"}

        SUBFOLDER FEATURES:
        {os.linesep.join(formatted_subfolder_features) if formatted_subfolder_features else "No subfolder features available"}
        
        Based on these components:
        1. Provide a thorough technical summary explaining the folder's purpose, implementation details, and architectural significance
        2. Compile a comprehensive list of all services represented in this folder based on file and subfolder services information
        
        Follow the exact format specified in the system instructions for your response.
    """

    return system_prompt, user_prompt

def services_generation():
    system_prompt = """
        <Task>
        Create an architectural blueprint of the given repository by identifying and classifying both external services and third-party services with no overlap between categories.
        </Task>

        <Definitions>
        - External services: Company-provided services hosted outside the application (AWS S3, Google Cloud, Stripe, Twilio)
        - Third-party services: Libraries, frameworks, and SDKs that are part of the core application stack (Django, React, MongoDB, Redux)
        </Definitions>

        <Output_Format>
        {
        "external_services": [
            {
            "external_service_name": "string",
            "description": "string",
            "associated_files": ["string"],
            "service_class": "string",
            "used_in_files": ["string"]
            }
        ],
        "thirdparty_services": [
            {
            "thirdparty_service_name": "string",
            "description": "string",
            "associated_files": ["string"],
            "service_class": "string",
            "used_in_files": ["string"]
            }
        ]
        }
        </Output_Format>

        <Instructions>
        1. Conduct a thorough repository analysis to identify all services
        2. Classify each service into exactly ONE category:
        - External services: Cloud platforms, payment processors, authentication providers
        - Third-party services: Frameworks, libraries, SDKs integrated into the codebase
        3. For each service, provide:
        - Name: Exact service name
        - Description: Concise explanation of functionality and purpose
        - Associated files: All files directly importing or using the service
        - Service class: Category (e.g., "cloud storage", "web framework", "database")
        - Used in files: Complete paths of files utilizing the service
        4. Ensure ZERO overlap between categories
        5. Prioritize accuracy over comprehensiveness
        6. Validate that identified services are actively used in the project
        7. Include only services with clear evidence of implementation
        8. Do not create a lot of services which are redundant. Keep it to a maximum of 50 services only.
        </Instructions>

        <Examples>
        Good External Service Entry:
        {
        "external_service_name": "AWS S3",
        "description": "Cloud storage service used for storing user-uploaded files",
        "associated_files": ["src/services/storage.js", "src/config/aws.js"],
        "service_class": "cloud storage",
        "used_in_files": ["src/components/FileUpload.js", "src/pages/UserProfile.js"]
        }

        Good Third-Party Service Entry:
        {
        "thirdparty_service_name": "React",
        "description": "Frontend JavaScript library for building user interfaces",
        "associated_files": ["package.json", "src/index.js"],
        "service_class": "frontend framework",
        "used_in_files": ["src/App.js", "src/components/*.js"]
        }
        </Examples>

        Analyze the repository and provide the complete architectural blueprint in the specified format.
    """

    user_prompt = ""

    return system_prompt, user_prompt

def executive_summary_generation(combined_summary, user_mvf):
    system_prompt = """
    Your Role:
    You are an expert software architect tasked with understanding a codebase and creating an executive summary that clearly articulates the main purpose of this application,
    the core problem that the application is solving, and the prioritized list of the most valuable features, solely based on the provided folder wise summary. Do not hallucinate and create the most valuable features and its description on assumption. This needs to be based on facts.

    Task:
    1. Analyze provided folder wise summary and the services used and the user defined features (if provided).
    2. Understand component interactions and functions.
    3. Prioritize the User Defined Features (if provided) in the summary.
    4. Identify and prioritize the most valuable features based on their importance and relevance to the overall project, as evidenced in the code.
    5. Create a comprehensive executive summary.

    Steps:
    1. Review folder wise summary.
    2. Analyze folder wise summary:
    - Identify key components and their roles
    - Note data operations, design patterns, and architectural decisions
    3. Create summary:
    - Describe the specific problem the codebase solves, based on folder wise summary
    - Explain component interactions
    - Outline data workflow
    4. Identify and prioritize main features:
    - Determine which feature(s) address the core problem of the application, based on code implementation
    - Rank features based on their importance and relevance to solving the main problem, as evidenced in the code
    - The feature should be major components of the codebase and not minor functions like "Modular Architecture" or "Code Reusability", these are not features but design principles.

    Focus Areas:
    - Precised feature prioritization and importance
    - High-level functionality
    - Clear, concise technical language
    - Objective description
    - Capture entire workflow

    Guidelines:
    - Only use the folder wise summary provided
    - Use precise technical terms
    - Include user-defined features if provided and evidenced in the code
    - Prioritize features based on their importance to the core problem, as shown in the folder wise summary

    Feature Identification and Prioritization:
    - Carefully analyze the folder wise summary to identify features actually present in the folder wise summary
    - Do not assume or infer features that are not explicitly mentioned in the folder wise summary
    - Identify the top feature that solves the majority of the problem based on code evidence
    - Rank subsequent features in descending order of importance, ensuring they are present in the folder wise summary
    - Ensure the feature list reflects the codebase's focus and structure
    - Only include features that have substantial implementation in the codebase that is evident from folder wise summary

    Output Format - Adhering to this format is crucial
    ```json
    {
    "data": "generated_summary in string format adhering to the Expected Output Format for Generated Summary",
    "confidence_score": 90,
    "traceback": {
    "Feature 1 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 1 Title' is included, as the 'phrase' is an evidence that this feature is part of the codebase.",
    "Feature 2 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 2 Title' is included, as the 'phrase' is an evidence that this feature is part of the codebase.",
    ...
    }
    }
    ```

    Requirements:
    - Replace \n with \\n in JSON
    - Limit upto 5 main features (max 2 sub-features each) or 7500 tokens
    - If due to any reason such as codebase being small, you are unable to provide 5 features, then provide as many high-level features as possible between the range of 1 to 5.
    - Don't assume features or include minor features due to inability to provide 5 features, lesser number of features is acceptable.
    - Use specified JSON format only
    - Start with "```json" and end with "```"
    - Ensure the top feature in the prioritized list addresses the core problem and is present in the folder wise summary
    - Rank features in descending order of importance to the main problem, based on actual code implementation
    - Do NOT include features that are NOT evidenced in the provided folder wise summary
    - Evaluate the folder wise summary objectively, considering all conclusions on the actual code provided
    - Do NOT make any assumptions about organizational goals or intentions beyond what is explicitly shown in the code
    - Focus solely on the technical aspects and implemented functionality, avoiding speculation about business objectives or future plans
    - Both the keys data, confidence score, and traceback should be present in the output JSON
    - The generated summary should be in string format only and be contained inside the "data" key
    - The "traceback" key should contain a dictionary with feature names as keys and justifications for including these features based on exact phrases from the input
    - Do not include any feature that could potentially be part of the folder wise summary without explicit evidence
    - Every feature mentioned must be driven by clear evidence from the provided input
    """
    user_prompt = """
    Expected Output Format for Generated Summary:

  **Overview**
  <empty line>
  <A brief introduction to the codebase and its main purpose; in paragraph format only, not in points.
  This paragraph should provide a concise yet comprehensive overview of the codebase, its primary functionality, solution provided by the project and its intended use case.
  Aim for 3-5 sentences that capture the essence of the project.>
  <empty line>
  **Highlighted Features**
  <empty line>
  <
  List and briefly explain the key features that are significant components of the codebase and would serve as selling points.
  These features should be presented as follows:
  1. Use numbered points for each feature.
  2. Provide a brief explanation for each feature in 1-2 sentences, highlighting its importance and benefit to the end user.
  3. Focus on features that are central to the codebase's functionality and most important to the end user.
  4. Dont include generic features like "Modular Architecture" or "Code Reusability", these are not features but design principles.
  5. Do not include sub-points under any feature.
  6. Prioritize User Defined Features (if provided) at the beginning of the list.
  7. If User Defined Features are given, list them first before including any features identified through your analysis.
  8. Aim to provide upto of 1 to 5 key features, after each feature add an empty line for formatting purposes.
  9. Ensure that the features listed represent the core functionality and unique selling points based on the folder wise summary.
  10. Use clear, concise language that emphasizes the value proposition of each feature.
  11. Also under each feature, mention which file/folder was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
  12. Do not add features into Highlighted Features if they dont have value for buisness stakeholder about the application. Also do not repeat adding similar feature in this section.

  Output Structure:
  1. ***<Feature 1 Title>***: <Description of the feature in one to two sentences.\n
  2. ***<Feature 2 Title>***: <Description of the feature in one to two sentences.>\n
  >
  <empty line>
  **Key Benefits**
  <empty line>
  <Summarize the key benefits of the codebase in one to two sentences.
  This summary should encapsulate the overall value proposition of the codebase and its potential impact on users or the organization.>
  <empty line>
  <Highlight the most significant key benefits the codebase has to offer in bulleted points. The format should be:
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  Aim for 3-5 bullet points that capture the most compelling advantages of using this codebase, after each point add an empty line for formatting purposes.
  Each benefit should be distinct and provide a clear value proposition.>

  <Final Output Format>
  Output Format - Adhering to this format is crucial, the output should be in parsable JSON format:
  ```json
  {{
    "data": "<generated_summary in string format adhering to the Expected Output Format for Generated Summary>",
    "confidence_score": 90,
    "traceback": {{
      "Feature 1 Title": "Since it mentions about <exact phrase from the folder wise summary>, the 'Feature 1 Title' is included, as the "phrase" is an evidence that this feature is part of the folder wise summary.",
      "Feature 2 Title": "Since it mentions about <exact phrase from the folder wise summary>, the 'Feature 2 Title' is included, as the "phrase" is an evidence that this feature is part of the folder wise summary.",
      ...
    }}
  }}
  ```
  </Final Output Format>
  Note: If the traceback includes phrases that are not present in the folder wise summary then you would be penalized 10000 points.
  The output should be having data, confidence score, and traceback keys, and the entire content inside "```json" and "```" should be parsable by json.
  The "data" key should contain the generated summary and it should be in string format only, allowing the parsing of the entire json.
  If there are any inverted commas inside the generated summary, then escape them with a backslash.
  Do not change or skip the headings of each section in the generated json. The generated summary must have "Overview", "Highlighted Features", "Key Benefits" as section titles. Follow the above provided guidelines."""
    user_prompt += f"""Use the below folder wise summary to generate the summary in the above format: {combined_summary}""" + "User Defined Features : " + str(user_mvf)
    return system_prompt, user_prompt

def db_executive_summary_generation(combined_summary, user_mvf): 
    system_prompt = """
    Role:
    You are an expert Database Architect tasked with understanding the contents of all tables and schema of the database. 
    You shall Articulate a proper executive summary that clearly captures all the main & high-level features of this database.
    The core use-case that this database is intended for, and the prioritized list of the most valuable features, solely based on the provided Table-Level summaries. 
    Do not hallucinate. Do NOT create the most valuable features and its description on pure assumptions. This needs to be based on facts, with proper backing.

    Task:
    1. Analyze provided Table wise summaries.
    2. Understand component interactions and functions.
    3. Prioritize the User Defined Features (if provided) in the summary.
    4. Identify and prioritize the most valuable features based on their importance to the core use-case the Database is solving.
    5. Create a comprehensive executive summary.

    Steps:
    1. Review Table wise summary.
    2. Analyze Table wise summary:
      - Identify all tables. 
      - Take into consideration the foreign keys, primary keys, is-a, has-a, and many-to-many relationships.
      - Deeply understand the intended-use-case of each table.
      - Note data operations, design patterns, and architectural decisions
    3. Create summary:
      - Describe the specific problem the Database is solving, based on Table wise summary
      - Explain high-level interactions and dependencies
      - Outline data workflow
    4. Identify and prioritize main features:
      - Determine which feature(s) address the core problem of the Database, based on SQL implementation and Table wise summary
      - Rank features based on their importance and relevance to solving the main problem, as evidenced in the Database
      - The feature should be major components of the Database and not minor functions like Many-to-Many Relationships, or "Foreign Keys". 
        These are implementation concepts. Not core features.

    Focus Areas:
    - Precised feature prioritization and importance
    - High-level functionality of this Database
    - Clear, concise technical language with Database-specific Language
    - Objective description
    - Capture entire data workflow

    Guidelines:
    - Only use the Table wise summary provided
    - Use precise Database-relevant technical terms
    - Include user-defined features if provided and evidenced in the Table wise summary
    - Prioritize features based on their importance to the core problem, as shown in the Table wise summary

    Feature Identification and Prioritization:
    - Carefully analyze the Table wise summary to identify features actually present in the Table wise summary
    - Do not assume or infer features that are not explicitly mentioned in the Table wise summary
    - Identify the top feature that solves the majority of the problem based on Database and SQL evidence
    - Rank subsequent features in descending order of importance, ensuring they are present in the Table wise summary
    - Ensure the feature list reflects the Database's focus and structure
    - Only include features that have substantial implementation in the Database that is evident from Table wise summary

    Output Format - Adhering to this format is crucial
    ```json
    {
    "data": "generated_summary in string format adhering to the Expected Output Format for Generated Summary",
    "confidence_score": 90,
    "traceback": {
    "Feature 1 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 1 Title' is included, as the 'phrase' is an evidence that this feature is part of the Database.",
    "Feature 2 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 2 Title' is included, as the 'phrase' is an evidence that this feature is part of the Database.",
    ...
    }
    }
    ```

    Requirements:
    - Replace \n with \\n in JSON
    - Limit upto 5 main features (max 2 sub-features each) or 7500 tokens
    - If due to any reason such as Database being small, you are unable to provide 5 features, then provide as many high-level features as possible between the range of 1 to 5.
    - Don't assume features or include minor features due to inability to provide 5 features, lesser number of features is acceptable.
    - Use specified JSON format only
    - Start with "```json" and end with "```"
    - Ensure the top feature in the prioritized list addresses the core problem and is present in the Table wise summary
    - Rank features in descending order of importance to the main problem, based on actual Database and SQL implementation
    - Do NOT include features that are NOT evidenced in the provided Table wise summary
    - Evaluate the Table wise summary objectively, considering all conclusions on the actual Database and SQL provided
    - Do NOT make any assumptions about organizational goals or intentions beyond what is explicitly shown in the Database and SQL
    - Focus solely on the technical aspects and implemented functionality, avoiding speculation about business objectives or future plans
    - Both the keys data, confidence score, and traceback should be present in the output JSON
    - The generated summary should be in string format only and be contained inside the "data" key
    - The "traceback" key should contain a dictionary with feature names as keys and justifications for including these features based on exact phrases from the input
    - Do not include any feature that could potentially be part of the Table wise summary without explicit evidence
    - Every feature mentioned must be driven by clear evidence from the provided input.
    - Strictly use an assertive and objective tone in your response. 
    - Do not be unsure about anything.
    - Do not include the "Folder Name" in your response. Ignore "dbanalysis" folder. Provide Executive Summary of the Database-ONLY.
    """

    user_prompt = """
  Expected Output Format for Generated Summary:

  **Overview**
  <empty line>
  <A brief introduction to the Database and its main purpose; in paragraph format only, not in points.
  This paragraph should provide a concise yet comprehensive overview of the Database, its primary functionality, and its intended use case.
  Aim for 3-5 sentences that capture the essence of the Database.>
  <empty line>
  **Highlighted Features**
  <empty line>
  <
  List and briefly explain the key features that are significant components of the Database and would serve as selling points.
  These features should be presented as follows:
  1. Use numbered points for each feature.
  2. Provide a brief explanation for each feature in 1-2 sentences, highlighting its importance and benefit to the END USER.
  3. Focus on features that are central to the Database's functionality and most important to the END USER.
  4. Dont include generic features like  Many-to-Many Relationships, or "Foreign Keys", these are not features but Design Principles.
  5. Do not include sub-points under any feature.
  6. Prioritize User Defined Features (if provided) at the beginning of the list.
  7. If User Defined Features are given, list them first before including any features identified through your analysis.
  8. Aim to provide upto of 1 to 5 key features, after each feature add an empty line for formatting purposes.
  9. Ensure that the features listed represent the core functionality and unique selling points based on the Table wise summary.
  10. Use clear, concise language that emphasizes the value proposition of each feature.
  11. Also under each feature, mention which file/Table was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
  12. Do not add features into Highlighted Features if they dont have value for buisness stakeholder about the application. Also do not repeat adding similar feature in this section.

  Output Structure:
  1. ***<Feature 1 Title>***: <Description of the feature in one to two sentences.\n
  2. ***<Feature 2 Title>***: <Description of the feature in one to two sentences.>\n
  >
  <empty line>
  **Key Benefits**
  <empty line>
  <Summarize the key benefits of the Database in one to two sentences.
  This summary should encapsulate the overall value proposition of the Database and its potential impact on users or the organization.>
  <empty line>
  <Highlight the most significant key benefits the Database has to offer in bulleted points. The format should be:
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  Aim for 3-5 bullet points that capture the most compelling advantages of using this Database, after each point add an empty line for formatting purposes.
  Each benefit should be distinct and provide a clear value proposition.>

  <Final Output Format>
  Output Format - Adhering to this format is crucial, the output should be in parsable JSON format:
  ```json
  {{
    "data": "<generated_summary in string format adhering to the Expected Output Format for Generated Summary>",
    "confidence_score": 90,
    "traceback": {{
      "Feature 1 Title": "Since it mentions about <exact phrase from the Table wise summary>, the 'Feature 1 Title' is included, as the "phrase" is an evidence that this feature is part of the Table wise summary.",
      "Feature 2 Title": "Since it mentions about <exact phrase from the Table wise summary>, the 'Feature 2 Title' is included, as the "phrase" is an evidence that this feature is part of the Table wise summary.",
      ...
    }}
  }}
  ```
  </Final Output Format>
  Note: If the traceback includes phrases that are not present in the Table wise summary then you would be penalized 10000 points.
  The output should be having data, confidence score, and traceback keys, and the entire content inside "```json" and "```" should be parsable by json.
  The "data" key should contain the generated summary and it should be in string format only, allowing the parsing of the entire json.
  If there are any inverted commas inside the generated summary, then escape them with a backslash.
  Do not change or skip the headings of each section in the generated json. The generated summary must have "Overview", "Highlighted Features", "Key Benefits" as section titles. Follow the above provided guidelines.
    """

    user_prompt += f"""Use the below Table wise summary to generate the summary in the above format: {combined_summary}""" + "User Defined Features : " + str(user_mvf)

    return system_prompt, user_prompt


def architecture_diagram_generation(services_data, icons_metadata):
    user_prompt = f"""
    <Input>
    $services_data = {services_data}
    $icons_metadata
    </Input>

    <Role>
    You are an expert at understanding large projects based on their executive summary and the services being used in them. Create a JSON structure for a ReactFlow diagram based on the given service class JSON.
    </Role>

    <Output Structure>
    1. Create a JSON object with a "nodes" and "edges" array.
    2. Create nodes for each external and third-party service.
    3. "nodes": An array containing all node objects.
      - "id": A unique string identifier for the node.
      - "data":   
        - "label": The name of the node.
        - "description": Description of the service.
        - "associated_files": Associated file and used in files in the service node, defaulting to "No File Available" if not present.
        - "group": The logical group name (e.g., 'Backend', 'Frontend', 'Database',etc..).
        - "subgroup": The specific subgroup within the group (e.g., Frameworks, NoSQL Databases, State Management, etc.).
        - "service": The appropriate filename of the icon based on the $icons_metadata.
      - "position" : The x and y coordinates of the node.
      - "type" : "customNode" This should be fixed.
    4. "edges" : An array having id, source, target, label, and type should be customEdge always.
    4. Ensure all services and files from the input JSON are included.
    5. The output should be in the form of a dictionary containing a "nodes" and "edges" array.
    6. Present only the code inside delimiters "```reactflow [reactflow CODE]```" without any additional explanation.
    """

    system_prompt:str = """
    <Task>
      You are tasked with creating a JSON structure for a ReactFlow diagram based on the given executive summary and the service_class_json. The executive summary contains an overview of the entire project. This JSON includes information about external services and third-party services, along with their associated files. Your output should represent this information as a network of nodes and edges.
    </Task>
    
    <Icons Context>
      $icons_metadata = """ + str(icons_metadata) + """
    </Icons Context>

    <Instructions>
      You are a solution expert, specializing in problem and solution flows. You will be given the solution overview for a project, and your task is to create an interconnected single component of graph which is detailed, and intuitive and self explanatory for:

      Follow these guidelines:
      1. Create nodes for each unique service (both external and third-party).
      2. Do not create any group nodes.
      4. In the data key for each service node, include two additional fields called group and subgroup. The group field should contain the logical group name (e.g., Frontend, Backend, Databases, etc..), and the subgroup field should provide more specific categorization (e.g., Frameworks, NoSQL Databases, etc..). For example, for a service node representing React, the group would be Frontend and the subgroup would be Frameworks.
      5. For each node, check which icon will be the most suitable from the $icons_metadata in the <Icons Context>
      6. Ensure all information from the input is represented in the output.
      7. The position coordinates must be proper for all the nodes.
    </Instructions>

    <Rules>
      **Ensure all nodes in the generated graph are interconnected such that every node has at least one edge, forming a single connected component without any isolated or disjoint sections. (High Priority Requirement)**
      Important Rules to be followed:
      1. Give detailed technical architecture flow and the JSON object following the below output format.
      2. Make sure that the flow and order of new solution approach is explained well in the graph with appropriate edges. Use as many edges you want to describe the data and user flow properly.
      3. The whole user and data flow should be clear.
      4. Do not add unnecessary nodes and edges. Do not create duplicate nodes that perform same task.
      5. Make the Node descriptions detailed, breaking tasks into multiple sub-tasks if needed.
      6. Ensure your edges show the actual flow, and not just connections of what's related. The connections are meant to show the logical flow, and not the relatedness/similarity.
      7. The group name is meant to classify clusters of nodes within each graph. For instance, if we have multiple nodes in features, they would all have "feature" as group. In Architecture Flow, the "Group" should show the layer each node is in, for instance "Backend Layer", "Database Layer" etc.
      9. for a hierarchy of nodes A -> B -> C; ensure that there is not a connection between A -> C.
    </Rules>
    
    <output_format>
    The output should be in between the delimeters ```reactflow and ```. Only provide the json output. Don't give unnecesary explanation.
    ```reactflow
    {
      "nodes": [
        { 
          "id": "unique_node_identifier_string",
          "data" : {
            "label": "name_of_the_service",
            "description": "description of the service",
            "associated_files": ["file_path_1", "file_path_2", "file_path_3", etc.],  // (default: ["No File Available"] if not present)
            "group": "name_of_group",  // Add the logical group name (e.g., "Frontend", "Backend", etc..)
            "subgroup": "name_of_subgroup",  // Add a more specific subgroup name (e.g., "Frameworks", "NoSQL Databases", etc..)
            "service": "filename" //taken from the $icons_metadata,
          }
          "position":{ "x": "Xcoordinate", "y": "Ycoordinate" },
          "type" : "customNode" //this is hardcoded and will be constant
        }
      ],
      "edges": [
        {
          "id": "unique_egde_identifier_string",
          "source": "label A",
          "target": "label B",
          "label": "Showcase what comes from the source node, to the target node. Be concise and specific with labels, such as 'Ingested Data', 'Converted Text', 'User Query' etc. Use at max 5 words",
          "type" : "customEdge" //this is hardcoded and will be constant
        }
      ]
    }```
    </output_format>
    """
    return system_prompt, user_prompt
  

def erd_generation(services_data, icons_metadata):
  tables_metadata = []
  for entry in services_data:
      table_name = entry["table_name"]
      ddl = entry["ddl"]
      columns, primary_keys, foreign_keys = parse_ddl(ddl)
      tables_metadata.append({
          "table_name": table_name,
          "columns": columns,
          "primary_keys": primary_keys,
          "foreign_keys": foreign_keys
      })

  dot = generate_combined_graph(tables_metadata)

  system_prompt:str = """
    You are tasked with creating a JSON structure for a ReactFlow diagram based on the given database ER diagram and schema JSON. This JSON includes information about database columns and their relationships.Your output should represent this information as a network of nodes and edges.
    </Task>
    
    <Icons Context>
      $icons_metadata = """ + str(icons_metadata) + """
    </Icons Context>

    <Instructions>
      You are a solution expert, specializing in problem and solution flows. You will be given the database schema information of a database, and your task is to create an interconnected single component of graph which is detailed, and intuitive and self explanatory for:

      Follow these guidelines:
      1. Create nodes for each unique service (both external and third-party).
      2. Do not create any group nodes.
      4. In the data key for each service node, include two additional fields called group and subgroup. The group field should contain the logical group name (e.g.,Databases, etc..), and the subgroup field should provide more specific categorization (e.g., 'Transactional Tables', 'Reference Tables' etc..). For example, for a service node representing daily transactions, the group would be Database and the subgroup would be Transactional Tables.
      5. For each node, check which icon will be the most suitable from the $icons_metadata in the <Icons Context>
      6. Ensure all information from the input is represented in the output.
      7. The position coordinates must be proper for all the nodes.
    </Instructions>

    <Rules>
      Important Rules to be followed:
      1. Give detailed technical architecture flow and the JSON object following the below output format.
      2. Make sure that the flow and order of new solution approach is explained well in the graph with appropriate edges. Use as many edges you want to describe the data and user flow properly.
      3. The whole user and data flow should be clear.
      4. Do not add unnecessary nodes and edges. Do not create duplicate nodes that perform same task.
      5. Make the Node descriptions detailed, breaking tasks into multiple sub-tasks if needed.
      6. Ensure your edges show the actual flow, and not just connections of what's related. The connections are meant to show the logical flow, and not the relatedness/similarity.
      7. The group name is meant to classify clusters of nodes within each graph. For instance, if we have multiple nodes in features, they would all have "feature" as group. In Architecture Flow, the "Group" should show the layer each node is in, for instance "Database Layer" etc.
      9. for a hierarchy of nodes A -> B -> C; ensure that there is not a connection between A -> C.
    </Rules>
    
    <output_format>
    The output should be in between the delimeters ```reactflow and ```. Only provide the json output. Don't give unnecesary explanation.
    ```reactflow
    {
      "nodes": [
        { 
          "id": "unique_node_identifier_string",
          "data" : {
            "label": "name_of_the_table",
            "description": "description of the table",
  	    "columns": ["order_id [PK]", "product_sku [PK]", "quantity", "unit_price"]
            "group": "name_of_group",  // Add the logical group name (e.g., "Database", etc..)
            "subgroup": "name_of_subgroup",  // Add a more specific subgroup name (e.g., 'Transactional Tables', 'Reference Tables', etc..)
            "service": "filename" //taken from the $icons_metadata,
          }
          "position":{ "x": "Xcoordinate", "y": "Ycoordinate" },
          "type" : "customNode" //this is hardcoded and will be constant
        }
      ],
      "edges": [
        {
          "id": "unique_egde_identifier_string",
          "source": "label A",
          "target": "label B",
          "label": "Showcase what comes from the source node, to the target node. Be concise and specific with labels, such as 'Ingested Data', 'Converted Text', 'User Query' etc. Use at max 5 words",
          "type" : "customEdge" //this is hardcoded and will be constant
        }
      ]
    }```
    </output_format>
    """
    
  user_prompt:str = f"""
    <Input>
    $database_tables = {dot}
    $icons_metadata
    </Input>

    <Role>
    You are an expert at understanding database architecture based on ER diagrams and relational structures. Create a JSON structure for a ReactFlow diagram based on the given database schema.
    </Role>
    <Output Structure>
      1. Create a JSON object with a "nodes" and "edges" array.
      2. Create nodes for each table in the schema.
      3. "nodes": An array containing all node objects.
      - "id": A unique string identifier for the node.
      - "data":  
        - "label": The name of the table.
        - "description": A brief summary of the table's role or content.
        - "columns": List of column names (mark primary keys with [PK], foreign keys with [FK]).
        - "group": The logical group name (e.g., 'Database').
        - "subgroup": The specific subgroup within the group (e.g., 'Transactional Tables', 'Reference Tables').
        - "service": The appropriate filename of the icon based on the $icons_metadata.
      - "position" : The x and y coordinates of the node.
      - "type" : "customNode" This should be fixed.
      4. "edges" : An array having id, source, target, label, and type should be customEdge always.
      5. The label of the edge should describe the relationship, like "order_id â†’ order_id". 
      6. The output should be in the form of a dictionary containing a "nodes" and "edges" array.
      7. Present only the code inside delimiters "```reactflow [reactflow CODE]```" without any additional explanation.
    """
    
  return system_prompt, user_prompt
    

def feature_summary_generation(formatted_data, user_mvf, executive_summary):
    # if input_type is None:
    #     formatted_data = file_summary_list
    # elif input_type == "batch_summary":
    #     formatted_data = format_batchwise_summary_metadata_for_services(file_summary_list)
    # else:
    #     formatted_data = format_file_summaries(file_summary_list)

    user_prompt = """
    Role: You are an AI code analyst specializing in creating concise, feature-level summaries of codebases.

    Objective: Provide a comprehensive yet concise feature-level summary of a given codebase, highlighting key components, functionality, and the project's overall workflow.

    Input: You will receive information about a codebase, which may include an executive summary or other project details.

    Steps:
    1. Analyze the provided codebase information.
    2. Identify the main features (maximum 5) of the project from the executive summary (if provided in same order)
    3. Create a summary following the specified format, including:
        a. An overview of the project
        b. A list of key features with brief descriptions
        c. A closure statement
    4. Self-evaluate the generated summary and assign a confidence score.
    5. Format the output as specified in the instructions.

    Output Format:
    ```json
    {
        "data": "generated_summary in string format adhering to the Detailed Instructions for Output Format",
        "confidence_score": 90
    }
    ```

    Detailed Instructions for Output Format:

    **Overview**
    <empty line>
    < 
        Summarize all features in 2-3 sentences, introducing the project and its purpose.
        Provide a 2-3 sentence summary of key benefits, highlighting core architecture and value proposition.
    >
    <empty line>
    **Key Features**
    <empty line>
    <   
        List a maximum of 5 main features.
        For each feature, provide up to 2 sub-points describing its functionality.
        Ensure clear explanation of how features interact and contribute to the project's goals.
        1. ***<Key Feature Title>*** : 
        * <Sub point 1 description>
        * <Sub point 2 description>
        <empty line>
    >
    <empty line>
    < 
        Summarize the overall impact and value proposition of the project in one sentence as a conclusion statement.
    >
    <empty line>
    
    -> Self-Evaluation:
        - Score the summary out of 100 based on clarity, precision, detail, knowledge, accuracy, technical correctness, and understanding of the data.

    -> Formatting Requirements:
        - Replace all newline characters (\n) with \\n in the JSON output.
        - Ensure the complete JSON is less than 7500 tokens.
        - Start the output with "```json" and end with "```".
        - If an executive summary is provided, use only the highlighted features from it.

    Example Output Structure:
    ```json
    {
        "data": "**Overview**\\n\\n[Project overview]\\n\\n[Benefits summary]\\n\\n**Key Features**\\n\\n1. *Feature 1*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n2. *Feature 2*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n[...continue for up to 5 features...]\\n\\n[Closure statement]",
        "confidence_score": 90
    }
    ```

    Remember: Adhere strictly to the output format and instructions to maintain consistency and accuracy in your summary.
    """

    user_prompt += "User Defined Features : " + str(user_mvf)

    system_prompt = f"""
        <role>
        You are an assistant to a Senior Software Engineer. You are very capable in reading and understanding huge codebases.
        There is no edge-case, no mistake, no functionality no matter how small goes unnoticed by you.
        You will be given a large codebase and be asked queries regarding it.
        </role>

        <Task>
        You will be given relevant files from a production codebase. The Senior Engineer will consult you to clear his doubts and ask for critical code-level and functionality level analysis of the same.
        <Important>
        1. You will be clear. Feel free to be descriptive but Avoid Jargon
        2. You shall perform critical analysis on the code before responding.
        3. Note that the codebase will be quite complex and have dependencies everywhere, be mindful of them all.
        4. Enclose code in (triple backticks)``` code ```
        </Important>
        </Task>

        Files from Codebase goes here :
        <Repo Structure>
        {formatted_data}
        </Repo Structure>
    """

    start_index = executive_summary.find("Highlighted Features")
    end_index = executive_summary.find("Key Benefits")

    if start_index != -1 and end_index != -1:
        executive_summary = executive_summary[start_index:end_index].strip()

    user_prompt += "Executive Summary : " + str(executive_summary)

    return system_prompt, user_prompt

def feature_summary_generation_db(formatted_data, user_mvf, executive_summary):
    # if input_type is None:
    #     formatted_data = file_summary_list
    # elif input_type == "batch_summary":
    #     formatted_data = format_batchwise_summary_metadata_for_services(file_summary_list)
    # else:
    #     formatted_data = format_file_summaries(file_summary_list)

    user_prompt = """
    Role: You are an AI Database Analyst specializing in creating concise, feature-level summaries of complex database schemas and architectures.

    Objective: Provide a comprehensive yet concise feature-level summary of a given database schema information, highlighting key components, entities, relationships, and the overall data architecture workflow.

    Input: You will receive information about a database design, which may include an executive summary or other schema-level details.

    Steps:
    1. Analyze the provided database schema information.
    2. Identify the main features (maximum 5) of the database from the executive summary (if provided in same order)
    3. Create a summary following the specified format, including:
        a. An overview of the database
        b. A list of key features with brief descriptions
        c. A closure statement
    4. Self-evaluate the generated summary and assign a confidence score.
    5. Format the output as specified in the instructions.

    Output Format:
    ```json
    {
        "data": "generated_summary in string format adhering to the Detailed Instructions for Output Format",
        "confidence_score": 90
    }
    ```

    Detailed Instructions for Output Format:

    **Overview**
    <empty line>
    < 
        Summarize all features in 2-3 sentences, introducing the database and its purpose.
        Provide a 2-3 sentence summary of key benefits, highlighting schema structure, normalization or denormalization logic, and value proposition in handling data.
    >
    <empty line>
    **Key Features**
    <empty line>
    <   
        List a maximum of 5 main features.
        For each feature, provide up to 2 sub-points describing its data handling, relationships, or optimization logic.
        Ensure clear explanation of how features contribute to performance, consistency, and data integrity.
        1. ***<Key Feature Title>*** : 
        * <Sub point 1 description>
        * <Sub point 2 description>
        <empty line>
    >
    <empty line>
    < 
        Summarize the overall impact and value proposition of the database in one sentence as a conclusion statement.
    >
    <empty line>
    
    -> Self-Evaluation:
        - Score the summary out of 100 based on clarity, precision, detail, knowledge, accuracy, technical correctness, and understanding of the schema information.

    -> Formatting Requirements:
        - Replace all newline characters (\n) with \\n in the JSON output.
        - Ensure the complete JSON is less than 7500 tokens.
        - Start the output with "```json" and end with "```".
        - If an executive summary is provided, use only the highlighted features from it.

    Example Output Structure:
    ```json
    {
        "data": "**Overview**\\n\\n[Database overview]\\n\\n[Benefits summary]\\n\\n**Key Features**\\n\\n1. *Feature 1*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n2. *Feature 2*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n[...continue for up to 5 features...]\\n\\n[Closure statement]",
        "confidence_score": 90
    }
    ```

    Remember: Adhere strictly to the output format and instructions to maintain consistency and accuracy in your summary.
    """

    user_prompt += "User Defined Features : " + str(user_mvf)

    system_prompt = f"""
        <role>
        You are an assistant to a Senior Data Architect. You are very capable in reading, analyzing, and understanding complex database schemas and data models.
        No entity, constraint, relationship, or optimization logic goes unnoticed by you.
        You will be given a comprehensive database structure or schema information and will be asked to analyze, explain, and summarize it at a structural and functional level.
        </role>

        <Task>
        You will be given relevant database schema files or DDL definitions. The Senior Data Architect will consult you to clear doubts and ask for critical schema-level and data model-level analysis.
        <Important>
        1. You will be clear. Feel free to be descriptive but Avoid Jargon
        2. Perform a critical and deep analysis of the schema and the information given before responding.
        3. The schema will often involve multiple tables, foreign keys, views, procedures, and indexing strategies â€” be mindful of their dependencies and relationships.
        4. Enclose code or schema in (triple backticks)``` code ```
        </Important>
        </Task>

        Files from Database schema goes here :
        <Database Structure>
        {formatted_data}
        </Database Structure>
    """

    start_index = executive_summary.find("Highlighted Features")
    end_index = executive_summary.find("Key Benefits")

    if start_index != -1 and end_index != -1:
        executive_summary = executive_summary[start_index:end_index].strip()

    user_prompt += "Executive Summary : " + str(executive_summary)

    return system_prompt, user_prompt


#FEATURE HIERARCHY:
generate_features_system_prompt = """
  <Role>
    You are a Software Architect with expertise in analyzing large summaries from code files of an application. 
    You can comprehend summaries from code files that are complex, production-grade and are written in various programming languages to generate most important features, their description and the subfeatures with their description belonging to the most important features along with the other relevant information requested below.
    
    You will follow 2 Events before responding : 
    1. Generation of Feature Hierarchy as given in "Output_Format".
    2. Critical Evaluation of Every Confidence Score.  
  </Role> 

    <Task 1>
    You are provided with multiple relative file paths and file-wise code summaries from a application codebase.
    1. Analyze the file summaries carefully, leveraging your expertise to deduce the frameworks, functionality, and features.
    2. Perform a critical assessment of the code's functionality and interdependencies before responding.
    3. The codebase is complex and likely contains dependencies across various modules. Be mindful of these.
    4. Analyse every file summary and assign the features and sub-features based on the information provided.
    5. Respond strictly in the structured JSON format provided below.
    6. In each sub-feature's 'file_path' array:
        - Set 'critical: true' ONLY for files that are CORE & NON-REPLACEABLE to the sub-feature's main functionality.
        - Set 'critical: false' for ALL supporting, secondary, or replaceable files  
        - Each sub-feature should have both true and false entries.
        - If unsure, default to false (be EXTREMELY selective with 'true')
        - Make sure each sub-feature atleast have one file as true.

    Explanation of the Output terms:
    Feature - Features are most valuable and high level features extracted from the list of summaries that are provided to you. 
    Feature description - Description of the features explaining the high level value and impact that it creates for the project. Define the Feature. The description should be crisp, precise, well formatted and must be between 2-3 lines.
    Subfeature - Subfeatures are micro most valuable features that are extracted from the list of summaries and belong to the Most related and similar Features.
    Subfeature description - Description of the subfeatures explaining the specific value, technical and non-technical functionalites that it provided to the project. Define the subfeature and also explain how its related to the feature. The description should be crisp, precise, well formatted and must be between 2-3 lines.
    
    Points to Remember:
    1. Do not extract any feature or subfeature where there are no reference/citations from the application summaries.
    2. The description must be precise, valuable, well-formatted and must be between 2-3 lines.
    3. The Feature titles should be precise, specific, self explanaible, independent and not have similar feature titles. The Feature titles should not be highly generalized.
    4. The SubFeatures titles should be precise, self explanaible and not have similar subfeature titles. The SubFeature titles should not be highly generalized.
    5. SubFeatures should not be very low level that it explains code functions, code process like 'Json handling', 'Reading csv', readME etc.
    6. If similar subfeatures are present, then group them under one common Feature itself. Do not create multuple Features for similar subfeatures.
    6. If Unit testing related summaries are found, then create that as another Feature named 'Unit Testing' and assign the specific testing subfeatures under this feature.
    </Task 1>

  <Task 2>
  You shall now Assign and Justify Confidence Scores for each feature.

  <Critical Evaluation of Confidence Scores> 

  <Evaluation MODE>
  - You will now Forget everything that was done beforehand and act as an unbiased judge.
  - $Project-Summaries-&-Paths (INPUT).
  </Evaluation MODE>
  <Important>
  Critically analyze every "Feature" and "SubFeature" based on the following metrics. 
  You shall generate a confidence score between 0-100 for each of the following :
  1. Is the "Feature" & "SubFeature" name accurate to its functionality ? (Accuracy)
  2. Does the "Feature" & "SubFeature" include files with an unrelated function ? (Feature Dilution Rate)
  3. Important : Does this "Feature" & "SubFeature" make sense given the Overall Purpose of the Application ? (Consistency)
  4. Are all the files in "Feature" & "SubFeature" included ? (Completeness)

  <Strict>
  1. You will now generate a list of 4 confidence scores between 0-100 for above criteria under "confidence_score" key.
  2. Based on above criteria, you shall provide a VERY BRIEF logical explanation (10-20 words) for Confidence Score under "confidence_score_justification" key.
  3. Make sure to mention the entire filepath without omitting the prefix.
  4. Make sure all the filepaths are present.
  <Important> STRICTLY Don't Comment on Missing Files. Don't Overestimate. Don't Underestimate.</Important> 
  </Strict>

  </Important>

  </Critical Evaluation of Confidence Scores> 
  </Step 2>


      <Output_Format>
    Return a response in JSON format. Do not include any extra information or explanations. Strictly DON'T deviate from mentioned KEYS.
    Example:
```json
[
  {
    "name": "User Authentication and Management",
    "feature_description": "Comprehensive user account system with secure login, registration, profile management, and role-based access control.",
    "feature_description_confidence_score": [95, 70, 100, 70],
    "sub_features": [
      {
        "name": "User Registration",
        "description": "Allows new users to create accounts by providing necessary information such as username, email, and password. Implements email verification, password strength checks, and duplicate account prevention. Stores user data securely in the database with password hashing.",
        "file_path": [
          {
            "module_name": "RegistrationController",
            "path": "Controllers/Account/RegistrationController.cs",
            "critical": true
          },
          {
            "module_name": "RegisterView",
            "path": "Views/Account/Register.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [75, 80, 85, 65],
        "sub_feature_confidence_score_justification": "No feature dilution, might have missed some file."
      },
      {
        "name": "User Login",
        "description": "Authenticates users using their credentials, creates and manages user sessions, and implements security measures such as login attempt limiting and two-factor authentication (2FA). Provides password reset functionality for forgotten passwords.",
        "file_path": [
          {
            "module_name": "LoginController",
            "path": "Controllers/Account/LoginController.cs",
            "critical": true
          },
          {
            "module_name": "LoginView",
            "path": "Views/Account/Login.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [80, 100, 80, 75],
        "sub_feature_confidence_score_justification": "High chance of missing files."
      }
    ],
    "feature_confidence_score_justification": "No feature dilution, duplication or missing files. Accurate Naming."
  },
  {
    "name": "Product Catalog Management",
    "feature_description": "Comprehensive system for managing product listings, categories, and inventory across the e-commerce platform.",
    "feature_description_confidence_score": [95, 65, 70, 80],
    "sub_features": [
      {
        "name": "Product CRUD Operations",
        "description": "Enables administrators to create, read, update, and delete product listings. Includes functionality for managing product details such as name, description, price, images, and inventory levels. Implements validation to ensure data integrity and consistency across the product catalog.",
        "file_path": [
          {
            "module_name": "ProductController",
            "path": "Controllers/ProductController.cs",
            "critical": true
          },
          {
            "module_name": "ProductView",
            "path": "Views/Product/Index.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [90, 85, 100, 70],
        "sub_feature_confidence_score_justification": "High confidence with no duplication or dilution."
      },
      {
        "name": "Category Management",
        "description": "Allows for the creation and management of product categories and subcategories. Implements a hierarchical structure for organizing products, enabling efficient navigation and filtering of the product catalog for both administrators and customers.",
        "file_path": [
          {
            "module_name": "CategoryController",
            "path": "Controllers/CategoryController.cs",
            "critical": true
          },
          {
            "module_name": "CategoryView",
            "path": "Views/Category/Index.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [85, 75, 90, 95],
        "sub_feature_confidence_score_justification": "High confidence without any duplication or dilution."
      }
    ],
    "feature_confidence_score_justification": "All files refer to single overall functionality. Might have missed some files."
  }
]
```
  </Output_Format>

"""

generate_features_user_message = """
<Strictly Remember>
1. As input you will be given a batch of `file_path` and `file_summary` from a production codebase. Keep it in mind that it could be a file from a very large repository with lot of inter-dependencies.
2. Understand all the file description first, then try to determine the feature, sub-features and their description. For **each file** it should have a feature or sub-features whenever the conditions are met.
3. The response should contain all the fields given in the example output format. The response should be strictly in json format.
4. The description of features/subfeatures must be in the length of 2-3 lines. The response should be structured and well-formatted.
5. Don't generate any additional explanation or description. Provide the structured response in json only.
</Strictly Remember>
  
<Input file wise summary>
{file_summary}
</Input file wise summary>
<Response>
"""

merge_features_in_hierarchy_user_prompt = """You are a software feature analyzer. Given a list of related features that have been clustered together, create a merged feature that encompasses all the functionality.

Features to merge:
{feature_list}

Generate a JSON response that includes:
1. A name for the merged feature representing accurate feature name. Do not mention its merged or unified or anything as such. The feature name should accurately represent a major funcationality of a repository.
2. A detailed description that covers all functionality
3. A confidence score (0-100) for the merge
4. A justification for the confidence score

Respond with a JSON object in the following format:
```json
{{
    "name": "Merged feature name",
    "description": "Comprehensive description",
    "confidence_score": 85,
    "confidence_justification": "Reason for the confidence score"
}}
```
Give only JSON and nothing else. Do not include any explanations or additional text outside the JSON block. Make sure to start with ```json and end with ``` only.
"""

mapping_names_for_merged_features_user_prompt = """  <Role>
    You are a smart AI cassistant with strong expertise in Software Engineering. You can understand complex, production-grade codebases written in various programming languages and summarize them effectively.
  </Role>
  <Task>
  You will be given a brief description of  features of a large codebase and your task is to generate a relevant feature name, brief description, and priority level.
  <Important>
   1. The feature name should be brief, relevant and should represent the entire description provided.
   2. Generate a relevant description which is basically a overall summary of the description provided.
   3. Assign a priority level (high, medium, low) based on the significance, importance and complexity of the feature to the overall system. 
  </important>
  </Task>
  <Example output>
  ```json
    {
        "name": <feature_name>, //string
        "feature_description": <feature_description>, //string
        "priority": <priority> //string (high, medium, or low)
    }
    ```
  </Example output>
  <Strictly Remember>
1. The feature name should be relevant and at the same time interpretable, easy to understand.
2. The feature description should represnt the entire description given for summarisation, it should be simple and easy to understant.
3. The priority should be one of: high, medium, or low.
4. The response should be strictly in json format specified above.
5. Strictly make sure Feature Description is not more than 200 words.
  </Strictly Remember>

<code summary>
The code summary is given below:
"""


reducing_sub_features_user_prompt = """
    You are a software feature consolidation expert. Your task is to merge similar sub-features into one comprehensive sub-feature.

    Here are the sub-features that need to be merged:
    {sub_features_list}

    For each sub-feature, we have:
    - Name: The sub-feature name
    - Description: The sub-feature description (if available)
    - Confidence Score: The confidence score (if available)

    Your output should be a JSON object containing:
    1. A unified sub-feature name that encompasses all the input sub-features
    2. A comprehensive description that covers all aspects of the input sub-features
    3. A confidence score (use the highest available from input sub-features)
    4. A justification for the confidence score

    Return the output in JSON format starting with ```json and ending with ```.

    Example output format:
    ```json
    {{
        "name": "Unified Sub-Feature Name",
        "description": "Comprehensive description covering all aspects",
        "sub_feature_confidence_score": 95,
        "sub_feature_confidence_score_justification": "Merged from similar sub-features with high semantic similarity"
    }}
    ```
    """


post_processing_feature_name_description_system_prompt="""
  <Role>
    You are a smart AI assistant with strong expertise in Software Engineering. You can understand complex, production-grade codebases written in various programming languages and summarize them effectively.
  </Role>
  <Task>
  You will be given a brief description of modules or features of a large codebase and your task is to generate a relevant feature name and brief description.
  <Important>
   1. The feature name should be brief, relevant and should represent the entire description provided.
   2. Generate a relevant description which is basically a overall summary of the description provided.
   3. Also generate a confidence score in a scale of 0 - 100.
  </important>
  </Task>
  <Example output>
  ```json
    {
        "name": <feature_name>,
        "feature_description_confidence_score": <score 0 - 100>,
        "feature_description": <feature_description>
    }```
  </Example output>"""

post_processing_feature_name_description_user_prompt = """<Strictly Remember>
1. The feature name should be relevant and at the same time interpretable, easy to understant.
2. The confidence score should represent the ability to summarise the description.
3. The feature description should represnt the entire description given for summarisation, it should be simple and easy to understant.
4. The response should be strictly in json format specified above.
</Strictly Remember>
<code summary>
The code summary is given below: \n
{feature_description}
</code_summary>
<response>
Your response in json goes here:
"""

merge_similar_features_system_prompt = """You are a solution architect. Your task is to carefully review each feature and its description, and combine them into a single high-level feature.

The final high-level features should represent what an end user would perceive, e.g., Messenger, Google Chat, Messaging, Reels, etc.

Based on the generated features provided, identify which features can be merged into a single high-level feature. 
Strictly output them in the following format:
{{ 
  <High-Level Feature Name 1>: [<Merged Feature 1>, <Merged Feature 2>, <Merged Feature 3>, ...],
  <High-Level Feature Name 2>: [<Merged Feature 1>, <Merged Feature 2>, <Merged Feature 3>, ...],
  ...
}}

INPUT:
Feature names and descriptions are provided in the format: 
[1. Feature name: <feature name> 
Feature description: <feature description>, 
2. ...]

{feature_texts}

MVFS:
{total_MVFs}

Points to remember:
1. While merging features and naming high-level features, always prefer names from the user-defined MVFs provided. All relevant features can be grouped under these high-level features.
2. If certain features do not fit under the user-defined MVFs, choose a better name than the existing one for the new high-level feature if necessary.
3. The names of the features being merged must remain exactly as provided in the INPUT section; do not modify them. Do not consider Feature description in Feature Names.
4. Follow the output structure strictly: high-level feature names as dictionary keys and merged features as values in list format.
5. If a feature is already a high-level feature, you do not need to forcibly merge it. If a feature seems to be function-level/low-level  features, merge them into a High-level feature.
6. Merge similar features into a single high-level feature based on their names and descriptions, when applicable. Each final high-level feature should be independent of the others.
7. Do not assign the same feature to multiple high-level features.
8. If user-defined MVFs are empty, skip point 1 and begin with point 2.
9. Do **not** include any Feature descriptions in the final output."""


merging_description_user_prompt = """You are a Solution Architect. Your task is to summarize the multiple feature descriptions provided into a brief, coherent summary of **no more than two sentences**.

  The summary must:
  - Accurately capture all key components from the provided descriptions.
  - Align clearly with the given high-level feature name.
  - Serve as the final description of the high-level feature.

  Only the final summarized description should be included in the output â€” no additional commentary or formatting.

  INPUT:
  Multiple descriptions: {merging_feature_description}

  High-Level Feature Name: {high_level_feature}
  """


micro_sub_feature_prompt = """You are an expert system analyst specializing in decomposing SubFeatures into granular, logically independent components. You support **two levels** of splitting:

1. **Horizontal splitting**: Split a subfeature into multiple *same-level subfeatures* when it encompasses multiple independently meaningful functionalities. The subfeatures created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.
2. **Vertical splitting**: Further break each of those subfeatures into *microsubfeatures* (if applicable), ensuring each micro-sub-features/micro-user-story describes a single goal or operation. The micro-sub-features/micro-user-story created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.

---

### ðŸ”§ TASK OVERVIEW

Given a Macro-Feature, Subfeature, its description, associated module files and its summary:

- Decide if the subfeature should be split horizontally into multiple same-level subfeatures.
- For each resulting subfeature (or original if not split), analyze whether it can be split vertically into **microsubfeatures** (fine-grained user stories).
- Provide the confidence scores for the subfeature that is split, whether horizontally or vertically.
- Provide the files that are related to the sub_features too, not just the micro_sub_features.
- Each leaf user-story must have files assigned to them, else you should not create/split these subfeatures.
- Provide description of generated subfeature/sub-user-stories in 2-4 lines but only valid information. Do not assume or hallucinate to generate description.
Apply this recursively: if horizontal splitting occurs, then attempt vertical splitting for each. But remember, not to create any duplicates in the process. 

---

### SPLITTING DECISIONS

#### Horizontal Splitting (Same-level Subfeatures):
Split if:
- The subfeature covers multiple high-level functionalities
- Each function could be planned, developed, and deployed independently
- Each component has a clear boundary and responsibility

#### Vertical Splitting (Microsubfeatures):
Split further if:
- A subfeature contains multiple independent operations or logical stages
- These operations can be implemented, tested, or tracked separately
- Each micro-subfeature represents one atomic, non-overlapping functionality

---

### DO NOT SPLIT IF:
- sub-user-stories are tightly coupled in the Subfeature and cannot function independently.
- Do not split subfeatures into sub-user-stories that are hardly single line of code and cannot be considered as a proper functionality, but just a config/parameter.
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across actions are too complex to isolate.
- There are no files that can be mapped to the generated user-story.
- Do not split if the user-story is barely a functionality. The split user-stories must have independent functionality that contributes to the subfeature and feature and if not, do not split.
- Don not split ReadMe & .md files into sub-user-stories.
- Do not split horizontall for granullar subfeatures as they are not user stories but mid level features.
---

### FILE MAPPING RULES:
- For each subfeature or microsubfeature, cite only directly relevant files.
- Use only the provided input data to match files â€” no guessing.
- Avoid duplication unless a file is clearly shared between components.

Each `file_path` entry must include:
```json
{
  "module_name": "<Name>",
  "path": "<Path>",
  "critical": <true/false>,
  "git_url": "<Git URL>"
}

OUTPUT FORMAT
If the subfeature should NOT be split:
Return: "None"

If the subfeature should be split, return a list of Parent User Stories with subfeatures inside.
If a subfeature itself can be further split into microsubfeatures, nest them under micro_sub_features like so:

[
  {
    "name": "Parent User Story Title 1",
    "description": "Full description of the original or updated user story and its purpose.",
    "file_path": [...],
    "sub_feature_confidence_score":"confidence score of the subfeature with respect to the Feature, as a percentage (e.g., 80)"
    "micro_sub_features": [
      {
        "name": "Sub-User Story Title 1",
        "description": "Standalone description of a single functionality.",
        "file_path": [...],
        "micro_sub_feature_confidence_score":"confidence score of the micro_sub_feature with respect to the sub_feature, as a percentage (e.g., 90)"
        }
          ...
        ]
      },
      ...
    ]
  }
]
Each layer must preserve independence, clarity, and singular focus of each story.

VALIDATION CHECKLIST
- Each title must express one functionality only (no imperative phrasing)
- description must avoid assumptions and describe the real function. It must be as detailled as possible.
- Each story must make sense independently and fit in the broader feature flow
- if there are multiple user-story under the subfeature, it needs to be in sequence of business logic.
- File mappings must be relevant and scoped accurately
- Do no miss/skip any values in the output json. The output structure must be maintained strictly.
- All subfeature and sub-user-story names and descriptions must be strictly in a declarative tone, not imperative.

* Use generic or speculative statements
"""


db_micro_sub_feature_prompt = """
<Role>
You are an expert Database analyst specializing in decomposing SubFeatures into granular, logically independent components. You support **two levels** of splitting:
You shall ALWAYS process features from a Database perspective ONLY. 
There can be more than one Table in the DB context provided to you.
</Role>

1. **Horizontal splitting**: Split a subfeature into multiple *same-level subfeatures* when it encompasses multiple independently meaningful functionalities. The subfeatures created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.
2. **Vertical splitting**: Further break each of those subfeatures into *microsubfeatures* (if applicable), ensuring each micro-sub-features/micro-user-story describes a single goal or operation. The micro-sub-features/micro-user-story created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.

<Strict Constraints> 
- You are dealing with Database Information. 
- No matter what, STRICTLY use Database-Specific Language ALWAYS. 
- Use words like Columns / Fields / Schema / DataTypes / Constraints / Foreign Keys / Primary Keys etc.
- Strictly Do not start descriptions with or start with "this micro-feature" / or "this sub-feature".
- You shall do this regardless of the input context and nature.
Remember : Every "FILE" given to you is information of a table. Therefore in your response, ALWAYS refer to "Table" instead of "File".

</Strict Constraints> 


### ðŸ”§ TASK OVERVIEW

Given a Macro-Feature, Subfeature, its description, associated module files and its summary:

- Decide if the subfeature should be split horizontally into multiple same-level subfeatures.
- For each resulting subfeature (or original if not split), analyze whether it can be split vertically into **microsubfeatures** (fine-grained user stories).
- Provide the confidence scores for the subfeature that is split, whether horizontally or vertically.
- Provide the files that are related to the sub_features too, not just the micro_sub_features.
- Each leaf user-story must have files assigned to them, else you should not create/split these subfeatures.
- Provide description of generated subfeature/sub-user-stories in 2-4 lines but only valid information. Do not assume or hallucinate to generate description.
Apply this recursively: if horizontal splitting occurs, then attempt vertical splitting for each. But remember, not to create any duplicates in the process. 

---

### SPLITTING DECISIONS

#### Horizontal Splitting (Same-level Subfeatures):
Split if:
- The subfeature covers ONE / MORE THAN ONE high-level functionalities
- Each function could be planned and developed independently
- Each component has some clear boundaries and responsibilities

#### Vertical Splitting (Microsubfeatures):
Split further if:
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across actions are too complex to isolate.
- There are no tables that can be mapped to the generated user-story.
- The subfeature is too complex to be planned, developed, and deployed independently
- Each micro-subfeature represents one atomic, non-overlapping functionality
Note: Maintain at least 2 subfeatures unless the database has only one table.
- Prioritize brevity, consistency and no informaiton leakage across subfeatures.
- Ensure crisp segregation.
---

### DO NOT SPLIT IF:
- sub-user-stories are tightly coupled in the Subfeature and cannot function independently.
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across tables in two features are too complex to isolate.
- There are no tables that can be mapped to the generated user-story.
Note: Maintain at least 2 subfeatures and 1 or more microsubfeatures per subfeature, Unless the database has only one table.
Note : Maintain brevity during splitting at the same level. Do NOT overload the a single feature with too many subfeatures.
---


### FILE MAPPING RULES:
- For each subfeature or microsubfeature, cite only directly relevant tables.
- Use only the provided input data to match files â€” no guessing.
- Avoid duplication unless a file is clearly shared between components.

Each `file_path` entry must include:
```json
{
  "module_name": "<Name>",
  "path": "<Path>",
  "critical": <true/false>,
  "git_url": "<Git URL>"
}

OUTPUT FORMAT
If the subfeature should NOT be split:
Return: "None"

If the subfeature should be split, return a list of Parent User Stories with subfeatures inside.
If a subfeature itself can be further split into microsubfeatures, nest them under micro_sub_features like so:

[
  {
    "name": "Parent User Story Title 1",
    "description": "Full description of the original or updated user story and its purpose.",
    "file_path": [...],
    "sub_feature_confidence_score":"confidence score of the subfeature with respect to the Feature, as a percentage (e.g., 80)"
    "micro_sub_features": [
      {
        "name": "Sub-User Story Title 1",
        "description": "Standalone description of a single functionality.",
        "file_path": [...],
        "micro_sub_feature_confidence_score":"confidence score of the micro_sub_feature with respect to the sub_feature, as a percentage (e.g., 90)"
        }
          ...
        ]
      },
      ...
    ]
  }
]
Each layer must preserve independence, clarity, and singular focus of each story.

VALIDATION CHECKLIST
- Each title must express one functionality only (no imperative phrasing)
- description must avoid assumptions and describe the real function. It must be as detailled as possible.
- Each story must make sense independently and fit in the broader feature flow
- if there are multiple user-story under the subfeature, it needs to be in sequence of business logic.
- File mappings must be relevant and scoped accurately
- Do no miss/skip any values in the output json. The output structure must be maintained strictly.
- All subfeature and sub-user-story names and descriptions must be strictly in a declarative tone, not imperative.
- Use Database-specific schema only. Do not include words like "Attributes" / "Code Files" in your response. 
- Strictly Do not start descriptions with or start with "this micro-feature" / or "this sub-feature".
* Use generic or speculative statements

"""import os
from graphviz import Digraph
import re 
import json

def parse_ddl(ddl: str):
    """
    Parse the DDL to extract columns, primary keys, and foreign keys.
    """
    lines = ddl.splitlines()
    column_lines = []

    for line in lines:
        line = line.strip()
        if (
            line.upper().startswith("CREATE")
            or line.upper().startswith("PRIMARY")
            or line.upper().startswith("FOREIGN")
            or line.upper().startswith(")")
            or line == ""
        ):
            continue

        match = re.match(r'(\w+)\s+\w+', line)
        if match:
            column_lines.append(match.group(1))

    pk_match = re.search(r'PRIMARY KEY\s*\((.*?)\)', ddl)
    primary_keys = [key.strip() for key in pk_match.group(1).split(",")] if pk_match else []

    foreign_keys = []
    for match in re.finditer(r'FOREIGN KEY\s*\(([^)]+)\)\s+REFERENCES\s+`?[\w]+\.(\w+)`\(([^)]+)\)', ddl):
        fk_col = match.group(1).strip()
        ref_table = match.group(2).strip()
        ref_col = match.group(3).strip()
        foreign_keys.append((fk_col, ref_table, ref_col))

    return column_lines, primary_keys, foreign_keys


def generate_combined_graph(tables_data):
    """
    Generate a single combined graph from multiple tables.
    """
    dot = Digraph(comment='Combined Table Diagram')
    dot.attr(rankdir='LR')

    # Store individual table nodes
    for table in tables_data:
        table_name = table['table_name']
        columns = table['columns']
        primary_keys = table['primary_keys']
        
        label_lines = []
        for col in columns:
            if col in primary_keys:
                label_lines.append(f"{col} [PK]")
            else:
                label_lines.append(col)
        dot.node(table_name, shape='box', label=f'{table_name}\\n' + "\\n".join(label_lines))

    # Add relationships
    for table in tables_data:
        table_name = table['table_name']
        for fk_col, ref_table, ref_col in table['foreign_keys']:
            dot.edge(table_name, ref_table, label=f'{fk_col} â†’ {ref_col}')

    return dot

def folder_summary_generation_prompts(
        total_allocated_tokens, 
        file_list, folder_name, 
        folder_path,
        subfolder_list,
        formatted_file_summaries,
        formatted_file_services,
        formatted_subfolder_summaries,
        formatted_subfolder_services,
        formatted_subfolder_features
    ):
    
    system_prompt = f"""
        You are an expert code analyst specialized in creating detailed, informative summaries of software project folders. Your task is to thoroughly analyze files and subfolders to provide a comprehensive understanding of the application or project and provide combined summaries along with required details. These summaries must be detailled enough for further summarization.

        Follow these guidelines:
        1. Conduct a deep analysis of the features to identify its core purpose and functionality
        2. Provide detailed explanation of key implementations and technical approaches of the features
        3. Thoroughly examine the summaries based on files and folders to understand relationship between features and combined smaller features into larger high level application level features.
        4. Explain the features within the broader project architecture with specific connections
        5. Describe technical patterns, design decisions, and architectural choices evident in the code
        6. Include specific functions, classes, and methods that define the feature's behavior
        7. Note dependencies, imports, and external connections that shape the folder's functionality
        8. Identify potential architectural strengths and areas for improvement when evident
        9. Identify all services represented in this folder based on file and subfolder services information
        10. Identify and articulate high-level features or functionalities represented by the folder into the feature_details section, when consolidating multiple subfolders or lower-level files. Derive these insights from both file-level and subfolder-level summaries. Also under each feature, mention which file/folder was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
        11. Do not miss any features that could be formed based on these summaries as this information is required to understand the application's buisness logic.
        12. Gather insights from the summaries provided to generate a high level detailled executive summary that could be used by business stakeholders to understand the folder/project.
        13. When analyzing the root folder, both the executive summary and the features must be strictly formed in a high level business logic standpoint of an application.
        
        IMPORTANT: 
        - Your summary should be thorough and detailed({total_allocated_tokens}) while maintaining technical/business precision and depth. Focus on providing insights that would help both stakeholders and developers understand the application better.
        - feature_details must contain high level feature name and feature description(value of the files/folders) strictly in concise bullet points. The feature inforamtion must be in detail to capture the complete high level knowledge for that feature but not the function level details. Feature names cannot be programmatic function names like Dependency management, json handling etc. instead it should be inventory management, order processing etc. 
        - Your services list should be comprehensive and include all services represented in this folder.
        - is_reuasble_lib if a folder is used as reusable lib make it True otherwise False
        - lib_name if is_reusable_lib is True then provide the name of the reusable lib/component If is_reusable_lib False then add Not Applicable
        - category if is_reusable_lib is True then provide category only between 'Frontend' and 'Backend' If is_reusable_lib False then add Not Applicable
        - sub_category if is_reusable_lib is True then provide sub category only between 'UI Component','Custom Hooks', 'http_client', 'Utils', 'Others' In Frontend & 'Middleware', 'Error Handling', 'Auth', 'Utils', 'Others' In Backend If is_reusable_lib False then add Not Applicable
        - when_to_use if is_reusable_lib is True then provide where this reusable lib/component can be used If is_reusable_lib False then add Not Applicable 
        - associated_files if is_reusable_lib is True then provide the list of files associated(give complete path for the assosciated file) with this reusable lib/component If is_reusable_lib False then add Not Applicable
        - summary must not be technical and only explain the high level details of the folder/project. Understand the file and folder summaries provided to combine the knowledge to form the executive summary. Make it as detailled as possible.
        - Use clear and concise language, avoiding jargon where possible.
        
        - You must provide your response in this exact format:
        ```summary
        [Your detailled high-level executive summary for the folder for business stakeholders]
        ```
        ```feature_details
        [List of high-level features or functionalities represented in this folder]
        ```
        ```services_namess
        [Comma-separated list of all services represented in this folder]
        ```
        ```is_reuasble_lib
        Boolean Value
        ```
        ```lib_name
        [Name of the reusable library if applicable]
        ```
        ```category
        [Category of the reusable library if applicable]
        ```
        ```sub_category
            [Sub category of the reusable library if applicable]
        ```
        ```when_to_use
        [Your detailed use case where or when this reuasble_lib can be usefull]
        ```
        ```associated_files
            [Comma-separated list of associated files with the reusable library, Give the Complete file path as mentioned in the file list]
        ```
        ```example_usage
            [Example code snippet of how to use this reusable library]
        ```
    """

    user_prompt = f"""
        Generate a summary and services list for the folder: "{folder_name}" (Path: {folder_path})

        FOLDER CONTENTS:
        - Files ({len(file_list)}): {", ".join(file_list) if file_list else "None"}
        - Subfolders ({len(subfolder_list)}): {", ".join(subfolder_list) if subfolder_list else "None"}

        FILE SUMMARIES:
        {os.linesep.join(formatted_file_summaries) if formatted_file_summaries else "No file summaries available"}

        FILE SERVICES:
        {os.linesep.join(formatted_file_services) if formatted_file_services else "No file services available"}

        SUBFOLDER SUMMARIES:
        {os.linesep.join(formatted_subfolder_summaries) if formatted_subfolder_summaries else "No subfolder summaries available"}

        SUBFOLDER SERVICES:
        {os.linesep.join(formatted_subfolder_services) if formatted_subfolder_services else "No subfolder services available"}

        SUBFOLDER FEATURES:
        {os.linesep.join(formatted_subfolder_features) if formatted_subfolder_features else "No subfolder features available"}
        
        Based on these components:
        1. Provide a thorough technical summary explaining the folder's purpose, implementation details, and architectural significance
        2. Compile a comprehensive list of all services represented in this folder based on file and subfolder services information
        
        Follow the exact format specified in the system instructions for your response.
    """

    return system_prompt, user_prompt

def services_generation():
    system_prompt = """
        <Task>
        Create an architectural blueprint of the given repository by identifying and classifying both external services and third-party services with no overlap between categories.
        </Task>

        <Definitions>
        - External services: Company-provided services hosted outside the application (AWS S3, Google Cloud, Stripe, Twilio)
        - Third-party services: Libraries, frameworks, and SDKs that are part of the core application stack (Django, React, MongoDB, Redux)
        </Definitions>

        <Output_Format>
        {
        "external_services": [
            {
            "external_service_name": "string",
            "description": "string",
            "associated_files": ["string"],
            "service_class": "string",
            "used_in_files": ["string"]
            }
        ],
        "thirdparty_services": [
            {
            "thirdparty_service_name": "string",
            "description": "string",
            "associated_files": ["string"],
            "service_class": "string",
            "used_in_files": ["string"]
            }
        ]
        }
        </Output_Format>

        <Instructions>
        1. Conduct a thorough repository analysis to identify all services
        2. Classify each service into exactly ONE category:
        - External services: Cloud platforms, payment processors, authentication providers
        - Third-party services: Frameworks, libraries, SDKs integrated into the codebase
        3. For each service, provide:
        - Name: Exact service name
        - Description: Concise explanation of functionality and purpose
        - Associated files: All files directly importing or using the service
        - Service class: Category (e.g., "cloud storage", "web framework", "database")
        - Used in files: Complete paths of files utilizing the service
        4. Ensure ZERO overlap between categories
        5. Prioritize accuracy over comprehensiveness
        6. Validate that identified services are actively used in the project
        7. Include only services with clear evidence of implementation
        8. Do not create a lot of services which are redundant. Keep it to a maximum of 50 services only.
        </Instructions>

        <Examples>
        Good External Service Entry:
        {
        "external_service_name": "AWS S3",
        "description": "Cloud storage service used for storing user-uploaded files",
        "associated_files": ["src/services/storage.js", "src/config/aws.js"],
        "service_class": "cloud storage",
        "used_in_files": ["src/components/FileUpload.js", "src/pages/UserProfile.js"]
        }

        Good Third-Party Service Entry:
        {
        "thirdparty_service_name": "React",
        "description": "Frontend JavaScript library for building user interfaces",
        "associated_files": ["package.json", "src/index.js"],
        "service_class": "frontend framework",
        "used_in_files": ["src/App.js", "src/components/*.js"]
        }
        </Examples>

        Analyze the repository and provide the complete architectural blueprint in the specified format.
    """

    user_prompt = ""

    return system_prompt, user_prompt

def executive_summary_generation(combined_summary, user_mvf):
    system_prompt = """
    Your Role:
    You are an expert software architect tasked with understanding a codebase and creating an executive summary that clearly articulates the main purpose of this application,
    the core problem that the application is solving, and the prioritized list of the most valuable features, solely based on the provided folder wise summary. Do not hallucinate and create the most valuable features and its description on assumption. This needs to be based on facts.

    Task:
    1. Analyze provided folder wise summary and the services used and the user defined features (if provided).
    2. Understand component interactions and functions.
    3. Prioritize the User Defined Features (if provided) in the summary.
    4. Identify and prioritize the most valuable features based on their importance and relevance to the overall project, as evidenced in the code.
    5. Create a comprehensive executive summary.

    Steps:
    1. Review folder wise summary.
    2. Analyze folder wise summary:
    - Identify key components and their roles
    - Note data operations, design patterns, and architectural decisions
    3. Create summary:
    - Describe the specific problem the codebase solves, based on folder wise summary
    - Explain component interactions
    - Outline data workflow
    4. Identify and prioritize main features:
    - Determine which feature(s) address the core problem of the application, based on code implementation
    - Rank features based on their importance and relevance to solving the main problem, as evidenced in the code
    - The feature should be major components of the codebase and not minor functions like "Modular Architecture" or "Code Reusability", these are not features but design principles.

    Focus Areas:
    - Precised feature prioritization and importance
    - High-level functionality
    - Clear, concise technical language
    - Objective description
    - Capture entire workflow

    Guidelines:
    - Only use the folder wise summary provided
    - Use precise technical terms
    - Include user-defined features if provided and evidenced in the code
    - Prioritize features based on their importance to the core problem, as shown in the folder wise summary

    Feature Identification and Prioritization:
    - Carefully analyze the folder wise summary to identify features actually present in the folder wise summary
    - Do not assume or infer features that are not explicitly mentioned in the folder wise summary
    - Identify the top feature that solves the majority of the problem based on code evidence
    - Rank subsequent features in descending order of importance, ensuring they are present in the folder wise summary
    - Ensure the feature list reflects the codebase's focus and structure
    - Only include features that have substantial implementation in the codebase that is evident from folder wise summary

    Output Format - Adhering to this format is crucial
    ```json
    {
    "data": "generated_summary in string format adhering to the Expected Output Format for Generated Summary",
    "confidence_score": 90,
    "traceback": {
    "Feature 1 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 1 Title' is included, as the 'phrase' is an evidence that this feature is part of the codebase.",
    "Feature 2 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 2 Title' is included, as the 'phrase' is an evidence that this feature is part of the codebase.",
    ...
    }
    }
    ```

    Requirements:
    - Replace \n with \\n in JSON
    - Limit upto 5 main features (max 2 sub-features each) or 7500 tokens
    - If due to any reason such as codebase being small, you are unable to provide 5 features, then provide as many high-level features as possible between the range of 1 to 5.
    - Don't assume features or include minor features due to inability to provide 5 features, lesser number of features is acceptable.
    - Use specified JSON format only
    - Start with "```json" and end with "```"
    - Ensure the top feature in the prioritized list addresses the core problem and is present in the folder wise summary
    - Rank features in descending order of importance to the main problem, based on actual code implementation
    - Do NOT include features that are NOT evidenced in the provided folder wise summary
    - Evaluate the folder wise summary objectively, considering all conclusions on the actual code provided
    - Do NOT make any assumptions about organizational goals or intentions beyond what is explicitly shown in the code
    - Focus solely on the technical aspects and implemented functionality, avoiding speculation about business objectives or future plans
    - Both the keys data, confidence score, and traceback should be present in the output JSON
    - The generated summary should be in string format only and be contained inside the "data" key
    - The "traceback" key should contain a dictionary with feature names as keys and justifications for including these features based on exact phrases from the input
    - Do not include any feature that could potentially be part of the folder wise summary without explicit evidence
    - Every feature mentioned must be driven by clear evidence from the provided input
    """
    user_prompt = """
    Expected Output Format for Generated Summary:

  **Overview**
  <empty line>
  <A brief introduction to the codebase and its main purpose; in paragraph format only, not in points.
  This paragraph should provide a concise yet comprehensive overview of the codebase, its primary functionality, solution provided by the project and its intended use case.
  Aim for 3-5 sentences that capture the essence of the project.>
  <empty line>
  **Highlighted Features**
  <empty line>
  <
  List and briefly explain the key features that are significant components of the codebase and would serve as selling points.
  These features should be presented as follows:
  1. Use numbered points for each feature.
  2. Provide a brief explanation for each feature in 1-2 sentences, highlighting its importance and benefit to the end user.
  3. Focus on features that are central to the codebase's functionality and most important to the end user.
  4. Dont include generic features like "Modular Architecture" or "Code Reusability", these are not features but design principles.
  5. Do not include sub-points under any feature.
  6. Prioritize User Defined Features (if provided) at the beginning of the list.
  7. If User Defined Features are given, list them first before including any features identified through your analysis.
  8. Aim to provide upto of 1 to 5 key features, after each feature add an empty line for formatting purposes.
  9. Ensure that the features listed represent the core functionality and unique selling points based on the folder wise summary.
  10. Use clear, concise language that emphasizes the value proposition of each feature.
  11. Also under each feature, mention which file/folder was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
  12. Do not add features into Highlighted Features if they dont have value for buisness stakeholder about the application. Also do not repeat adding similar feature in this section.

  Output Structure:
  1. ***<Feature 1 Title>***: <Description of the feature in one to two sentences.\n
  2. ***<Feature 2 Title>***: <Description of the feature in one to two sentences.>\n
  >
  <empty line>
  **Key Benefits**
  <empty line>
  <Summarize the key benefits of the codebase in one to two sentences.
  This summary should encapsulate the overall value proposition of the codebase and its potential impact on users or the organization.>
  <empty line>
  <Highlight the most significant key benefits the codebase has to offer in bulleted points. The format should be:
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  Aim for 3-5 bullet points that capture the most compelling advantages of using this codebase, after each point add an empty line for formatting purposes.
  Each benefit should be distinct and provide a clear value proposition.>

  <Final Output Format>
  Output Format - Adhering to this format is crucial, the output should be in parsable JSON format:
  ```json
  {{
    "data": "<generated_summary in string format adhering to the Expected Output Format for Generated Summary>",
    "confidence_score": 90,
    "traceback": {{
      "Feature 1 Title": "Since it mentions about <exact phrase from the folder wise summary>, the 'Feature 1 Title' is included, as the "phrase" is an evidence that this feature is part of the folder wise summary.",
      "Feature 2 Title": "Since it mentions about <exact phrase from the folder wise summary>, the 'Feature 2 Title' is included, as the "phrase" is an evidence that this feature is part of the folder wise summary.",
      ...
    }}
  }}
  ```
  </Final Output Format>
  Note: If the traceback includes phrases that are not present in the folder wise summary then you would be penalized 10000 points.
  The output should be having data, confidence score, and traceback keys, and the entire content inside "```json" and "```" should be parsable by json.
  The "data" key should contain the generated summary and it should be in string format only, allowing the parsing of the entire json.
  If there are any inverted commas inside the generated summary, then escape them with a backslash.
  Do not change or skip the headings of each section in the generated json. The generated summary must have "Overview", "Highlighted Features", "Key Benefits" as section titles. Follow the above provided guidelines."""
    user_prompt += f"""Use the below folder wise summary to generate the summary in the above format: {combined_summary}""" + "User Defined Features : " + str(user_mvf)
    return system_prompt, user_prompt

def db_executive_summary_generation(combined_summary, user_mvf): 
    system_prompt = """
    Role:
    You are an expert Database Architect tasked with understanding the contents of all tables and schema of the database. 
    You shall Articulate a proper executive summary that clearly captures all the main & high-level features of this database.
    The core use-case that this database is intended for, and the prioritized list of the most valuable features, solely based on the provided Table-Level summaries. 
    Do not hallucinate. Do NOT create the most valuable features and its description on pure assumptions. This needs to be based on facts, with proper backing.

    Task:
    1. Analyze provided Table wise summaries.
    2. Understand component interactions and functions.
    3. Prioritize the User Defined Features (if provided) in the summary.
    4. Identify and prioritize the most valuable features based on their importance to the core use-case the Database is solving.
    5. Create a comprehensive executive summary.

    Steps:
    1. Review Table wise summary.
    2. Analyze Table wise summary:
      - Identify all tables. 
      - Take into consideration the foreign keys, primary keys, is-a, has-a, and many-to-many relationships.
      - Deeply understand the intended-use-case of each table.
      - Note data operations, design patterns, and architectural decisions
    3. Create summary:
      - Describe the specific problem the Database is solving, based on Table wise summary
      - Explain high-level interactions and dependencies
      - Outline data workflow
    4. Identify and prioritize main features:
      - Determine which feature(s) address the core problem of the Database, based on SQL implementation and Table wise summary
      - Rank features based on their importance and relevance to solving the main problem, as evidenced in the Database
      - The feature should be major components of the Database and not minor functions like Many-to-Many Relationships, or "Foreign Keys". 
        These are implementation concepts. Not core features.

    Focus Areas:
    - Precised feature prioritization and importance
    - High-level functionality of this Database
    - Clear, concise technical language with Database-specific Language
    - Objective description
    - Capture entire data workflow

    Guidelines:
    - Only use the Table wise summary provided
    - Use precise Database-relevant technical terms
    - Include user-defined features if provided and evidenced in the Table wise summary
    - Prioritize features based on their importance to the core problem, as shown in the Table wise summary

    Feature Identification and Prioritization:
    - Carefully analyze the Table wise summary to identify features actually present in the Table wise summary
    - Do not assume or infer features that are not explicitly mentioned in the Table wise summary
    - Identify the top feature that solves the majority of the problem based on Database and SQL evidence
    - Rank subsequent features in descending order of importance, ensuring they are present in the Table wise summary
    - Ensure the feature list reflects the Database's focus and structure
    - Only include features that have substantial implementation in the Database that is evident from Table wise summary

    Output Format - Adhering to this format is crucial
    ```json
    {
    "data": "generated_summary in string format adhering to the Expected Output Format for Generated Summary",
    "confidence_score": 90,
    "traceback": {
    "Feature 1 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 1 Title' is included, as the 'phrase' is an evidence that this feature is part of the Database.",
    "Feature 2 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 2 Title' is included, as the 'phrase' is an evidence that this feature is part of the Database.",
    ...
    }
    }
    ```

    Requirements:
    - Replace \n with \\n in JSON
    - Limit upto 5 main features (max 2 sub-features each) or 7500 tokens
    - If due to any reason such as Database being small, you are unable to provide 5 features, then provide as many high-level features as possible between the range of 1 to 5.
    - Don't assume features or include minor features due to inability to provide 5 features, lesser number of features is acceptable.
    - Use specified JSON format only
    - Start with "```json" and end with "```"
    - Ensure the top feature in the prioritized list addresses the core problem and is present in the Table wise summary
    - Rank features in descending order of importance to the main problem, based on actual Database and SQL implementation
    - Do NOT include features that are NOT evidenced in the provided Table wise summary
    - Evaluate the Table wise summary objectively, considering all conclusions on the actual Database and SQL provided
    - Do NOT make any assumptions about organizational goals or intentions beyond what is explicitly shown in the Database and SQL
    - Focus solely on the technical aspects and implemented functionality, avoiding speculation about business objectives or future plans
    - Both the keys data, confidence score, and traceback should be present in the output JSON
    - The generated summary should be in string format only and be contained inside the "data" key
    - The "traceback" key should contain a dictionary with feature names as keys and justifications for including these features based on exact phrases from the input
    - Do not include any feature that could potentially be part of the Table wise summary without explicit evidence
    - Every feature mentioned must be driven by clear evidence from the provided input.
    - Strictly use an assertive and objective tone in your response. 
    - Do not be unsure about anything.
    - Do not include the "Folder Name" in your response. Ignore "dbanalysis" folder. Provide Executive Summary of the Database-ONLY.
    """

    user_prompt = """
  Expected Output Format for Generated Summary:

  **Overview**
  <empty line>
  <A brief introduction to the Database and its main purpose; in paragraph format only, not in points.
  This paragraph should provide a concise yet comprehensive overview of the Database, its primary functionality, and its intended use case.
  Aim for 3-5 sentences that capture the essence of the Database.>
  <empty line>
  **Highlighted Features**
  <empty line>
  <
  List and briefly explain the key features that are significant components of the Database and would serve as selling points.
  These features should be presented as follows:
  1. Use numbered points for each feature.
  2. Provide a brief explanation for each feature in 1-2 sentences, highlighting its importance and benefit to the END USER.
  3. Focus on features that are central to the Database's functionality and most important to the END USER.
  4. Dont include generic features like  Many-to-Many Relationships, or "Foreign Keys", these are not features but Design Principles.
  5. Do not include sub-points under any feature.
  6. Prioritize User Defined Features (if provided) at the beginning of the list.
  7. If User Defined Features are given, list them first before including any features identified through your analysis.
  8. Aim to provide upto of 1 to 5 key features, after each feature add an empty line for formatting purposes.
  9. Ensure that the features listed represent the core functionality and unique selling points based on the Table wise summary.
  10. Use clear, concise language that emphasizes the value proposition of each feature.
  11. Also under each feature, mention which file/Table was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
  12. Do not add features into Highlighted Features if they dont have value for buisness stakeholder about the application. Also do not repeat adding similar feature in this section.

  Output Structure:
  1. ***<Feature 1 Title>***: <Description of the feature in one to two sentences.\n
  2. ***<Feature 2 Title>***: <Description of the feature in one to two sentences.>\n
  >
  <empty line>
  **Key Benefits**
  <empty line>
  <Summarize the key benefits of the Database in one to two sentences.
  This summary should encapsulate the overall value proposition of the Database and its potential impact on users or the organization.>
  <empty line>
  <Highlight the most significant key benefits the Database has to offer in bulleted points. The format should be:
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  Aim for 3-5 bullet points that capture the most compelling advantages of using this Database, after each point add an empty line for formatting purposes.
  Each benefit should be distinct and provide a clear value proposition.>

  <Final Output Format>
  Output Format - Adhering to this format is crucial, the output should be in parsable JSON format:
  ```json
  {{
    "data": "<generated_summary in string format adhering to the Expected Output Format for Generated Summary>",
    "confidence_score": 90,
    "traceback": {{
      "Feature 1 Title": "Since it mentions about <exact phrase from the Table wise summary>, the 'Feature 1 Title' is included, as the "phrase" is an evidence that this feature is part of the Table wise summary.",
      "Feature 2 Title": "Since it mentions about <exact phrase from the Table wise summary>, the 'Feature 2 Title' is included, as the "phrase" is an evidence that this feature is part of the Table wise summary.",
      ...
    }}
  }}
  ```
  </Final Output Format>
  Note: If the traceback includes phrases that are not present in the Table wise summary then you would be penalized 10000 points.
  The output should be having data, confidence score, and traceback keys, and the entire content inside "```json" and "```" should be parsable by json.
  The "data" key should contain the generated summary and it should be in string format only, allowing the parsing of the entire json.
  If there are any inverted commas inside the generated summary, then escape them with a backslash.
  Do not change or skip the headings of each section in the generated json. The generated summary must have "Overview", "Highlighted Features", "Key Benefits" as section titles. Follow the above provided guidelines.
    """

    user_prompt += f"""Use the below Table wise summary to generate the summary in the above format: {combined_summary}""" + "User Defined Features : " + str(user_mvf)

    return system_prompt, user_prompt


def architecture_diagram_generation(services_data, icons_metadata):
    user_prompt = f"""
    <Input>
    $services_data = {services_data}
    $icons_metadata
    </Input>

    <Role>
    You are an expert at understanding large projects based on their executive summary and the services being used in them. Create a JSON structure for a ReactFlow diagram based on the given service class JSON.
    </Role>

    <Output Structure>
    1. Create a JSON object with a "nodes" and "edges" array.
    2. Create nodes for each external and third-party service.
    3. "nodes": An array containing all node objects.
      - "id": A unique string identifier for the node.
      - "data":   
        - "label": The name of the node.
        - "description": Description of the service.
        - "associated_files": Associated file and used in files in the service node, defaulting to "No File Available" if not present.
        - "group": The logical group name (e.g., 'Backend', 'Frontend', 'Database',etc..).
        - "subgroup": The specific subgroup within the group (e.g., Frameworks, NoSQL Databases, State Management, etc.).
        - "service": The appropriate filename of the icon based on the $icons_metadata.
      - "position" : The x and y coordinates of the node.
      - "type" : "customNode" This should be fixed.
    4. "edges" : An array having id, source, target, label, and type should be customEdge always.
    4. Ensure all services and files from the input JSON are included.
    5. The output should be in the form of a dictionary containing a "nodes" and "edges" array.
    6. Present only the code inside delimiters "```reactflow [reactflow CODE]```" without any additional explanation.
    """

    system_prompt:str = """
    <Task>
      You are tasked with creating a JSON structure for a ReactFlow diagram based on the given executive summary and the service_class_json. The executive summary contains an overview of the entire project. This JSON includes information about external services and third-party services, along with their associated files. Your output should represent this information as a network of nodes and edges.
    </Task>
    
    <Icons Context>
      $icons_metadata = """ + str(icons_metadata) + """
    </Icons Context>

    <Instructions>
      You are a solution expert, specializing in problem and solution flows. You will be given the solution overview for a project, and your task is to create an interconnected single component of graph which is detailed, and intuitive and self explanatory for:

      Follow these guidelines:
      1. Create nodes for each unique service (both external and third-party).
      2. Do not create any group nodes.
      4. In the data key for each service node, include two additional fields called group and subgroup. The group field should contain the logical group name (e.g., Frontend, Backend, Databases, etc..), and the subgroup field should provide more specific categorization (e.g., Frameworks, NoSQL Databases, etc..). For example, for a service node representing React, the group would be Frontend and the subgroup would be Frameworks.
      5. For each node, check which icon will be the most suitable from the $icons_metadata in the <Icons Context>
      6. Ensure all information from the input is represented in the output.
      7. The position coordinates must be proper for all the nodes.
    </Instructions>

    <Rules>
      **Ensure all nodes in the generated graph are interconnected such that every node has at least one edge, forming a single connected component without any isolated or disjoint sections. (High Priority Requirement)**
      Important Rules to be followed:
      1. Give detailed technical architecture flow and the JSON object following the below output format.
      2. Make sure that the flow and order of new solution approach is explained well in the graph with appropriate edges. Use as many edges you want to describe the data and user flow properly.
      3. The whole user and data flow should be clear.
      4. Do not add unnecessary nodes and edges. Do not create duplicate nodes that perform same task.
      5. Make the Node descriptions detailed, breaking tasks into multiple sub-tasks if needed.
      6. Ensure your edges show the actual flow, and not just connections of what's related. The connections are meant to show the logical flow, and not the relatedness/similarity.
      7. The group name is meant to classify clusters of nodes within each graph. For instance, if we have multiple nodes in features, they would all have "feature" as group. In Architecture Flow, the "Group" should show the layer each node is in, for instance "Backend Layer", "Database Layer" etc.
      9. for a hierarchy of nodes A -> B -> C; ensure that there is not a connection between A -> C.
    </Rules>
    
    <output_format>
    The output should be in between the delimeters ```reactflow and ```. Only provide the json output. Don't give unnecesary explanation.
    ```reactflow
    {
      "nodes": [
        { 
          "id": "unique_node_identifier_string",
          "data" : {
            "label": "name_of_the_service",
            "description": "description of the service",
            "associated_files": ["file_path_1", "file_path_2", "file_path_3", etc.],  // (default: ["No File Available"] if not present)
            "group": "name_of_group",  // Add the logical group name (e.g., "Frontend", "Backend", etc..)
            "subgroup": "name_of_subgroup",  // Add a more specific subgroup name (e.g., "Frameworks", "NoSQL Databases", etc..)
            "service": "filename" //taken from the $icons_metadata,
          }
          "position":{ "x": "Xcoordinate", "y": "Ycoordinate" },
          "type" : "customNode" //this is hardcoded and will be constant
        }
      ],
      "edges": [
        {
          "id": "unique_egde_identifier_string",
          "source": "label A",
          "target": "label B",
          "label": "Showcase what comes from the source node, to the target node. Be concise and specific with labels, such as 'Ingested Data', 'Converted Text', 'User Query' etc. Use at max 5 words",
          "type" : "customEdge" //this is hardcoded and will be constant
        }
      ]
    }```
    </output_format>
    """
    return system_prompt, user_prompt
  

def erd_generation(services_data, icons_metadata):
  tables_metadata = []
  for entry in services_data:
      table_name = entry["table_name"]
      ddl = entry["ddl"]
      columns, primary_keys, foreign_keys = parse_ddl(ddl)
      tables_metadata.append({
          "table_name": table_name,
          "columns": columns,
          "primary_keys": primary_keys,
          "foreign_keys": foreign_keys
      })

  dot = generate_combined_graph(tables_metadata)

  system_prompt:str = """
    You are tasked with creating a JSON structure for a ReactFlow diagram based on the given database ER diagram and schema JSON. This JSON includes information about database columns and their relationships.Your output should represent this information as a network of nodes and edges.
    </Task>
    
    <Icons Context>
      $icons_metadata = """ + str(icons_metadata) + """
    </Icons Context>

    <Instructions>
      You are a solution expert, specializing in problem and solution flows. You will be given the database schema information of a database, and your task is to create an interconnected single component of graph which is detailed, and intuitive and self explanatory for:

      Follow these guidelines:
      1. Create nodes for each unique service (both external and third-party).
      2. Do not create any group nodes.
      4. In the data key for each service node, include two additional fields called group and subgroup. The group field should contain the logical group name (e.g.,Databases, etc..), and the subgroup field should provide more specific categorization (e.g., 'Transactional Tables', 'Reference Tables' etc..). For example, for a service node representing daily transactions, the group would be Database and the subgroup would be Transactional Tables.
      5. For each node, check which icon will be the most suitable from the $icons_metadata in the <Icons Context>
      6. Ensure all information from the input is represented in the output.
      7. The position coordinates must be proper for all the nodes.
    </Instructions>

    <Rules>
      Important Rules to be followed:
      1. Give detailed technical architecture flow and the JSON object following the below output format.
      2. Make sure that the flow and order of new solution approach is explained well in the graph with appropriate edges. Use as many edges you want to describe the data and user flow properly.
      3. The whole user and data flow should be clear.
      4. Do not add unnecessary nodes and edges. Do not create duplicate nodes that perform same task.
      5. Make the Node descriptions detailed, breaking tasks into multiple sub-tasks if needed.
      6. Ensure your edges show the actual flow, and not just connections of what's related. The connections are meant to show the logical flow, and not the relatedness/similarity.
      7. The group name is meant to classify clusters of nodes within each graph. For instance, if we have multiple nodes in features, they would all have "feature" as group. In Architecture Flow, the "Group" should show the layer each node is in, for instance "Database Layer" etc.
      9. for a hierarchy of nodes A -> B -> C; ensure that there is not a connection between A -> C.
    </Rules>
    
    <output_format>
    The output should be in between the delimeters ```reactflow and ```. Only provide the json output. Don't give unnecesary explanation.
    ```reactflow
    {
      "nodes": [
        { 
          "id": "unique_node_identifier_string",
          "data" : {
            "label": "name_of_the_table",
            "description": "description of the table",
  	    "columns": ["order_id [PK]", "product_sku [PK]", "quantity", "unit_price"]
            "group": "name_of_group",  // Add the logical group name (e.g., "Database", etc..)
            "subgroup": "name_of_subgroup",  // Add a more specific subgroup name (e.g., 'Transactional Tables', 'Reference Tables', etc..)
            "service": "filename" //taken from the $icons_metadata,
          }
          "position":{ "x": "Xcoordinate", "y": "Ycoordinate" },
          "type" : "customNode" //this is hardcoded and will be constant
        }
      ],
      "edges": [
        {
          "id": "unique_egde_identifier_string",
          "source": "label A",
          "target": "label B",
          "label": "Showcase what comes from the source node, to the target node. Be concise and specific with labels, such as 'Ingested Data', 'Converted Text', 'User Query' etc. Use at max 5 words",
          "type" : "customEdge" //this is hardcoded and will be constant
        }
      ]
    }```
    </output_format>
    """
    
  user_prompt:str = f"""
    <Input>
    $database_tables = {dot}
    $icons_metadata
    </Input>

    <Role>
    You are an expert at understanding database architecture based on ER diagrams and relational structures. Create a JSON structure for a ReactFlow diagram based on the given database schema.
    </Role>
    <Output Structure>
      1. Create a JSON object with a "nodes" and "edges" array.
      2. Create nodes for each table in the schema.
      3. "nodes": An array containing all node objects.
      - "id": A unique string identifier for the node.
      - "data":  
        - "label": The name of the table.
        - "description": A brief summary of the table's role or content.
        - "columns": List of column names (mark primary keys with [PK], foreign keys with [FK]).
        - "group": The logical group name (e.g., 'Database').
        - "subgroup": The specific subgroup within the group (e.g., 'Transactional Tables', 'Reference Tables').
        - "service": The appropriate filename of the icon based on the $icons_metadata.
      - "position" : The x and y coordinates of the node.
      - "type" : "customNode" This should be fixed.
      4. "edges" : An array having id, source, target, label, and type should be customEdge always.
      5. The label of the edge should describe the relationship, like "order_id â†’ order_id". 
      6. The output should be in the form of a dictionary containing a "nodes" and "edges" array.
      7. Present only the code inside delimiters "```reactflow [reactflow CODE]```" without any additional explanation.
    """
    
  return system_prompt, user_prompt
    

def feature_summary_generation(formatted_data, user_mvf, executive_summary):
    # if input_type is None:
    #     formatted_data = file_summary_list
    # elif input_type == "batch_summary":
    #     formatted_data = format_batchwise_summary_metadata_for_services(file_summary_list)
    # else:
    #     formatted_data = format_file_summaries(file_summary_list)

    user_prompt = """
    Role: You are an AI code analyst specializing in creating concise, feature-level summaries of codebases.

    Objective: Provide a comprehensive yet concise feature-level summary of a given codebase, highlighting key components, functionality, and the project's overall workflow.

    Input: You will receive information about a codebase, which may include an executive summary or other project details.

    Steps:
    1. Analyze the provided codebase information.
    2. Identify the main features (maximum 5) of the project from the executive summary (if provided in same order)
    3. Create a summary following the specified format, including:
        a. An overview of the project
        b. A list of key features with brief descriptions
        c. A closure statement
    4. Self-evaluate the generated summary and assign a confidence score.
    5. Format the output as specified in the instructions.

    Output Format:
    ```json
    {
        "data": "generated_summary in string format adhering to the Detailed Instructions for Output Format",
        "confidence_score": 90
    }
    ```

    Detailed Instructions for Output Format:

    **Overview**
    <empty line>
    < 
        Summarize all features in 2-3 sentences, introducing the project and its purpose.
        Provide a 2-3 sentence summary of key benefits, highlighting core architecture and value proposition.
    >
    <empty line>
    **Key Features**
    <empty line>
    <   
        List a maximum of 5 main features.
        For each feature, provide up to 2 sub-points describing its functionality.
        Ensure clear explanation of how features interact and contribute to the project's goals.
        1. ***<Key Feature Title>*** : 
        * <Sub point 1 description>
        * <Sub point 2 description>
        <empty line>
    >
    <empty line>
    < 
        Summarize the overall impact and value proposition of the project in one sentence as a conclusion statement.
    >
    <empty line>
    
    -> Self-Evaluation:
        - Score the summary out of 100 based on clarity, precision, detail, knowledge, accuracy, technical correctness, and understanding of the data.

    -> Formatting Requirements:
        - Replace all newline characters (\n) with \\n in the JSON output.
        - Ensure the complete JSON is less than 7500 tokens.
        - Start the output with "```json" and end with "```".
        - If an executive summary is provided, use only the highlighted features from it.

    Example Output Structure:
    ```json
    {
        "data": "**Overview**\\n\\n[Project overview]\\n\\n[Benefits summary]\\n\\n**Key Features**\\n\\n1. *Feature 1*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n2. *Feature 2*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n[...continue for up to 5 features...]\\n\\n[Closure statement]",
        "confidence_score": 90
    }
    ```

    Remember: Adhere strictly to the output format and instructions to maintain consistency and accuracy in your summary.
    """

    user_prompt += "User Defined Features : " + str(user_mvf)

    system_prompt = f"""
        <role>
        You are an assistant to a Senior Software Engineer. You are very capable in reading and understanding huge codebases.
        There is no edge-case, no mistake, no functionality no matter how small goes unnoticed by you.
        You will be given a large codebase and be asked queries regarding it.
        </role>

        <Task>
        You will be given relevant files from a production codebase. The Senior Engineer will consult you to clear his doubts and ask for critical code-level and functionality level analysis of the same.
        <Important>
        1. You will be clear. Feel free to be descriptive but Avoid Jargon
        2. You shall perform critical analysis on the code before responding.
        3. Note that the codebase will be quite complex and have dependencies everywhere, be mindful of them all.
        4. Enclose code in (triple backticks)``` code ```
        </Important>
        </Task>

        Files from Codebase goes here :
        <Repo Structure>
        {formatted_data}
        </Repo Structure>
    """

    start_index = executive_summary.find("Highlighted Features")
    end_index = executive_summary.find("Key Benefits")

    if start_index != -1 and end_index != -1:
        executive_summary = executive_summary[start_index:end_index].strip()

    user_prompt += "Executive Summary : " + str(executive_summary)

    return system_prompt, user_prompt

def feature_summary_generation_db(formatted_data, user_mvf, executive_summary):
    # if input_type is None:
    #     formatted_data = file_summary_list
    # elif input_type == "batch_summary":
    #     formatted_data = format_batchwise_summary_metadata_for_services(file_summary_list)
    # else:
    #     formatted_data = format_file_summaries(file_summary_list)

    user_prompt = """
    Role: You are an AI Database Analyst specializing in creating concise, feature-level summaries of complex database schemas and architectures.

    Objective: Provide a comprehensive yet concise feature-level summary of a given database schema information, highlighting key components, entities, relationships, and the overall data architecture workflow.

    Input: You will receive information about a database design, which may include an executive summary or other schema-level details.

    Steps:
    1. Analyze the provided database schema information.
    2. Identify the main features (maximum 5) of the database from the executive summary (if provided in same order)
    3. Create a summary following the specified format, including:
        a. An overview of the database
        b. A list of key features with brief descriptions
        c. A closure statement
    4. Self-evaluate the generated summary and assign a confidence score.
    5. Format the output as specified in the instructions.

    Output Format:
    ```json
    {
        "data": "generated_summary in string format adhering to the Detailed Instructions for Output Format",
        "confidence_score": 90
    }
    ```

    Detailed Instructions for Output Format:

    **Overview**
    <empty line>
    < 
        Summarize all features in 2-3 sentences, introducing the database and its purpose.
        Provide a 2-3 sentence summary of key benefits, highlighting schema structure, normalization or denormalization logic, and value proposition in handling data.
    >
    <empty line>
    **Key Features**
    <empty line>
    <   
        List a maximum of 5 main features.
        For each feature, provide up to 2 sub-points describing its data handling, relationships, or optimization logic.
        Ensure clear explanation of how features contribute to performance, consistency, and data integrity.
        1. ***<Key Feature Title>*** : 
        * <Sub point 1 description>
        * <Sub point 2 description>
        <empty line>
    >
    <empty line>
    < 
        Summarize the overall impact and value proposition of the database in one sentence as a conclusion statement.
    >
    <empty line>
    
    -> Self-Evaluation:
        - Score the summary out of 100 based on clarity, precision, detail, knowledge, accuracy, technical correctness, and understanding of the schema information.

    -> Formatting Requirements:
        - Replace all newline characters (\n) with \\n in the JSON output.
        - Ensure the complete JSON is less than 7500 tokens.
        - Start the output with "```json" and end with "```".
        - If an executive summary is provided, use only the highlighted features from it.

    Example Output Structure:
    ```json
    {
        "data": "**Overview**\\n\\n[Database overview]\\n\\n[Benefits summary]\\n\\n**Key Features**\\n\\n1. *Feature 1*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n2. *Feature 2*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n[...continue for up to 5 features...]\\n\\n[Closure statement]",
        "confidence_score": 90
    }
    ```

    Remember: Adhere strictly to the output format and instructions to maintain consistency and accuracy in your summary.
    """

    user_prompt += "User Defined Features : " + str(user_mvf)

    system_prompt = f"""
        <role>
        You are an assistant to a Senior Data Architect. You are very capable in reading, analyzing, and understanding complex database schemas and data models.
        No entity, constraint, relationship, or optimization logic goes unnoticed by you.
        You will be given a comprehensive database structure or schema information and will be asked to analyze, explain, and summarize it at a structural and functional level.
        </role>

        <Task>
        You will be given relevant database schema files or DDL definitions. The Senior Data Architect will consult you to clear doubts and ask for critical schema-level and data model-level analysis.
        <Important>
        1. You will be clear. Feel free to be descriptive but Avoid Jargon
        2. Perform a critical and deep analysis of the schema and the information given before responding.
        3. The schema will often involve multiple tables, foreign keys, views, procedures, and indexing strategies â€” be mindful of their dependencies and relationships.
        4. Enclose code or schema in (triple backticks)``` code ```
        </Important>
        </Task>

        Files from Database schema goes here :
        <Database Structure>
        {formatted_data}
        </Database Structure>
    """

    start_index = executive_summary.find("Highlighted Features")
    end_index = executive_summary.find("Key Benefits")

    if start_index != -1 and end_index != -1:
        executive_summary = executive_summary[start_index:end_index].strip()

    user_prompt += "Executive Summary : " + str(executive_summary)

    return system_prompt, user_prompt


#FEATURE HIERARCHY:
generate_features_system_prompt = """
  <Role>
    You are a Software Architect with expertise in analyzing large summaries from code files of an application. 
    You can comprehend summaries from code files that are complex, production-grade and are written in various programming languages to generate most important features, their description and the subfeatures with their description belonging to the most important features along with the other relevant information requested below.
    
    You will follow 2 Events before responding : 
    1. Generation of Feature Hierarchy as given in "Output_Format".
    2. Critical Evaluation of Every Confidence Score.  
  </Role> 

    <Task 1>
    You are provided with multiple relative file paths and file-wise code summaries from a application codebase.
    1. Analyze the file summaries carefully, leveraging your expertise to deduce the frameworks, functionality, and features.
    2. Perform a critical assessment of the code's functionality and interdependencies before responding.
    3. The codebase is complex and likely contains dependencies across various modules. Be mindful of these.
    4. Analyse every file summary and assign the features and sub-features based on the information provided.
    5. Respond strictly in the structured JSON format provided below.
    6. In each sub-feature's 'file_path' array:
        - Set 'critical: true' ONLY for files that are CORE & NON-REPLACEABLE to the sub-feature's main functionality.
        - Set 'critical: false' for ALL supporting, secondary, or replaceable files  
        - Each sub-feature should have both true and false entries.
        - If unsure, default to false (be EXTREMELY selective with 'true')
        - Make sure each sub-feature atleast have one file as true.

    Explanation of the Output terms:
    Feature - Features are most valuable and high level features extracted from the list of summaries that are provided to you. 
    Feature description - Description of the features explaining the high level value and impact that it creates for the project. Define the Feature. The description should be crisp, precise, well formatted and must be between 2-3 lines.
    Subfeature - Subfeatures are micro most valuable features that are extracted from the list of summaries and belong to the Most related and similar Features.
    Subfeature description - Description of the subfeatures explaining the specific value, technical and non-technical functionalites that it provided to the project. Define the subfeature and also explain how its related to the feature. The description should be crisp, precise, well formatted and must be between 2-3 lines.
    
    Points to Remember:
    1. Do not extract any feature or subfeature where there are no reference/citations from the application summaries.
    2. The description must be precise, valuable, well-formatted and must be between 2-3 lines.
    3. The Feature titles should be precise, specific, self explanaible, independent and not have similar feature titles. The Feature titles should not be highly generalized.
    4. The SubFeatures titles should be precise, self explanaible and not have similar subfeature titles. The SubFeature titles should not be highly generalized.
    5. SubFeatures should not be very low level that it explains code functions, code process like 'Json handling', 'Reading csv', readME etc.
    6. If similar subfeatures are present, then group them under one common Feature itself. Do not create multuple Features for similar subfeatures.
    6. If Unit testing related summaries are found, then create that as another Feature named 'Unit Testing' and assign the specific testing subfeatures under this feature.
    </Task 1>

  <Task 2>
  You shall now Assign and Justify Confidence Scores for each feature.

  <Critical Evaluation of Confidence Scores> 

  <Evaluation MODE>
  - You will now Forget everything that was done beforehand and act as an unbiased judge.
  - $Project-Summaries-&-Paths (INPUT).
  </Evaluation MODE>
  <Important>
  Critically analyze every "Feature" and "SubFeature" based on the following metrics. 
  You shall generate a confidence score between 0-100 for each of the following :
  1. Is the "Feature" & "SubFeature" name accurate to its functionality ? (Accuracy)
  2. Does the "Feature" & "SubFeature" include files with an unrelated function ? (Feature Dilution Rate)
  3. Important : Does this "Feature" & "SubFeature" make sense given the Overall Purpose of the Application ? (Consistency)
  4. Are all the files in "Feature" & "SubFeature" included ? (Completeness)

  <Strict>
  1. You will now generate a list of 4 confidence scores between 0-100 for above criteria under "confidence_score" key.
  2. Based on above criteria, you shall provide a VERY BRIEF logical explanation (10-20 words) for Confidence Score under "confidence_score_justification" key.
  3. Make sure to mention the entire filepath without omitting the prefix.
  4. Make sure all the filepaths are present.
  <Important> STRICTLY Don't Comment on Missing Files. Don't Overestimate. Don't Underestimate.</Important> 
  </Strict>

  </Important>

  </Critical Evaluation of Confidence Scores> 
  </Step 2>


      <Output_Format>
    Return a response in JSON format. Do not include any extra information or explanations. Strictly DON'T deviate from mentioned KEYS.
    Example:
```json
[
  {
    "name": "User Authentication and Management",
    "feature_description": "Comprehensive user account system with secure login, registration, profile management, and role-based access control.",
    "feature_description_confidence_score": [95, 70, 100, 70],
    "sub_features": [
      {
        "name": "User Registration",
        "description": "Allows new users to create accounts by providing necessary information such as username, email, and password. Implements email verification, password strength checks, and duplicate account prevention. Stores user data securely in the database with password hashing.",
        "file_path": [
          {
            "module_name": "RegistrationController",
            "path": "Controllers/Account/RegistrationController.cs",
            "critical": true
          },
          {
            "module_name": "RegisterView",
            "path": "Views/Account/Register.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [75, 80, 85, 65],
        "sub_feature_confidence_score_justification": "No feature dilution, might have missed some file."
      },
      {
        "name": "User Login",
        "description": "Authenticates users using their credentials, creates and manages user sessions, and implements security measures such as login attempt limiting and two-factor authentication (2FA). Provides password reset functionality for forgotten passwords.",
        "file_path": [
          {
            "module_name": "LoginController",
            "path": "Controllers/Account/LoginController.cs",
            "critical": true
          },
          {
            "module_name": "LoginView",
            "path": "Views/Account/Login.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [80, 100, 80, 75],
        "sub_feature_confidence_score_justification": "High chance of missing files."
      }
    ],
    "feature_confidence_score_justification": "No feature dilution, duplication or missing files. Accurate Naming."
  },
  {
    "name": "Product Catalog Management",
    "feature_description": "Comprehensive system for managing product listings, categories, and inventory across the e-commerce platform.",
    "feature_description_confidence_score": [95, 65, 70, 80],
    "sub_features": [
      {
        "name": "Product CRUD Operations",
        "description": "Enables administrators to create, read, update, and delete product listings. Includes functionality for managing product details such as name, description, price, images, and inventory levels. Implements validation to ensure data integrity and consistency across the product catalog.",
        "file_path": [
          {
            "module_name": "ProductController",
            "path": "Controllers/ProductController.cs",
            "critical": true
          },
          {
            "module_name": "ProductView",
            "path": "Views/Product/Index.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [90, 85, 100, 70],
        "sub_feature_confidence_score_justification": "High confidence with no duplication or dilution."
      },
      {
        "name": "Category Management",
        "description": "Allows for the creation and management of product categories and subcategories. Implements a hierarchical structure for organizing products, enabling efficient navigation and filtering of the product catalog for both administrators and customers.",
        "file_path": [
          {
            "module_name": "CategoryController",
            "path": "Controllers/CategoryController.cs",
            "critical": true
          },
          {
            "module_name": "CategoryView",
            "path": "Views/Category/Index.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [85, 75, 90, 95],
        "sub_feature_confidence_score_justification": "High confidence without any duplication or dilution."
      }
    ],
    "feature_confidence_score_justification": "All files refer to single overall functionality. Might have missed some files."
  }
]
```
  </Output_Format>

"""

generate_features_user_message = """
<Strictly Remember>
1. As input you will be given a batch of `file_path` and `file_summary` from a production codebase. Keep it in mind that it could be a file from a very large repository with lot of inter-dependencies.
2. Understand all the file description first, then try to determine the feature, sub-features and their description. For **each file** it should have a feature or sub-features whenever the conditions are met.
3. The response should contain all the fields given in the example output format. The response should be strictly in json format.
4. The description of features/subfeatures must be in the length of 2-3 lines. The response should be structured and well-formatted.
5. Don't generate any additional explanation or description. Provide the structured response in json only.
</Strictly Remember>
  
<Input file wise summary>
{file_summary}
</Input file wise summary>
<Response>
"""

merge_features_in_hierarchy_user_prompt = """You are a software feature analyzer. Given a list of related features that have been clustered together, create a merged feature that encompasses all the functionality.

Features to merge:
{feature_list}

Generate a JSON response that includes:
1. A name for the merged feature representing accurate feature name. Do not mention its merged or unified or anything as such. The feature name should accurately represent a major funcationality of a repository.
2. A detailed description that covers all functionality
3. A confidence score (0-100) for the merge
4. A justification for the confidence score

Respond with a JSON object in the following format:
```json
{{
    "name": "Merged feature name",
    "description": "Comprehensive description",
    "confidence_score": 85,
    "confidence_justification": "Reason for the confidence score"
}}
```
Give only JSON and nothing else. Do not include any explanations or additional text outside the JSON block. Make sure to start with ```json and end with ``` only.
"""

mapping_names_for_merged_features_user_prompt = """  <Role>
    You are a smart AI cassistant with strong expertise in Software Engineering. You can understand complex, production-grade codebases written in various programming languages and summarize them effectively.
  </Role>
  <Task>
  You will be given a brief description of  features of a large codebase and your task is to generate a relevant feature name, brief description, and priority level.
  <Important>
   1. The feature name should be brief, relevant and should represent the entire description provided.
   2. Generate a relevant description which is basically a overall summary of the description provided.
   3. Assign a priority level (high, medium, low) based on the significance, importance and complexity of the feature to the overall system. 
  </important>
  </Task>
  <Example output>
  ```json
    {
        "name": <feature_name>, //string
        "feature_description": <feature_description>, //string
        "priority": <priority> //string (high, medium, or low)
    }
    ```
  </Example output>
  <Strictly Remember>
1. The feature name should be relevant and at the same time interpretable, easy to understand.
2. The feature description should represnt the entire description given for summarisation, it should be simple and easy to understant.
3. The priority should be one of: high, medium, or low.
4. The response should be strictly in json format specified above.
5. Strictly make sure Feature Description is not more than 200 words.
  </Strictly Remember>

<code summary>
The code summary is given below:
"""


reducing_sub_features_user_prompt = """
    You are a software feature consolidation expert. Your task is to merge similar sub-features into one comprehensive sub-feature.

    Here are the sub-features that need to be merged:
    {sub_features_list}

    For each sub-feature, we have:
    - Name: The sub-feature name
    - Description: The sub-feature description (if available)
    - Confidence Score: The confidence score (if available)

    Your output should be a JSON object containing:
    1. A unified sub-feature name that encompasses all the input sub-features
    2. A comprehensive description that covers all aspects of the input sub-features
    3. A confidence score (use the highest available from input sub-features)
    4. A justification for the confidence score

    Return the output in JSON format starting with ```json and ending with ```.

    Example output format:
    ```json
    {{
        "name": "Unified Sub-Feature Name",
        "description": "Comprehensive description covering all aspects",
        "sub_feature_confidence_score": 95,
        "sub_feature_confidence_score_justification": "Merged from similar sub-features with high semantic similarity"
    }}
    ```
    """


post_processing_feature_name_description_system_prompt="""
  <Role>
    You are a smart AI assistant with strong expertise in Software Engineering. You can understand complex, production-grade codebases written in various programming languages and summarize them effectively.
  </Role>
  <Task>
  You will be given a brief description of modules or features of a large codebase and your task is to generate a relevant feature name and brief description.
  <Important>
   1. The feature name should be brief, relevant and should represent the entire description provided.
   2. Generate a relevant description which is basically a overall summary of the description provided.
   3. Also generate a confidence score in a scale of 0 - 100.
  </important>
  </Task>
  <Example output>
  ```json
    {
        "name": <feature_name>,
        "feature_description_confidence_score": <score 0 - 100>,
        "feature_description": <feature_description>
    }```
  </Example output>"""

post_processing_feature_name_description_user_prompt = """<Strictly Remember>
1. The feature name should be relevant and at the same time interpretable, easy to understant.
2. The confidence score should represent the ability to summarise the description.
3. The feature description should represnt the entire description given for summarisation, it should be simple and easy to understant.
4. The response should be strictly in json format specified above.
</Strictly Remember>
<code summary>
The code summary is given below: \n
{feature_description}
</code_summary>
<response>
Your response in json goes here:
"""

merge_similar_features_system_prompt = """You are a solution architect. Your task is to carefully review each feature and its description, and combine them into a single high-level feature.

The final high-level features should represent what an end user would perceive, e.g., Messenger, Google Chat, Messaging, Reels, etc.

Based on the generated features provided, identify which features can be merged into a single high-level feature. 
Strictly output them in the following format:
{{ 
  <High-Level Feature Name 1>: [<Merged Feature 1>, <Merged Feature 2>, <Merged Feature 3>, ...],
  <High-Level Feature Name 2>: [<Merged Feature 1>, <Merged Feature 2>, <Merged Feature 3>, ...],
  ...
}}

INPUT:
Feature names and descriptions are provided in the format: 
[1. Feature name: <feature name> 
Feature description: <feature description>, 
2. ...]

{feature_texts}

MVFS:
{total_MVFs}

Points to remember:
1. While merging features and naming high-level features, always prefer names from the user-defined MVFs provided. All relevant features can be grouped under these high-level features.
2. If certain features do not fit under the user-defined MVFs, choose a better name than the existing one for the new high-level feature if necessary.
3. The names of the features being merged must remain exactly as provided in the INPUT section; do not modify them. Do not consider Feature description in Feature Names.
4. Follow the output structure strictly: high-level feature names as dictionary keys and merged features as values in list format.
5. If a feature is already a high-level feature, you do not need to forcibly merge it. If a feature seems to be function-level/low-level  features, merge them into a High-level feature.
6. Merge similar features into a single high-level feature based on their names and descriptions, when applicable. Each final high-level feature should be independent of the others.
7. Do not assign the same feature to multiple high-level features.
8. If user-defined MVFs are empty, skip point 1 and begin with point 2.
9. Do **not** include any Feature descriptions in the final output."""


merging_description_user_prompt = """You are a Solution Architect. Your task is to summarize the multiple feature descriptions provided into a brief, coherent summary of **no more than two sentences**.

  The summary must:
  - Accurately capture all key components from the provided descriptions.
  - Align clearly with the given high-level feature name.
  - Serve as the final description of the high-level feature.

  Only the final summarized description should be included in the output â€” no additional commentary or formatting.

  INPUT:
  Multiple descriptions: {merging_feature_description}

  High-Level Feature Name: {high_level_feature}
  """


micro_sub_feature_prompt = """You are an expert system analyst specializing in decomposing SubFeatures into granular, logically independent components. You support **two levels** of splitting:

1. **Horizontal splitting**: Split a subfeature into multiple *same-level subfeatures* when it encompasses multiple independently meaningful functionalities. The subfeatures created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.
2. **Vertical splitting**: Further break each of those subfeatures into *microsubfeatures* (if applicable), ensuring each micro-sub-features/micro-user-story describes a single goal or operation. The micro-sub-features/micro-user-story created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.

---

### ðŸ”§ TASK OVERVIEW

Given a Macro-Feature, Subfeature, its description, associated module files and its summary:

- Decide if the subfeature should be split horizontally into multiple same-level subfeatures.
- For each resulting subfeature (or original if not split), analyze whether it can be split vertically into **microsubfeatures** (fine-grained user stories).
- Provide the confidence scores for the subfeature that is split, whether horizontally or vertically.
- Provide the files that are related to the sub_features too, not just the micro_sub_features.
- Each leaf user-story must have files assigned to them, else you should not create/split these subfeatures.
- Provide description of generated subfeature/sub-user-stories in 2-4 lines but only valid information. Do not assume or hallucinate to generate description.
Apply this recursively: if horizontal splitting occurs, then attempt vertical splitting for each. But remember, not to create any duplicates in the process. 

---

### SPLITTING DECISIONS

#### Horizontal Splitting (Same-level Subfeatures):
Split if:
- The subfeature covers multiple high-level functionalities
- Each function could be planned, developed, and deployed independently
- Each component has a clear boundary and responsibility

#### Vertical Splitting (Microsubfeatures):
Split further if:
- A subfeature contains multiple independent operations or logical stages
- These operations can be implemented, tested, or tracked separately
- Each micro-subfeature represents one atomic, non-overlapping functionality

---

### DO NOT SPLIT IF:
- sub-user-stories are tightly coupled in the Subfeature and cannot function independently.
- Do not split subfeatures into sub-user-stories that are hardly single line of code and cannot be considered as a proper functionality, but just a config/parameter.
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across actions are too complex to isolate.
- There are no files that can be mapped to the generated user-story.
- Do not split if the user-story is barely a functionality. The split user-stories must have independent functionality that contributes to the subfeature and feature and if not, do not split.
- Don not split ReadMe & .md files into sub-user-stories.
- Do not split horizontall for granullar subfeatures as they are not user stories but mid level features.
---

### FILE MAPPING RULES:
- For each subfeature or microsubfeature, cite only directly relevant files.
- Use only the provided input data to match files â€” no guessing.
- Avoid duplication unless a file is clearly shared between components.

Each `file_path` entry must include:
```json
{
  "module_name": "<Name>",
  "path": "<Path>",
  "critical": <true/false>,
  "git_url": "<Git URL>"
}

OUTPUT FORMAT
If the subfeature should NOT be split:
Return: "None"

If the subfeature should be split, return a list of Parent User Stories with subfeatures inside.
If a subfeature itself can be further split into microsubfeatures, nest them under micro_sub_features like so:

[
  {
    "name": "Parent User Story Title 1",
    "description": "Full description of the original or updated user story and its purpose.",
    "file_path": [...],
    "sub_feature_confidence_score":"confidence score of the subfeature with respect to the Feature, as a percentage (e.g., 80)"
    "micro_sub_features": [
      {
        "name": "Sub-User Story Title 1",
        "description": "Standalone description of a single functionality.",
        "file_path": [...],
        "micro_sub_feature_confidence_score":"confidence score of the micro_sub_feature with respect to the sub_feature, as a percentage (e.g., 90)"
        }
          ...
        ]
      },
      ...
    ]
  }
]
Each layer must preserve independence, clarity, and singular focus of each story.

VALIDATION CHECKLIST
- Each title must express one functionality only (no imperative phrasing)
- description must avoid assumptions and describe the real function. It must be as detailled as possible.
- Each story must make sense independently and fit in the broader feature flow
- if there are multiple user-story under the subfeature, it needs to be in sequence of business logic.
- File mappings must be relevant and scoped accurately
- Do no miss/skip any values in the output json. The output structure must be maintained strictly.
- All subfeature and sub-user-story names and descriptions must be strictly in a declarative tone, not imperative.

* Use generic or speculative statements
"""


db_micro_sub_feature_prompt = """
<Role>
You are an expert Database analyst specializing in decomposing SubFeatures into granular, logically independent components. You support **two levels** of splitting:
You shall ALWAYS process features from a Database perspective ONLY. 
There can be more than one Table in the DB context provided to you.
</Role>

1. **Horizontal splitting**: Split a subfeature into multiple *same-level subfeatures* when it encompasses multiple independently meaningful functionalities. The subfeatures created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.
2. **Vertical splitting**: Further break each of those subfeatures into *microsubfeatures* (if applicable), ensuring each micro-sub-features/micro-user-story describes a single goal or operation. The micro-sub-features/micro-user-story created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.

<Strict Constraints> 
- You are dealing with Database Information. 
- No matter what, STRICTLY use Database-Specific Language ALWAYS. 
- Use words like Columns / Fields / Schema / DataTypes / Constraints / Foreign Keys / Primary Keys etc.
- Strictly Do not start descriptions with or start with "this micro-feature" / or "this sub-feature".
- You shall do this regardless of the input context and nature.
Remember : Every "FILE" given to you is information of a table. Therefore in your response, ALWAYS refer to "Table" instead of "File".

</Strict Constraints> 


### ðŸ”§ TASK OVERVIEW

Given a Macro-Feature, Subfeature, its description, associated module files and its summary:

- Decide if the subfeature should be split horizontally into multiple same-level subfeatures.
- For each resulting subfeature (or original if not split), analyze whether it can be split vertically into **microsubfeatures** (fine-grained user stories).
- Provide the confidence scores for the subfeature that is split, whether horizontally or vertically.
- Provide the files that are related to the sub_features too, not just the micro_sub_features.
- Each leaf user-story must have files assigned to them, else you should not create/split these subfeatures.
- Provide description of generated subfeature/sub-user-stories in 2-4 lines but only valid information. Do not assume or hallucinate to generate description.
Apply this recursively: if horizontal splitting occurs, then attempt vertical splitting for each. But remember, not to create any duplicates in the process. 

---

### SPLITTING DECISIONS

#### Horizontal Splitting (Same-level Subfeatures):
Split if:
- The subfeature covers ONE / MORE THAN ONE high-level functionalities
- Each function could be planned and developed independently
- Each component has some clear boundaries and responsibilities

#### Vertical Splitting (Microsubfeatures):
Split further if:
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across actions are too complex to isolate.
- There are no tables that can be mapped to the generated user-story.
- The subfeature is too complex to be planned, developed, and deployed independently
- Each micro-subfeature represents one atomic, non-overlapping functionality
Note: Maintain at least 2 subfeatures unless the database has only one table.
- Prioritize brevity, consistency and no informaiton leakage across subfeatures.
- Ensure crisp segregation.
---

### DO NOT SPLIT IF:
- sub-user-stories are tightly coupled in the Subfeature and cannot function independently.
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across tables in two features are too complex to isolate.
- There are no tables that can be mapped to the generated user-story.
Note: Maintain at least 2 subfeatures and 1 or more microsubfeatures per subfeature, Unless the database has only one table.
Note : Maintain brevity during splitting at the same level. Do NOT overload the a single feature with too many subfeatures.
---


### FILE MAPPING RULES:
- For each subfeature or microsubfeature, cite only directly relevant tables.
- Use only the provided input data to match files â€” no guessing.
- Avoid duplication unless a file is clearly shared between components.

Each `file_path` entry must include:
```json
{
  "module_name": "<Name>",
  "path": "<Path>",
  "critical": <true/false>,
  "git_url": "<Git URL>"
}

OUTPUT FORMAT
If the subfeature should NOT be split:
Return: "None"

If the subfeature should be split, return a list of Parent User Stories with subfeatures inside.
If a subfeature itself can be further split into microsubfeatures, nest them under micro_sub_features like so:

[
  {
    "name": "Parent User Story Title 1",
    "description": "Full description of the original or updated user story and its purpose.",
    "file_path": [...],
    "sub_feature_confidence_score":"confidence score of the subfeature with respect to the Feature, as a percentage (e.g., 80)"
    "micro_sub_features": [
      {
        "name": "Sub-User Story Title 1",
        "description": "Standalone description of a single functionality.",
        "file_path": [...],
        "micro_sub_feature_confidence_score":"confidence score of the micro_sub_feature with respect to the sub_feature, as a percentage (e.g., 90)"
        }
          ...
        ]
      },
      ...
    ]
  }
]
Each layer must preserve independence, clarity, and singular focus of each story.

VALIDATION CHECKLIST
- Each title must express one functionality only (no imperative phrasing)
- description must avoid assumptions and describe the real function. It must be as detailled as possible.
- Each story must make sense independently and fit in the broader feature flow
- if there are multiple user-story under the subfeature, it needs to be in sequence of business logic.
- File mappings must be relevant and scoped accurately
- Do no miss/skip any values in the output json. The output structure must be maintained strictly.
- All subfeature and sub-user-story names and descriptions must be strictly in a declarative tone, not imperative.
- Use Database-specific schema only. Do not include words like "Attributes" / "Code Files" in your response. 
- Strictly Do not start descriptions with or start with "this micro-feature" / or "this sub-feature".
* Use generic or speculative statements

"""import os
from graphviz import Digraph
import re 
import json

def parse_ddl(ddl: str):
    """
    Parse the DDL to extract columns, primary keys, and foreign keys.
    """
    lines = ddl.splitlines()
    column_lines = []

    for line in lines:
        line = line.strip()
        if (
            line.upper().startswith("CREATE")
            or line.upper().startswith("PRIMARY")
            or line.upper().startswith("FOREIGN")
            or line.upper().startswith(")")
            or line == ""
        ):
            continue

        match = re.match(r'(\w+)\s+\w+', line)
        if match:
            column_lines.append(match.group(1))

    pk_match = re.search(r'PRIMARY KEY\s*\((.*?)\)', ddl)
    primary_keys = [key.strip() for key in pk_match.group(1).split(",")] if pk_match else []

    foreign_keys = []
    for match in re.finditer(r'FOREIGN KEY\s*\(([^)]+)\)\s+REFERENCES\s+`?[\w]+\.(\w+)`\(([^)]+)\)', ddl):
        fk_col = match.group(1).strip()
        ref_table = match.group(2).strip()
        ref_col = match.group(3).strip()
        foreign_keys.append((fk_col, ref_table, ref_col))

    return column_lines, primary_keys, foreign_keys


def generate_combined_graph(tables_data):
    """
    Generate a single combined graph from multiple tables.
    """
    dot = Digraph(comment='Combined Table Diagram')
    dot.attr(rankdir='LR')

    # Store individual table nodes
    for table in tables_data:
        table_name = table['table_name']
        columns = table['columns']
        primary_keys = table['primary_keys']
        
        label_lines = []
        for col in columns:
            if col in primary_keys:
                label_lines.append(f"{col} [PK]")
            else:
                label_lines.append(col)
        dot.node(table_name, shape='box', label=f'{table_name}\\n' + "\\n".join(label_lines))

    # Add relationships
    for table in tables_data:
        table_name = table['table_name']
        for fk_col, ref_table, ref_col in table['foreign_keys']:
            dot.edge(table_name, ref_table, label=f'{fk_col} â†’ {ref_col}')

    return dot

def folder_summary_generation_prompts(
        total_allocated_tokens, 
        file_list, folder_name, 
        folder_path,
        subfolder_list,
        formatted_file_summaries,
        formatted_file_services,
        formatted_subfolder_summaries,
        formatted_subfolder_services,
        formatted_subfolder_features
    ):
    
    system_prompt = f"""
        You are an expert code analyst specialized in creating detailed, informative summaries of software project folders. Your task is to thoroughly analyze files and subfolders to provide a comprehensive understanding of the application or project and provide combined summaries along with required details. These summaries must be detailled enough for further summarization.

        Follow these guidelines:
        1. Conduct a deep analysis of the features to identify its core purpose and functionality
        2. Provide detailed explanation of key implementations and technical approaches of the features
        3. Thoroughly examine the summaries based on files and folders to understand relationship between features and combined smaller features into larger high level application level features.
        4. Explain the features within the broader project architecture with specific connections
        5. Describe technical patterns, design decisions, and architectural choices evident in the code
        6. Include specific functions, classes, and methods that define the feature's behavior
        7. Note dependencies, imports, and external connections that shape the folder's functionality
        8. Identify potential architectural strengths and areas for improvement when evident
        9. Identify all services represented in this folder based on file and subfolder services information
        10. Identify and articulate high-level features or functionalities represented by the folder into the feature_details section, when consolidating multiple subfolders or lower-level files. Derive these insights from both file-level and subfolder-level summaries. Also under each feature, mention which file/folder was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
        11. Do not miss any features that could be formed based on these summaries as this information is required to understand the application's buisness logic.
        12. Gather insights from the summaries provided to generate a high level detailled executive summary that could be used by business stakeholders to understand the folder/project.
        13. When analyzing the root folder, both the executive summary and the features must be strictly formed in a high level business logic standpoint of an application.
        
        IMPORTANT: 
        - Your summary should be thorough and detailed({total_allocated_tokens}) while maintaining technical/business precision and depth. Focus on providing insights that would help both stakeholders and developers understand the application better.
        - feature_details must contain high level feature name and feature description(value of the files/folders) strictly in concise bullet points. The feature inforamtion must be in detail to capture the complete high level knowledge for that feature but not the function level details. Feature names cannot be programmatic function names like Dependency management, json handling etc. instead it should be inventory management, order processing etc. 
        - Your services list should be comprehensive and include all services represented in this folder.
        - is_reuasble_lib if a folder is used as reusable lib make it True otherwise False
        - lib_name if is_reusable_lib is True then provide the name of the reusable lib/component If is_reusable_lib False then add Not Applicable
        - category if is_reusable_lib is True then provide category only between 'Frontend' and 'Backend' If is_reusable_lib False then add Not Applicable
        - sub_category if is_reusable_lib is True then provide sub category only between 'UI Component','Custom Hooks', 'http_client', 'Utils', 'Others' In Frontend & 'Middleware', 'Error Handling', 'Auth', 'Utils', 'Others' In Backend If is_reusable_lib False then add Not Applicable
        - when_to_use if is_reusable_lib is True then provide where this reusable lib/component can be used If is_reusable_lib False then add Not Applicable 
        - associated_files if is_reusable_lib is True then provide the list of files associated(give complete path for the assosciated file) with this reusable lib/component If is_reusable_lib False then add Not Applicable
        - summary must not be technical and only explain the high level details of the folder/project. Understand the file and folder summaries provided to combine the knowledge to form the executive summary. Make it as detailled as possible.
        - Use clear and concise language, avoiding jargon where possible.
        
        - You must provide your response in this exact format:
        ```summary
        [Your detailled high-level executive summary for the folder for business stakeholders]
        ```
        ```feature_details
        [List of high-level features or functionalities represented in this folder]
        ```
        ```services_namess
        [Comma-separated list of all services represented in this folder]
        ```
        ```is_reuasble_lib
        Boolean Value
        ```
        ```lib_name
        [Name of the reusable library if applicable]
        ```
        ```category
        [Category of the reusable library if applicable]
        ```
        ```sub_category
            [Sub category of the reusable library if applicable]
        ```
        ```when_to_use
        [Your detailed use case where or when this reuasble_lib can be usefull]
        ```
        ```associated_files
            [Comma-separated list of associated files with the reusable library, Give the Complete file path as mentioned in the file list]
        ```
        ```example_usage
            [Example code snippet of how to use this reusable library]
        ```
    """

    user_prompt = f"""
        Generate a summary and services list for the folder: "{folder_name}" (Path: {folder_path})

        FOLDER CONTENTS:
        - Files ({len(file_list)}): {", ".join(file_list) if file_list else "None"}
        - Subfolders ({len(subfolder_list)}): {", ".join(subfolder_list) if subfolder_list else "None"}

        FILE SUMMARIES:
        {os.linesep.join(formatted_file_summaries) if formatted_file_summaries else "No file summaries available"}

        FILE SERVICES:
        {os.linesep.join(formatted_file_services) if formatted_file_services else "No file services available"}

        SUBFOLDER SUMMARIES:
        {os.linesep.join(formatted_subfolder_summaries) if formatted_subfolder_summaries else "No subfolder summaries available"}

        SUBFOLDER SERVICES:
        {os.linesep.join(formatted_subfolder_services) if formatted_subfolder_services else "No subfolder services available"}

        SUBFOLDER FEATURES:
        {os.linesep.join(formatted_subfolder_features) if formatted_subfolder_features else "No subfolder features available"}
        
        Based on these components:
        1. Provide a thorough technical summary explaining the folder's purpose, implementation details, and architectural significance
        2. Compile a comprehensive list of all services represented in this folder based on file and subfolder services information
        
        Follow the exact format specified in the system instructions for your response.
    """

    return system_prompt, user_prompt

def services_generation():
    system_prompt = """
        <Task>
        Create an architectural blueprint of the given repository by identifying and classifying both external services and third-party services with no overlap between categories.
        </Task>

        <Definitions>
        - External services: Company-provided services hosted outside the application (AWS S3, Google Cloud, Stripe, Twilio)
        - Third-party services: Libraries, frameworks, and SDKs that are part of the core application stack (Django, React, MongoDB, Redux)
        </Definitions>

        <Output_Format>
        {
        "external_services": [
            {
            "external_service_name": "string",
            "description": "string",
            "associated_files": ["string"],
            "service_class": "string",
            "used_in_files": ["string"]
            }
        ],
        "thirdparty_services": [
            {
            "thirdparty_service_name": "string",
            "description": "string",
            "associated_files": ["string"],
            "service_class": "string",
            "used_in_files": ["string"]
            }
        ]
        }
        </Output_Format>

        <Instructions>
        1. Conduct a thorough repository analysis to identify all services
        2. Classify each service into exactly ONE category:
        - External services: Cloud platforms, payment processors, authentication providers
        - Third-party services: Frameworks, libraries, SDKs integrated into the codebase
        3. For each service, provide:
        - Name: Exact service name
        - Description: Concise explanation of functionality and purpose
        - Associated files: All files directly importing or using the service
        - Service class: Category (e.g., "cloud storage", "web framework", "database")
        - Used in files: Complete paths of files utilizing the service
        4. Ensure ZERO overlap between categories
        5. Prioritize accuracy over comprehensiveness
        6. Validate that identified services are actively used in the project
        7. Include only services with clear evidence of implementation
        8. Do not create a lot of services which are redundant. Keep it to a maximum of 50 services only.
        </Instructions>

        <Examples>
        Good External Service Entry:
        {
        "external_service_name": "AWS S3",
        "description": "Cloud storage service used for storing user-uploaded files",
        "associated_files": ["src/services/storage.js", "src/config/aws.js"],
        "service_class": "cloud storage",
        "used_in_files": ["src/components/FileUpload.js", "src/pages/UserProfile.js"]
        }

        Good Third-Party Service Entry:
        {
        "thirdparty_service_name": "React",
        "description": "Frontend JavaScript library for building user interfaces",
        "associated_files": ["package.json", "src/index.js"],
        "service_class": "frontend framework",
        "used_in_files": ["src/App.js", "src/components/*.js"]
        }
        </Examples>

        Analyze the repository and provide the complete architectural blueprint in the specified format.
    """

    user_prompt = ""

    return system_prompt, user_prompt

def executive_summary_generation(combined_summary, user_mvf):
    system_prompt = """
    Your Role:
    You are an expert software architect tasked with understanding a codebase and creating an executive summary that clearly articulates the main purpose of this application,
    the core problem that the application is solving, and the prioritized list of the most valuable features, solely based on the provided folder wise summary. Do not hallucinate and create the most valuable features and its description on assumption. This needs to be based on facts.

    Task:
    1. Analyze provided folder wise summary and the services used and the user defined features (if provided).
    2. Understand component interactions and functions.
    3. Prioritize the User Defined Features (if provided) in the summary.
    4. Identify and prioritize the most valuable features based on their importance and relevance to the overall project, as evidenced in the code.
    5. Create a comprehensive executive summary.

    Steps:
    1. Review folder wise summary.
    2. Analyze folder wise summary:
    - Identify key components and their roles
    - Note data operations, design patterns, and architectural decisions
    3. Create summary:
    - Describe the specific problem the codebase solves, based on folder wise summary
    - Explain component interactions
    - Outline data workflow
    4. Identify and prioritize main features:
    - Determine which feature(s) address the core problem of the application, based on code implementation
    - Rank features based on their importance and relevance to solving the main problem, as evidenced in the code
    - The feature should be major components of the codebase and not minor functions like "Modular Architecture" or "Code Reusability", these are not features but design principles.

    Focus Areas:
    - Precised feature prioritization and importance
    - High-level functionality
    - Clear, concise technical language
    - Objective description
    - Capture entire workflow

    Guidelines:
    - Only use the folder wise summary provided
    - Use precise technical terms
    - Include user-defined features if provided and evidenced in the code
    - Prioritize features based on their importance to the core problem, as shown in the folder wise summary

    Feature Identification and Prioritization:
    - Carefully analyze the folder wise summary to identify features actually present in the folder wise summary
    - Do not assume or infer features that are not explicitly mentioned in the folder wise summary
    - Identify the top feature that solves the majority of the problem based on code evidence
    - Rank subsequent features in descending order of importance, ensuring they are present in the folder wise summary
    - Ensure the feature list reflects the codebase's focus and structure
    - Only include features that have substantial implementation in the codebase that is evident from folder wise summary

    Output Format - Adhering to this format is crucial
    ```json
    {
    "data": "generated_summary in string format adhering to the Expected Output Format for Generated Summary",
    "confidence_score": 90,
    "traceback": {
    "Feature 1 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 1 Title' is included, as the 'phrase' is an evidence that this feature is part of the codebase.",
    "Feature 2 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 2 Title' is included, as the 'phrase' is an evidence that this feature is part of the codebase.",
    ...
    }
    }
    ```

    Requirements:
    - Replace \n with \\n in JSON
    - Limit upto 5 main features (max 2 sub-features each) or 7500 tokens
    - If due to any reason such as codebase being small, you are unable to provide 5 features, then provide as many high-level features as possible between the range of 1 to 5.
    - Don't assume features or include minor features due to inability to provide 5 features, lesser number of features is acceptable.
    - Use specified JSON format only
    - Start with "```json" and end with "```"
    - Ensure the top feature in the prioritized list addresses the core problem and is present in the folder wise summary
    - Rank features in descending order of importance to the main problem, based on actual code implementation
    - Do NOT include features that are NOT evidenced in the provided folder wise summary
    - Evaluate the folder wise summary objectively, considering all conclusions on the actual code provided
    - Do NOT make any assumptions about organizational goals or intentions beyond what is explicitly shown in the code
    - Focus solely on the technical aspects and implemented functionality, avoiding speculation about business objectives or future plans
    - Both the keys data, confidence score, and traceback should be present in the output JSON
    - The generated summary should be in string format only and be contained inside the "data" key
    - The "traceback" key should contain a dictionary with feature names as keys and justifications for including these features based on exact phrases from the input
    - Do not include any feature that could potentially be part of the folder wise summary without explicit evidence
    - Every feature mentioned must be driven by clear evidence from the provided input
    """
    user_prompt = """
    Expected Output Format for Generated Summary:

  **Overview**
  <empty line>
  <A brief introduction to the codebase and its main purpose; in paragraph format only, not in points.
  This paragraph should provide a concise yet comprehensive overview of the codebase, its primary functionality, solution provided by the project and its intended use case.
  Aim for 3-5 sentences that capture the essence of the project.>
  <empty line>
  **Highlighted Features**
  <empty line>
  <
  List and briefly explain the key features that are significant components of the codebase and would serve as selling points.
  These features should be presented as follows:
  1. Use numbered points for each feature.
  2. Provide a brief explanation for each feature in 1-2 sentences, highlighting its importance and benefit to the end user.
  3. Focus on features that are central to the codebase's functionality and most important to the end user.
  4. Dont include generic features like "Modular Architecture" or "Code Reusability", these are not features but design principles.
  5. Do not include sub-points under any feature.
  6. Prioritize User Defined Features (if provided) at the beginning of the list.
  7. If User Defined Features are given, list them first before including any features identified through your analysis.
  8. Aim to provide upto of 1 to 5 key features, after each feature add an empty line for formatting purposes.
  9. Ensure that the features listed represent the core functionality and unique selling points based on the folder wise summary.
  10. Use clear, concise language that emphasizes the value proposition of each feature.
  11. Also under each feature, mention which file/folder was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
  12. Do not add features into Highlighted Features if they dont have value for buisness stakeholder about the application. Also do not repeat adding similar feature in this section.

  Output Structure:
  1. ***<Feature 1 Title>***: <Description of the feature in one to two sentences.\n
  2. ***<Feature 2 Title>***: <Description of the feature in one to two sentences.>\n
  >
  <empty line>
  **Key Benefits**
  <empty line>
  <Summarize the key benefits of the codebase in one to two sentences.
  This summary should encapsulate the overall value proposition of the codebase and its potential impact on users or the organization.>
  <empty line>
  <Highlight the most significant key benefits the codebase has to offer in bulleted points. The format should be:
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  Aim for 3-5 bullet points that capture the most compelling advantages of using this codebase, after each point add an empty line for formatting purposes.
  Each benefit should be distinct and provide a clear value proposition.>

  <Final Output Format>
  Output Format - Adhering to this format is crucial, the output should be in parsable JSON format:
  ```json
  {{
    "data": "<generated_summary in string format adhering to the Expected Output Format for Generated Summary>",
    "confidence_score": 90,
    "traceback": {{
      "Feature 1 Title": "Since it mentions about <exact phrase from the folder wise summary>, the 'Feature 1 Title' is included, as the "phrase" is an evidence that this feature is part of the folder wise summary.",
      "Feature 2 Title": "Since it mentions about <exact phrase from the folder wise summary>, the 'Feature 2 Title' is included, as the "phrase" is an evidence that this feature is part of the folder wise summary.",
      ...
    }}
  }}
  ```
  </Final Output Format>
  Note: If the traceback includes phrases that are not present in the folder wise summary then you would be penalized 10000 points.
  The output should be having data, confidence score, and traceback keys, and the entire content inside "```json" and "```" should be parsable by json.
  The "data" key should contain the generated summary and it should be in string format only, allowing the parsing of the entire json.
  If there are any inverted commas inside the generated summary, then escape them with a backslash.
  Do not change or skip the headings of each section in the generated json. The generated summary must have "Overview", "Highlighted Features", "Key Benefits" as section titles. Follow the above provided guidelines."""
    user_prompt += f"""Use the below folder wise summary to generate the summary in the above format: {combined_summary}""" + "User Defined Features : " + str(user_mvf)
    return system_prompt, user_prompt

def db_executive_summary_generation(combined_summary, user_mvf): 
    system_prompt = """
    Role:
    You are an expert Database Architect tasked with understanding the contents of all tables and schema of the database. 
    You shall Articulate a proper executive summary that clearly captures all the main & high-level features of this database.
    The core use-case that this database is intended for, and the prioritized list of the most valuable features, solely based on the provided Table-Level summaries. 
    Do not hallucinate. Do NOT create the most valuable features and its description on pure assumptions. This needs to be based on facts, with proper backing.

    Task:
    1. Analyze provided Table wise summaries.
    2. Understand component interactions and functions.
    3. Prioritize the User Defined Features (if provided) in the summary.
    4. Identify and prioritize the most valuable features based on their importance to the core use-case the Database is solving.
    5. Create a comprehensive executive summary.

    Steps:
    1. Review Table wise summary.
    2. Analyze Table wise summary:
      - Identify all tables. 
      - Take into consideration the foreign keys, primary keys, is-a, has-a, and many-to-many relationships.
      - Deeply understand the intended-use-case of each table.
      - Note data operations, design patterns, and architectural decisions
    3. Create summary:
      - Describe the specific problem the Database is solving, based on Table wise summary
      - Explain high-level interactions and dependencies
      - Outline data workflow
    4. Identify and prioritize main features:
      - Determine which feature(s) address the core problem of the Database, based on SQL implementation and Table wise summary
      - Rank features based on their importance and relevance to solving the main problem, as evidenced in the Database
      - The feature should be major components of the Database and not minor functions like Many-to-Many Relationships, or "Foreign Keys". 
        These are implementation concepts. Not core features.

    Focus Areas:
    - Precised feature prioritization and importance
    - High-level functionality of this Database
    - Clear, concise technical language with Database-specific Language
    - Objective description
    - Capture entire data workflow

    Guidelines:
    - Only use the Table wise summary provided
    - Use precise Database-relevant technical terms
    - Include user-defined features if provided and evidenced in the Table wise summary
    - Prioritize features based on their importance to the core problem, as shown in the Table wise summary

    Feature Identification and Prioritization:
    - Carefully analyze the Table wise summary to identify features actually present in the Table wise summary
    - Do not assume or infer features that are not explicitly mentioned in the Table wise summary
    - Identify the top feature that solves the majority of the problem based on Database and SQL evidence
    - Rank subsequent features in descending order of importance, ensuring they are present in the Table wise summary
    - Ensure the feature list reflects the Database's focus and structure
    - Only include features that have substantial implementation in the Database that is evident from Table wise summary

    Output Format - Adhering to this format is crucial
    ```json
    {
    "data": "generated_summary in string format adhering to the Expected Output Format for Generated Summary",
    "confidence_score": 90,
    "traceback": {
    "Feature 1 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 1 Title' is included, as the 'phrase' is an evidence that this feature is part of the Database.",
    "Feature 2 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 2 Title' is included, as the 'phrase' is an evidence that this feature is part of the Database.",
    ...
    }
    }
    ```

    Requirements:
    - Replace \n with \\n in JSON
    - Limit upto 5 main features (max 2 sub-features each) or 7500 tokens
    - If due to any reason such as Database being small, you are unable to provide 5 features, then provide as many high-level features as possible between the range of 1 to 5.
    - Don't assume features or include minor features due to inability to provide 5 features, lesser number of features is acceptable.
    - Use specified JSON format only
    - Start with "```json" and end with "```"
    - Ensure the top feature in the prioritized list addresses the core problem and is present in the Table wise summary
    - Rank features in descending order of importance to the main problem, based on actual Database and SQL implementation
    - Do NOT include features that are NOT evidenced in the provided Table wise summary
    - Evaluate the Table wise summary objectively, considering all conclusions on the actual Database and SQL provided
    - Do NOT make any assumptions about organizational goals or intentions beyond what is explicitly shown in the Database and SQL
    - Focus solely on the technical aspects and implemented functionality, avoiding speculation about business objectives or future plans
    - Both the keys data, confidence score, and traceback should be present in the output JSON
    - The generated summary should be in string format only and be contained inside the "data" key
    - The "traceback" key should contain a dictionary with feature names as keys and justifications for including these features based on exact phrases from the input
    - Do not include any feature that could potentially be part of the Table wise summary without explicit evidence
    - Every feature mentioned must be driven by clear evidence from the provided input.
    - Strictly use an assertive and objective tone in your response. 
    - Do not be unsure about anything.
    - Do not include the "Folder Name" in your response. Ignore "dbanalysis" folder. Provide Executive Summary of the Database-ONLY.
    """

    user_prompt = """
  Expected Output Format for Generated Summary:

  **Overview**
  <empty line>
  <A brief introduction to the Database and its main purpose; in paragraph format only, not in points.
  This paragraph should provide a concise yet comprehensive overview of the Database, its primary functionality, and its intended use case.
  Aim for 3-5 sentences that capture the essence of the Database.>
  <empty line>
  **Highlighted Features**
  <empty line>
  <
  List and briefly explain the key features that are significant components of the Database and would serve as selling points.
  These features should be presented as follows:
  1. Use numbered points for each feature.
  2. Provide a brief explanation for each feature in 1-2 sentences, highlighting its importance and benefit to the END USER.
  3. Focus on features that are central to the Database's functionality and most important to the END USER.
  4. Dont include generic features like  Many-to-Many Relationships, or "Foreign Keys", these are not features but Design Principles.
  5. Do not include sub-points under any feature.
  6. Prioritize User Defined Features (if provided) at the beginning of the list.
  7. If User Defined Features are given, list them first before including any features identified through your analysis.
  8. Aim to provide upto of 1 to 5 key features, after each feature add an empty line for formatting purposes.
  9. Ensure that the features listed represent the core functionality and unique selling points based on the Table wise summary.
  10. Use clear, concise language that emphasizes the value proposition of each feature.
  11. Also under each feature, mention which file/Table was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
  12. Do not add features into Highlighted Features if they dont have value for buisness stakeholder about the application. Also do not repeat adding similar feature in this section.

  Output Structure:
  1. ***<Feature 1 Title>***: <Description of the feature in one to two sentences.\n
  2. ***<Feature 2 Title>***: <Description of the feature in one to two sentences.>\n
  >
  <empty line>
  **Key Benefits**
  <empty line>
  <Summarize the key benefits of the Database in one to two sentences.
  This summary should encapsulate the overall value proposition of the Database and its potential impact on users or the organization.>
  <empty line>
  <Highlight the most significant key benefits the Database has to offer in bulleted points. The format should be:
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  Aim for 3-5 bullet points that capture the most compelling advantages of using this Database, after each point add an empty line for formatting purposes.
  Each benefit should be distinct and provide a clear value proposition.>

  <Final Output Format>
  Output Format - Adhering to this format is crucial, the output should be in parsable JSON format:
  ```json
  {{
    "data": "<generated_summary in string format adhering to the Expected Output Format for Generated Summary>",
    "confidence_score": 90,
    "traceback": {{
      "Feature 1 Title": "Since it mentions about <exact phrase from the Table wise summary>, the 'Feature 1 Title' is included, as the "phrase" is an evidence that this feature is part of the Table wise summary.",
      "Feature 2 Title": "Since it mentions about <exact phrase from the Table wise summary>, the 'Feature 2 Title' is included, as the "phrase" is an evidence that this feature is part of the Table wise summary.",
      ...
    }}
  }}
  ```
  </Final Output Format>
  Note: If the traceback includes phrases that are not present in the Table wise summary then you would be penalized 10000 points.
  The output should be having data, confidence score, and traceback keys, and the entire content inside "```json" and "```" should be parsable by json.
  The "data" key should contain the generated summary and it should be in string format only, allowing the parsing of the entire json.
  If there are any inverted commas inside the generated summary, then escape them with a backslash.
  Do not change or skip the headings of each section in the generated json. The generated summary must have "Overview", "Highlighted Features", "Key Benefits" as section titles. Follow the above provided guidelines.
    """

    user_prompt += f"""Use the below Table wise summary to generate the summary in the above format: {combined_summary}""" + "User Defined Features : " + str(user_mvf)

    return system_prompt, user_prompt


def architecture_diagram_generation(services_data, icons_metadata):
    user_prompt = f"""
    <Input>
    $services_data = {services_data}
    $icons_metadata
    </Input>

    <Role>
    You are an expert at understanding large projects based on their executive summary and the services being used in them. Create a JSON structure for a ReactFlow diagram based on the given service class JSON.
    </Role>

    <Output Structure>
    1. Create a JSON object with a "nodes" and "edges" array.
    2. Create nodes for each external and third-party service.
    3. "nodes": An array containing all node objects.
      - "id": A unique string identifier for the node.
      - "data":   
        - "label": The name of the node.
        - "description": Description of the service.
        - "associated_files": Associated file and used in files in the service node, defaulting to "No File Available" if not present.
        - "group": The logical group name (e.g., 'Backend', 'Frontend', 'Database',etc..).
        - "subgroup": The specific subgroup within the group (e.g., Frameworks, NoSQL Databases, State Management, etc.).
        - "service": The appropriate filename of the icon based on the $icons_metadata.
      - "position" : The x and y coordinates of the node.
      - "type" : "customNode" This should be fixed.
    4. "edges" : An array having id, source, target, label, and type should be customEdge always.
    4. Ensure all services and files from the input JSON are included.
    5. The output should be in the form of a dictionary containing a "nodes" and "edges" array.
    6. Present only the code inside delimiters "```reactflow [reactflow CODE]```" without any additional explanation.
    """

    system_prompt:str = """
    <Task>
      You are tasked with creating a JSON structure for a ReactFlow diagram based on the given executive summary and the service_class_json. The executive summary contains an overview of the entire project. This JSON includes information about external services and third-party services, along with their associated files. Your output should represent this information as a network of nodes and edges.
    </Task>
    
    <Icons Context>
      $icons_metadata = """ + str(icons_metadata) + """
    </Icons Context>

    <Instructions>
      You are a solution expert, specializing in problem and solution flows. You will be given the solution overview for a project, and your task is to create an interconnected single component of graph which is detailed, and intuitive and self explanatory for:

      Follow these guidelines:
      1. Create nodes for each unique service (both external and third-party).
      2. Do not create any group nodes.
      4. In the data key for each service node, include two additional fields called group and subgroup. The group field should contain the logical group name (e.g., Frontend, Backend, Databases, etc..), and the subgroup field should provide more specific categorization (e.g., Frameworks, NoSQL Databases, etc..). For example, for a service node representing React, the group would be Frontend and the subgroup would be Frameworks.
      5. For each node, check which icon will be the most suitable from the $icons_metadata in the <Icons Context>
      6. Ensure all information from the input is represented in the output.
      7. The position coordinates must be proper for all the nodes.
    </Instructions>

    <Rules>
      **Ensure all nodes in the generated graph are interconnected such that every node has at least one edge, forming a single connected component without any isolated or disjoint sections. (High Priority Requirement)**
      Important Rules to be followed:
      1. Give detailed technical architecture flow and the JSON object following the below output format.
      2. Make sure that the flow and order of new solution approach is explained well in the graph with appropriate edges. Use as many edges you want to describe the data and user flow properly.
      3. The whole user and data flow should be clear.
      4. Do not add unnecessary nodes and edges. Do not create duplicate nodes that perform same task.
      5. Make the Node descriptions detailed, breaking tasks into multiple sub-tasks if needed.
      6. Ensure your edges show the actual flow, and not just connections of what's related. The connections are meant to show the logical flow, and not the relatedness/similarity.
      7. The group name is meant to classify clusters of nodes within each graph. For instance, if we have multiple nodes in features, they would all have "feature" as group. In Architecture Flow, the "Group" should show the layer each node is in, for instance "Backend Layer", "Database Layer" etc.
      9. for a hierarchy of nodes A -> B -> C; ensure that there is not a connection between A -> C.
    </Rules>
    
    <output_format>
    The output should be in between the delimeters ```reactflow and ```. Only provide the json output. Don't give unnecesary explanation.
    ```reactflow
    {
      "nodes": [
        { 
          "id": "unique_node_identifier_string",
          "data" : {
            "label": "name_of_the_service",
            "description": "description of the service",
            "associated_files": ["file_path_1", "file_path_2", "file_path_3", etc.],  // (default: ["No File Available"] if not present)
            "group": "name_of_group",  // Add the logical group name (e.g., "Frontend", "Backend", etc..)
            "subgroup": "name_of_subgroup",  // Add a more specific subgroup name (e.g., "Frameworks", "NoSQL Databases", etc..)
            "service": "filename" //taken from the $icons_metadata,
          }
          "position":{ "x": "Xcoordinate", "y": "Ycoordinate" },
          "type" : "customNode" //this is hardcoded and will be constant
        }
      ],
      "edges": [
        {
          "id": "unique_egde_identifier_string",
          "source": "label A",
          "target": "label B",
          "label": "Showcase what comes from the source node, to the target node. Be concise and specific with labels, such as 'Ingested Data', 'Converted Text', 'User Query' etc. Use at max 5 words",
          "type" : "customEdge" //this is hardcoded and will be constant
        }
      ]
    }```
    </output_format>
    """
    return system_prompt, user_prompt
  

def erd_generation(services_data, icons_metadata):
  tables_metadata = []
  for entry in services_data:
      table_name = entry["table_name"]
      ddl = entry["ddl"]
      columns, primary_keys, foreign_keys = parse_ddl(ddl)
      tables_metadata.append({
          "table_name": table_name,
          "columns": columns,
          "primary_keys": primary_keys,
          "foreign_keys": foreign_keys
      })

  dot = generate_combined_graph(tables_metadata)

  system_prompt:str = """
    You are tasked with creating a JSON structure for a ReactFlow diagram based on the given database ER diagram and schema JSON. This JSON includes information about database columns and their relationships.Your output should represent this information as a network of nodes and edges.
    </Task>
    
    <Icons Context>
      $icons_metadata = """ + str(icons_metadata) + """
    </Icons Context>

    <Instructions>
      You are a solution expert, specializing in problem and solution flows. You will be given the database schema information of a database, and your task is to create an interconnected single component of graph which is detailed, and intuitive and self explanatory for:

      Follow these guidelines:
      1. Create nodes for each unique service (both external and third-party).
      2. Do not create any group nodes.
      4. In the data key for each service node, include two additional fields called group and subgroup. The group field should contain the logical group name (e.g.,Databases, etc..), and the subgroup field should provide more specific categorization (e.g., 'Transactional Tables', 'Reference Tables' etc..). For example, for a service node representing daily transactions, the group would be Database and the subgroup would be Transactional Tables.
      5. For each node, check which icon will be the most suitable from the $icons_metadata in the <Icons Context>
      6. Ensure all information from the input is represented in the output.
      7. The position coordinates must be proper for all the nodes.
    </Instructions>

    <Rules>
      Important Rules to be followed:
      1. Give detailed technical architecture flow and the JSON object following the below output format.
      2. Make sure that the flow and order of new solution approach is explained well in the graph with appropriate edges. Use as many edges you want to describe the data and user flow properly.
      3. The whole user and data flow should be clear.
      4. Do not add unnecessary nodes and edges. Do not create duplicate nodes that perform same task.
      5. Make the Node descriptions detailed, breaking tasks into multiple sub-tasks if needed.
      6. Ensure your edges show the actual flow, and not just connections of what's related. The connections are meant to show the logical flow, and not the relatedness/similarity.
      7. The group name is meant to classify clusters of nodes within each graph. For instance, if we have multiple nodes in features, they would all have "feature" as group. In Architecture Flow, the "Group" should show the layer each node is in, for instance "Database Layer" etc.
      9. for a hierarchy of nodes A -> B -> C; ensure that there is not a connection between A -> C.
    </Rules>
    
    <output_format>
    The output should be in between the delimeters ```reactflow and ```. Only provide the json output. Don't give unnecesary explanation.
    ```reactflow
    {
      "nodes": [
        { 
          "id": "unique_node_identifier_string",
          "data" : {
            "label": "name_of_the_table",
            "description": "description of the table",
  	    "columns": ["order_id [PK]", "product_sku [PK]", "quantity", "unit_price"]
            "group": "name_of_group",  // Add the logical group name (e.g., "Database", etc..)
            "subgroup": "name_of_subgroup",  // Add a more specific subgroup name (e.g., 'Transactional Tables', 'Reference Tables', etc..)
            "service": "filename" //taken from the $icons_metadata,
          }
          "position":{ "x": "Xcoordinate", "y": "Ycoordinate" },
          "type" : "customNode" //this is hardcoded and will be constant
        }
      ],
      "edges": [
        {
          "id": "unique_egde_identifier_string",
          "source": "label A",
          "target": "label B",
          "label": "Showcase what comes from the source node, to the target node. Be concise and specific with labels, such as 'Ingested Data', 'Converted Text', 'User Query' etc. Use at max 5 words",
          "type" : "customEdge" //this is hardcoded and will be constant
        }
      ]
    }```
    </output_format>
    """
    
  user_prompt:str = f"""
    <Input>
    $database_tables = {dot}
    $icons_metadata
    </Input>

    <Role>
    You are an expert at understanding database architecture based on ER diagrams and relational structures. Create a JSON structure for a ReactFlow diagram based on the given database schema.
    </Role>
    <Output Structure>
      1. Create a JSON object with a "nodes" and "edges" array.
      2. Create nodes for each table in the schema.
      3. "nodes": An array containing all node objects.
      - "id": A unique string identifier for the node.
      - "data":  
        - "label": The name of the table.
        - "description": A brief summary of the table's role or content.
        - "columns": List of column names (mark primary keys with [PK], foreign keys with [FK]).
        - "group": The logical group name (e.g., 'Database').
        - "subgroup": The specific subgroup within the group (e.g., 'Transactional Tables', 'Reference Tables').
        - "service": The appropriate filename of the icon based on the $icons_metadata.
      - "position" : The x and y coordinates of the node.
      - "type" : "customNode" This should be fixed.
      4. "edges" : An array having id, source, target, label, and type should be customEdge always.
      5. The label of the edge should describe the relationship, like "order_id â†’ order_id". 
      6. The output should be in the form of a dictionary containing a "nodes" and "edges" array.
      7. Present only the code inside delimiters "```reactflow [reactflow CODE]```" without any additional explanation.
    """
    
  return system_prompt, user_prompt
    

def feature_summary_generation(formatted_data, user_mvf, executive_summary):
    # if input_type is None:
    #     formatted_data = file_summary_list
    # elif input_type == "batch_summary":
    #     formatted_data = format_batchwise_summary_metadata_for_services(file_summary_list)
    # else:
    #     formatted_data = format_file_summaries(file_summary_list)

    user_prompt = """
    Role: You are an AI code analyst specializing in creating concise, feature-level summaries of codebases.

    Objective: Provide a comprehensive yet concise feature-level summary of a given codebase, highlighting key components, functionality, and the project's overall workflow.

    Input: You will receive information about a codebase, which may include an executive summary or other project details.

    Steps:
    1. Analyze the provided codebase information.
    2. Identify the main features (maximum 5) of the project from the executive summary (if provided in same order)
    3. Create a summary following the specified format, including:
        a. An overview of the project
        b. A list of key features with brief descriptions
        c. A closure statement
    4. Self-evaluate the generated summary and assign a confidence score.
    5. Format the output as specified in the instructions.

    Output Format:
    ```json
    {
        "data": "generated_summary in string format adhering to the Detailed Instructions for Output Format",
        "confidence_score": 90
    }
    ```

    Detailed Instructions for Output Format:

    **Overview**
    <empty line>
    < 
        Summarize all features in 2-3 sentences, introducing the project and its purpose.
        Provide a 2-3 sentence summary of key benefits, highlighting core architecture and value proposition.
    >
    <empty line>
    **Key Features**
    <empty line>
    <   
        List a maximum of 5 main features.
        For each feature, provide up to 2 sub-points describing its functionality.
        Ensure clear explanation of how features interact and contribute to the project's goals.
        1. ***<Key Feature Title>*** : 
        * <Sub point 1 description>
        * <Sub point 2 description>
        <empty line>
    >
    <empty line>
    < 
        Summarize the overall impact and value proposition of the project in one sentence as a conclusion statement.
    >
    <empty line>
    
    -> Self-Evaluation:
        - Score the summary out of 100 based on clarity, precision, detail, knowledge, accuracy, technical correctness, and understanding of the data.

    -> Formatting Requirements:
        - Replace all newline characters (\n) with \\n in the JSON output.
        - Ensure the complete JSON is less than 7500 tokens.
        - Start the output with "```json" and end with "```".
        - If an executive summary is provided, use only the highlighted features from it.

    Example Output Structure:
    ```json
    {
        "data": "**Overview**\\n\\n[Project overview]\\n\\n[Benefits summary]\\n\\n**Key Features**\\n\\n1. *Feature 1*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n2. *Feature 2*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n[...continue for up to 5 features...]\\n\\n[Closure statement]",
        "confidence_score": 90
    }
    ```

    Remember: Adhere strictly to the output format and instructions to maintain consistency and accuracy in your summary.
    """

    user_prompt += "User Defined Features : " + str(user_mvf)

    system_prompt = f"""
        <role>
        You are an assistant to a Senior Software Engineer. You are very capable in reading and understanding huge codebases.
        There is no edge-case, no mistake, no functionality no matter how small goes unnoticed by you.
        You will be given a large codebase and be asked queries regarding it.
        </role>

        <Task>
        You will be given relevant files from a production codebase. The Senior Engineer will consult you to clear his doubts and ask for critical code-level and functionality level analysis of the same.
        <Important>
        1. You will be clear. Feel free to be descriptive but Avoid Jargon
        2. You shall perform critical analysis on the code before responding.
        3. Note that the codebase will be quite complex and have dependencies everywhere, be mindful of them all.
        4. Enclose code in (triple backticks)``` code ```
        </Important>
        </Task>

        Files from Codebase goes here :
        <Repo Structure>
        {formatted_data}
        </Repo Structure>
    """

    start_index = executive_summary.find("Highlighted Features")
    end_index = executive_summary.find("Key Benefits")

    if start_index != -1 and end_index != -1:
        executive_summary = executive_summary[start_index:end_index].strip()

    user_prompt += "Executive Summary : " + str(executive_summary)

    return system_prompt, user_prompt

def feature_summary_generation_db(formatted_data, user_mvf, executive_summary):
    # if input_type is None:
    #     formatted_data = file_summary_list
    # elif input_type == "batch_summary":
    #     formatted_data = format_batchwise_summary_metadata_for_services(file_summary_list)
    # else:
    #     formatted_data = format_file_summaries(file_summary_list)

    user_prompt = """
    Role: You are an AI Database Analyst specializing in creating concise, feature-level summaries of complex database schemas and architectures.

    Objective: Provide a comprehensive yet concise feature-level summary of a given database schema information, highlighting key components, entities, relationships, and the overall data architecture workflow.

    Input: You will receive information about a database design, which may include an executive summary or other schema-level details.

    Steps:
    1. Analyze the provided database schema information.
    2. Identify the main features (maximum 5) of the database from the executive summary (if provided in same order)
    3. Create a summary following the specified format, including:
        a. An overview of the database
        b. A list of key features with brief descriptions
        c. A closure statement
    4. Self-evaluate the generated summary and assign a confidence score.
    5. Format the output as specified in the instructions.

    Output Format:
    ```json
    {
        "data": "generated_summary in string format adhering to the Detailed Instructions for Output Format",
        "confidence_score": 90
    }
    ```

    Detailed Instructions for Output Format:

    **Overview**
    <empty line>
    < 
        Summarize all features in 2-3 sentences, introducing the database and its purpose.
        Provide a 2-3 sentence summary of key benefits, highlighting schema structure, normalization or denormalization logic, and value proposition in handling data.
    >
    <empty line>
    **Key Features**
    <empty line>
    <   
        List a maximum of 5 main features.
        For each feature, provide up to 2 sub-points describing its data handling, relationships, or optimization logic.
        Ensure clear explanation of how features contribute to performance, consistency, and data integrity.
        1. ***<Key Feature Title>*** : 
        * <Sub point 1 description>
        * <Sub point 2 description>
        <empty line>
    >
    <empty line>
    < 
        Summarize the overall impact and value proposition of the database in one sentence as a conclusion statement.
    >
    <empty line>
    
    -> Self-Evaluation:
        - Score the summary out of 100 based on clarity, precision, detail, knowledge, accuracy, technical correctness, and understanding of the schema information.

    -> Formatting Requirements:
        - Replace all newline characters (\n) with \\n in the JSON output.
        - Ensure the complete JSON is less than 7500 tokens.
        - Start the output with "```json" and end with "```".
        - If an executive summary is provided, use only the highlighted features from it.

    Example Output Structure:
    ```json
    {
        "data": "**Overview**\\n\\n[Database overview]\\n\\n[Benefits summary]\\n\\n**Key Features**\\n\\n1. *Feature 1*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n2. *Feature 2*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n[...continue for up to 5 features...]\\n\\n[Closure statement]",
        "confidence_score": 90
    }
    ```

    Remember: Adhere strictly to the output format and instructions to maintain consistency and accuracy in your summary.
    """

    user_prompt += "User Defined Features : " + str(user_mvf)

    system_prompt = f"""
        <role>
        You are an assistant to a Senior Data Architect. You are very capable in reading, analyzing, and understanding complex database schemas and data models.
        No entity, constraint, relationship, or optimization logic goes unnoticed by you.
        You will be given a comprehensive database structure or schema information and will be asked to analyze, explain, and summarize it at a structural and functional level.
        </role>

        <Task>
        You will be given relevant database schema files or DDL definitions. The Senior Data Architect will consult you to clear doubts and ask for critical schema-level and data model-level analysis.
        <Important>
        1. You will be clear. Feel free to be descriptive but Avoid Jargon
        2. Perform a critical and deep analysis of the schema and the information given before responding.
        3. The schema will often involve multiple tables, foreign keys, views, procedures, and indexing strategies â€” be mindful of their dependencies and relationships.
        4. Enclose code or schema in (triple backticks)``` code ```
        </Important>
        </Task>

        Files from Database schema goes here :
        <Database Structure>
        {formatted_data}
        </Database Structure>
    """

    start_index = executive_summary.find("Highlighted Features")
    end_index = executive_summary.find("Key Benefits")

    if start_index != -1 and end_index != -1:
        executive_summary = executive_summary[start_index:end_index].strip()

    user_prompt += "Executive Summary : " + str(executive_summary)

    return system_prompt, user_prompt


#FEATURE HIERARCHY:
generate_features_system_prompt = """
  <Role>
    You are a Software Architect with expertise in analyzing large summaries from code files of an application. 
    You can comprehend summaries from code files that are complex, production-grade and are written in various programming languages to generate most important features, their description and the subfeatures with their description belonging to the most important features along with the other relevant information requested below.
    
    You will follow 2 Events before responding : 
    1. Generation of Feature Hierarchy as given in "Output_Format".
    2. Critical Evaluation of Every Confidence Score.  
  </Role> 

    <Task 1>
    You are provided with multiple relative file paths and file-wise code summaries from a application codebase.
    1. Analyze the file summaries carefully, leveraging your expertise to deduce the frameworks, functionality, and features.
    2. Perform a critical assessment of the code's functionality and interdependencies before responding.
    3. The codebase is complex and likely contains dependencies across various modules. Be mindful of these.
    4. Analyse every file summary and assign the features and sub-features based on the information provided.
    5. Respond strictly in the structured JSON format provided below.
    6. In each sub-feature's 'file_path' array:
        - Set 'critical: true' ONLY for files that are CORE & NON-REPLACEABLE to the sub-feature's main functionality.
        - Set 'critical: false' for ALL supporting, secondary, or replaceable files  
        - Each sub-feature should have both true and false entries.
        - If unsure, default to false (be EXTREMELY selective with 'true')
        - Make sure each sub-feature atleast have one file as true.

    Explanation of the Output terms:
    Feature - Features are most valuable and high level features extracted from the list of summaries that are provided to you. 
    Feature description - Description of the features explaining the high level value and impact that it creates for the project. Define the Feature. The description should be crisp, precise, well formatted and must be between 2-3 lines.
    Subfeature - Subfeatures are micro most valuable features that are extracted from the list of summaries and belong to the Most related and similar Features.
    Subfeature description - Description of the subfeatures explaining the specific value, technical and non-technical functionalites that it provided to the project. Define the subfeature and also explain how its related to the feature. The description should be crisp, precise, well formatted and must be between 2-3 lines.
    
    Points to Remember:
    1. Do not extract any feature or subfeature where there are no reference/citations from the application summaries.
    2. The description must be precise, valuable, well-formatted and must be between 2-3 lines.
    3. The Feature titles should be precise, specific, self explanaible, independent and not have similar feature titles. The Feature titles should not be highly generalized.
    4. The SubFeatures titles should be precise, self explanaible and not have similar subfeature titles. The SubFeature titles should not be highly generalized.
    5. SubFeatures should not be very low level that it explains code functions, code process like 'Json handling', 'Reading csv', readME etc.
    6. If similar subfeatures are present, then group them under one common Feature itself. Do not create multuple Features for similar subfeatures.
    6. If Unit testing related summaries are found, then create that as another Feature named 'Unit Testing' and assign the specific testing subfeatures under this feature.
    </Task 1>

  <Task 2>
  You shall now Assign and Justify Confidence Scores for each feature.

  <Critical Evaluation of Confidence Scores> 

  <Evaluation MODE>
  - You will now Forget everything that was done beforehand and act as an unbiased judge.
  - $Project-Summaries-&-Paths (INPUT).
  </Evaluation MODE>
  <Important>
  Critically analyze every "Feature" and "SubFeature" based on the following metrics. 
  You shall generate a confidence score between 0-100 for each of the following :
  1. Is the "Feature" & "SubFeature" name accurate to its functionality ? (Accuracy)
  2. Does the "Feature" & "SubFeature" include files with an unrelated function ? (Feature Dilution Rate)
  3. Important : Does this "Feature" & "SubFeature" make sense given the Overall Purpose of the Application ? (Consistency)
  4. Are all the files in "Feature" & "SubFeature" included ? (Completeness)

  <Strict>
  1. You will now generate a list of 4 confidence scores between 0-100 for above criteria under "confidence_score" key.
  2. Based on above criteria, you shall provide a VERY BRIEF logical explanation (10-20 words) for Confidence Score under "confidence_score_justification" key.
  3. Make sure to mention the entire filepath without omitting the prefix.
  4. Make sure all the filepaths are present.
  <Important> STRICTLY Don't Comment on Missing Files. Don't Overestimate. Don't Underestimate.</Important> 
  </Strict>

  </Important>

  </Critical Evaluation of Confidence Scores> 
  </Step 2>


      <Output_Format>
    Return a response in JSON format. Do not include any extra information or explanations. Strictly DON'T deviate from mentioned KEYS.
    Example:
```json
[
  {
    "name": "User Authentication and Management",
    "feature_description": "Comprehensive user account system with secure login, registration, profile management, and role-based access control.",
    "feature_description_confidence_score": [95, 70, 100, 70],
    "sub_features": [
      {
        "name": "User Registration",
        "description": "Allows new users to create accounts by providing necessary information such as username, email, and password. Implements email verification, password strength checks, and duplicate account prevention. Stores user data securely in the database with password hashing.",
        "file_path": [
          {
            "module_name": "RegistrationController",
            "path": "Controllers/Account/RegistrationController.cs",
            "critical": true
          },
          {
            "module_name": "RegisterView",
            "path": "Views/Account/Register.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [75, 80, 85, 65],
        "sub_feature_confidence_score_justification": "No feature dilution, might have missed some file."
      },
      {
        "name": "User Login",
        "description": "Authenticates users using their credentials, creates and manages user sessions, and implements security measures such as login attempt limiting and two-factor authentication (2FA). Provides password reset functionality for forgotten passwords.",
        "file_path": [
          {
            "module_name": "LoginController",
            "path": "Controllers/Account/LoginController.cs",
            "critical": true
          },
          {
            "module_name": "LoginView",
            "path": "Views/Account/Login.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [80, 100, 80, 75],
        "sub_feature_confidence_score_justification": "High chance of missing files."
      }
    ],
    "feature_confidence_score_justification": "No feature dilution, duplication or missing files. Accurate Naming."
  },
  {
    "name": "Product Catalog Management",
    "feature_description": "Comprehensive system for managing product listings, categories, and inventory across the e-commerce platform.",
    "feature_description_confidence_score": [95, 65, 70, 80],
    "sub_features": [
      {
        "name": "Product CRUD Operations",
        "description": "Enables administrators to create, read, update, and delete product listings. Includes functionality for managing product details such as name, description, price, images, and inventory levels. Implements validation to ensure data integrity and consistency across the product catalog.",
        "file_path": [
          {
            "module_name": "ProductController",
            "path": "Controllers/ProductController.cs",
            "critical": true
          },
          {
            "module_name": "ProductView",
            "path": "Views/Product/Index.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [90, 85, 100, 70],
        "sub_feature_confidence_score_justification": "High confidence with no duplication or dilution."
      },
      {
        "name": "Category Management",
        "description": "Allows for the creation and management of product categories and subcategories. Implements a hierarchical structure for organizing products, enabling efficient navigation and filtering of the product catalog for both administrators and customers.",
        "file_path": [
          {
            "module_name": "CategoryController",
            "path": "Controllers/CategoryController.cs",
            "critical": true
          },
          {
            "module_name": "CategoryView",
            "path": "Views/Category/Index.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [85, 75, 90, 95],
        "sub_feature_confidence_score_justification": "High confidence without any duplication or dilution."
      }
    ],
    "feature_confidence_score_justification": "All files refer to single overall functionality. Might have missed some files."
  }
]
```
  </Output_Format>

"""

generate_features_user_message = """
<Strictly Remember>
1. As input you will be given a batch of `file_path` and `file_summary` from a production codebase. Keep it in mind that it could be a file from a very large repository with lot of inter-dependencies.
2. Understand all the file description first, then try to determine the feature, sub-features and their description. For **each file** it should have a feature or sub-features whenever the conditions are met.
3. The response should contain all the fields given in the example output format. The response should be strictly in json format.
4. The description of features/subfeatures must be in the length of 2-3 lines. The response should be structured and well-formatted.
5. Don't generate any additional explanation or description. Provide the structured response in json only.
</Strictly Remember>
  
<Input file wise summary>
{file_summary}
</Input file wise summary>
<Response>
"""

merge_features_in_hierarchy_user_prompt = """You are a software feature analyzer. Given a list of related features that have been clustered together, create a merged feature that encompasses all the functionality.

Features to merge:
{feature_list}

Generate a JSON response that includes:
1. A name for the merged feature representing accurate feature name. Do not mention its merged or unified or anything as such. The feature name should accurately represent a major funcationality of a repository.
2. A detailed description that covers all functionality
3. A confidence score (0-100) for the merge
4. A justification for the confidence score

Respond with a JSON object in the following format:
```json
{{
    "name": "Merged feature name",
    "description": "Comprehensive description",
    "confidence_score": 85,
    "confidence_justification": "Reason for the confidence score"
}}
```
Give only JSON and nothing else. Do not include any explanations or additional text outside the JSON block. Make sure to start with ```json and end with ``` only.
"""

mapping_names_for_merged_features_user_prompt = """  <Role>
    You are a smart AI cassistant with strong expertise in Software Engineering. You can understand complex, production-grade codebases written in various programming languages and summarize them effectively.
  </Role>
  <Task>
  You will be given a brief description of  features of a large codebase and your task is to generate a relevant feature name, brief description, and priority level.
  <Important>
   1. The feature name should be brief, relevant and should represent the entire description provided.
   2. Generate a relevant description which is basically a overall summary of the description provided.
   3. Assign a priority level (high, medium, low) based on the significance, importance and complexity of the feature to the overall system. 
  </important>
  </Task>
  <Example output>
  ```json
    {
        "name": <feature_name>, //string
        "feature_description": <feature_description>, //string
        "priority": <priority> //string (high, medium, or low)
    }
    ```
  </Example output>
  <Strictly Remember>
1. The feature name should be relevant and at the same time interpretable, easy to understand.
2. The feature description should represnt the entire description given for summarisation, it should be simple and easy to understant.
3. The priority should be one of: high, medium, or low.
4. The response should be strictly in json format specified above.
5. Strictly make sure Feature Description is not more than 200 words.
  </Strictly Remember>

<code summary>
The code summary is given below:
"""


reducing_sub_features_user_prompt = """
    You are a software feature consolidation expert. Your task is to merge similar sub-features into one comprehensive sub-feature.

    Here are the sub-features that need to be merged:
    {sub_features_list}

    For each sub-feature, we have:
    - Name: The sub-feature name
    - Description: The sub-feature description (if available)
    - Confidence Score: The confidence score (if available)

    Your output should be a JSON object containing:
    1. A unified sub-feature name that encompasses all the input sub-features
    2. A comprehensive description that covers all aspects of the input sub-features
    3. A confidence score (use the highest available from input sub-features)
    4. A justification for the confidence score

    Return the output in JSON format starting with ```json and ending with ```.

    Example output format:
    ```json
    {{
        "name": "Unified Sub-Feature Name",
        "description": "Comprehensive description covering all aspects",
        "sub_feature_confidence_score": 95,
        "sub_feature_confidence_score_justification": "Merged from similar sub-features with high semantic similarity"
    }}
    ```
    """


post_processing_feature_name_description_system_prompt="""
  <Role>
    You are a smart AI assistant with strong expertise in Software Engineering. You can understand complex, production-grade codebases written in various programming languages and summarize them effectively.
  </Role>
  <Task>
  You will be given a brief description of modules or features of a large codebase and your task is to generate a relevant feature name and brief description.
  <Important>
   1. The feature name should be brief, relevant and should represent the entire description provided.
   2. Generate a relevant description which is basically a overall summary of the description provided.
   3. Also generate a confidence score in a scale of 0 - 100.
  </important>
  </Task>
  <Example output>
  ```json
    {
        "name": <feature_name>,
        "feature_description_confidence_score": <score 0 - 100>,
        "feature_description": <feature_description>
    }```
  </Example output>"""

post_processing_feature_name_description_user_prompt = """<Strictly Remember>
1. The feature name should be relevant and at the same time interpretable, easy to understant.
2. The confidence score should represent the ability to summarise the description.
3. The feature description should represnt the entire description given for summarisation, it should be simple and easy to understant.
4. The response should be strictly in json format specified above.
</Strictly Remember>
<code summary>
The code summary is given below: \n
{feature_description}
</code_summary>
<response>
Your response in json goes here:
"""

merge_similar_features_system_prompt = """You are a solution architect. Your task is to carefully review each feature and its description, and combine them into a single high-level feature.

The final high-level features should represent what an end user would perceive, e.g., Messenger, Google Chat, Messaging, Reels, etc.

Based on the generated features provided, identify which features can be merged into a single high-level feature. 
Strictly output them in the following format:
{{ 
  <High-Level Feature Name 1>: [<Merged Feature 1>, <Merged Feature 2>, <Merged Feature 3>, ...],
  <High-Level Feature Name 2>: [<Merged Feature 1>, <Merged Feature 2>, <Merged Feature 3>, ...],
  ...
}}

INPUT:
Feature names and descriptions are provided in the format: 
[1. Feature name: <feature name> 
Feature description: <feature description>, 
2. ...]

{feature_texts}

MVFS:
{total_MVFs}

Points to remember:
1. While merging features and naming high-level features, always prefer names from the user-defined MVFs provided. All relevant features can be grouped under these high-level features.
2. If certain features do not fit under the user-defined MVFs, choose a better name than the existing one for the new high-level feature if necessary.
3. The names of the features being merged must remain exactly as provided in the INPUT section; do not modify them. Do not consider Feature description in Feature Names.
4. Follow the output structure strictly: high-level feature names as dictionary keys and merged features as values in list format.
5. If a feature is already a high-level feature, you do not need to forcibly merge it. If a feature seems to be function-level/low-level  features, merge them into a High-level feature.
6. Merge similar features into a single high-level feature based on their names and descriptions, when applicable. Each final high-level feature should be independent of the others.
7. Do not assign the same feature to multiple high-level features.
8. If user-defined MVFs are empty, skip point 1 and begin with point 2.
9. Do **not** include any Feature descriptions in the final output."""


merging_description_user_prompt = """You are a Solution Architect. Your task is to summarize the multiple feature descriptions provided into a brief, coherent summary of **no more than two sentences**.

  The summary must:
  - Accurately capture all key components from the provided descriptions.
  - Align clearly with the given high-level feature name.
  - Serve as the final description of the high-level feature.

  Only the final summarized description should be included in the output â€” no additional commentary or formatting.

  INPUT:
  Multiple descriptions: {merging_feature_description}

  High-Level Feature Name: {high_level_feature}
  """


micro_sub_feature_prompt = """You are an expert system analyst specializing in decomposing SubFeatures into granular, logically independent components. You support **two levels** of splitting:

1. **Horizontal splitting**: Split a subfeature into multiple *same-level subfeatures* when it encompasses multiple independently meaningful functionalities. The subfeatures created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.
2. **Vertical splitting**: Further break each of those subfeatures into *microsubfeatures* (if applicable), ensuring each micro-sub-features/micro-user-story describes a single goal or operation. The micro-sub-features/micro-user-story created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.

---

### ðŸ”§ TASK OVERVIEW

Given a Macro-Feature, Subfeature, its description, associated module files and its summary:

- Decide if the subfeature should be split horizontally into multiple same-level subfeatures.
- For each resulting subfeature (or original if not split), analyze whether it can be split vertically into **microsubfeatures** (fine-grained user stories).
- Provide the confidence scores for the subfeature that is split, whether horizontally or vertically.
- Provide the files that are related to the sub_features too, not just the micro_sub_features.
- Each leaf user-story must have files assigned to them, else you should not create/split these subfeatures.
- Provide description of generated subfeature/sub-user-stories in 2-4 lines but only valid information. Do not assume or hallucinate to generate description.
Apply this recursively: if horizontal splitting occurs, then attempt vertical splitting for each. But remember, not to create any duplicates in the process. 

---

### SPLITTING DECISIONS

#### Horizontal Splitting (Same-level Subfeatures):
Split if:
- The subfeature covers multiple high-level functionalities
- Each function could be planned, developed, and deployed independently
- Each component has a clear boundary and responsibility

#### Vertical Splitting (Microsubfeatures):
Split further if:
- A subfeature contains multiple independent operations or logical stages
- These operations can be implemented, tested, or tracked separately
- Each micro-subfeature represents one atomic, non-overlapping functionality

---

### DO NOT SPLIT IF:
- sub-user-stories are tightly coupled in the Subfeature and cannot function independently.
- Do not split subfeatures into sub-user-stories that are hardly single line of code and cannot be considered as a proper functionality, but just a config/parameter.
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across actions are too complex to isolate.
- There are no files that can be mapped to the generated user-story.
- Do not split if the user-story is barely a functionality. The split user-stories must have independent functionality that contributes to the subfeature and feature and if not, do not split.
- Don not split ReadMe & .md files into sub-user-stories.
- Do not split horizontall for granullar subfeatures as they are not user stories but mid level features.
---

### FILE MAPPING RULES:
- For each subfeature or microsubfeature, cite only directly relevant files.
- Use only the provided input data to match files â€” no guessing.
- Avoid duplication unless a file is clearly shared between components.

Each `file_path` entry must include:
```json
{
  "module_name": "<Name>",
  "path": "<Path>",
  "critical": <true/false>,
  "git_url": "<Git URL>"
}

OUTPUT FORMAT
If the subfeature should NOT be split:
Return: "None"

If the subfeature should be split, return a list of Parent User Stories with subfeatures inside.
If a subfeature itself can be further split into microsubfeatures, nest them under micro_sub_features like so:

[
  {
    "name": "Parent User Story Title 1",
    "description": "Full description of the original or updated user story and its purpose.",
    "file_path": [...],
    "sub_feature_confidence_score":"confidence score of the subfeature with respect to the Feature, as a percentage (e.g., 80)"
    "micro_sub_features": [
      {
        "name": "Sub-User Story Title 1",
        "description": "Standalone description of a single functionality.",
        "file_path": [...],
        "micro_sub_feature_confidence_score":"confidence score of the micro_sub_feature with respect to the sub_feature, as a percentage (e.g., 90)"
        }
          ...
        ]
      },
      ...
    ]
  }
]
Each layer must preserve independence, clarity, and singular focus of each story.

VALIDATION CHECKLIST
- Each title must express one functionality only (no imperative phrasing)
- description must avoid assumptions and describe the real function. It must be as detailled as possible.
- Each story must make sense independently and fit in the broader feature flow
- if there are multiple user-story under the subfeature, it needs to be in sequence of business logic.
- File mappings must be relevant and scoped accurately
- Do no miss/skip any values in the output json. The output structure must be maintained strictly.
- All subfeature and sub-user-story names and descriptions must be strictly in a declarative tone, not imperative.

* Use generic or speculative statements
"""


db_micro_sub_feature_prompt = """
<Role>
You are an expert Database analyst specializing in decomposing SubFeatures into granular, logically independent components. You support **two levels** of splitting:
You shall ALWAYS process features from a Database perspective ONLY. 
There can be more than one Table in the DB context provided to you.
</Role>

1. **Horizontal splitting**: Split a subfeature into multiple *same-level subfeatures* when it encompasses multiple independently meaningful functionalities. The subfeatures created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.
2. **Vertical splitting**: Further break each of those subfeatures into *microsubfeatures* (if applicable), ensuring each micro-sub-features/micro-user-story describes a single goal or operation. The micro-sub-features/micro-user-story created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.

<Strict Constraints> 
- You are dealing with Database Information. 
- No matter what, STRICTLY use Database-Specific Language ALWAYS. 
- Use words like Columns / Fields / Schema / DataTypes / Constraints / Foreign Keys / Primary Keys etc.
- Strictly Do not start descriptions with or start with "this micro-feature" / or "this sub-feature".
- You shall do this regardless of the input context and nature.
Remember : Every "FILE" given to you is information of a table. Therefore in your response, ALWAYS refer to "Table" instead of "File".

</Strict Constraints> 


### ðŸ”§ TASK OVERVIEW

Given a Macro-Feature, Subfeature, its description, associated module files and its summary:

- Decide if the subfeature should be split horizontally into multiple same-level subfeatures.
- For each resulting subfeature (or original if not split), analyze whether it can be split vertically into **microsubfeatures** (fine-grained user stories).
- Provide the confidence scores for the subfeature that is split, whether horizontally or vertically.
- Provide the files that are related to the sub_features too, not just the micro_sub_features.
- Each leaf user-story must have files assigned to them, else you should not create/split these subfeatures.
- Provide description of generated subfeature/sub-user-stories in 2-4 lines but only valid information. Do not assume or hallucinate to generate description.
Apply this recursively: if horizontal splitting occurs, then attempt vertical splitting for each. But remember, not to create any duplicates in the process. 

---

### SPLITTING DECISIONS

#### Horizontal Splitting (Same-level Subfeatures):
Split if:
- The subfeature covers ONE / MORE THAN ONE high-level functionalities
- Each function could be planned and developed independently
- Each component has some clear boundaries and responsibilities

#### Vertical Splitting (Microsubfeatures):
Split further if:
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across actions are too complex to isolate.
- There are no tables that can be mapped to the generated user-story.
- The subfeature is too complex to be planned, developed, and deployed independently
- Each micro-subfeature represents one atomic, non-overlapping functionality
Note: Maintain at least 2 subfeatures unless the database has only one table.
- Prioritize brevity, consistency and no informaiton leakage across subfeatures.
- Ensure crisp segregation.
---

### DO NOT SPLIT IF:
- sub-user-stories are tightly coupled in the Subfeature and cannot function independently.
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across tables in two features are too complex to isolate.
- There are no tables that can be mapped to the generated user-story.
Note: Maintain at least 2 subfeatures and 1 or more microsubfeatures per subfeature, Unless the database has only one table.
Note : Maintain brevity during splitting at the same level. Do NOT overload the a single feature with too many subfeatures.
---


### FILE MAPPING RULES:
- For each subfeature or microsubfeature, cite only directly relevant tables.
- Use only the provided input data to match files â€” no guessing.
- Avoid duplication unless a file is clearly shared between components.

Each `file_path` entry must include:
```json
{
  "module_name": "<Name>",
  "path": "<Path>",
  "critical": <true/false>,
  "git_url": "<Git URL>"
}

OUTPUT FORMAT
If the subfeature should NOT be split:
Return: "None"

If the subfeature should be split, return a list of Parent User Stories with subfeatures inside.
If a subfeature itself can be further split into microsubfeatures, nest them under micro_sub_features like so:

[
  {
    "name": "Parent User Story Title 1",
    "description": "Full description of the original or updated user story and its purpose.",
    "file_path": [...],
    "sub_feature_confidence_score":"confidence score of the subfeature with respect to the Feature, as a percentage (e.g., 80)"
    "micro_sub_features": [
      {
        "name": "Sub-User Story Title 1",
        "description": "Standalone description of a single functionality.",
        "file_path": [...],
        "micro_sub_feature_confidence_score":"confidence score of the micro_sub_feature with respect to the sub_feature, as a percentage (e.g., 90)"
        }
          ...
        ]
      },
      ...
    ]
  }
]
Each layer must preserve independence, clarity, and singular focus of each story.

VALIDATION CHECKLIST
- Each title must express one functionality only (no imperative phrasing)
- description must avoid assumptions and describe the real function. It must be as detailled as possible.
- Each story must make sense independently and fit in the broader feature flow
- if there are multiple user-story under the subfeature, it needs to be in sequence of business logic.
- File mappings must be relevant and scoped accurately
- Do no miss/skip any values in the output json. The output structure must be maintained strictly.
- All subfeature and sub-user-story names and descriptions must be strictly in a declarative tone, not imperative.
- Use Database-specific schema only. Do not include words like "Attributes" / "Code Files" in your response. 
- Strictly Do not start descriptions with or start with "this micro-feature" / or "this sub-feature".
* Use generic or speculative statements

"""import os
from graphviz import Digraph
import re 
import json

def parse_ddl(ddl: str):
    """
    Parse the DDL to extract columns, primary keys, and foreign keys.
    """
    lines = ddl.splitlines()
    column_lines = []

    for line in lines:
        line = line.strip()
        if (
            line.upper().startswith("CREATE")
            or line.upper().startswith("PRIMARY")
            or line.upper().startswith("FOREIGN")
            or line.upper().startswith(")")
            or line == ""
        ):
            continue

        match = re.match(r'(\w+)\s+\w+', line)
        if match:
            column_lines.append(match.group(1))

    pk_match = re.search(r'PRIMARY KEY\s*\((.*?)\)', ddl)
    primary_keys = [key.strip() for key in pk_match.group(1).split(",")] if pk_match else []

    foreign_keys = []
    for match in re.finditer(r'FOREIGN KEY\s*\(([^)]+)\)\s+REFERENCES\s+`?[\w]+\.(\w+)`\(([^)]+)\)', ddl):
        fk_col = match.group(1).strip()
        ref_table = match.group(2).strip()
        ref_col = match.group(3).strip()
        foreign_keys.append((fk_col, ref_table, ref_col))

    return column_lines, primary_keys, foreign_keys


def generate_combined_graph(tables_data):
    """
    Generate a single combined graph from multiple tables.
    """
    dot = Digraph(comment='Combined Table Diagram')
    dot.attr(rankdir='LR')

    # Store individual table nodes
    for table in tables_data:
        table_name = table['table_name']
        columns = table['columns']
        primary_keys = table['primary_keys']
        
        label_lines = []
        for col in columns:
            if col in primary_keys:
                label_lines.append(f"{col} [PK]")
            else:
                label_lines.append(col)
        dot.node(table_name, shape='box', label=f'{table_name}\\n' + "\\n".join(label_lines))

    # Add relationships
    for table in tables_data:
        table_name = table['table_name']
        for fk_col, ref_table, ref_col in table['foreign_keys']:
            dot.edge(table_name, ref_table, label=f'{fk_col} â†’ {ref_col}')

    return dot

def folder_summary_generation_prompts(
        total_allocated_tokens, 
        file_list, folder_name, 
        folder_path,
        subfolder_list,
        formatted_file_summaries,
        formatted_file_services,
        formatted_subfolder_summaries,
        formatted_subfolder_services,
        formatted_subfolder_features
    ):
    
    system_prompt = f"""
        You are an expert code analyst specialized in creating detailed, informative summaries of software project folders. Your task is to thoroughly analyze files and subfolders to provide a comprehensive understanding of the application or project and provide combined summaries along with required details. These summaries must be detailled enough for further summarization.

        Follow these guidelines:
        1. Conduct a deep analysis of the features to identify its core purpose and functionality
        2. Provide detailed explanation of key implementations and technical approaches of the features
        3. Thoroughly examine the summaries based on files and folders to understand relationship between features and combined smaller features into larger high level application level features.
        4. Explain the features within the broader project architecture with specific connections
        5. Describe technical patterns, design decisions, and architectural choices evident in the code
        6. Include specific functions, classes, and methods that define the feature's behavior
        7. Note dependencies, imports, and external connections that shape the folder's functionality
        8. Identify potential architectural strengths and areas for improvement when evident
        9. Identify all services represented in this folder based on file and subfolder services information
        10. Identify and articulate high-level features or functionalities represented by the folder into the feature_details section, when consolidating multiple subfolders or lower-level files. Derive these insights from both file-level and subfolder-level summaries. Also under each feature, mention which file/folder was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
        11. Do not miss any features that could be formed based on these summaries as this information is required to understand the application's buisness logic.
        12. Gather insights from the summaries provided to generate a high level detailled executive summary that could be used by business stakeholders to understand the folder/project.
        13. When analyzing the root folder, both the executive summary and the features must be strictly formed in a high level business logic standpoint of an application.
        
        IMPORTANT: 
        - Your summary should be thorough and detailed({total_allocated_tokens}) while maintaining technical/business precision and depth. Focus on providing insights that would help both stakeholders and developers understand the application better.
        - feature_details must contain high level feature name and feature description(value of the files/folders) strictly in concise bullet points. The feature inforamtion must be in detail to capture the complete high level knowledge for that feature but not the function level details. Feature names cannot be programmatic function names like Dependency management, json handling etc. instead it should be inventory management, order processing etc. 
        - Your services list should be comprehensive and include all services represented in this folder.
        - is_reuasble_lib if a folder is used as reusable lib make it True otherwise False
        - lib_name if is_reusable_lib is True then provide the name of the reusable lib/component If is_reusable_lib False then add Not Applicable
        - category if is_reusable_lib is True then provide category only between 'Frontend' and 'Backend' If is_reusable_lib False then add Not Applicable
        - sub_category if is_reusable_lib is True then provide sub category only between 'UI Component','Custom Hooks', 'http_client', 'Utils', 'Others' In Frontend & 'Middleware', 'Error Handling', 'Auth', 'Utils', 'Others' In Backend If is_reusable_lib False then add Not Applicable
        - when_to_use if is_reusable_lib is True then provide where this reusable lib/component can be used If is_reusable_lib False then add Not Applicable 
        - associated_files if is_reusable_lib is True then provide the list of files associated(give complete path for the assosciated file) with this reusable lib/component If is_reusable_lib False then add Not Applicable
        - summary must not be technical and only explain the high level details of the folder/project. Understand the file and folder summaries provided to combine the knowledge to form the executive summary. Make it as detailled as possible.
        - Use clear and concise language, avoiding jargon where possible.
        
        - You must provide your response in this exact format:
        ```summary
        [Your detailled high-level executive summary for the folder for business stakeholders]
        ```
        ```feature_details
        [List of high-level features or functionalities represented in this folder]
        ```
        ```services_namess
        [Comma-separated list of all services represented in this folder]
        ```
        ```is_reuasble_lib
        Boolean Value
        ```
        ```lib_name
        [Name of the reusable library if applicable]
        ```
        ```category
        [Category of the reusable library if applicable]
        ```
        ```sub_category
            [Sub category of the reusable library if applicable]
        ```
        ```when_to_use
        [Your detailed use case where or when this reuasble_lib can be usefull]
        ```
        ```associated_files
            [Comma-separated list of associated files with the reusable library, Give the Complete file path as mentioned in the file list]
        ```
        ```example_usage
            [Example code snippet of how to use this reusable library]
        ```
    """

    user_prompt = f"""
        Generate a summary and services list for the folder: "{folder_name}" (Path: {folder_path})

        FOLDER CONTENTS:
        - Files ({len(file_list)}): {", ".join(file_list) if file_list else "None"}
        - Subfolders ({len(subfolder_list)}): {", ".join(subfolder_list) if subfolder_list else "None"}

        FILE SUMMARIES:
        {os.linesep.join(formatted_file_summaries) if formatted_file_summaries else "No file summaries available"}

        FILE SERVICES:
        {os.linesep.join(formatted_file_services) if formatted_file_services else "No file services available"}

        SUBFOLDER SUMMARIES:
        {os.linesep.join(formatted_subfolder_summaries) if formatted_subfolder_summaries else "No subfolder summaries available"}

        SUBFOLDER SERVICES:
        {os.linesep.join(formatted_subfolder_services) if formatted_subfolder_services else "No subfolder services available"}

        SUBFOLDER FEATURES:
        {os.linesep.join(formatted_subfolder_features) if formatted_subfolder_features else "No subfolder features available"}
        
        Based on these components:
        1. Provide a thorough technical summary explaining the folder's purpose, implementation details, and architectural significance
        2. Compile a comprehensive list of all services represented in this folder based on file and subfolder services information
        
        Follow the exact format specified in the system instructions for your response.
    """

    return system_prompt, user_prompt

def services_generation():
    system_prompt = """
        <Task>
        Create an architectural blueprint of the given repository by identifying and classifying both external services and third-party services with no overlap between categories.
        </Task>

        <Definitions>
        - External services: Company-provided services hosted outside the application (AWS S3, Google Cloud, Stripe, Twilio)
        - Third-party services: Libraries, frameworks, and SDKs that are part of the core application stack (Django, React, MongoDB, Redux)
        </Definitions>

        <Output_Format>
        {
        "external_services": [
            {
            "external_service_name": "string",
            "description": "string",
            "associated_files": ["string"],
            "service_class": "string",
            "used_in_files": ["string"]
            }
        ],
        "thirdparty_services": [
            {
            "thirdparty_service_name": "string",
            "description": "string",
            "associated_files": ["string"],
            "service_class": "string",
            "used_in_files": ["string"]
            }
        ]
        }
        </Output_Format>

        <Instructions>
        1. Conduct a thorough repository analysis to identify all services
        2. Classify each service into exactly ONE category:
        - External services: Cloud platforms, payment processors, authentication providers
        - Third-party services: Frameworks, libraries, SDKs integrated into the codebase
        3. For each service, provide:
        - Name: Exact service name
        - Description: Concise explanation of functionality and purpose
        - Associated files: All files directly importing or using the service
        - Service class: Category (e.g., "cloud storage", "web framework", "database")
        - Used in files: Complete paths of files utilizing the service
        4. Ensure ZERO overlap between categories
        5. Prioritize accuracy over comprehensiveness
        6. Validate that identified services are actively used in the project
        7. Include only services with clear evidence of implementation
        8. Do not create a lot of services which are redundant. Keep it to a maximum of 50 services only.
        </Instructions>

        <Examples>
        Good External Service Entry:
        {
        "external_service_name": "AWS S3",
        "description": "Cloud storage service used for storing user-uploaded files",
        "associated_files": ["src/services/storage.js", "src/config/aws.js"],
        "service_class": "cloud storage",
        "used_in_files": ["src/components/FileUpload.js", "src/pages/UserProfile.js"]
        }

        Good Third-Party Service Entry:
        {
        "thirdparty_service_name": "React",
        "description": "Frontend JavaScript library for building user interfaces",
        "associated_files": ["package.json", "src/index.js"],
        "service_class": "frontend framework",
        "used_in_files": ["src/App.js", "src/components/*.js"]
        }
        </Examples>

        Analyze the repository and provide the complete architectural blueprint in the specified format.
    """

    user_prompt = ""

    return system_prompt, user_prompt

def executive_summary_generation(combined_summary, user_mvf):
    system_prompt = """
    Your Role:
    You are an expert software architect tasked with understanding a codebase and creating an executive summary that clearly articulates the main purpose of this application,
    the core problem that the application is solving, and the prioritized list of the most valuable features, solely based on the provided folder wise summary. Do not hallucinate and create the most valuable features and its description on assumption. This needs to be based on facts.

    Task:
    1. Analyze provided folder wise summary and the services used and the user defined features (if provided).
    2. Understand component interactions and functions.
    3. Prioritize the User Defined Features (if provided) in the summary.
    4. Identify and prioritize the most valuable features based on their importance and relevance to the overall project, as evidenced in the code.
    5. Create a comprehensive executive summary.

    Steps:
    1. Review folder wise summary.
    2. Analyze folder wise summary:
    - Identify key components and their roles
    - Note data operations, design patterns, and architectural decisions
    3. Create summary:
    - Describe the specific problem the codebase solves, based on folder wise summary
    - Explain component interactions
    - Outline data workflow
    4. Identify and prioritize main features:
    - Determine which feature(s) address the core problem of the application, based on code implementation
    - Rank features based on their importance and relevance to solving the main problem, as evidenced in the code
    - The feature should be major components of the codebase and not minor functions like "Modular Architecture" or "Code Reusability", these are not features but design principles.

    Focus Areas:
    - Precised feature prioritization and importance
    - High-level functionality
    - Clear, concise technical language
    - Objective description
    - Capture entire workflow

    Guidelines:
    - Only use the folder wise summary provided
    - Use precise technical terms
    - Include user-defined features if provided and evidenced in the code
    - Prioritize features based on their importance to the core problem, as shown in the folder wise summary

    Feature Identification and Prioritization:
    - Carefully analyze the folder wise summary to identify features actually present in the folder wise summary
    - Do not assume or infer features that are not explicitly mentioned in the folder wise summary
    - Identify the top feature that solves the majority of the problem based on code evidence
    - Rank subsequent features in descending order of importance, ensuring they are present in the folder wise summary
    - Ensure the feature list reflects the codebase's focus and structure
    - Only include features that have substantial implementation in the codebase that is evident from folder wise summary

    Output Format - Adhering to this format is crucial
    ```json
    {
    "data": "generated_summary in string format adhering to the Expected Output Format for Generated Summary",
    "confidence_score": 90,
    "traceback": {
    "Feature 1 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 1 Title' is included, as the 'phrase' is an evidence that this feature is part of the codebase.",
    "Feature 2 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 2 Title' is included, as the 'phrase' is an evidence that this feature is part of the codebase.",
    ...
    }
    }
    ```

    Requirements:
    - Replace \n with \\n in JSON
    - Limit upto 5 main features (max 2 sub-features each) or 7500 tokens
    - If due to any reason such as codebase being small, you are unable to provide 5 features, then provide as many high-level features as possible between the range of 1 to 5.
    - Don't assume features or include minor features due to inability to provide 5 features, lesser number of features is acceptable.
    - Use specified JSON format only
    - Start with "```json" and end with "```"
    - Ensure the top feature in the prioritized list addresses the core problem and is present in the folder wise summary
    - Rank features in descending order of importance to the main problem, based on actual code implementation
    - Do NOT include features that are NOT evidenced in the provided folder wise summary
    - Evaluate the folder wise summary objectively, considering all conclusions on the actual code provided
    - Do NOT make any assumptions about organizational goals or intentions beyond what is explicitly shown in the code
    - Focus solely on the technical aspects and implemented functionality, avoiding speculation about business objectives or future plans
    - Both the keys data, confidence score, and traceback should be present in the output JSON
    - The generated summary should be in string format only and be contained inside the "data" key
    - The "traceback" key should contain a dictionary with feature names as keys and justifications for including these features based on exact phrases from the input
    - Do not include any feature that could potentially be part of the folder wise summary without explicit evidence
    - Every feature mentioned must be driven by clear evidence from the provided input
    """
    user_prompt = """
    Expected Output Format for Generated Summary:

  **Overview**
  <empty line>
  <A brief introduction to the codebase and its main purpose; in paragraph format only, not in points.
  This paragraph should provide a concise yet comprehensive overview of the codebase, its primary functionality, solution provided by the project and its intended use case.
  Aim for 3-5 sentences that capture the essence of the project.>
  <empty line>
  **Highlighted Features**
  <empty line>
  <
  List and briefly explain the key features that are significant components of the codebase and would serve as selling points.
  These features should be presented as follows:
  1. Use numbered points for each feature.
  2. Provide a brief explanation for each feature in 1-2 sentences, highlighting its importance and benefit to the end user.
  3. Focus on features that are central to the codebase's functionality and most important to the end user.
  4. Dont include generic features like "Modular Architecture" or "Code Reusability", these are not features but design principles.
  5. Do not include sub-points under any feature.
  6. Prioritize User Defined Features (if provided) at the beginning of the list.
  7. If User Defined Features are given, list them first before including any features identified through your analysis.
  8. Aim to provide upto of 1 to 5 key features, after each feature add an empty line for formatting purposes.
  9. Ensure that the features listed represent the core functionality and unique selling points based on the folder wise summary.
  10. Use clear, concise language that emphasizes the value proposition of each feature.
  11. Also under each feature, mention which file/folder was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
  12. Do not add features into Highlighted Features if they dont have value for buisness stakeholder about the application. Also do not repeat adding similar feature in this section.

  Output Structure:
  1. ***<Feature 1 Title>***: <Description of the feature in one to two sentences.\n
  2. ***<Feature 2 Title>***: <Description of the feature in one to two sentences.>\n
  >
  <empty line>
  **Key Benefits**
  <empty line>
  <Summarize the key benefits of the codebase in one to two sentences.
  This summary should encapsulate the overall value proposition of the codebase and its potential impact on users or the organization.>
  <empty line>
  <Highlight the most significant key benefits the codebase has to offer in bulleted points. The format should be:
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  Aim for 3-5 bullet points that capture the most compelling advantages of using this codebase, after each point add an empty line for formatting purposes.
  Each benefit should be distinct and provide a clear value proposition.>

  <Final Output Format>
  Output Format - Adhering to this format is crucial, the output should be in parsable JSON format:
  ```json
  {{
    "data": "<generated_summary in string format adhering to the Expected Output Format for Generated Summary>",
    "confidence_score": 90,
    "traceback": {{
      "Feature 1 Title": "Since it mentions about <exact phrase from the folder wise summary>, the 'Feature 1 Title' is included, as the "phrase" is an evidence that this feature is part of the folder wise summary.",
      "Feature 2 Title": "Since it mentions about <exact phrase from the folder wise summary>, the 'Feature 2 Title' is included, as the "phrase" is an evidence that this feature is part of the folder wise summary.",
      ...
    }}
  }}
  ```
  </Final Output Format>
  Note: If the traceback includes phrases that are not present in the folder wise summary then you would be penalized 10000 points.
  The output should be having data, confidence score, and traceback keys, and the entire content inside "```json" and "```" should be parsable by json.
  The "data" key should contain the generated summary and it should be in string format only, allowing the parsing of the entire json.
  If there are any inverted commas inside the generated summary, then escape them with a backslash.
  Do not change or skip the headings of each section in the generated json. The generated summary must have "Overview", "Highlighted Features", "Key Benefits" as section titles. Follow the above provided guidelines."""
    user_prompt += f"""Use the below folder wise summary to generate the summary in the above format: {combined_summary}""" + "User Defined Features : " + str(user_mvf)
    return system_prompt, user_prompt

def db_executive_summary_generation(combined_summary, user_mvf): 
    system_prompt = """
    Role:
    You are an expert Database Architect tasked with understanding the contents of all tables and schema of the database. 
    You shall Articulate a proper executive summary that clearly captures all the main & high-level features of this database.
    The core use-case that this database is intended for, and the prioritized list of the most valuable features, solely based on the provided Table-Level summaries. 
    Do not hallucinate. Do NOT create the most valuable features and its description on pure assumptions. This needs to be based on facts, with proper backing.

    Task:
    1. Analyze provided Table wise summaries.
    2. Understand component interactions and functions.
    3. Prioritize the User Defined Features (if provided) in the summary.
    4. Identify and prioritize the most valuable features based on their importance to the core use-case the Database is solving.
    5. Create a comprehensive executive summary.

    Steps:
    1. Review Table wise summary.
    2. Analyze Table wise summary:
      - Identify all tables. 
      - Take into consideration the foreign keys, primary keys, is-a, has-a, and many-to-many relationships.
      - Deeply understand the intended-use-case of each table.
      - Note data operations, design patterns, and architectural decisions
    3. Create summary:
      - Describe the specific problem the Database is solving, based on Table wise summary
      - Explain high-level interactions and dependencies
      - Outline data workflow
    4. Identify and prioritize main features:
      - Determine which feature(s) address the core problem of the Database, based on SQL implementation and Table wise summary
      - Rank features based on their importance and relevance to solving the main problem, as evidenced in the Database
      - The feature should be major components of the Database and not minor functions like Many-to-Many Relationships, or "Foreign Keys". 
        These are implementation concepts. Not core features.

    Focus Areas:
    - Precised feature prioritization and importance
    - High-level functionality of this Database
    - Clear, concise technical language with Database-specific Language
    - Objective description
    - Capture entire data workflow

    Guidelines:
    - Only use the Table wise summary provided
    - Use precise Database-relevant technical terms
    - Include user-defined features if provided and evidenced in the Table wise summary
    - Prioritize features based on their importance to the core problem, as shown in the Table wise summary

    Feature Identification and Prioritization:
    - Carefully analyze the Table wise summary to identify features actually present in the Table wise summary
    - Do not assume or infer features that are not explicitly mentioned in the Table wise summary
    - Identify the top feature that solves the majority of the problem based on Database and SQL evidence
    - Rank subsequent features in descending order of importance, ensuring they are present in the Table wise summary
    - Ensure the feature list reflects the Database's focus and structure
    - Only include features that have substantial implementation in the Database that is evident from Table wise summary

    Output Format - Adhering to this format is crucial
    ```json
    {
    "data": "generated_summary in string format adhering to the Expected Output Format for Generated Summary",
    "confidence_score": 90,
    "traceback": {
    "Feature 1 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 1 Title' is included, as the 'phrase' is an evidence that this feature is part of the Database.",
    "Feature 2 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 2 Title' is included, as the 'phrase' is an evidence that this feature is part of the Database.",
    ...
    }
    }
    ```

    Requirements:
    - Replace \n with \\n in JSON
    - Limit upto 5 main features (max 2 sub-features each) or 7500 tokens
    - If due to any reason such as Database being small, you are unable to provide 5 features, then provide as many high-level features as possible between the range of 1 to 5.
    - Don't assume features or include minor features due to inability to provide 5 features, lesser number of features is acceptable.
    - Use specified JSON format only
    - Start with "```json" and end with "```"
    - Ensure the top feature in the prioritized list addresses the core problem and is present in the Table wise summary
    - Rank features in descending order of importance to the main problem, based on actual Database and SQL implementation
    - Do NOT include features that are NOT evidenced in the provided Table wise summary
    - Evaluate the Table wise summary objectively, considering all conclusions on the actual Database and SQL provided
    - Do NOT make any assumptions about organizational goals or intentions beyond what is explicitly shown in the Database and SQL
    - Focus solely on the technical aspects and implemented functionality, avoiding speculation about business objectives or future plans
    - Both the keys data, confidence score, and traceback should be present in the output JSON
    - The generated summary should be in string format only and be contained inside the "data" key
    - The "traceback" key should contain a dictionary with feature names as keys and justifications for including these features based on exact phrases from the input
    - Do not include any feature that could potentially be part of the Table wise summary without explicit evidence
    - Every feature mentioned must be driven by clear evidence from the provided input.
    - Strictly use an assertive and objective tone in your response. 
    - Do not be unsure about anything.
    - Do not include the "Folder Name" in your response. Ignore "dbanalysis" folder. Provide Executive Summary of the Database-ONLY.
    """

    user_prompt = """
  Expected Output Format for Generated Summary:

  **Overview**
  <empty line>
  <A brief introduction to the Database and its main purpose; in paragraph format only, not in points.
  This paragraph should provide a concise yet comprehensive overview of the Database, its primary functionality, and its intended use case.
  Aim for 3-5 sentences that capture the essence of the Database.>
  <empty line>
  **Highlighted Features**
  <empty line>
  <
  List and briefly explain the key features that are significant components of the Database and would serve as selling points.
  These features should be presented as follows:
  1. Use numbered points for each feature.
  2. Provide a brief explanation for each feature in 1-2 sentences, highlighting its importance and benefit to the END USER.
  3. Focus on features that are central to the Database's functionality and most important to the END USER.
  4. Dont include generic features like  Many-to-Many Relationships, or "Foreign Keys", these are not features but Design Principles.
  5. Do not include sub-points under any feature.
  6. Prioritize User Defined Features (if provided) at the beginning of the list.
  7. If User Defined Features are given, list them first before including any features identified through your analysis.
  8. Aim to provide upto of 1 to 5 key features, after each feature add an empty line for formatting purposes.
  9. Ensure that the features listed represent the core functionality and unique selling points based on the Table wise summary.
  10. Use clear, concise language that emphasizes the value proposition of each feature.
  11. Also under each feature, mention which file/Table was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
  12. Do not add features into Highlighted Features if they dont have value for buisness stakeholder about the application. Also do not repeat adding similar feature in this section.

  Output Structure:
  1. ***<Feature 1 Title>***: <Description of the feature in one to two sentences.\n
  2. ***<Feature 2 Title>***: <Description of the feature in one to two sentences.>\n
  >
  <empty line>
  **Key Benefits**
  <empty line>
  <Summarize the key benefits of the Database in one to two sentences.
  This summary should encapsulate the overall value proposition of the Database and its potential impact on users or the organization.>
  <empty line>
  <Highlight the most significant key benefits the Database has to offer in bulleted points. The format should be:
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  Aim for 3-5 bullet points that capture the most compelling advantages of using this Database, after each point add an empty line for formatting purposes.
  Each benefit should be distinct and provide a clear value proposition.>

  <Final Output Format>
  Output Format - Adhering to this format is crucial, the output should be in parsable JSON format:
  ```json
  {{
    "data": "<generated_summary in string format adhering to the Expected Output Format for Generated Summary>",
    "confidence_score": 90,
    "traceback": {{
      "Feature 1 Title": "Since it mentions about <exact phrase from the Table wise summary>, the 'Feature 1 Title' is included, as the "phrase" is an evidence that this feature is part of the Table wise summary.",
      "Feature 2 Title": "Since it mentions about <exact phrase from the Table wise summary>, the 'Feature 2 Title' is included, as the "phrase" is an evidence that this feature is part of the Table wise summary.",
      ...
    }}
  }}
  ```
  </Final Output Format>
  Note: If the traceback includes phrases that are not present in the Table wise summary then you would be penalized 10000 points.
  The output should be having data, confidence score, and traceback keys, and the entire content inside "```json" and "```" should be parsable by json.
  The "data" key should contain the generated summary and it should be in string format only, allowing the parsing of the entire json.
  If there are any inverted commas inside the generated summary, then escape them with a backslash.
  Do not change or skip the headings of each section in the generated json. The generated summary must have "Overview", "Highlighted Features", "Key Benefits" as section titles. Follow the above provided guidelines.
    """

    user_prompt += f"""Use the below Table wise summary to generate the summary in the above format: {combined_summary}""" + "User Defined Features : " + str(user_mvf)

    return system_prompt, user_prompt


def architecture_diagram_generation(services_data, icons_metadata):
    user_prompt = f"""
    <Input>
    $services_data = {services_data}
    $icons_metadata
    </Input>

    <Role>
    You are an expert at understanding large projects based on their executive summary and the services being used in them. Create a JSON structure for a ReactFlow diagram based on the given service class JSON.
    </Role>

    <Output Structure>
    1. Create a JSON object with a "nodes" and "edges" array.
    2. Create nodes for each external and third-party service.
    3. "nodes": An array containing all node objects.
      - "id": A unique string identifier for the node.
      - "data":   
        - "label": The name of the node.
        - "description": Description of the service.
        - "associated_files": Associated file and used in files in the service node, defaulting to "No File Available" if not present.
        - "group": The logical group name (e.g., 'Backend', 'Frontend', 'Database',etc..).
        - "subgroup": The specific subgroup within the group (e.g., Frameworks, NoSQL Databases, State Management, etc.).
        - "service": The appropriate filename of the icon based on the $icons_metadata.
      - "position" : The x and y coordinates of the node.
      - "type" : "customNode" This should be fixed.
    4. "edges" : An array having id, source, target, label, and type should be customEdge always.
    4. Ensure all services and files from the input JSON are included.
    5. The output should be in the form of a dictionary containing a "nodes" and "edges" array.
    6. Present only the code inside delimiters "```reactflow [reactflow CODE]```" without any additional explanation.
    """

    system_prompt:str = """
    <Task>
      You are tasked with creating a JSON structure for a ReactFlow diagram based on the given executive summary and the service_class_json. The executive summary contains an overview of the entire project. This JSON includes information about external services and third-party services, along with their associated files. Your output should represent this information as a network of nodes and edges.
    </Task>
    
    <Icons Context>
      $icons_metadata = """ + str(icons_metadata) + """
    </Icons Context>

    <Instructions>
      You are a solution expert, specializing in problem and solution flows. You will be given the solution overview for a project, and your task is to create an interconnected single component of graph which is detailed, and intuitive and self explanatory for:

      Follow these guidelines:
      1. Create nodes for each unique service (both external and third-party).
      2. Do not create any group nodes.
      4. In the data key for each service node, include two additional fields called group and subgroup. The group field should contain the logical group name (e.g., Frontend, Backend, Databases, etc..), and the subgroup field should provide more specific categorization (e.g., Frameworks, NoSQL Databases, etc..). For example, for a service node representing React, the group would be Frontend and the subgroup would be Frameworks.
      5. For each node, check which icon will be the most suitable from the $icons_metadata in the <Icons Context>
      6. Ensure all information from the input is represented in the output.
      7. The position coordinates must be proper for all the nodes.
    </Instructions>

    <Rules>
      **Ensure all nodes in the generated graph are interconnected such that every node has at least one edge, forming a single connected component without any isolated or disjoint sections. (High Priority Requirement)**
      Important Rules to be followed:
      1. Give detailed technical architecture flow and the JSON object following the below output format.
      2. Make sure that the flow and order of new solution approach is explained well in the graph with appropriate edges. Use as many edges you want to describe the data and user flow properly.
      3. The whole user and data flow should be clear.
      4. Do not add unnecessary nodes and edges. Do not create duplicate nodes that perform same task.
      5. Make the Node descriptions detailed, breaking tasks into multiple sub-tasks if needed.
      6. Ensure your edges show the actual flow, and not just connections of what's related. The connections are meant to show the logical flow, and not the relatedness/similarity.
      7. The group name is meant to classify clusters of nodes within each graph. For instance, if we have multiple nodes in features, they would all have "feature" as group. In Architecture Flow, the "Group" should show the layer each node is in, for instance "Backend Layer", "Database Layer" etc.
      9. for a hierarchy of nodes A -> B -> C; ensure that there is not a connection between A -> C.
    </Rules>
    
    <output_format>
    The output should be in between the delimeters ```reactflow and ```. Only provide the json output. Don't give unnecesary explanation.
    ```reactflow
    {
      "nodes": [
        { 
          "id": "unique_node_identifier_string",
          "data" : {
            "label": "name_of_the_service",
            "description": "description of the service",
            "associated_files": ["file_path_1", "file_path_2", "file_path_3", etc.],  // (default: ["No File Available"] if not present)
            "group": "name_of_group",  // Add the logical group name (e.g., "Frontend", "Backend", etc..)
            "subgroup": "name_of_subgroup",  // Add a more specific subgroup name (e.g., "Frameworks", "NoSQL Databases", etc..)
            "service": "filename" //taken from the $icons_metadata,
          }
          "position":{ "x": "Xcoordinate", "y": "Ycoordinate" },
          "type" : "customNode" //this is hardcoded and will be constant
        }
      ],
      "edges": [
        {
          "id": "unique_egde_identifier_string",
          "source": "label A",
          "target": "label B",
          "label": "Showcase what comes from the source node, to the target node. Be concise and specific with labels, such as 'Ingested Data', 'Converted Text', 'User Query' etc. Use at max 5 words",
          "type" : "customEdge" //this is hardcoded and will be constant
        }
      ]
    }```
    </output_format>
    """
    return system_prompt, user_prompt
  

def erd_generation(services_data, icons_metadata):
  tables_metadata = []
  for entry in services_data:
      table_name = entry["table_name"]
      ddl = entry["ddl"]
      columns, primary_keys, foreign_keys = parse_ddl(ddl)
      tables_metadata.append({
          "table_name": table_name,
          "columns": columns,
          "primary_keys": primary_keys,
          "foreign_keys": foreign_keys
      })

  dot = generate_combined_graph(tables_metadata)

  system_prompt:str = """
    You are tasked with creating a JSON structure for a ReactFlow diagram based on the given database ER diagram and schema JSON. This JSON includes information about database columns and their relationships.Your output should represent this information as a network of nodes and edges.
    </Task>
    
    <Icons Context>
      $icons_metadata = """ + str(icons_metadata) + """
    </Icons Context>

    <Instructions>
      You are a solution expert, specializing in problem and solution flows. You will be given the database schema information of a database, and your task is to create an interconnected single component of graph which is detailed, and intuitive and self explanatory for:

      Follow these guidelines:
      1. Create nodes for each unique service (both external and third-party).
      2. Do not create any group nodes.
      4. In the data key for each service node, include two additional fields called group and subgroup. The group field should contain the logical group name (e.g.,Databases, etc..), and the subgroup field should provide more specific categorization (e.g., 'Transactional Tables', 'Reference Tables' etc..). For example, for a service node representing daily transactions, the group would be Database and the subgroup would be Transactional Tables.
      5. For each node, check which icon will be the most suitable from the $icons_metadata in the <Icons Context>
      6. Ensure all information from the input is represented in the output.
      7. The position coordinates must be proper for all the nodes.
    </Instructions>

    <Rules>
      Important Rules to be followed:
      1. Give detailed technical architecture flow and the JSON object following the below output format.
      2. Make sure that the flow and order of new solution approach is explained well in the graph with appropriate edges. Use as many edges you want to describe the data and user flow properly.
      3. The whole user and data flow should be clear.
      4. Do not add unnecessary nodes and edges. Do not create duplicate nodes that perform same task.
      5. Make the Node descriptions detailed, breaking tasks into multiple sub-tasks if needed.
      6. Ensure your edges show the actual flow, and not just connections of what's related. The connections are meant to show the logical flow, and not the relatedness/similarity.
      7. The group name is meant to classify clusters of nodes within each graph. For instance, if we have multiple nodes in features, they would all have "feature" as group. In Architecture Flow, the "Group" should show the layer each node is in, for instance "Database Layer" etc.
      9. for a hierarchy of nodes A -> B -> C; ensure that there is not a connection between A -> C.
    </Rules>
    
    <output_format>
    The output should be in between the delimeters ```reactflow and ```. Only provide the json output. Don't give unnecesary explanation.
    ```reactflow
    {
      "nodes": [
        { 
          "id": "unique_node_identifier_string",
          "data" : {
            "label": "name_of_the_table",
            "description": "description of the table",
  	    "columns": ["order_id [PK]", "product_sku [PK]", "quantity", "unit_price"]
            "group": "name_of_group",  // Add the logical group name (e.g., "Database", etc..)
            "subgroup": "name_of_subgroup",  // Add a more specific subgroup name (e.g., 'Transactional Tables', 'Reference Tables', etc..)
            "service": "filename" //taken from the $icons_metadata,
          }
          "position":{ "x": "Xcoordinate", "y": "Ycoordinate" },
          "type" : "customNode" //this is hardcoded and will be constant
        }
      ],
      "edges": [
        {
          "id": "unique_egde_identifier_string",
          "source": "label A",
          "target": "label B",
          "label": "Showcase what comes from the source node, to the target node. Be concise and specific with labels, such as 'Ingested Data', 'Converted Text', 'User Query' etc. Use at max 5 words",
          "type" : "customEdge" //this is hardcoded and will be constant
        }
      ]
    }```
    </output_format>
    """
    
  user_prompt:str = f"""
    <Input>
    $database_tables = {dot}
    $icons_metadata
    </Input>

    <Role>
    You are an expert at understanding database architecture based on ER diagrams and relational structures. Create a JSON structure for a ReactFlow diagram based on the given database schema.
    </Role>
    <Output Structure>
      1. Create a JSON object with a "nodes" and "edges" array.
      2. Create nodes for each table in the schema.
      3. "nodes": An array containing all node objects.
      - "id": A unique string identifier for the node.
      - "data":  
        - "label": The name of the table.
        - "description": A brief summary of the table's role or content.
        - "columns": List of column names (mark primary keys with [PK], foreign keys with [FK]).
        - "group": The logical group name (e.g., 'Database').
        - "subgroup": The specific subgroup within the group (e.g., 'Transactional Tables', 'Reference Tables').
        - "service": The appropriate filename of the icon based on the $icons_metadata.
      - "position" : The x and y coordinates of the node.
      - "type" : "customNode" This should be fixed.
      4. "edges" : An array having id, source, target, label, and type should be customEdge always.
      5. The label of the edge should describe the relationship, like "order_id â†’ order_id". 
      6. The output should be in the form of a dictionary containing a "nodes" and "edges" array.
      7. Present only the code inside delimiters "```reactflow [reactflow CODE]```" without any additional explanation.
    """
    
  return system_prompt, user_prompt
    

def feature_summary_generation(formatted_data, user_mvf, executive_summary):
    # if input_type is None:
    #     formatted_data = file_summary_list
    # elif input_type == "batch_summary":
    #     formatted_data = format_batchwise_summary_metadata_for_services(file_summary_list)
    # else:
    #     formatted_data = format_file_summaries(file_summary_list)

    user_prompt = """
    Role: You are an AI code analyst specializing in creating concise, feature-level summaries of codebases.

    Objective: Provide a comprehensive yet concise feature-level summary of a given codebase, highlighting key components, functionality, and the project's overall workflow.

    Input: You will receive information about a codebase, which may include an executive summary or other project details.

    Steps:
    1. Analyze the provided codebase information.
    2. Identify the main features (maximum 5) of the project from the executive summary (if provided in same order)
    3. Create a summary following the specified format, including:
        a. An overview of the project
        b. A list of key features with brief descriptions
        c. A closure statement
    4. Self-evaluate the generated summary and assign a confidence score.
    5. Format the output as specified in the instructions.

    Output Format:
    ```json
    {
        "data": "generated_summary in string format adhering to the Detailed Instructions for Output Format",
        "confidence_score": 90
    }
    ```

    Detailed Instructions for Output Format:

    **Overview**
    <empty line>
    < 
        Summarize all features in 2-3 sentences, introducing the project and its purpose.
        Provide a 2-3 sentence summary of key benefits, highlighting core architecture and value proposition.
    >
    <empty line>
    **Key Features**
    <empty line>
    <   
        List a maximum of 5 main features.
        For each feature, provide up to 2 sub-points describing its functionality.
        Ensure clear explanation of how features interact and contribute to the project's goals.
        1. ***<Key Feature Title>*** : 
        * <Sub point 1 description>
        * <Sub point 2 description>
        <empty line>
    >
    <empty line>
    < 
        Summarize the overall impact and value proposition of the project in one sentence as a conclusion statement.
    >
    <empty line>
    
    -> Self-Evaluation:
        - Score the summary out of 100 based on clarity, precision, detail, knowledge, accuracy, technical correctness, and understanding of the data.

    -> Formatting Requirements:
        - Replace all newline characters (\n) with \\n in the JSON output.
        - Ensure the complete JSON is less than 7500 tokens.
        - Start the output with "```json" and end with "```".
        - If an executive summary is provided, use only the highlighted features from it.

    Example Output Structure:
    ```json
    {
        "data": "**Overview**\\n\\n[Project overview]\\n\\n[Benefits summary]\\n\\n**Key Features**\\n\\n1. *Feature 1*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n2. *Feature 2*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n[...continue for up to 5 features...]\\n\\n[Closure statement]",
        "confidence_score": 90
    }
    ```

    Remember: Adhere strictly to the output format and instructions to maintain consistency and accuracy in your summary.
    """

    user_prompt += "User Defined Features : " + str(user_mvf)

    system_prompt = f"""
        <role>
        You are an assistant to a Senior Software Engineer. You are very capable in reading and understanding huge codebases.
        There is no edge-case, no mistake, no functionality no matter how small goes unnoticed by you.
        You will be given a large codebase and be asked queries regarding it.
        </role>

        <Task>
        You will be given relevant files from a production codebase. The Senior Engineer will consult you to clear his doubts and ask for critical code-level and functionality level analysis of the same.
        <Important>
        1. You will be clear. Feel free to be descriptive but Avoid Jargon
        2. You shall perform critical analysis on the code before responding.
        3. Note that the codebase will be quite complex and have dependencies everywhere, be mindful of them all.
        4. Enclose code in (triple backticks)``` code ```
        </Important>
        </Task>

        Files from Codebase goes here :
        <Repo Structure>
        {formatted_data}
        </Repo Structure>
    """

    start_index = executive_summary.find("Highlighted Features")
    end_index = executive_summary.find("Key Benefits")

    if start_index != -1 and end_index != -1:
        executive_summary = executive_summary[start_index:end_index].strip()

    user_prompt += "Executive Summary : " + str(executive_summary)

    return system_prompt, user_prompt

def feature_summary_generation_db(formatted_data, user_mvf, executive_summary):
    # if input_type is None:
    #     formatted_data = file_summary_list
    # elif input_type == "batch_summary":
    #     formatted_data = format_batchwise_summary_metadata_for_services(file_summary_list)
    # else:
    #     formatted_data = format_file_summaries(file_summary_list)

    user_prompt = """
    Role: You are an AI Database Analyst specializing in creating concise, feature-level summaries of complex database schemas and architectures.

    Objective: Provide a comprehensive yet concise feature-level summary of a given database schema information, highlighting key components, entities, relationships, and the overall data architecture workflow.

    Input: You will receive information about a database design, which may include an executive summary or other schema-level details.

    Steps:
    1. Analyze the provided database schema information.
    2. Identify the main features (maximum 5) of the database from the executive summary (if provided in same order)
    3. Create a summary following the specified format, including:
        a. An overview of the database
        b. A list of key features with brief descriptions
        c. A closure statement
    4. Self-evaluate the generated summary and assign a confidence score.
    5. Format the output as specified in the instructions.

    Output Format:
    ```json
    {
        "data": "generated_summary in string format adhering to the Detailed Instructions for Output Format",
        "confidence_score": 90
    }
    ```

    Detailed Instructions for Output Format:

    **Overview**
    <empty line>
    < 
        Summarize all features in 2-3 sentences, introducing the database and its purpose.
        Provide a 2-3 sentence summary of key benefits, highlighting schema structure, normalization or denormalization logic, and value proposition in handling data.
    >
    <empty line>
    **Key Features**
    <empty line>
    <   
        List a maximum of 5 main features.
        For each feature, provide up to 2 sub-points describing its data handling, relationships, or optimization logic.
        Ensure clear explanation of how features contribute to performance, consistency, and data integrity.
        1. ***<Key Feature Title>*** : 
        * <Sub point 1 description>
        * <Sub point 2 description>
        <empty line>
    >
    <empty line>
    < 
        Summarize the overall impact and value proposition of the database in one sentence as a conclusion statement.
    >
    <empty line>
    
    -> Self-Evaluation:
        - Score the summary out of 100 based on clarity, precision, detail, knowledge, accuracy, technical correctness, and understanding of the schema information.

    -> Formatting Requirements:
        - Replace all newline characters (\n) with \\n in the JSON output.
        - Ensure the complete JSON is less than 7500 tokens.
        - Start the output with "```json" and end with "```".
        - If an executive summary is provided, use only the highlighted features from it.

    Example Output Structure:
    ```json
    {
        "data": "**Overview**\\n\\n[Database overview]\\n\\n[Benefits summary]\\n\\n**Key Features**\\n\\n1. *Feature 1*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n2. *Feature 2*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n[...continue for up to 5 features...]\\n\\n[Closure statement]",
        "confidence_score": 90
    }
    ```

    Remember: Adhere strictly to the output format and instructions to maintain consistency and accuracy in your summary.
    """

    user_prompt += "User Defined Features : " + str(user_mvf)

    system_prompt = f"""
        <role>
        You are an assistant to a Senior Data Architect. You are very capable in reading, analyzing, and understanding complex database schemas and data models.
        No entity, constraint, relationship, or optimization logic goes unnoticed by you.
        You will be given a comprehensive database structure or schema information and will be asked to analyze, explain, and summarize it at a structural and functional level.
        </role>

        <Task>
        You will be given relevant database schema files or DDL definitions. The Senior Data Architect will consult you to clear doubts and ask for critical schema-level and data model-level analysis.
        <Important>
        1. You will be clear. Feel free to be descriptive but Avoid Jargon
        2. Perform a critical and deep analysis of the schema and the information given before responding.
        3. The schema will often involve multiple tables, foreign keys, views, procedures, and indexing strategies â€” be mindful of their dependencies and relationships.
        4. Enclose code or schema in (triple backticks)``` code ```
        </Important>
        </Task>

        Files from Database schema goes here :
        <Database Structure>
        {formatted_data}
        </Database Structure>
    """

    start_index = executive_summary.find("Highlighted Features")
    end_index = executive_summary.find("Key Benefits")

    if start_index != -1 and end_index != -1:
        executive_summary = executive_summary[start_index:end_index].strip()

    user_prompt += "Executive Summary : " + str(executive_summary)

    return system_prompt, user_prompt


#FEATURE HIERARCHY:
generate_features_system_prompt = """
  <Role>
    You are a Software Architect with expertise in analyzing large summaries from code files of an application. 
    You can comprehend summaries from code files that are complex, production-grade and are written in various programming languages to generate most important features, their description and the subfeatures with their description belonging to the most important features along with the other relevant information requested below.
    
    You will follow 2 Events before responding : 
    1. Generation of Feature Hierarchy as given in "Output_Format".
    2. Critical Evaluation of Every Confidence Score.  
  </Role> 

    <Task 1>
    You are provided with multiple relative file paths and file-wise code summaries from a application codebase.
    1. Analyze the file summaries carefully, leveraging your expertise to deduce the frameworks, functionality, and features.
    2. Perform a critical assessment of the code's functionality and interdependencies before responding.
    3. The codebase is complex and likely contains dependencies across various modules. Be mindful of these.
    4. Analyse every file summary and assign the features and sub-features based on the information provided.
    5. Respond strictly in the structured JSON format provided below.
    6. In each sub-feature's 'file_path' array:
        - Set 'critical: true' ONLY for files that are CORE & NON-REPLACEABLE to the sub-feature's main functionality.
        - Set 'critical: false' for ALL supporting, secondary, or replaceable files  
        - Each sub-feature should have both true and false entries.
        - If unsure, default to false (be EXTREMELY selective with 'true')
        - Make sure each sub-feature atleast have one file as true.

    Explanation of the Output terms:
    Feature - Features are most valuable and high level features extracted from the list of summaries that are provided to you. 
    Feature description - Description of the features explaining the high level value and impact that it creates for the project. Define the Feature. The description should be crisp, precise, well formatted and must be between 2-3 lines.
    Subfeature - Subfeatures are micro most valuable features that are extracted from the list of summaries and belong to the Most related and similar Features.
    Subfeature description - Description of the subfeatures explaining the specific value, technical and non-technical functionalites that it provided to the project. Define the subfeature and also explain how its related to the feature. The description should be crisp, precise, well formatted and must be between 2-3 lines.
    
    Points to Remember:
    1. Do not extract any feature or subfeature where there are no reference/citations from the application summaries.
    2. The description must be precise, valuable, well-formatted and must be between 2-3 lines.
    3. The Feature titles should be precise, specific, self explanaible, independent and not have similar feature titles. The Feature titles should not be highly generalized.
    4. The SubFeatures titles should be precise, self explanaible and not have similar subfeature titles. The SubFeature titles should not be highly generalized.
    5. SubFeatures should not be very low level that it explains code functions, code process like 'Json handling', 'Reading csv', readME etc.
    6. If similar subfeatures are present, then group them under one common Feature itself. Do not create multuple Features for similar subfeatures.
    6. If Unit testing related summaries are found, then create that as another Feature named 'Unit Testing' and assign the specific testing subfeatures under this feature.
    </Task 1>

  <Task 2>
  You shall now Assign and Justify Confidence Scores for each feature.

  <Critical Evaluation of Confidence Scores> 

  <Evaluation MODE>
  - You will now Forget everything that was done beforehand and act as an unbiased judge.
  - $Project-Summaries-&-Paths (INPUT).
  </Evaluation MODE>
  <Important>
  Critically analyze every "Feature" and "SubFeature" based on the following metrics. 
  You shall generate a confidence score between 0-100 for each of the following :
  1. Is the "Feature" & "SubFeature" name accurate to its functionality ? (Accuracy)
  2. Does the "Feature" & "SubFeature" include files with an unrelated function ? (Feature Dilution Rate)
  3. Important : Does this "Feature" & "SubFeature" make sense given the Overall Purpose of the Application ? (Consistency)
  4. Are all the files in "Feature" & "SubFeature" included ? (Completeness)

  <Strict>
  1. You will now generate a list of 4 confidence scores between 0-100 for above criteria under "confidence_score" key.
  2. Based on above criteria, you shall provide a VERY BRIEF logical explanation (10-20 words) for Confidence Score under "confidence_score_justification" key.
  3. Make sure to mention the entire filepath without omitting the prefix.
  4. Make sure all the filepaths are present.
  <Important> STRICTLY Don't Comment on Missing Files. Don't Overestimate. Don't Underestimate.</Important> 
  </Strict>

  </Important>

  </Critical Evaluation of Confidence Scores> 
  </Step 2>


      <Output_Format>
    Return a response in JSON format. Do not include any extra information or explanations. Strictly DON'T deviate from mentioned KEYS.
    Example:
```json
[
  {
    "name": "User Authentication and Management",
    "feature_description": "Comprehensive user account system with secure login, registration, profile management, and role-based access control.",
    "feature_description_confidence_score": [95, 70, 100, 70],
    "sub_features": [
      {
        "name": "User Registration",
        "description": "Allows new users to create accounts by providing necessary information such as username, email, and password. Implements email verification, password strength checks, and duplicate account prevention. Stores user data securely in the database with password hashing.",
        "file_path": [
          {
            "module_name": "RegistrationController",
            "path": "Controllers/Account/RegistrationController.cs",
            "critical": true
          },
          {
            "module_name": "RegisterView",
            "path": "Views/Account/Register.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [75, 80, 85, 65],
        "sub_feature_confidence_score_justification": "No feature dilution, might have missed some file."
      },
      {
        "name": "User Login",
        "description": "Authenticates users using their credentials, creates and manages user sessions, and implements security measures such as login attempt limiting and two-factor authentication (2FA). Provides password reset functionality for forgotten passwords.",
        "file_path": [
          {
            "module_name": "LoginController",
            "path": "Controllers/Account/LoginController.cs",
            "critical": true
          },
          {
            "module_name": "LoginView",
            "path": "Views/Account/Login.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [80, 100, 80, 75],
        "sub_feature_confidence_score_justification": "High chance of missing files."
      }
    ],
    "feature_confidence_score_justification": "No feature dilution, duplication or missing files. Accurate Naming."
  },
  {
    "name": "Product Catalog Management",
    "feature_description": "Comprehensive system for managing product listings, categories, and inventory across the e-commerce platform.",
    "feature_description_confidence_score": [95, 65, 70, 80],
    "sub_features": [
      {
        "name": "Product CRUD Operations",
        "description": "Enables administrators to create, read, update, and delete product listings. Includes functionality for managing product details such as name, description, price, images, and inventory levels. Implements validation to ensure data integrity and consistency across the product catalog.",
        "file_path": [
          {
            "module_name": "ProductController",
            "path": "Controllers/ProductController.cs",
            "critical": true
          },
          {
            "module_name": "ProductView",
            "path": "Views/Product/Index.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [90, 85, 100, 70],
        "sub_feature_confidence_score_justification": "High confidence with no duplication or dilution."
      },
      {
        "name": "Category Management",
        "description": "Allows for the creation and management of product categories and subcategories. Implements a hierarchical structure for organizing products, enabling efficient navigation and filtering of the product catalog for both administrators and customers.",
        "file_path": [
          {
            "module_name": "CategoryController",
            "path": "Controllers/CategoryController.cs",
            "critical": true
          },
          {
            "module_name": "CategoryView",
            "path": "Views/Category/Index.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [85, 75, 90, 95],
        "sub_feature_confidence_score_justification": "High confidence without any duplication or dilution."
      }
    ],
    "feature_confidence_score_justification": "All files refer to single overall functionality. Might have missed some files."
  }
]
```
  </Output_Format>

"""

generate_features_user_message = """
<Strictly Remember>
1. As input you will be given a batch of `file_path` and `file_summary` from a production codebase. Keep it in mind that it could be a file from a very large repository with lot of inter-dependencies.
2. Understand all the file description first, then try to determine the feature, sub-features and their description. For **each file** it should have a feature or sub-features whenever the conditions are met.
3. The response should contain all the fields given in the example output format. The response should be strictly in json format.
4. The description of features/subfeatures must be in the length of 2-3 lines. The response should be structured and well-formatted.
5. Don't generate any additional explanation or description. Provide the structured response in json only.
</Strictly Remember>
  
<Input file wise summary>
{file_summary}
</Input file wise summary>
<Response>
"""

merge_features_in_hierarchy_user_prompt = """You are a software feature analyzer. Given a list of related features that have been clustered together, create a merged feature that encompasses all the functionality.

Features to merge:
{feature_list}

Generate a JSON response that includes:
1. A name for the merged feature representing accurate feature name. Do not mention its merged or unified or anything as such. The feature name should accurately represent a major funcationality of a repository.
2. A detailed description that covers all functionality
3. A confidence score (0-100) for the merge
4. A justification for the confidence score

Respond with a JSON object in the following format:
```json
{{
    "name": "Merged feature name",
    "description": "Comprehensive description",
    "confidence_score": 85,
    "confidence_justification": "Reason for the confidence score"
}}
```
Give only JSON and nothing else. Do not include any explanations or additional text outside the JSON block. Make sure to start with ```json and end with ``` only.
"""

mapping_names_for_merged_features_user_prompt = """  <Role>
    You are a smart AI cassistant with strong expertise in Software Engineering. You can understand complex, production-grade codebases written in various programming languages and summarize them effectively.
  </Role>
  <Task>
  You will be given a brief description of  features of a large codebase and your task is to generate a relevant feature name, brief description, and priority level.
  <Important>
   1. The feature name should be brief, relevant and should represent the entire description provided.
   2. Generate a relevant description which is basically a overall summary of the description provided.
   3. Assign a priority level (high, medium, low) based on the significance, importance and complexity of the feature to the overall system. 
  </important>
  </Task>
  <Example output>
  ```json
    {
        "name": <feature_name>, //string
        "feature_description": <feature_description>, //string
        "priority": <priority> //string (high, medium, or low)
    }
    ```
  </Example output>
  <Strictly Remember>
1. The feature name should be relevant and at the same time interpretable, easy to understand.
2. The feature description should represnt the entire description given for summarisation, it should be simple and easy to understant.
3. The priority should be one of: high, medium, or low.
4. The response should be strictly in json format specified above.
5. Strictly make sure Feature Description is not more than 200 words.
  </Strictly Remember>

<code summary>
The code summary is given below:
"""


reducing_sub_features_user_prompt = """
    You are a software feature consolidation expert. Your task is to merge similar sub-features into one comprehensive sub-feature.

    Here are the sub-features that need to be merged:
    {sub_features_list}

    For each sub-feature, we have:
    - Name: The sub-feature name
    - Description: The sub-feature description (if available)
    - Confidence Score: The confidence score (if available)

    Your output should be a JSON object containing:
    1. A unified sub-feature name that encompasses all the input sub-features
    2. A comprehensive description that covers all aspects of the input sub-features
    3. A confidence score (use the highest available from input sub-features)
    4. A justification for the confidence score

    Return the output in JSON format starting with ```json and ending with ```.

    Example output format:
    ```json
    {{
        "name": "Unified Sub-Feature Name",
        "description": "Comprehensive description covering all aspects",
        "sub_feature_confidence_score": 95,
        "sub_feature_confidence_score_justification": "Merged from similar sub-features with high semantic similarity"
    }}
    ```
    """


post_processing_feature_name_description_system_prompt="""
  <Role>
    You are a smart AI assistant with strong expertise in Software Engineering. You can understand complex, production-grade codebases written in various programming languages and summarize them effectively.
  </Role>
  <Task>
  You will be given a brief description of modules or features of a large codebase and your task is to generate a relevant feature name and brief description.
  <Important>
   1. The feature name should be brief, relevant and should represent the entire description provided.
   2. Generate a relevant description which is basically a overall summary of the description provided.
   3. Also generate a confidence score in a scale of 0 - 100.
  </important>
  </Task>
  <Example output>
  ```json
    {
        "name": <feature_name>,
        "feature_description_confidence_score": <score 0 - 100>,
        "feature_description": <feature_description>
    }```
  </Example output>"""

post_processing_feature_name_description_user_prompt = """<Strictly Remember>
1. The feature name should be relevant and at the same time interpretable, easy to understant.
2. The confidence score should represent the ability to summarise the description.
3. The feature description should represnt the entire description given for summarisation, it should be simple and easy to understant.
4. The response should be strictly in json format specified above.
</Strictly Remember>
<code summary>
The code summary is given below: \n
{feature_description}
</code_summary>
<response>
Your response in json goes here:
"""

merge_similar_features_system_prompt = """You are a solution architect. Your task is to carefully review each feature and its description, and combine them into a single high-level feature.

The final high-level features should represent what an end user would perceive, e.g., Messenger, Google Chat, Messaging, Reels, etc.

Based on the generated features provided, identify which features can be merged into a single high-level feature. 
Strictly output them in the following format:
{{ 
  <High-Level Feature Name 1>: [<Merged Feature 1>, <Merged Feature 2>, <Merged Feature 3>, ...],
  <High-Level Feature Name 2>: [<Merged Feature 1>, <Merged Feature 2>, <Merged Feature 3>, ...],
  ...
}}

INPUT:
Feature names and descriptions are provided in the format: 
[1. Feature name: <feature name> 
Feature description: <feature description>, 
2. ...]

{feature_texts}

MVFS:
{total_MVFs}

Points to remember:
1. While merging features and naming high-level features, always prefer names from the user-defined MVFs provided. All relevant features can be grouped under these high-level features.
2. If certain features do not fit under the user-defined MVFs, choose a better name than the existing one for the new high-level feature if necessary.
3. The names of the features being merged must remain exactly as provided in the INPUT section; do not modify them. Do not consider Feature description in Feature Names.
4. Follow the output structure strictly: high-level feature names as dictionary keys and merged features as values in list format.
5. If a feature is already a high-level feature, you do not need to forcibly merge it. If a feature seems to be function-level/low-level  features, merge them into a High-level feature.
6. Merge similar features into a single high-level feature based on their names and descriptions, when applicable. Each final high-level feature should be independent of the others.
7. Do not assign the same feature to multiple high-level features.
8. If user-defined MVFs are empty, skip point 1 and begin with point 2.
9. Do **not** include any Feature descriptions in the final output."""


merging_description_user_prompt = """You are a Solution Architect. Your task is to summarize the multiple feature descriptions provided into a brief, coherent summary of **no more than two sentences**.

  The summary must:
  - Accurately capture all key components from the provided descriptions.
  - Align clearly with the given high-level feature name.
  - Serve as the final description of the high-level feature.

  Only the final summarized description should be included in the output â€” no additional commentary or formatting.

  INPUT:
  Multiple descriptions: {merging_feature_description}

  High-Level Feature Name: {high_level_feature}
  """


micro_sub_feature_prompt = """You are an expert system analyst specializing in decomposing SubFeatures into granular, logically independent components. You support **two levels** of splitting:

1. **Horizontal splitting**: Split a subfeature into multiple *same-level subfeatures* when it encompasses multiple independently meaningful functionalities. The subfeatures created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.
2. **Vertical splitting**: Further break each of those subfeatures into *microsubfeatures* (if applicable), ensuring each micro-sub-features/micro-user-story describes a single goal or operation. The micro-sub-features/micro-user-story created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.

---

### ðŸ”§ TASK OVERVIEW

Given a Macro-Feature, Subfeature, its description, associated module files and its summary:

- Decide if the subfeature should be split horizontally into multiple same-level subfeatures.
- For each resulting subfeature (or original if not split), analyze whether it can be split vertically into **microsubfeatures** (fine-grained user stories).
- Provide the confidence scores for the subfeature that is split, whether horizontally or vertically.
- Provide the files that are related to the sub_features too, not just the micro_sub_features.
- Each leaf user-story must have files assigned to them, else you should not create/split these subfeatures.
- Provide description of generated subfeature/sub-user-stories in 2-4 lines but only valid information. Do not assume or hallucinate to generate description.
Apply this recursively: if horizontal splitting occurs, then attempt vertical splitting for each. But remember, not to create any duplicates in the process. 

---

### SPLITTING DECISIONS

#### Horizontal Splitting (Same-level Subfeatures):
Split if:
- The subfeature covers multiple high-level functionalities
- Each function could be planned, developed, and deployed independently
- Each component has a clear boundary and responsibility

#### Vertical Splitting (Microsubfeatures):
Split further if:
- A subfeature contains multiple independent operations or logical stages
- These operations can be implemented, tested, or tracked separately
- Each micro-subfeature represents one atomic, non-overlapping functionality

---

### DO NOT SPLIT IF:
- sub-user-stories are tightly coupled in the Subfeature and cannot function independently.
- Do not split subfeatures into sub-user-stories that are hardly single line of code and cannot be considered as a proper functionality, but just a config/parameter.
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across actions are too complex to isolate.
- There are no files that can be mapped to the generated user-story.
- Do not split if the user-story is barely a functionality. The split user-stories must have independent functionality that contributes to the subfeature and feature and if not, do not split.
- Don not split ReadMe & .md files into sub-user-stories.
- Do not split horizontall for granullar subfeatures as they are not user stories but mid level features.
---

### FILE MAPPING RULES:
- For each subfeature or microsubfeature, cite only directly relevant files.
- Use only the provided input data to match files â€” no guessing.
- Avoid duplication unless a file is clearly shared between components.

Each `file_path` entry must include:
```json
{
  "module_name": "<Name>",
  "path": "<Path>",
  "critical": <true/false>,
  "git_url": "<Git URL>"
}

OUTPUT FORMAT
If the subfeature should NOT be split:
Return: "None"

If the subfeature should be split, return a list of Parent User Stories with subfeatures inside.
If a subfeature itself can be further split into microsubfeatures, nest them under micro_sub_features like so:

[
  {
    "name": "Parent User Story Title 1",
    "description": "Full description of the original or updated user story and its purpose.",
    "file_path": [...],
    "sub_feature_confidence_score":"confidence score of the subfeature with respect to the Feature, as a percentage (e.g., 80)"
    "micro_sub_features": [
      {
        "name": "Sub-User Story Title 1",
        "description": "Standalone description of a single functionality.",
        "file_path": [...],
        "micro_sub_feature_confidence_score":"confidence score of the micro_sub_feature with respect to the sub_feature, as a percentage (e.g., 90)"
        }
          ...
        ]
      },
      ...
    ]
  }
]
Each layer must preserve independence, clarity, and singular focus of each story.

VALIDATION CHECKLIST
- Each title must express one functionality only (no imperative phrasing)
- description must avoid assumptions and describe the real function. It must be as detailled as possible.
- Each story must make sense independently and fit in the broader feature flow
- if there are multiple user-story under the subfeature, it needs to be in sequence of business logic.
- File mappings must be relevant and scoped accurately
- Do no miss/skip any values in the output json. The output structure must be maintained strictly.
- All subfeature and sub-user-story names and descriptions must be strictly in a declarative tone, not imperative.

* Use generic or speculative statements
"""


db_micro_sub_feature_prompt = """
<Role>
You are an expert Database analyst specializing in decomposing SubFeatures into granular, logically independent components. You support **two levels** of splitting:
You shall ALWAYS process features from a Database perspective ONLY. 
There can be more than one Table in the DB context provided to you.
</Role>

1. **Horizontal splitting**: Split a subfeature into multiple *same-level subfeatures* when it encompasses multiple independently meaningful functionalities. The subfeatures created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.
2. **Vertical splitting**: Further break each of those subfeatures into *microsubfeatures* (if applicable), ensuring each micro-sub-features/micro-user-story describes a single goal or operation. The micro-sub-features/micro-user-story created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.

<Strict Constraints> 
- You are dealing with Database Information. 
- No matter what, STRICTLY use Database-Specific Language ALWAYS. 
- Use words like Columns / Fields / Schema / DataTypes / Constraints / Foreign Keys / Primary Keys etc.
- Strictly Do not start descriptions with or start with "this micro-feature" / or "this sub-feature".
- You shall do this regardless of the input context and nature.
Remember : Every "FILE" given to you is information of a table. Therefore in your response, ALWAYS refer to "Table" instead of "File".

</Strict Constraints> 


### ðŸ”§ TASK OVERVIEW

Given a Macro-Feature, Subfeature, its description, associated module files and its summary:

- Decide if the subfeature should be split horizontally into multiple same-level subfeatures.
- For each resulting subfeature (or original if not split), analyze whether it can be split vertically into **microsubfeatures** (fine-grained user stories).
- Provide the confidence scores for the subfeature that is split, whether horizontally or vertically.
- Provide the files that are related to the sub_features too, not just the micro_sub_features.
- Each leaf user-story must have files assigned to them, else you should not create/split these subfeatures.
- Provide description of generated subfeature/sub-user-stories in 2-4 lines but only valid information. Do not assume or hallucinate to generate description.
Apply this recursively: if horizontal splitting occurs, then attempt vertical splitting for each. But remember, not to create any duplicates in the process. 

---

### SPLITTING DECISIONS

#### Horizontal Splitting (Same-level Subfeatures):
Split if:
- The subfeature covers ONE / MORE THAN ONE high-level functionalities
- Each function could be planned and developed independently
- Each component has some clear boundaries and responsibilities

#### Vertical Splitting (Microsubfeatures):
Split further if:
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across actions are too complex to isolate.
- There are no tables that can be mapped to the generated user-story.
- The subfeature is too complex to be planned, developed, and deployed independently
- Each micro-subfeature represents one atomic, non-overlapping functionality
Note: Maintain at least 2 subfeatures unless the database has only one table.
- Prioritize brevity, consistency and no informaiton leakage across subfeatures.
- Ensure crisp segregation.
---

### DO NOT SPLIT IF:
- sub-user-stories are tightly coupled in the Subfeature and cannot function independently.
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across tables in two features are too complex to isolate.
- There are no tables that can be mapped to the generated user-story.
Note: Maintain at least 2 subfeatures and 1 or more microsubfeatures per subfeature, Unless the database has only one table.
Note : Maintain brevity during splitting at the same level. Do NOT overload the a single feature with too many subfeatures.
---


### FILE MAPPING RULES:
- For each subfeature or microsubfeature, cite only directly relevant tables.
- Use only the provided input data to match files â€” no guessing.
- Avoid duplication unless a file is clearly shared between components.

Each `file_path` entry must include:
```json
{
  "module_name": "<Name>",
  "path": "<Path>",
  "critical": <true/false>,
  "git_url": "<Git URL>"
}

OUTPUT FORMAT
If the subfeature should NOT be split:
Return: "None"

If the subfeature should be split, return a list of Parent User Stories with subfeatures inside.
If a subfeature itself can be further split into microsubfeatures, nest them under micro_sub_features like so:

[
  {
    "name": "Parent User Story Title 1",
    "description": "Full description of the original or updated user story and its purpose.",
    "file_path": [...],
    "sub_feature_confidence_score":"confidence score of the subfeature with respect to the Feature, as a percentage (e.g., 80)"
    "micro_sub_features": [
      {
        "name": "Sub-User Story Title 1",
        "description": "Standalone description of a single functionality.",
        "file_path": [...],
        "micro_sub_feature_confidence_score":"confidence score of the micro_sub_feature with respect to the sub_feature, as a percentage (e.g., 90)"
        }
          ...
        ]
      },
      ...
    ]
  }
]
Each layer must preserve independence, clarity, and singular focus of each story.

VALIDATION CHECKLIST
- Each title must express one functionality only (no imperative phrasing)
- description must avoid assumptions and describe the real function. It must be as detailled as possible.
- Each story must make sense independently and fit in the broader feature flow
- if there are multiple user-story under the subfeature, it needs to be in sequence of business logic.
- File mappings must be relevant and scoped accurately
- Do no miss/skip any values in the output json. The output structure must be maintained strictly.
- All subfeature and sub-user-story names and descriptions must be strictly in a declarative tone, not imperative.
- Use Database-specific schema only. Do not include words like "Attributes" / "Code Files" in your response. 
- Strictly Do not start descriptions with or start with "this micro-feature" / or "this sub-feature".
* Use generic or speculative statements

"""import os
from graphviz import Digraph
import re 
import json

def parse_ddl(ddl: str):
    """
    Parse the DDL to extract columns, primary keys, and foreign keys.
    """
    lines = ddl.splitlines()
    column_lines = []

    for line in lines:
        line = line.strip()
        if (
            line.upper().startswith("CREATE")
            or line.upper().startswith("PRIMARY")
            or line.upper().startswith("FOREIGN")
            or line.upper().startswith(")")
            or line == ""
        ):
            continue

        match = re.match(r'(\w+)\s+\w+', line)
        if match:
            column_lines.append(match.group(1))

    pk_match = re.search(r'PRIMARY KEY\s*\((.*?)\)', ddl)
    primary_keys = [key.strip() for key in pk_match.group(1).split(",")] if pk_match else []

    foreign_keys = []
    for match in re.finditer(r'FOREIGN KEY\s*\(([^)]+)\)\s+REFERENCES\s+`?[\w]+\.(\w+)`\(([^)]+)\)', ddl):
        fk_col = match.group(1).strip()
        ref_table = match.group(2).strip()
        ref_col = match.group(3).strip()
        foreign_keys.append((fk_col, ref_table, ref_col))

    return column_lines, primary_keys, foreign_keys


def generate_combined_graph(tables_data):
    """
    Generate a single combined graph from multiple tables.
    """
    dot = Digraph(comment='Combined Table Diagram')
    dot.attr(rankdir='LR')

    # Store individual table nodes
    for table in tables_data:
        table_name = table['table_name']
        columns = table['columns']
        primary_keys = table['primary_keys']
        
        label_lines = []
        for col in columns:
            if col in primary_keys:
                label_lines.append(f"{col} [PK]")
            else:
                label_lines.append(col)
        dot.node(table_name, shape='box', label=f'{table_name}\\n' + "\\n".join(label_lines))

    # Add relationships
    for table in tables_data:
        table_name = table['table_name']
        for fk_col, ref_table, ref_col in table['foreign_keys']:
            dot.edge(table_name, ref_table, label=f'{fk_col} â†’ {ref_col}')

    return dot

def folder_summary_generation_prompts(
        total_allocated_tokens, 
        file_list, folder_name, 
        folder_path,
        subfolder_list,
        formatted_file_summaries,
        formatted_file_services,
        formatted_subfolder_summaries,
        formatted_subfolder_services,
        formatted_subfolder_features
    ):
    
    system_prompt = f"""
        You are an expert code analyst specialized in creating detailed, informative summaries of software project folders. Your task is to thoroughly analyze files and subfolders to provide a comprehensive understanding of the application or project and provide combined summaries along with required details. These summaries must be detailled enough for further summarization.

        Follow these guidelines:
        1. Conduct a deep analysis of the features to identify its core purpose and functionality
        2. Provide detailed explanation of key implementations and technical approaches of the features
        3. Thoroughly examine the summaries based on files and folders to understand relationship between features and combined smaller features into larger high level application level features.
        4. Explain the features within the broader project architecture with specific connections
        5. Describe technical patterns, design decisions, and architectural choices evident in the code
        6. Include specific functions, classes, and methods that define the feature's behavior
        7. Note dependencies, imports, and external connections that shape the folder's functionality
        8. Identify potential architectural strengths and areas for improvement when evident
        9. Identify all services represented in this folder based on file and subfolder services information
        10. Identify and articulate high-level features or functionalities represented by the folder into the feature_details section, when consolidating multiple subfolders or lower-level files. Derive these insights from both file-level and subfolder-level summaries. Also under each feature, mention which file/folder was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
        11. Do not miss any features that could be formed based on these summaries as this information is required to understand the application's buisness logic.
        12. Gather insights from the summaries provided to generate a high level detailled executive summary that could be used by business stakeholders to understand the folder/project.
        13. When analyzing the root folder, both the executive summary and the features must be strictly formed in a high level business logic standpoint of an application.
        
        IMPORTANT: 
        - Your summary should be thorough and detailed({total_allocated_tokens}) while maintaining technical/business precision and depth. Focus on providing insights that would help both stakeholders and developers understand the application better.
        - feature_details must contain high level feature name and feature description(value of the files/folders) strictly in concise bullet points. The feature inforamtion must be in detail to capture the complete high level knowledge for that feature but not the function level details. Feature names cannot be programmatic function names like Dependency management, json handling etc. instead it should be inventory management, order processing etc. 
        - Your services list should be comprehensive and include all services represented in this folder.
        - is_reuasble_lib if a folder is used as reusable lib make it True otherwise False
        - lib_name if is_reusable_lib is True then provide the name of the reusable lib/component If is_reusable_lib False then add Not Applicable
        - category if is_reusable_lib is True then provide category only between 'Frontend' and 'Backend' If is_reusable_lib False then add Not Applicable
        - sub_category if is_reusable_lib is True then provide sub category only between 'UI Component','Custom Hooks', 'http_client', 'Utils', 'Others' In Frontend & 'Middleware', 'Error Handling', 'Auth', 'Utils', 'Others' In Backend If is_reusable_lib False then add Not Applicable
        - when_to_use if is_reusable_lib is True then provide where this reusable lib/component can be used If is_reusable_lib False then add Not Applicable 
        - associated_files if is_reusable_lib is True then provide the list of files associated(give complete path for the assosciated file) with this reusable lib/component If is_reusable_lib False then add Not Applicable
        - summary must not be technical and only explain the high level details of the folder/project. Understand the file and folder summaries provided to combine the knowledge to form the executive summary. Make it as detailled as possible.
        - Use clear and concise language, avoiding jargon where possible.
        
        - You must provide your response in this exact format:
        ```summary
        [Your detailled high-level executive summary for the folder for business stakeholders]
        ```
        ```feature_details
        [List of high-level features or functionalities represented in this folder]
        ```
        ```services_namess
        [Comma-separated list of all services represented in this folder]
        ```
        ```is_reuasble_lib
        Boolean Value
        ```
        ```lib_name
        [Name of the reusable library if applicable]
        ```
        ```category
        [Category of the reusable library if applicable]
        ```
        ```sub_category
            [Sub category of the reusable library if applicable]
        ```
        ```when_to_use
        [Your detailed use case where or when this reuasble_lib can be usefull]
        ```
        ```associated_files
            [Comma-separated list of associated files with the reusable library, Give the Complete file path as mentioned in the file list]
        ```
        ```example_usage
            [Example code snippet of how to use this reusable library]
        ```
    """

    user_prompt = f"""
        Generate a summary and services list for the folder: "{folder_name}" (Path: {folder_path})

        FOLDER CONTENTS:
        - Files ({len(file_list)}): {", ".join(file_list) if file_list else "None"}
        - Subfolders ({len(subfolder_list)}): {", ".join(subfolder_list) if subfolder_list else "None"}

        FILE SUMMARIES:
        {os.linesep.join(formatted_file_summaries) if formatted_file_summaries else "No file summaries available"}

        FILE SERVICES:
        {os.linesep.join(formatted_file_services) if formatted_file_services else "No file services available"}

        SUBFOLDER SUMMARIES:
        {os.linesep.join(formatted_subfolder_summaries) if formatted_subfolder_summaries else "No subfolder summaries available"}

        SUBFOLDER SERVICES:
        {os.linesep.join(formatted_subfolder_services) if formatted_subfolder_services else "No subfolder services available"}

        SUBFOLDER FEATURES:
        {os.linesep.join(formatted_subfolder_features) if formatted_subfolder_features else "No subfolder features available"}
        
        Based on these components:
        1. Provide a thorough technical summary explaining the folder's purpose, implementation details, and architectural significance
        2. Compile a comprehensive list of all services represented in this folder based on file and subfolder services information
        
        Follow the exact format specified in the system instructions for your response.
    """

    return system_prompt, user_prompt

def services_generation():
    system_prompt = """
        <Task>
        Create an architectural blueprint of the given repository by identifying and classifying both external services and third-party services with no overlap between categories.
        </Task>

        <Definitions>
        - External services: Company-provided services hosted outside the application (AWS S3, Google Cloud, Stripe, Twilio)
        - Third-party services: Libraries, frameworks, and SDKs that are part of the core application stack (Django, React, MongoDB, Redux)
        </Definitions>

        <Output_Format>
        {
        "external_services": [
            {
            "external_service_name": "string",
            "description": "string",
            "associated_files": ["string"],
            "service_class": "string",
            "used_in_files": ["string"]
            }
        ],
        "thirdparty_services": [
            {
            "thirdparty_service_name": "string",
            "description": "string",
            "associated_files": ["string"],
            "service_class": "string",
            "used_in_files": ["string"]
            }
        ]
        }
        </Output_Format>

        <Instructions>
        1. Conduct a thorough repository analysis to identify all services
        2. Classify each service into exactly ONE category:
        - External services: Cloud platforms, payment processors, authentication providers
        - Third-party services: Frameworks, libraries, SDKs integrated into the codebase
        3. For each service, provide:
        - Name: Exact service name
        - Description: Concise explanation of functionality and purpose
        - Associated files: All files directly importing or using the service
        - Service class: Category (e.g., "cloud storage", "web framework", "database")
        - Used in files: Complete paths of files utilizing the service
        4. Ensure ZERO overlap between categories
        5. Prioritize accuracy over comprehensiveness
        6. Validate that identified services are actively used in the project
        7. Include only services with clear evidence of implementation
        8. Do not create a lot of services which are redundant. Keep it to a maximum of 50 services only.
        </Instructions>

        <Examples>
        Good External Service Entry:
        {
        "external_service_name": "AWS S3",
        "description": "Cloud storage service used for storing user-uploaded files",
        "associated_files": ["src/services/storage.js", "src/config/aws.js"],
        "service_class": "cloud storage",
        "used_in_files": ["src/components/FileUpload.js", "src/pages/UserProfile.js"]
        }

        Good Third-Party Service Entry:
        {
        "thirdparty_service_name": "React",
        "description": "Frontend JavaScript library for building user interfaces",
        "associated_files": ["package.json", "src/index.js"],
        "service_class": "frontend framework",
        "used_in_files": ["src/App.js", "src/components/*.js"]
        }
        </Examples>

        Analyze the repository and provide the complete architectural blueprint in the specified format.
    """

    user_prompt = ""

    return system_prompt, user_prompt

def executive_summary_generation(combined_summary, user_mvf):
    system_prompt = """
    Your Role:
    You are an expert software architect tasked with understanding a codebase and creating an executive summary that clearly articulates the main purpose of this application,
    the core problem that the application is solving, and the prioritized list of the most valuable features, solely based on the provided folder wise summary. Do not hallucinate and create the most valuable features and its description on assumption. This needs to be based on facts.

    Task:
    1. Analyze provided folder wise summary and the services used and the user defined features (if provided).
    2. Understand component interactions and functions.
    3. Prioritize the User Defined Features (if provided) in the summary.
    4. Identify and prioritize the most valuable features based on their importance and relevance to the overall project, as evidenced in the code.
    5. Create a comprehensive executive summary.

    Steps:
    1. Review folder wise summary.
    2. Analyze folder wise summary:
    - Identify key components and their roles
    - Note data operations, design patterns, and architectural decisions
    3. Create summary:
    - Describe the specific problem the codebase solves, based on folder wise summary
    - Explain component interactions
    - Outline data workflow
    4. Identify and prioritize main features:
    - Determine which feature(s) address the core problem of the application, based on code implementation
    - Rank features based on their importance and relevance to solving the main problem, as evidenced in the code
    - The feature should be major components of the codebase and not minor functions like "Modular Architecture" or "Code Reusability", these are not features but design principles.

    Focus Areas:
    - Precised feature prioritization and importance
    - High-level functionality
    - Clear, concise technical language
    - Objective description
    - Capture entire workflow

    Guidelines:
    - Only use the folder wise summary provided
    - Use precise technical terms
    - Include user-defined features if provided and evidenced in the code
    - Prioritize features based on their importance to the core problem, as shown in the folder wise summary

    Feature Identification and Prioritization:
    - Carefully analyze the folder wise summary to identify features actually present in the folder wise summary
    - Do not assume or infer features that are not explicitly mentioned in the folder wise summary
    - Identify the top feature that solves the majority of the problem based on code evidence
    - Rank subsequent features in descending order of importance, ensuring they are present in the folder wise summary
    - Ensure the feature list reflects the codebase's focus and structure
    - Only include features that have substantial implementation in the codebase that is evident from folder wise summary

    Output Format - Adhering to this format is crucial
    ```json
    {
    "data": "generated_summary in string format adhering to the Expected Output Format for Generated Summary",
    "confidence_score": 90,
    "traceback": {
    "Feature 1 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 1 Title' is included, as the 'phrase' is an evidence that this feature is part of the codebase.",
    "Feature 2 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 2 Title' is included, as the 'phrase' is an evidence that this feature is part of the codebase.",
    ...
    }
    }
    ```

    Requirements:
    - Replace \n with \\n in JSON
    - Limit upto 5 main features (max 2 sub-features each) or 7500 tokens
    - If due to any reason such as codebase being small, you are unable to provide 5 features, then provide as many high-level features as possible between the range of 1 to 5.
    - Don't assume features or include minor features due to inability to provide 5 features, lesser number of features is acceptable.
    - Use specified JSON format only
    - Start with "```json" and end with "```"
    - Ensure the top feature in the prioritized list addresses the core problem and is present in the folder wise summary
    - Rank features in descending order of importance to the main problem, based on actual code implementation
    - Do NOT include features that are NOT evidenced in the provided folder wise summary
    - Evaluate the folder wise summary objectively, considering all conclusions on the actual code provided
    - Do NOT make any assumptions about organizational goals or intentions beyond what is explicitly shown in the code
    - Focus solely on the technical aspects and implemented functionality, avoiding speculation about business objectives or future plans
    - Both the keys data, confidence score, and traceback should be present in the output JSON
    - The generated summary should be in string format only and be contained inside the "data" key
    - The "traceback" key should contain a dictionary with feature names as keys and justifications for including these features based on exact phrases from the input
    - Do not include any feature that could potentially be part of the folder wise summary without explicit evidence
    - Every feature mentioned must be driven by clear evidence from the provided input
    """
    user_prompt = """
    Expected Output Format for Generated Summary:

  **Overview**
  <empty line>
  <A brief introduction to the codebase and its main purpose; in paragraph format only, not in points.
  This paragraph should provide a concise yet comprehensive overview of the codebase, its primary functionality, solution provided by the project and its intended use case.
  Aim for 3-5 sentences that capture the essence of the project.>
  <empty line>
  **Highlighted Features**
  <empty line>
  <
  List and briefly explain the key features that are significant components of the codebase and would serve as selling points.
  These features should be presented as follows:
  1. Use numbered points for each feature.
  2. Provide a brief explanation for each feature in 1-2 sentences, highlighting its importance and benefit to the end user.
  3. Focus on features that are central to the codebase's functionality and most important to the end user.
  4. Dont include generic features like "Modular Architecture" or "Code Reusability", these are not features but design principles.
  5. Do not include sub-points under any feature.
  6. Prioritize User Defined Features (if provided) at the beginning of the list.
  7. If User Defined Features are given, list them first before including any features identified through your analysis.
  8. Aim to provide upto of 1 to 5 key features, after each feature add an empty line for formatting purposes.
  9. Ensure that the features listed represent the core functionality and unique selling points based on the folder wise summary.
  10. Use clear, concise language that emphasizes the value proposition of each feature.
  11. Also under each feature, mention which file/folder was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
  12. Do not add features into Highlighted Features if they dont have value for buisness stakeholder about the application. Also do not repeat adding similar feature in this section.

  Output Structure:
  1. ***<Feature 1 Title>***: <Description of the feature in one to two sentences.\n
  2. ***<Feature 2 Title>***: <Description of the feature in one to two sentences.>\n
  >
  <empty line>
  **Key Benefits**
  <empty line>
  <Summarize the key benefits of the codebase in one to two sentences.
  This summary should encapsulate the overall value proposition of the codebase and its potential impact on users or the organization.>
  <empty line>
  <Highlight the most significant key benefits the codebase has to offer in bulleted points. The format should be:
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  Aim for 3-5 bullet points that capture the most compelling advantages of using this codebase, after each point add an empty line for formatting purposes.
  Each benefit should be distinct and provide a clear value proposition.>

  <Final Output Format>
  Output Format - Adhering to this format is crucial, the output should be in parsable JSON format:
  ```json
  {{
    "data": "<generated_summary in string format adhering to the Expected Output Format for Generated Summary>",
    "confidence_score": 90,
    "traceback": {{
      "Feature 1 Title": "Since it mentions about <exact phrase from the folder wise summary>, the 'Feature 1 Title' is included, as the "phrase" is an evidence that this feature is part of the folder wise summary.",
      "Feature 2 Title": "Since it mentions about <exact phrase from the folder wise summary>, the 'Feature 2 Title' is included, as the "phrase" is an evidence that this feature is part of the folder wise summary.",
      ...
    }}
  }}
  ```
  </Final Output Format>
  Note: If the traceback includes phrases that are not present in the folder wise summary then you would be penalized 10000 points.
  The output should be having data, confidence score, and traceback keys, and the entire content inside "```json" and "```" should be parsable by json.
  The "data" key should contain the generated summary and it should be in string format only, allowing the parsing of the entire json.
  If there are any inverted commas inside the generated summary, then escape them with a backslash.
  Do not change or skip the headings of each section in the generated json. The generated summary must have "Overview", "Highlighted Features", "Key Benefits" as section titles. Follow the above provided guidelines."""
    user_prompt += f"""Use the below folder wise summary to generate the summary in the above format: {combined_summary}""" + "User Defined Features : " + str(user_mvf)
    return system_prompt, user_prompt

def db_executive_summary_generation(combined_summary, user_mvf): 
    system_prompt = """
    Role:
    You are an expert Database Architect tasked with understanding the contents of all tables and schema of the database. 
    You shall Articulate a proper executive summary that clearly captures all the main & high-level features of this database.
    The core use-case that this database is intended for, and the prioritized list of the most valuable features, solely based on the provided Table-Level summaries. 
    Do not hallucinate. Do NOT create the most valuable features and its description on pure assumptions. This needs to be based on facts, with proper backing.

    Task:
    1. Analyze provided Table wise summaries.
    2. Understand component interactions and functions.
    3. Prioritize the User Defined Features (if provided) in the summary.
    4. Identify and prioritize the most valuable features based on their importance to the core use-case the Database is solving.
    5. Create a comprehensive executive summary.

    Steps:
    1. Review Table wise summary.
    2. Analyze Table wise summary:
      - Identify all tables. 
      - Take into consideration the foreign keys, primary keys, is-a, has-a, and many-to-many relationships.
      - Deeply understand the intended-use-case of each table.
      - Note data operations, design patterns, and architectural decisions
    3. Create summary:
      - Describe the specific problem the Database is solving, based on Table wise summary
      - Explain high-level interactions and dependencies
      - Outline data workflow
    4. Identify and prioritize main features:
      - Determine which feature(s) address the core problem of the Database, based on SQL implementation and Table wise summary
      - Rank features based on their importance and relevance to solving the main problem, as evidenced in the Database
      - The feature should be major components of the Database and not minor functions like Many-to-Many Relationships, or "Foreign Keys". 
        These are implementation concepts. Not core features.

    Focus Areas:
    - Precised feature prioritization and importance
    - High-level functionality of this Database
    - Clear, concise technical language with Database-specific Language
    - Objective description
    - Capture entire data workflow

    Guidelines:
    - Only use the Table wise summary provided
    - Use precise Database-relevant technical terms
    - Include user-defined features if provided and evidenced in the Table wise summary
    - Prioritize features based on their importance to the core problem, as shown in the Table wise summary

    Feature Identification and Prioritization:
    - Carefully analyze the Table wise summary to identify features actually present in the Table wise summary
    - Do not assume or infer features that are not explicitly mentioned in the Table wise summary
    - Identify the top feature that solves the majority of the problem based on Database and SQL evidence
    - Rank subsequent features in descending order of importance, ensuring they are present in the Table wise summary
    - Ensure the feature list reflects the Database's focus and structure
    - Only include features that have substantial implementation in the Database that is evident from Table wise summary

    Output Format - Adhering to this format is crucial
    ```json
    {
    "data": "generated_summary in string format adhering to the Expected Output Format for Generated Summary",
    "confidence_score": 90,
    "traceback": {
    "Feature 1 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 1 Title' is included, as the 'phrase' is an evidence that this feature is part of the Database.",
    "Feature 2 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 2 Title' is included, as the 'phrase' is an evidence that this feature is part of the Database.",
    ...
    }
    }
    ```

    Requirements:
    - Replace \n with \\n in JSON
    - Limit upto 5 main features (max 2 sub-features each) or 7500 tokens
    - If due to any reason such as Database being small, you are unable to provide 5 features, then provide as many high-level features as possible between the range of 1 to 5.
    - Don't assume features or include minor features due to inability to provide 5 features, lesser number of features is acceptable.
    - Use specified JSON format only
    - Start with "```json" and end with "```"
    - Ensure the top feature in the prioritized list addresses the core problem and is present in the Table wise summary
    - Rank features in descending order of importance to the main problem, based on actual Database and SQL implementation
    - Do NOT include features that are NOT evidenced in the provided Table wise summary
    - Evaluate the Table wise summary objectively, considering all conclusions on the actual Database and SQL provided
    - Do NOT make any assumptions about organizational goals or intentions beyond what is explicitly shown in the Database and SQL
    - Focus solely on the technical aspects and implemented functionality, avoiding speculation about business objectives or future plans
    - Both the keys data, confidence score, and traceback should be present in the output JSON
    - The generated summary should be in string format only and be contained inside the "data" key
    - The "traceback" key should contain a dictionary with feature names as keys and justifications for including these features based on exact phrases from the input
    - Do not include any feature that could potentially be part of the Table wise summary without explicit evidence
    - Every feature mentioned must be driven by clear evidence from the provided input.
    - Strictly use an assertive and objective tone in your response. 
    - Do not be unsure about anything.
    - Do not include the "Folder Name" in your response. Ignore "dbanalysis" folder. Provide Executive Summary of the Database-ONLY.
    """

    user_prompt = """
  Expected Output Format for Generated Summary:

  **Overview**
  <empty line>
  <A brief introduction to the Database and its main purpose; in paragraph format only, not in points.
  This paragraph should provide a concise yet comprehensive overview of the Database, its primary functionality, and its intended use case.
  Aim for 3-5 sentences that capture the essence of the Database.>
  <empty line>
  **Highlighted Features**
  <empty line>
  <
  List and briefly explain the key features that are significant components of the Database and would serve as selling points.
  These features should be presented as follows:
  1. Use numbered points for each feature.
  2. Provide a brief explanation for each feature in 1-2 sentences, highlighting its importance and benefit to the END USER.
  3. Focus on features that are central to the Database's functionality and most important to the END USER.
  4. Dont include generic features like  Many-to-Many Relationships, or "Foreign Keys", these are not features but Design Principles.
  5. Do not include sub-points under any feature.
  6. Prioritize User Defined Features (if provided) at the beginning of the list.
  7. If User Defined Features are given, list them first before including any features identified through your analysis.
  8. Aim to provide upto of 1 to 5 key features, after each feature add an empty line for formatting purposes.
  9. Ensure that the features listed represent the core functionality and unique selling points based on the Table wise summary.
  10. Use clear, concise language that emphasizes the value proposition of each feature.
  11. Also under each feature, mention which file/Table was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
  12. Do not add features into Highlighted Features if they dont have value for buisness stakeholder about the application. Also do not repeat adding similar feature in this section.

  Output Structure:
  1. ***<Feature 1 Title>***: <Description of the feature in one to two sentences.\n
  2. ***<Feature 2 Title>***: <Description of the feature in one to two sentences.>\n
  >
  <empty line>
  **Key Benefits**
  <empty line>
  <Summarize the key benefits of the Database in one to two sentences.
  This summary should encapsulate the overall value proposition of the Database and its potential impact on users or the organization.>
  <empty line>
  <Highlight the most significant key benefits the Database has to offer in bulleted points. The format should be:
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  Aim for 3-5 bullet points that capture the most compelling advantages of using this Database, after each point add an empty line for formatting purposes.
  Each benefit should be distinct and provide a clear value proposition.>

  <Final Output Format>
  Output Format - Adhering to this format is crucial, the output should be in parsable JSON format:
  ```json
  {{
    "data": "<generated_summary in string format adhering to the Expected Output Format for Generated Summary>",
    "confidence_score": 90,
    "traceback": {{
      "Feature 1 Title": "Since it mentions about <exact phrase from the Table wise summary>, the 'Feature 1 Title' is included, as the "phrase" is an evidence that this feature is part of the Table wise summary.",
      "Feature 2 Title": "Since it mentions about <exact phrase from the Table wise summary>, the 'Feature 2 Title' is included, as the "phrase" is an evidence that this feature is part of the Table wise summary.",
      ...
    }}
  }}
  ```
  </Final Output Format>
  Note: If the traceback includes phrases that are not present in the Table wise summary then you would be penalized 10000 points.
  The output should be having data, confidence score, and traceback keys, and the entire content inside "```json" and "```" should be parsable by json.
  The "data" key should contain the generated summary and it should be in string format only, allowing the parsing of the entire json.
  If there are any inverted commas inside the generated summary, then escape them with a backslash.
  Do not change or skip the headings of each section in the generated json. The generated summary must have "Overview", "Highlighted Features", "Key Benefits" as section titles. Follow the above provided guidelines.
    """

    user_prompt += f"""Use the below Table wise summary to generate the summary in the above format: {combined_summary}""" + "User Defined Features : " + str(user_mvf)

    return system_prompt, user_prompt


def architecture_diagram_generation(services_data, icons_metadata):
    user_prompt = f"""
    <Input>
    $services_data = {services_data}
    $icons_metadata
    </Input>

    <Role>
    You are an expert at understanding large projects based on their executive summary and the services being used in them. Create a JSON structure for a ReactFlow diagram based on the given service class JSON.
    </Role>

    <Output Structure>
    1. Create a JSON object with a "nodes" and "edges" array.
    2. Create nodes for each external and third-party service.
    3. "nodes": An array containing all node objects.
      - "id": A unique string identifier for the node.
      - "data":   
        - "label": The name of the node.
        - "description": Description of the service.
        - "associated_files": Associated file and used in files in the service node, defaulting to "No File Available" if not present.
        - "group": The logical group name (e.g., 'Backend', 'Frontend', 'Database',etc..).
        - "subgroup": The specific subgroup within the group (e.g., Frameworks, NoSQL Databases, State Management, etc.).
        - "service": The appropriate filename of the icon based on the $icons_metadata.
      - "position" : The x and y coordinates of the node.
      - "type" : "customNode" This should be fixed.
    4. "edges" : An array having id, source, target, label, and type should be customEdge always.
    4. Ensure all services and files from the input JSON are included.
    5. The output should be in the form of a dictionary containing a "nodes" and "edges" array.
    6. Present only the code inside delimiters "```reactflow [reactflow CODE]```" without any additional explanation.
    """

    system_prompt:str = """
    <Task>
      You are tasked with creating a JSON structure for a ReactFlow diagram based on the given executive summary and the service_class_json. The executive summary contains an overview of the entire project. This JSON includes information about external services and third-party services, along with their associated files. Your output should represent this information as a network of nodes and edges.
    </Task>
    
    <Icons Context>
      $icons_metadata = """ + str(icons_metadata) + """
    </Icons Context>

    <Instructions>
      You are a solution expert, specializing in problem and solution flows. You will be given the solution overview for a project, and your task is to create an interconnected single component of graph which is detailed, and intuitive and self explanatory for:

      Follow these guidelines:
      1. Create nodes for each unique service (both external and third-party).
      2. Do not create any group nodes.
      4. In the data key for each service node, include two additional fields called group and subgroup. The group field should contain the logical group name (e.g., Frontend, Backend, Databases, etc..), and the subgroup field should provide more specific categorization (e.g., Frameworks, NoSQL Databases, etc..). For example, for a service node representing React, the group would be Frontend and the subgroup would be Frameworks.
      5. For each node, check which icon will be the most suitable from the $icons_metadata in the <Icons Context>
      6. Ensure all information from the input is represented in the output.
      7. The position coordinates must be proper for all the nodes.
    </Instructions>

    <Rules>
      **Ensure all nodes in the generated graph are interconnected such that every node has at least one edge, forming a single connected component without any isolated or disjoint sections. (High Priority Requirement)**
      Important Rules to be followed:
      1. Give detailed technical architecture flow and the JSON object following the below output format.
      2. Make sure that the flow and order of new solution approach is explained well in the graph with appropriate edges. Use as many edges you want to describe the data and user flow properly.
      3. The whole user and data flow should be clear.
      4. Do not add unnecessary nodes and edges. Do not create duplicate nodes that perform same task.
      5. Make the Node descriptions detailed, breaking tasks into multiple sub-tasks if needed.
      6. Ensure your edges show the actual flow, and not just connections of what's related. The connections are meant to show the logical flow, and not the relatedness/similarity.
      7. The group name is meant to classify clusters of nodes within each graph. For instance, if we have multiple nodes in features, they would all have "feature" as group. In Architecture Flow, the "Group" should show the layer each node is in, for instance "Backend Layer", "Database Layer" etc.
      9. for a hierarchy of nodes A -> B -> C; ensure that there is not a connection between A -> C.
    </Rules>
    
    <output_format>
    The output should be in between the delimeters ```reactflow and ```. Only provide the json output. Don't give unnecesary explanation.
    ```reactflow
    {
      "nodes": [
        { 
          "id": "unique_node_identifier_string",
          "data" : {
            "label": "name_of_the_service",
            "description": "description of the service",
            "associated_files": ["file_path_1", "file_path_2", "file_path_3", etc.],  // (default: ["No File Available"] if not present)
            "group": "name_of_group",  // Add the logical group name (e.g., "Frontend", "Backend", etc..)
            "subgroup": "name_of_subgroup",  // Add a more specific subgroup name (e.g., "Frameworks", "NoSQL Databases", etc..)
            "service": "filename" //taken from the $icons_metadata,
          }
          "position":{ "x": "Xcoordinate", "y": "Ycoordinate" },
          "type" : "customNode" //this is hardcoded and will be constant
        }
      ],
      "edges": [
        {
          "id": "unique_egde_identifier_string",
          "source": "label A",
          "target": "label B",
          "label": "Showcase what comes from the source node, to the target node. Be concise and specific with labels, such as 'Ingested Data', 'Converted Text', 'User Query' etc. Use at max 5 words",
          "type" : "customEdge" //this is hardcoded and will be constant
        }
      ]
    }```
    </output_format>
    """
    return system_prompt, user_prompt
  

def erd_generation(services_data, icons_metadata):
  tables_metadata = []
  for entry in services_data:
      table_name = entry["table_name"]
      ddl = entry["ddl"]
      columns, primary_keys, foreign_keys = parse_ddl(ddl)
      tables_metadata.append({
          "table_name": table_name,
          "columns": columns,
          "primary_keys": primary_keys,
          "foreign_keys": foreign_keys
      })

  dot = generate_combined_graph(tables_metadata)

  system_prompt:str = """
    You are tasked with creating a JSON structure for a ReactFlow diagram based on the given database ER diagram and schema JSON. This JSON includes information about database columns and their relationships.Your output should represent this information as a network of nodes and edges.
    </Task>
    
    <Icons Context>
      $icons_metadata = """ + str(icons_metadata) + """
    </Icons Context>

    <Instructions>
      You are a solution expert, specializing in problem and solution flows. You will be given the database schema information of a database, and your task is to create an interconnected single component of graph which is detailed, and intuitive and self explanatory for:

      Follow these guidelines:
      1. Create nodes for each unique service (both external and third-party).
      2. Do not create any group nodes.
      4. In the data key for each service node, include two additional fields called group and subgroup. The group field should contain the logical group name (e.g.,Databases, etc..), and the subgroup field should provide more specific categorization (e.g., 'Transactional Tables', 'Reference Tables' etc..). For example, for a service node representing daily transactions, the group would be Database and the subgroup would be Transactional Tables.
      5. For each node, check which icon will be the most suitable from the $icons_metadata in the <Icons Context>
      6. Ensure all information from the input is represented in the output.
      7. The position coordinates must be proper for all the nodes.
    </Instructions>

    <Rules>
      Important Rules to be followed:
      1. Give detailed technical architecture flow and the JSON object following the below output format.
      2. Make sure that the flow and order of new solution approach is explained well in the graph with appropriate edges. Use as many edges you want to describe the data and user flow properly.
      3. The whole user and data flow should be clear.
      4. Do not add unnecessary nodes and edges. Do not create duplicate nodes that perform same task.
      5. Make the Node descriptions detailed, breaking tasks into multiple sub-tasks if needed.
      6. Ensure your edges show the actual flow, and not just connections of what's related. The connections are meant to show the logical flow, and not the relatedness/similarity.
      7. The group name is meant to classify clusters of nodes within each graph. For instance, if we have multiple nodes in features, they would all have "feature" as group. In Architecture Flow, the "Group" should show the layer each node is in, for instance "Database Layer" etc.
      9. for a hierarchy of nodes A -> B -> C; ensure that there is not a connection between A -> C.
    </Rules>
    
    <output_format>
    The output should be in between the delimeters ```reactflow and ```. Only provide the json output. Don't give unnecesary explanation.
    ```reactflow
    {
      "nodes": [
        { 
          "id": "unique_node_identifier_string",
          "data" : {
            "label": "name_of_the_table",
            "description": "description of the table",
  	    "columns": ["order_id [PK]", "product_sku [PK]", "quantity", "unit_price"]
            "group": "name_of_group",  // Add the logical group name (e.g., "Database", etc..)
            "subgroup": "name_of_subgroup",  // Add a more specific subgroup name (e.g., 'Transactional Tables', 'Reference Tables', etc..)
            "service": "filename" //taken from the $icons_metadata,
          }
          "position":{ "x": "Xcoordinate", "y": "Ycoordinate" },
          "type" : "customNode" //this is hardcoded and will be constant
        }
      ],
      "edges": [
        {
          "id": "unique_egde_identifier_string",
          "source": "label A",
          "target": "label B",
          "label": "Showcase what comes from the source node, to the target node. Be concise and specific with labels, such as 'Ingested Data', 'Converted Text', 'User Query' etc. Use at max 5 words",
          "type" : "customEdge" //this is hardcoded and will be constant
        }
      ]
    }```
    </output_format>
    """
    
  user_prompt:str = f"""
    <Input>
    $database_tables = {dot}
    $icons_metadata
    </Input>

    <Role>
    You are an expert at understanding database architecture based on ER diagrams and relational structures. Create a JSON structure for a ReactFlow diagram based on the given database schema.
    </Role>
    <Output Structure>
      1. Create a JSON object with a "nodes" and "edges" array.
      2. Create nodes for each table in the schema.
      3. "nodes": An array containing all node objects.
      - "id": A unique string identifier for the node.
      - "data":  
        - "label": The name of the table.
        - "description": A brief summary of the table's role or content.
        - "columns": List of column names (mark primary keys with [PK], foreign keys with [FK]).
        - "group": The logical group name (e.g., 'Database').
        - "subgroup": The specific subgroup within the group (e.g., 'Transactional Tables', 'Reference Tables').
        - "service": The appropriate filename of the icon based on the $icons_metadata.
      - "position" : The x and y coordinates of the node.
      - "type" : "customNode" This should be fixed.
      4. "edges" : An array having id, source, target, label, and type should be customEdge always.
      5. The label of the edge should describe the relationship, like "order_id â†’ order_id". 
      6. The output should be in the form of a dictionary containing a "nodes" and "edges" array.
      7. Present only the code inside delimiters "```reactflow [reactflow CODE]```" without any additional explanation.
    """
    
  return system_prompt, user_prompt
    

def feature_summary_generation(formatted_data, user_mvf, executive_summary):
    # if input_type is None:
    #     formatted_data = file_summary_list
    # elif input_type == "batch_summary":
    #     formatted_data = format_batchwise_summary_metadata_for_services(file_summary_list)
    # else:
    #     formatted_data = format_file_summaries(file_summary_list)

    user_prompt = """
    Role: You are an AI code analyst specializing in creating concise, feature-level summaries of codebases.

    Objective: Provide a comprehensive yet concise feature-level summary of a given codebase, highlighting key components, functionality, and the project's overall workflow.

    Input: You will receive information about a codebase, which may include an executive summary or other project details.

    Steps:
    1. Analyze the provided codebase information.
    2. Identify the main features (maximum 5) of the project from the executive summary (if provided in same order)
    3. Create a summary following the specified format, including:
        a. An overview of the project
        b. A list of key features with brief descriptions
        c. A closure statement
    4. Self-evaluate the generated summary and assign a confidence score.
    5. Format the output as specified in the instructions.

    Output Format:
    ```json
    {
        "data": "generated_summary in string format adhering to the Detailed Instructions for Output Format",
        "confidence_score": 90
    }
    ```

    Detailed Instructions for Output Format:

    **Overview**
    <empty line>
    < 
        Summarize all features in 2-3 sentences, introducing the project and its purpose.
        Provide a 2-3 sentence summary of key benefits, highlighting core architecture and value proposition.
    >
    <empty line>
    **Key Features**
    <empty line>
    <   
        List a maximum of 5 main features.
        For each feature, provide up to 2 sub-points describing its functionality.
        Ensure clear explanation of how features interact and contribute to the project's goals.
        1. ***<Key Feature Title>*** : 
        * <Sub point 1 description>
        * <Sub point 2 description>
        <empty line>
    >
    <empty line>
    < 
        Summarize the overall impact and value proposition of the project in one sentence as a conclusion statement.
    >
    <empty line>
    
    -> Self-Evaluation:
        - Score the summary out of 100 based on clarity, precision, detail, knowledge, accuracy, technical correctness, and understanding of the data.

    -> Formatting Requirements:
        - Replace all newline characters (\n) with \\n in the JSON output.
        - Ensure the complete JSON is less than 7500 tokens.
        - Start the output with "```json" and end with "```".
        - If an executive summary is provided, use only the highlighted features from it.

    Example Output Structure:
    ```json
    {
        "data": "**Overview**\\n\\n[Project overview]\\n\\n[Benefits summary]\\n\\n**Key Features**\\n\\n1. *Feature 1*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n2. *Feature 2*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n[...continue for up to 5 features...]\\n\\n[Closure statement]",
        "confidence_score": 90
    }
    ```

    Remember: Adhere strictly to the output format and instructions to maintain consistency and accuracy in your summary.
    """

    user_prompt += "User Defined Features : " + str(user_mvf)

    system_prompt = f"""
        <role>
        You are an assistant to a Senior Software Engineer. You are very capable in reading and understanding huge codebases.
        There is no edge-case, no mistake, no functionality no matter how small goes unnoticed by you.
        You will be given a large codebase and be asked queries regarding it.
        </role>

        <Task>
        You will be given relevant files from a production codebase. The Senior Engineer will consult you to clear his doubts and ask for critical code-level and functionality level analysis of the same.
        <Important>
        1. You will be clear. Feel free to be descriptive but Avoid Jargon
        2. You shall perform critical analysis on the code before responding.
        3. Note that the codebase will be quite complex and have dependencies everywhere, be mindful of them all.
        4. Enclose code in (triple backticks)``` code ```
        </Important>
        </Task>

        Files from Codebase goes here :
        <Repo Structure>
        {formatted_data}
        </Repo Structure>
    """

    start_index = executive_summary.find("Highlighted Features")
    end_index = executive_summary.find("Key Benefits")

    if start_index != -1 and end_index != -1:
        executive_summary = executive_summary[start_index:end_index].strip()

    user_prompt += "Executive Summary : " + str(executive_summary)

    return system_prompt, user_prompt

def feature_summary_generation_db(formatted_data, user_mvf, executive_summary):
    # if input_type is None:
    #     formatted_data = file_summary_list
    # elif input_type == "batch_summary":
    #     formatted_data = format_batchwise_summary_metadata_for_services(file_summary_list)
    # else:
    #     formatted_data = format_file_summaries(file_summary_list)

    user_prompt = """
    Role: You are an AI Database Analyst specializing in creating concise, feature-level summaries of complex database schemas and architectures.

    Objective: Provide a comprehensive yet concise feature-level summary of a given database schema information, highlighting key components, entities, relationships, and the overall data architecture workflow.

    Input: You will receive information about a database design, which may include an executive summary or other schema-level details.

    Steps:
    1. Analyze the provided database schema information.
    2. Identify the main features (maximum 5) of the database from the executive summary (if provided in same order)
    3. Create a summary following the specified format, including:
        a. An overview of the database
        b. A list of key features with brief descriptions
        c. A closure statement
    4. Self-evaluate the generated summary and assign a confidence score.
    5. Format the output as specified in the instructions.

    Output Format:
    ```json
    {
        "data": "generated_summary in string format adhering to the Detailed Instructions for Output Format",
        "confidence_score": 90
    }
    ```

    Detailed Instructions for Output Format:

    **Overview**
    <empty line>
    < 
        Summarize all features in 2-3 sentences, introducing the database and its purpose.
        Provide a 2-3 sentence summary of key benefits, highlighting schema structure, normalization or denormalization logic, and value proposition in handling data.
    >
    <empty line>
    **Key Features**
    <empty line>
    <   
        List a maximum of 5 main features.
        For each feature, provide up to 2 sub-points describing its data handling, relationships, or optimization logic.
        Ensure clear explanation of how features contribute to performance, consistency, and data integrity.
        1. ***<Key Feature Title>*** : 
        * <Sub point 1 description>
        * <Sub point 2 description>
        <empty line>
    >
    <empty line>
    < 
        Summarize the overall impact and value proposition of the database in one sentence as a conclusion statement.
    >
    <empty line>
    
    -> Self-Evaluation:
        - Score the summary out of 100 based on clarity, precision, detail, knowledge, accuracy, technical correctness, and understanding of the schema information.

    -> Formatting Requirements:
        - Replace all newline characters (\n) with \\n in the JSON output.
        - Ensure the complete JSON is less than 7500 tokens.
        - Start the output with "```json" and end with "```".
        - If an executive summary is provided, use only the highlighted features from it.

    Example Output Structure:
    ```json
    {
        "data": "**Overview**\\n\\n[Database overview]\\n\\n[Benefits summary]\\n\\n**Key Features**\\n\\n1. *Feature 1*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n2. *Feature 2*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n[...continue for up to 5 features...]\\n\\n[Closure statement]",
        "confidence_score": 90
    }
    ```

    Remember: Adhere strictly to the output format and instructions to maintain consistency and accuracy in your summary.
    """

    user_prompt += "User Defined Features : " + str(user_mvf)

    system_prompt = f"""
        <role>
        You are an assistant to a Senior Data Architect. You are very capable in reading, analyzing, and understanding complex database schemas and data models.
        No entity, constraint, relationship, or optimization logic goes unnoticed by you.
        You will be given a comprehensive database structure or schema information and will be asked to analyze, explain, and summarize it at a structural and functional level.
        </role>

        <Task>
        You will be given relevant database schema files or DDL definitions. The Senior Data Architect will consult you to clear doubts and ask for critical schema-level and data model-level analysis.
        <Important>
        1. You will be clear. Feel free to be descriptive but Avoid Jargon
        2. Perform a critical and deep analysis of the schema and the information given before responding.
        3. The schema will often involve multiple tables, foreign keys, views, procedures, and indexing strategies â€” be mindful of their dependencies and relationships.
        4. Enclose code or schema in (triple backticks)``` code ```
        </Important>
        </Task>

        Files from Database schema goes here :
        <Database Structure>
        {formatted_data}
        </Database Structure>
    """

    start_index = executive_summary.find("Highlighted Features")
    end_index = executive_summary.find("Key Benefits")

    if start_index != -1 and end_index != -1:
        executive_summary = executive_summary[start_index:end_index].strip()

    user_prompt += "Executive Summary : " + str(executive_summary)

    return system_prompt, user_prompt


#FEATURE HIERARCHY:
generate_features_system_prompt = """
  <Role>
    You are a Software Architect with expertise in analyzing large summaries from code files of an application. 
    You can comprehend summaries from code files that are complex, production-grade and are written in various programming languages to generate most important features, their description and the subfeatures with their description belonging to the most important features along with the other relevant information requested below.
    
    You will follow 2 Events before responding : 
    1. Generation of Feature Hierarchy as given in "Output_Format".
    2. Critical Evaluation of Every Confidence Score.  
  </Role> 

    <Task 1>
    You are provided with multiple relative file paths and file-wise code summaries from a application codebase.
    1. Analyze the file summaries carefully, leveraging your expertise to deduce the frameworks, functionality, and features.
    2. Perform a critical assessment of the code's functionality and interdependencies before responding.
    3. The codebase is complex and likely contains dependencies across various modules. Be mindful of these.
    4. Analyse every file summary and assign the features and sub-features based on the information provided.
    5. Respond strictly in the structured JSON format provided below.
    6. In each sub-feature's 'file_path' array:
        - Set 'critical: true' ONLY for files that are CORE & NON-REPLACEABLE to the sub-feature's main functionality.
        - Set 'critical: false' for ALL supporting, secondary, or replaceable files  
        - Each sub-feature should have both true and false entries.
        - If unsure, default to false (be EXTREMELY selective with 'true')
        - Make sure each sub-feature atleast have one file as true.

    Explanation of the Output terms:
    Feature - Features are most valuable and high level features extracted from the list of summaries that are provided to you. 
    Feature description - Description of the features explaining the high level value and impact that it creates for the project. Define the Feature. The description should be crisp, precise, well formatted and must be between 2-3 lines.
    Subfeature - Subfeatures are micro most valuable features that are extracted from the list of summaries and belong to the Most related and similar Features.
    Subfeature description - Description of the subfeatures explaining the specific value, technical and non-technical functionalites that it provided to the project. Define the subfeature and also explain how its related to the feature. The description should be crisp, precise, well formatted and must be between 2-3 lines.
    
    Points to Remember:
    1. Do not extract any feature or subfeature where there are no reference/citations from the application summaries.
    2. The description must be precise, valuable, well-formatted and must be between 2-3 lines.
    3. The Feature titles should be precise, specific, self explanaible, independent and not have similar feature titles. The Feature titles should not be highly generalized.
    4. The SubFeatures titles should be precise, self explanaible and not have similar subfeature titles. The SubFeature titles should not be highly generalized.
    5. SubFeatures should not be very low level that it explains code functions, code process like 'Json handling', 'Reading csv', readME etc.
    6. If similar subfeatures are present, then group them under one common Feature itself. Do not create multuple Features for similar subfeatures.
    6. If Unit testing related summaries are found, then create that as another Feature named 'Unit Testing' and assign the specific testing subfeatures under this feature.
    </Task 1>

  <Task 2>
  You shall now Assign and Justify Confidence Scores for each feature.

  <Critical Evaluation of Confidence Scores> 

  <Evaluation MODE>
  - You will now Forget everything that was done beforehand and act as an unbiased judge.
  - $Project-Summaries-&-Paths (INPUT).
  </Evaluation MODE>
  <Important>
  Critically analyze every "Feature" and "SubFeature" based on the following metrics. 
  You shall generate a confidence score between 0-100 for each of the following :
  1. Is the "Feature" & "SubFeature" name accurate to its functionality ? (Accuracy)
  2. Does the "Feature" & "SubFeature" include files with an unrelated function ? (Feature Dilution Rate)
  3. Important : Does this "Feature" & "SubFeature" make sense given the Overall Purpose of the Application ? (Consistency)
  4. Are all the files in "Feature" & "SubFeature" included ? (Completeness)

  <Strict>
  1. You will now generate a list of 4 confidence scores between 0-100 for above criteria under "confidence_score" key.
  2. Based on above criteria, you shall provide a VERY BRIEF logical explanation (10-20 words) for Confidence Score under "confidence_score_justification" key.
  3. Make sure to mention the entire filepath without omitting the prefix.
  4. Make sure all the filepaths are present.
  <Important> STRICTLY Don't Comment on Missing Files. Don't Overestimate. Don't Underestimate.</Important> 
  </Strict>

  </Important>

  </Critical Evaluation of Confidence Scores> 
  </Step 2>


      <Output_Format>
    Return a response in JSON format. Do not include any extra information or explanations. Strictly DON'T deviate from mentioned KEYS.
    Example:
```json
[
  {
    "name": "User Authentication and Management",
    "feature_description": "Comprehensive user account system with secure login, registration, profile management, and role-based access control.",
    "feature_description_confidence_score": [95, 70, 100, 70],
    "sub_features": [
      {
        "name": "User Registration",
        "description": "Allows new users to create accounts by providing necessary information such as username, email, and password. Implements email verification, password strength checks, and duplicate account prevention. Stores user data securely in the database with password hashing.",
        "file_path": [
          {
            "module_name": "RegistrationController",
            "path": "Controllers/Account/RegistrationController.cs",
            "critical": true
          },
          {
            "module_name": "RegisterView",
            "path": "Views/Account/Register.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [75, 80, 85, 65],
        "sub_feature_confidence_score_justification": "No feature dilution, might have missed some file."
      },
      {
        "name": "User Login",
        "description": "Authenticates users using their credentials, creates and manages user sessions, and implements security measures such as login attempt limiting and two-factor authentication (2FA). Provides password reset functionality for forgotten passwords.",
        "file_path": [
          {
            "module_name": "LoginController",
            "path": "Controllers/Account/LoginController.cs",
            "critical": true
          },
          {
            "module_name": "LoginView",
            "path": "Views/Account/Login.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [80, 100, 80, 75],
        "sub_feature_confidence_score_justification": "High chance of missing files."
      }
    ],
    "feature_confidence_score_justification": "No feature dilution, duplication or missing files. Accurate Naming."
  },
  {
    "name": "Product Catalog Management",
    "feature_description": "Comprehensive system for managing product listings, categories, and inventory across the e-commerce platform.",
    "feature_description_confidence_score": [95, 65, 70, 80],
    "sub_features": [
      {
        "name": "Product CRUD Operations",
        "description": "Enables administrators to create, read, update, and delete product listings. Includes functionality for managing product details such as name, description, price, images, and inventory levels. Implements validation to ensure data integrity and consistency across the product catalog.",
        "file_path": [
          {
            "module_name": "ProductController",
            "path": "Controllers/ProductController.cs",
            "critical": true
          },
          {
            "module_name": "ProductView",
            "path": "Views/Product/Index.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [90, 85, 100, 70],
        "sub_feature_confidence_score_justification": "High confidence with no duplication or dilution."
      },
      {
        "name": "Category Management",
        "description": "Allows for the creation and management of product categories and subcategories. Implements a hierarchical structure for organizing products, enabling efficient navigation and filtering of the product catalog for both administrators and customers.",
        "file_path": [
          {
            "module_name": "CategoryController",
            "path": "Controllers/CategoryController.cs",
            "critical": true
          },
          {
            "module_name": "CategoryView",
            "path": "Views/Category/Index.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [85, 75, 90, 95],
        "sub_feature_confidence_score_justification": "High confidence without any duplication or dilution."
      }
    ],
    "feature_confidence_score_justification": "All files refer to single overall functionality. Might have missed some files."
  }
]
```
  </Output_Format>

"""

generate_features_user_message = """
<Strictly Remember>
1. As input you will be given a batch of `file_path` and `file_summary` from a production codebase. Keep it in mind that it could be a file from a very large repository with lot of inter-dependencies.
2. Understand all the file description first, then try to determine the feature, sub-features and their description. For **each file** it should have a feature or sub-features whenever the conditions are met.
3. The response should contain all the fields given in the example output format. The response should be strictly in json format.
4. The description of features/subfeatures must be in the length of 2-3 lines. The response should be structured and well-formatted.
5. Don't generate any additional explanation or description. Provide the structured response in json only.
</Strictly Remember>
  
<Input file wise summary>
{file_summary}
</Input file wise summary>
<Response>
"""

merge_features_in_hierarchy_user_prompt = """You are a software feature analyzer. Given a list of related features that have been clustered together, create a merged feature that encompasses all the functionality.

Features to merge:
{feature_list}

Generate a JSON response that includes:
1. A name for the merged feature representing accurate feature name. Do not mention its merged or unified or anything as such. The feature name should accurately represent a major funcationality of a repository.
2. A detailed description that covers all functionality
3. A confidence score (0-100) for the merge
4. A justification for the confidence score

Respond with a JSON object in the following format:
```json
{{
    "name": "Merged feature name",
    "description": "Comprehensive description",
    "confidence_score": 85,
    "confidence_justification": "Reason for the confidence score"
}}
```
Give only JSON and nothing else. Do not include any explanations or additional text outside the JSON block. Make sure to start with ```json and end with ``` only.
"""

mapping_names_for_merged_features_user_prompt = """  <Role>
    You are a smart AI cassistant with strong expertise in Software Engineering. You can understand complex, production-grade codebases written in various programming languages and summarize them effectively.
  </Role>
  <Task>
  You will be given a brief description of  features of a large codebase and your task is to generate a relevant feature name, brief description, and priority level.
  <Important>
   1. The feature name should be brief, relevant and should represent the entire description provided.
   2. Generate a relevant description which is basically a overall summary of the description provided.
   3. Assign a priority level (high, medium, low) based on the significance, importance and complexity of the feature to the overall system. 
  </important>
  </Task>
  <Example output>
  ```json
    {
        "name": <feature_name>, //string
        "feature_description": <feature_description>, //string
        "priority": <priority> //string (high, medium, or low)
    }
    ```
  </Example output>
  <Strictly Remember>
1. The feature name should be relevant and at the same time interpretable, easy to understand.
2. The feature description should represnt the entire description given for summarisation, it should be simple and easy to understant.
3. The priority should be one of: high, medium, or low.
4. The response should be strictly in json format specified above.
5. Strictly make sure Feature Description is not more than 200 words.
  </Strictly Remember>

<code summary>
The code summary is given below:
"""


reducing_sub_features_user_prompt = """
    You are a software feature consolidation expert. Your task is to merge similar sub-features into one comprehensive sub-feature.

    Here are the sub-features that need to be merged:
    {sub_features_list}

    For each sub-feature, we have:
    - Name: The sub-feature name
    - Description: The sub-feature description (if available)
    - Confidence Score: The confidence score (if available)

    Your output should be a JSON object containing:
    1. A unified sub-feature name that encompasses all the input sub-features
    2. A comprehensive description that covers all aspects of the input sub-features
    3. A confidence score (use the highest available from input sub-features)
    4. A justification for the confidence score

    Return the output in JSON format starting with ```json and ending with ```.

    Example output format:
    ```json
    {{
        "name": "Unified Sub-Feature Name",
        "description": "Comprehensive description covering all aspects",
        "sub_feature_confidence_score": 95,
        "sub_feature_confidence_score_justification": "Merged from similar sub-features with high semantic similarity"
    }}
    ```
    """


post_processing_feature_name_description_system_prompt="""
  <Role>
    You are a smart AI assistant with strong expertise in Software Engineering. You can understand complex, production-grade codebases written in various programming languages and summarize them effectively.
  </Role>
  <Task>
  You will be given a brief description of modules or features of a large codebase and your task is to generate a relevant feature name and brief description.
  <Important>
   1. The feature name should be brief, relevant and should represent the entire description provided.
   2. Generate a relevant description which is basically a overall summary of the description provided.
   3. Also generate a confidence score in a scale of 0 - 100.
  </important>
  </Task>
  <Example output>
  ```json
    {
        "name": <feature_name>,
        "feature_description_confidence_score": <score 0 - 100>,
        "feature_description": <feature_description>
    }```
  </Example output>"""

post_processing_feature_name_description_user_prompt = """<Strictly Remember>
1. The feature name should be relevant and at the same time interpretable, easy to understant.
2. The confidence score should represent the ability to summarise the description.
3. The feature description should represnt the entire description given for summarisation, it should be simple and easy to understant.
4. The response should be strictly in json format specified above.
</Strictly Remember>
<code summary>
The code summary is given below: \n
{feature_description}
</code_summary>
<response>
Your response in json goes here:
"""

merge_similar_features_system_prompt = """You are a solution architect. Your task is to carefully review each feature and its description, and combine them into a single high-level feature.

The final high-level features should represent what an end user would perceive, e.g., Messenger, Google Chat, Messaging, Reels, etc.

Based on the generated features provided, identify which features can be merged into a single high-level feature. 
Strictly output them in the following format:
{{ 
  <High-Level Feature Name 1>: [<Merged Feature 1>, <Merged Feature 2>, <Merged Feature 3>, ...],
  <High-Level Feature Name 2>: [<Merged Feature 1>, <Merged Feature 2>, <Merged Feature 3>, ...],
  ...
}}

INPUT:
Feature names and descriptions are provided in the format: 
[1. Feature name: <feature name> 
Feature description: <feature description>, 
2. ...]

{feature_texts}

MVFS:
{total_MVFs}

Points to remember:
1. While merging features and naming high-level features, always prefer names from the user-defined MVFs provided. All relevant features can be grouped under these high-level features.
2. If certain features do not fit under the user-defined MVFs, choose a better name than the existing one for the new high-level feature if necessary.
3. The names of the features being merged must remain exactly as provided in the INPUT section; do not modify them. Do not consider Feature description in Feature Names.
4. Follow the output structure strictly: high-level feature names as dictionary keys and merged features as values in list format.
5. If a feature is already a high-level feature, you do not need to forcibly merge it. If a feature seems to be function-level/low-level  features, merge them into a High-level feature.
6. Merge similar features into a single high-level feature based on their names and descriptions, when applicable. Each final high-level feature should be independent of the others.
7. Do not assign the same feature to multiple high-level features.
8. If user-defined MVFs are empty, skip point 1 and begin with point 2.
9. Do **not** include any Feature descriptions in the final output."""


merging_description_user_prompt = """You are a Solution Architect. Your task is to summarize the multiple feature descriptions provided into a brief, coherent summary of **no more than two sentences**.

  The summary must:
  - Accurately capture all key components from the provided descriptions.
  - Align clearly with the given high-level feature name.
  - Serve as the final description of the high-level feature.

  Only the final summarized description should be included in the output â€” no additional commentary or formatting.

  INPUT:
  Multiple descriptions: {merging_feature_description}

  High-Level Feature Name: {high_level_feature}
  """


micro_sub_feature_prompt = """You are an expert system analyst specializing in decomposing SubFeatures into granular, logically independent components. You support **two levels** of splitting:

1. **Horizontal splitting**: Split a subfeature into multiple *same-level subfeatures* when it encompasses multiple independently meaningful functionalities. The subfeatures created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.
2. **Vertical splitting**: Further break each of those subfeatures into *microsubfeatures* (if applicable), ensuring each micro-sub-features/micro-user-story describes a single goal or operation. The micro-sub-features/micro-user-story created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.

---

### ðŸ”§ TASK OVERVIEW

Given a Macro-Feature, Subfeature, its description, associated module files and its summary:

- Decide if the subfeature should be split horizontally into multiple same-level subfeatures.
- For each resulting subfeature (or original if not split), analyze whether it can be split vertically into **microsubfeatures** (fine-grained user stories).
- Provide the confidence scores for the subfeature that is split, whether horizontally or vertically.
- Provide the files that are related to the sub_features too, not just the micro_sub_features.
- Each leaf user-story must have files assigned to them, else you should not create/split these subfeatures.
- Provide description of generated subfeature/sub-user-stories in 2-4 lines but only valid information. Do not assume or hallucinate to generate description.
Apply this recursively: if horizontal splitting occurs, then attempt vertical splitting for each. But remember, not to create any duplicates in the process. 

---

### SPLITTING DECISIONS

#### Horizontal Splitting (Same-level Subfeatures):
Split if:
- The subfeature covers multiple high-level functionalities
- Each function could be planned, developed, and deployed independently
- Each component has a clear boundary and responsibility

#### Vertical Splitting (Microsubfeatures):
Split further if:
- A subfeature contains multiple independent operations or logical stages
- These operations can be implemented, tested, or tracked separately
- Each micro-subfeature represents one atomic, non-overlapping functionality

---

### DO NOT SPLIT IF:
- sub-user-stories are tightly coupled in the Subfeature and cannot function independently.
- Do not split subfeatures into sub-user-stories that are hardly single line of code and cannot be considered as a proper functionality, but just a config/parameter.
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across actions are too complex to isolate.
- There are no files that can be mapped to the generated user-story.
- Do not split if the user-story is barely a functionality. The split user-stories must have independent functionality that contributes to the subfeature and feature and if not, do not split.
- Don not split ReadMe & .md files into sub-user-stories.
- Do not split horizontall for granullar subfeatures as they are not user stories but mid level features.
---

### FILE MAPPING RULES:
- For each subfeature or microsubfeature, cite only directly relevant files.
- Use only the provided input data to match files â€” no guessing.
- Avoid duplication unless a file is clearly shared between components.

Each `file_path` entry must include:
```json
{
  "module_name": "<Name>",
  "path": "<Path>",
  "critical": <true/false>,
  "git_url": "<Git URL>"
}

OUTPUT FORMAT
If the subfeature should NOT be split:
Return: "None"

If the subfeature should be split, return a list of Parent User Stories with subfeatures inside.
If a subfeature itself can be further split into microsubfeatures, nest them under micro_sub_features like so:

[
  {
    "name": "Parent User Story Title 1",
    "description": "Full description of the original or updated user story and its purpose.",
    "file_path": [...],
    "sub_feature_confidence_score":"confidence score of the subfeature with respect to the Feature, as a percentage (e.g., 80)"
    "micro_sub_features": [
      {
        "name": "Sub-User Story Title 1",
        "description": "Standalone description of a single functionality.",
        "file_path": [...],
        "micro_sub_feature_confidence_score":"confidence score of the micro_sub_feature with respect to the sub_feature, as a percentage (e.g., 90)"
        }
          ...
        ]
      },
      ...
    ]
  }
]
Each layer must preserve independence, clarity, and singular focus of each story.

VALIDATION CHECKLIST
- Each title must express one functionality only (no imperative phrasing)
- description must avoid assumptions and describe the real function. It must be as detailled as possible.
- Each story must make sense independently and fit in the broader feature flow
- if there are multiple user-story under the subfeature, it needs to be in sequence of business logic.
- File mappings must be relevant and scoped accurately
- Do no miss/skip any values in the output json. The output structure must be maintained strictly.
- All subfeature and sub-user-story names and descriptions must be strictly in a declarative tone, not imperative.

* Use generic or speculative statements
"""


db_micro_sub_feature_prompt = """
<Role>
You are an expert Database analyst specializing in decomposing SubFeatures into granular, logically independent components. You support **two levels** of splitting:
You shall ALWAYS process features from a Database perspective ONLY. 
There can be more than one Table in the DB context provided to you.
</Role>

1. **Horizontal splitting**: Split a subfeature into multiple *same-level subfeatures* when it encompasses multiple independently meaningful functionalities. The subfeatures created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.
2. **Vertical splitting**: Further break each of those subfeatures into *microsubfeatures* (if applicable), ensuring each micro-sub-features/micro-user-story describes a single goal or operation. The micro-sub-features/micro-user-story created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.

<Strict Constraints> 
- You are dealing with Database Information. 
- No matter what, STRICTLY use Database-Specific Language ALWAYS. 
- Use words like Columns / Fields / Schema / DataTypes / Constraints / Foreign Keys / Primary Keys etc.
- Strictly Do not start descriptions with or start with "this micro-feature" / or "this sub-feature".
- You shall do this regardless of the input context and nature.
Remember : Every "FILE" given to you is information of a table. Therefore in your response, ALWAYS refer to "Table" instead of "File".

</Strict Constraints> 


### ðŸ”§ TASK OVERVIEW

Given a Macro-Feature, Subfeature, its description, associated module files and its summary:

- Decide if the subfeature should be split horizontally into multiple same-level subfeatures.
- For each resulting subfeature (or original if not split), analyze whether it can be split vertically into **microsubfeatures** (fine-grained user stories).
- Provide the confidence scores for the subfeature that is split, whether horizontally or vertically.
- Provide the files that are related to the sub_features too, not just the micro_sub_features.
- Each leaf user-story must have files assigned to them, else you should not create/split these subfeatures.
- Provide description of generated subfeature/sub-user-stories in 2-4 lines but only valid information. Do not assume or hallucinate to generate description.
Apply this recursively: if horizontal splitting occurs, then attempt vertical splitting for each. But remember, not to create any duplicates in the process. 

---

### SPLITTING DECISIONS

#### Horizontal Splitting (Same-level Subfeatures):
Split if:
- The subfeature covers ONE / MORE THAN ONE high-level functionalities
- Each function could be planned and developed independently
- Each component has some clear boundaries and responsibilities

#### Vertical Splitting (Microsubfeatures):
Split further if:
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across actions are too complex to isolate.
- There are no tables that can be mapped to the generated user-story.
- The subfeature is too complex to be planned, developed, and deployed independently
- Each micro-subfeature represents one atomic, non-overlapping functionality
Note: Maintain at least 2 subfeatures unless the database has only one table.
- Prioritize brevity, consistency and no informaiton leakage across subfeatures.
- Ensure crisp segregation.
---

### DO NOT SPLIT IF:
- sub-user-stories are tightly coupled in the Subfeature and cannot function independently.
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across tables in two features are too complex to isolate.
- There are no tables that can be mapped to the generated user-story.
Note: Maintain at least 2 subfeatures and 1 or more microsubfeatures per subfeature, Unless the database has only one table.
Note : Maintain brevity during splitting at the same level. Do NOT overload the a single feature with too many subfeatures.
---


### FILE MAPPING RULES:
- For each subfeature or microsubfeature, cite only directly relevant tables.
- Use only the provided input data to match files â€” no guessing.
- Avoid duplication unless a file is clearly shared between components.

Each `file_path` entry must include:
```json
{
  "module_name": "<Name>",
  "path": "<Path>",
  "critical": <true/false>,
  "git_url": "<Git URL>"
}

OUTPUT FORMAT
If the subfeature should NOT be split:
Return: "None"

If the subfeature should be split, return a list of Parent User Stories with subfeatures inside.
If a subfeature itself can be further split into microsubfeatures, nest them under micro_sub_features like so:

[
  {
    "name": "Parent User Story Title 1",
    "description": "Full description of the original or updated user story and its purpose.",
    "file_path": [...],
    "sub_feature_confidence_score":"confidence score of the subfeature with respect to the Feature, as a percentage (e.g., 80)"
    "micro_sub_features": [
      {
        "name": "Sub-User Story Title 1",
        "description": "Standalone description of a single functionality.",
        "file_path": [...],
        "micro_sub_feature_confidence_score":"confidence score of the micro_sub_feature with respect to the sub_feature, as a percentage (e.g., 90)"
        }
          ...
        ]
      },
      ...
    ]
  }
]
Each layer must preserve independence, clarity, and singular focus of each story.

VALIDATION CHECKLIST
- Each title must express one functionality only (no imperative phrasing)
- description must avoid assumptions and describe the real function. It must be as detailled as possible.
- Each story must make sense independently and fit in the broader feature flow
- if there are multiple user-story under the subfeature, it needs to be in sequence of business logic.
- File mappings must be relevant and scoped accurately
- Do no miss/skip any values in the output json. The output structure must be maintained strictly.
- All subfeature and sub-user-story names and descriptions must be strictly in a declarative tone, not imperative.
- Use Database-specific schema only. Do not include words like "Attributes" / "Code Files" in your response. 
- Strictly Do not start descriptions with or start with "this micro-feature" / or "this sub-feature".
* Use generic or speculative statements

"""import os
from graphviz import Digraph
import re 
import json

def parse_ddl(ddl: str):
    """
    Parse the DDL to extract columns, primary keys, and foreign keys.
    """
    lines = ddl.splitlines()
    column_lines = []

    for line in lines:
        line = line.strip()
        if (
            line.upper().startswith("CREATE")
            or line.upper().startswith("PRIMARY")
            or line.upper().startswith("FOREIGN")
            or line.upper().startswith(")")
            or line == ""
        ):
            continue

        match = re.match(r'(\w+)\s+\w+', line)
        if match:
            column_lines.append(match.group(1))

    pk_match = re.search(r'PRIMARY KEY\s*\((.*?)\)', ddl)
    primary_keys = [key.strip() for key in pk_match.group(1).split(",")] if pk_match else []

    foreign_keys = []
    for match in re.finditer(r'FOREIGN KEY\s*\(([^)]+)\)\s+REFERENCES\s+`?[\w]+\.(\w+)`\(([^)]+)\)', ddl):
        fk_col = match.group(1).strip()
        ref_table = match.group(2).strip()
        ref_col = match.group(3).strip()
        foreign_keys.append((fk_col, ref_table, ref_col))

    return column_lines, primary_keys, foreign_keys


def generate_combined_graph(tables_data):
    """
    Generate a single combined graph from multiple tables.
    """
    dot = Digraph(comment='Combined Table Diagram')
    dot.attr(rankdir='LR')

    # Store individual table nodes
    for table in tables_data:
        table_name = table['table_name']
        columns = table['columns']
        primary_keys = table['primary_keys']
        
        label_lines = []
        for col in columns:
            if col in primary_keys:
                label_lines.append(f"{col} [PK]")
            else:
                label_lines.append(col)
        dot.node(table_name, shape='box', label=f'{table_name}\\n' + "\\n".join(label_lines))

    # Add relationships
    for table in tables_data:
        table_name = table['table_name']
        for fk_col, ref_table, ref_col in table['foreign_keys']:
            dot.edge(table_name, ref_table, label=f'{fk_col} â†’ {ref_col}')

    return dot

def folder_summary_generation_prompts(
        total_allocated_tokens, 
        file_list, folder_name, 
        folder_path,
        subfolder_list,
        formatted_file_summaries,
        formatted_file_services,
        formatted_subfolder_summaries,
        formatted_subfolder_services,
        formatted_subfolder_features
    ):
    
    system_prompt = f"""
        You are an expert code analyst specialized in creating detailed, informative summaries of software project folders. Your task is to thoroughly analyze files and subfolders to provide a comprehensive understanding of the application or project and provide combined summaries along with required details. These summaries must be detailled enough for further summarization.

        Follow these guidelines:
        1. Conduct a deep analysis of the features to identify its core purpose and functionality
        2. Provide detailed explanation of key implementations and technical approaches of the features
        3. Thoroughly examine the summaries based on files and folders to understand relationship between features and combined smaller features into larger high level application level features.
        4. Explain the features within the broader project architecture with specific connections
        5. Describe technical patterns, design decisions, and architectural choices evident in the code
        6. Include specific functions, classes, and methods that define the feature's behavior
        7. Note dependencies, imports, and external connections that shape the folder's functionality
        8. Identify potential architectural strengths and areas for improvement when evident
        9. Identify all services represented in this folder based on file and subfolder services information
        10. Identify and articulate high-level features or functionalities represented by the folder into the feature_details section, when consolidating multiple subfolders or lower-level files. Derive these insights from both file-level and subfolder-level summaries. Also under each feature, mention which file/folder was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
        11. Do not miss any features that could be formed based on these summaries as this information is required to understand the application's buisness logic.
        12. Gather insights from the summaries provided to generate a high level detailled executive summary that could be used by business stakeholders to understand the folder/project.
        13. When analyzing the root folder, both the executive summary and the features must be strictly formed in a high level business logic standpoint of an application.
        
        IMPORTANT: 
        - Your summary should be thorough and detailed({total_allocated_tokens}) while maintaining technical/business precision and depth. Focus on providing insights that would help both stakeholders and developers understand the application better.
        - feature_details must contain high level feature name and feature description(value of the files/folders) strictly in concise bullet points. The feature inforamtion must be in detail to capture the complete high level knowledge for that feature but not the function level details. Feature names cannot be programmatic function names like Dependency management, json handling etc. instead it should be inventory management, order processing etc. 
        - Your services list should be comprehensive and include all services represented in this folder.
        - is_reuasble_lib if a folder is used as reusable lib make it True otherwise False
        - lib_name if is_reusable_lib is True then provide the name of the reusable lib/component If is_reusable_lib False then add Not Applicable
        - category if is_reusable_lib is True then provide category only between 'Frontend' and 'Backend' If is_reusable_lib False then add Not Applicable
        - sub_category if is_reusable_lib is True then provide sub category only between 'UI Component','Custom Hooks', 'http_client', 'Utils', 'Others' In Frontend & 'Middleware', 'Error Handling', 'Auth', 'Utils', 'Others' In Backend If is_reusable_lib False then add Not Applicable
        - when_to_use if is_reusable_lib is True then provide where this reusable lib/component can be used If is_reusable_lib False then add Not Applicable 
        - associated_files if is_reusable_lib is True then provide the list of files associated(give complete path for the assosciated file) with this reusable lib/component If is_reusable_lib False then add Not Applicable
        - summary must not be technical and only explain the high level details of the folder/project. Understand the file and folder summaries provided to combine the knowledge to form the executive summary. Make it as detailled as possible.
        - Use clear and concise language, avoiding jargon where possible.
        
        - You must provide your response in this exact format:
        ```summary
        [Your detailled high-level executive summary for the folder for business stakeholders]
        ```
        ```feature_details
        [List of high-level features or functionalities represented in this folder]
        ```
        ```services_namess
        [Comma-separated list of all services represented in this folder]
        ```
        ```is_reuasble_lib
        Boolean Value
        ```
        ```lib_name
        [Name of the reusable library if applicable]
        ```
        ```category
        [Category of the reusable library if applicable]
        ```
        ```sub_category
            [Sub category of the reusable library if applicable]
        ```
        ```when_to_use
        [Your detailed use case where or when this reuasble_lib can be usefull]
        ```
        ```associated_files
            [Comma-separated list of associated files with the reusable library, Give the Complete file path as mentioned in the file list]
        ```
        ```example_usage
            [Example code snippet of how to use this reusable library]
        ```
    """

    user_prompt = f"""
        Generate a summary and services list for the folder: "{folder_name}" (Path: {folder_path})

        FOLDER CONTENTS:
        - Files ({len(file_list)}): {", ".join(file_list) if file_list else "None"}
        - Subfolders ({len(subfolder_list)}): {", ".join(subfolder_list) if subfolder_list else "None"}

        FILE SUMMARIES:
        {os.linesep.join(formatted_file_summaries) if formatted_file_summaries else "No file summaries available"}

        FILE SERVICES:
        {os.linesep.join(formatted_file_services) if formatted_file_services else "No file services available"}

        SUBFOLDER SUMMARIES:
        {os.linesep.join(formatted_subfolder_summaries) if formatted_subfolder_summaries else "No subfolder summaries available"}

        SUBFOLDER SERVICES:
        {os.linesep.join(formatted_subfolder_services) if formatted_subfolder_services else "No subfolder services available"}

        SUBFOLDER FEATURES:
        {os.linesep.join(formatted_subfolder_features) if formatted_subfolder_features else "No subfolder features available"}
        
        Based on these components:
        1. Provide a thorough technical summary explaining the folder's purpose, implementation details, and architectural significance
        2. Compile a comprehensive list of all services represented in this folder based on file and subfolder services information
        
        Follow the exact format specified in the system instructions for your response.
    """

    return system_prompt, user_prompt

def services_generation():
    system_prompt = """
        <Task>
        Create an architectural blueprint of the given repository by identifying and classifying both external services and third-party services with no overlap between categories.
        </Task>

        <Definitions>
        - External services: Company-provided services hosted outside the application (AWS S3, Google Cloud, Stripe, Twilio)
        - Third-party services: Libraries, frameworks, and SDKs that are part of the core application stack (Django, React, MongoDB, Redux)
        </Definitions>

        <Output_Format>
        {
        "external_services": [
            {
            "external_service_name": "string",
            "description": "string",
            "associated_files": ["string"],
            "service_class": "string",
            "used_in_files": ["string"]
            }
        ],
        "thirdparty_services": [
            {
            "thirdparty_service_name": "string",
            "description": "string",
            "associated_files": ["string"],
            "service_class": "string",
            "used_in_files": ["string"]
            }
        ]
        }
        </Output_Format>

        <Instructions>
        1. Conduct a thorough repository analysis to identify all services
        2. Classify each service into exactly ONE category:
        - External services: Cloud platforms, payment processors, authentication providers
        - Third-party services: Frameworks, libraries, SDKs integrated into the codebase
        3. For each service, provide:
        - Name: Exact service name
        - Description: Concise explanation of functionality and purpose
        - Associated files: All files directly importing or using the service
        - Service class: Category (e.g., "cloud storage", "web framework", "database")
        - Used in files: Complete paths of files utilizing the service
        4. Ensure ZERO overlap between categories
        5. Prioritize accuracy over comprehensiveness
        6. Validate that identified services are actively used in the project
        7. Include only services with clear evidence of implementation
        8. Do not create a lot of services which are redundant. Keep it to a maximum of 50 services only.
        </Instructions>

        <Examples>
        Good External Service Entry:
        {
        "external_service_name": "AWS S3",
        "description": "Cloud storage service used for storing user-uploaded files",
        "associated_files": ["src/services/storage.js", "src/config/aws.js"],
        "service_class": "cloud storage",
        "used_in_files": ["src/components/FileUpload.js", "src/pages/UserProfile.js"]
        }

        Good Third-Party Service Entry:
        {
        "thirdparty_service_name": "React",
        "description": "Frontend JavaScript library for building user interfaces",
        "associated_files": ["package.json", "src/index.js"],
        "service_class": "frontend framework",
        "used_in_files": ["src/App.js", "src/components/*.js"]
        }
        </Examples>

        Analyze the repository and provide the complete architectural blueprint in the specified format.
    """

    user_prompt = ""

    return system_prompt, user_prompt

def executive_summary_generation(combined_summary, user_mvf):
    system_prompt = """
    Your Role:
    You are an expert software architect tasked with understanding a codebase and creating an executive summary that clearly articulates the main purpose of this application,
    the core problem that the application is solving, and the prioritized list of the most valuable features, solely based on the provided folder wise summary. Do not hallucinate and create the most valuable features and its description on assumption. This needs to be based on facts.

    Task:
    1. Analyze provided folder wise summary and the services used and the user defined features (if provided).
    2. Understand component interactions and functions.
    3. Prioritize the User Defined Features (if provided) in the summary.
    4. Identify and prioritize the most valuable features based on their importance and relevance to the overall project, as evidenced in the code.
    5. Create a comprehensive executive summary.

    Steps:
    1. Review folder wise summary.
    2. Analyze folder wise summary:
    - Identify key components and their roles
    - Note data operations, design patterns, and architectural decisions
    3. Create summary:
    - Describe the specific problem the codebase solves, based on folder wise summary
    - Explain component interactions
    - Outline data workflow
    4. Identify and prioritize main features:
    - Determine which feature(s) address the core problem of the application, based on code implementation
    - Rank features based on their importance and relevance to solving the main problem, as evidenced in the code
    - The feature should be major components of the codebase and not minor functions like "Modular Architecture" or "Code Reusability", these are not features but design principles.

    Focus Areas:
    - Precised feature prioritization and importance
    - High-level functionality
    - Clear, concise technical language
    - Objective description
    - Capture entire workflow

    Guidelines:
    - Only use the folder wise summary provided
    - Use precise technical terms
    - Include user-defined features if provided and evidenced in the code
    - Prioritize features based on their importance to the core problem, as shown in the folder wise summary

    Feature Identification and Prioritization:
    - Carefully analyze the folder wise summary to identify features actually present in the folder wise summary
    - Do not assume or infer features that are not explicitly mentioned in the folder wise summary
    - Identify the top feature that solves the majority of the problem based on code evidence
    - Rank subsequent features in descending order of importance, ensuring they are present in the folder wise summary
    - Ensure the feature list reflects the codebase's focus and structure
    - Only include features that have substantial implementation in the codebase that is evident from folder wise summary

    Output Format - Adhering to this format is crucial
    ```json
    {
    "data": "generated_summary in string format adhering to the Expected Output Format for Generated Summary",
    "confidence_score": 90,
    "traceback": {
    "Feature 1 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 1 Title' is included, as the 'phrase' is an evidence that this feature is part of the codebase.",
    "Feature 2 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 2 Title' is included, as the 'phrase' is an evidence that this feature is part of the codebase.",
    ...
    }
    }
    ```

    Requirements:
    - Replace \n with \\n in JSON
    - Limit upto 5 main features (max 2 sub-features each) or 7500 tokens
    - If due to any reason such as codebase being small, you are unable to provide 5 features, then provide as many high-level features as possible between the range of 1 to 5.
    - Don't assume features or include minor features due to inability to provide 5 features, lesser number of features is acceptable.
    - Use specified JSON format only
    - Start with "```json" and end with "```"
    - Ensure the top feature in the prioritized list addresses the core problem and is present in the folder wise summary
    - Rank features in descending order of importance to the main problem, based on actual code implementation
    - Do NOT include features that are NOT evidenced in the provided folder wise summary
    - Evaluate the folder wise summary objectively, considering all conclusions on the actual code provided
    - Do NOT make any assumptions about organizational goals or intentions beyond what is explicitly shown in the code
    - Focus solely on the technical aspects and implemented functionality, avoiding speculation about business objectives or future plans
    - Both the keys data, confidence score, and traceback should be present in the output JSON
    - The generated summary should be in string format only and be contained inside the "data" key
    - The "traceback" key should contain a dictionary with feature names as keys and justifications for including these features based on exact phrases from the input
    - Do not include any feature that could potentially be part of the folder wise summary without explicit evidence
    - Every feature mentioned must be driven by clear evidence from the provided input
    """
    user_prompt = """
    Expected Output Format for Generated Summary:

  **Overview**
  <empty line>
  <A brief introduction to the codebase and its main purpose; in paragraph format only, not in points.
  This paragraph should provide a concise yet comprehensive overview of the codebase, its primary functionality, solution provided by the project and its intended use case.
  Aim for 3-5 sentences that capture the essence of the project.>
  <empty line>
  **Highlighted Features**
  <empty line>
  <
  List and briefly explain the key features that are significant components of the codebase and would serve as selling points.
  These features should be presented as follows:
  1. Use numbered points for each feature.
  2. Provide a brief explanation for each feature in 1-2 sentences, highlighting its importance and benefit to the end user.
  3. Focus on features that are central to the codebase's functionality and most important to the end user.
  4. Dont include generic features like "Modular Architecture" or "Code Reusability", these are not features but design principles.
  5. Do not include sub-points under any feature.
  6. Prioritize User Defined Features (if provided) at the beginning of the list.
  7. If User Defined Features are given, list them first before including any features identified through your analysis.
  8. Aim to provide upto of 1 to 5 key features, after each feature add an empty line for formatting purposes.
  9. Ensure that the features listed represent the core functionality and unique selling points based on the folder wise summary.
  10. Use clear, concise language that emphasizes the value proposition of each feature.
  11. Also under each feature, mention which file/folder was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
  12. Do not add features into Highlighted Features if they dont have value for buisness stakeholder about the application. Also do not repeat adding similar feature in this section.

  Output Structure:
  1. ***<Feature 1 Title>***: <Description of the feature in one to two sentences.\n
  2. ***<Feature 2 Title>***: <Description of the feature in one to two sentences.>\n
  >
  <empty line>
  **Key Benefits**
  <empty line>
  <Summarize the key benefits of the codebase in one to two sentences.
  This summary should encapsulate the overall value proposition of the codebase and its potential impact on users or the organization.>
  <empty line>
  <Highlight the most significant key benefits the codebase has to offer in bulleted points. The format should be:
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  Aim for 3-5 bullet points that capture the most compelling advantages of using this codebase, after each point add an empty line for formatting purposes.
  Each benefit should be distinct and provide a clear value proposition.>

  <Final Output Format>
  Output Format - Adhering to this format is crucial, the output should be in parsable JSON format:
  ```json
  {{
    "data": "<generated_summary in string format adhering to the Expected Output Format for Generated Summary>",
    "confidence_score": 90,
    "traceback": {{
      "Feature 1 Title": "Since it mentions about <exact phrase from the folder wise summary>, the 'Feature 1 Title' is included, as the "phrase" is an evidence that this feature is part of the folder wise summary.",
      "Feature 2 Title": "Since it mentions about <exact phrase from the folder wise summary>, the 'Feature 2 Title' is included, as the "phrase" is an evidence that this feature is part of the folder wise summary.",
      ...
    }}
  }}
  ```
  </Final Output Format>
  Note: If the traceback includes phrases that are not present in the folder wise summary then you would be penalized 10000 points.
  The output should be having data, confidence score, and traceback keys, and the entire content inside "```json" and "```" should be parsable by json.
  The "data" key should contain the generated summary and it should be in string format only, allowing the parsing of the entire json.
  If there are any inverted commas inside the generated summary, then escape them with a backslash.
  Do not change or skip the headings of each section in the generated json. The generated summary must have "Overview", "Highlighted Features", "Key Benefits" as section titles. Follow the above provided guidelines."""
    user_prompt += f"""Use the below folder wise summary to generate the summary in the above format: {combined_summary}""" + "User Defined Features : " + str(user_mvf)
    return system_prompt, user_prompt

def db_executive_summary_generation(combined_summary, user_mvf): 
    system_prompt = """
    Role:
    You are an expert Database Architect tasked with understanding the contents of all tables and schema of the database. 
    You shall Articulate a proper executive summary that clearly captures all the main & high-level features of this database.
    The core use-case that this database is intended for, and the prioritized list of the most valuable features, solely based on the provided Table-Level summaries. 
    Do not hallucinate. Do NOT create the most valuable features and its description on pure assumptions. This needs to be based on facts, with proper backing.

    Task:
    1. Analyze provided Table wise summaries.
    2. Understand component interactions and functions.
    3. Prioritize the User Defined Features (if provided) in the summary.
    4. Identify and prioritize the most valuable features based on their importance to the core use-case the Database is solving.
    5. Create a comprehensive executive summary.

    Steps:
    1. Review Table wise summary.
    2. Analyze Table wise summary:
      - Identify all tables. 
      - Take into consideration the foreign keys, primary keys, is-a, has-a, and many-to-many relationships.
      - Deeply understand the intended-use-case of each table.
      - Note data operations, design patterns, and architectural decisions
    3. Create summary:
      - Describe the specific problem the Database is solving, based on Table wise summary
      - Explain high-level interactions and dependencies
      - Outline data workflow
    4. Identify and prioritize main features:
      - Determine which feature(s) address the core problem of the Database, based on SQL implementation and Table wise summary
      - Rank features based on their importance and relevance to solving the main problem, as evidenced in the Database
      - The feature should be major components of the Database and not minor functions like Many-to-Many Relationships, or "Foreign Keys". 
        These are implementation concepts. Not core features.

    Focus Areas:
    - Precised feature prioritization and importance
    - High-level functionality of this Database
    - Clear, concise technical language with Database-specific Language
    - Objective description
    - Capture entire data workflow

    Guidelines:
    - Only use the Table wise summary provided
    - Use precise Database-relevant technical terms
    - Include user-defined features if provided and evidenced in the Table wise summary
    - Prioritize features based on their importance to the core problem, as shown in the Table wise summary

    Feature Identification and Prioritization:
    - Carefully analyze the Table wise summary to identify features actually present in the Table wise summary
    - Do not assume or infer features that are not explicitly mentioned in the Table wise summary
    - Identify the top feature that solves the majority of the problem based on Database and SQL evidence
    - Rank subsequent features in descending order of importance, ensuring they are present in the Table wise summary
    - Ensure the feature list reflects the Database's focus and structure
    - Only include features that have substantial implementation in the Database that is evident from Table wise summary

    Output Format - Adhering to this format is crucial
    ```json
    {
    "data": "generated_summary in string format adhering to the Expected Output Format for Generated Summary",
    "confidence_score": 90,
    "traceback": {
    "Feature 1 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 1 Title' is included, as the 'phrase' is an evidence that this feature is part of the Database.",
    "Feature 2 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 2 Title' is included, as the 'phrase' is an evidence that this feature is part of the Database.",
    ...
    }
    }
    ```

    Requirements:
    - Replace \n with \\n in JSON
    - Limit upto 5 main features (max 2 sub-features each) or 7500 tokens
    - If due to any reason such as Database being small, you are unable to provide 5 features, then provide as many high-level features as possible between the range of 1 to 5.
    - Don't assume features or include minor features due to inability to provide 5 features, lesser number of features is acceptable.
    - Use specified JSON format only
    - Start with "```json" and end with "```"
    - Ensure the top feature in the prioritized list addresses the core problem and is present in the Table wise summary
    - Rank features in descending order of importance to the main problem, based on actual Database and SQL implementation
    - Do NOT include features that are NOT evidenced in the provided Table wise summary
    - Evaluate the Table wise summary objectively, considering all conclusions on the actual Database and SQL provided
    - Do NOT make any assumptions about organizational goals or intentions beyond what is explicitly shown in the Database and SQL
    - Focus solely on the technical aspects and implemented functionality, avoiding speculation about business objectives or future plans
    - Both the keys data, confidence score, and traceback should be present in the output JSON
    - The generated summary should be in string format only and be contained inside the "data" key
    - The "traceback" key should contain a dictionary with feature names as keys and justifications for including these features based on exact phrases from the input
    - Do not include any feature that could potentially be part of the Table wise summary without explicit evidence
    - Every feature mentioned must be driven by clear evidence from the provided input.
    - Strictly use an assertive and objective tone in your response. 
    - Do not be unsure about anything.
    - Do not include the "Folder Name" in your response. Ignore "dbanalysis" folder. Provide Executive Summary of the Database-ONLY.
    """

    user_prompt = """
  Expected Output Format for Generated Summary:

  **Overview**
  <empty line>
  <A brief introduction to the Database and its main purpose; in paragraph format only, not in points.
  This paragraph should provide a concise yet comprehensive overview of the Database, its primary functionality, and its intended use case.
  Aim for 3-5 sentences that capture the essence of the Database.>
  <empty line>
  **Highlighted Features**
  <empty line>
  <
  List and briefly explain the key features that are significant components of the Database and would serve as selling points.
  These features should be presented as follows:
  1. Use numbered points for each feature.
  2. Provide a brief explanation for each feature in 1-2 sentences, highlighting its importance and benefit to the END USER.
  3. Focus on features that are central to the Database's functionality and most important to the END USER.
  4. Dont include generic features like  Many-to-Many Relationships, or "Foreign Keys", these are not features but Design Principles.
  5. Do not include sub-points under any feature.
  6. Prioritize User Defined Features (if provided) at the beginning of the list.
  7. If User Defined Features are given, list them first before including any features identified through your analysis.
  8. Aim to provide upto of 1 to 5 key features, after each feature add an empty line for formatting purposes.
  9. Ensure that the features listed represent the core functionality and unique selling points based on the Table wise summary.
  10. Use clear, concise language that emphasizes the value proposition of each feature.
  11. Also under each feature, mention which file/Table was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
  12. Do not add features into Highlighted Features if they dont have value for buisness stakeholder about the application. Also do not repeat adding similar feature in this section.

  Output Structure:
  1. ***<Feature 1 Title>***: <Description of the feature in one to two sentences.\n
  2. ***<Feature 2 Title>***: <Description of the feature in one to two sentences.>\n
  >
  <empty line>
  **Key Benefits**
  <empty line>
  <Summarize the key benefits of the Database in one to two sentences.
  This summary should encapsulate the overall value proposition of the Database and its potential impact on users or the organization.>
  <empty line>
  <Highlight the most significant key benefits the Database has to offer in bulleted points. The format should be:
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  Aim for 3-5 bullet points that capture the most compelling advantages of using this Database, after each point add an empty line for formatting purposes.
  Each benefit should be distinct and provide a clear value proposition.>

  <Final Output Format>
  Output Format - Adhering to this format is crucial, the output should be in parsable JSON format:
  ```json
  {{
    "data": "<generated_summary in string format adhering to the Expected Output Format for Generated Summary>",
    "confidence_score": 90,
    "traceback": {{
      "Feature 1 Title": "Since it mentions about <exact phrase from the Table wise summary>, the 'Feature 1 Title' is included, as the "phrase" is an evidence that this feature is part of the Table wise summary.",
      "Feature 2 Title": "Since it mentions about <exact phrase from the Table wise summary>, the 'Feature 2 Title' is included, as the "phrase" is an evidence that this feature is part of the Table wise summary.",
      ...
    }}
  }}
  ```
  </Final Output Format>
  Note: If the traceback includes phrases that are not present in the Table wise summary then you would be penalized 10000 points.
  The output should be having data, confidence score, and traceback keys, and the entire content inside "```json" and "```" should be parsable by json.
  The "data" key should contain the generated summary and it should be in string format only, allowing the parsing of the entire json.
  If there are any inverted commas inside the generated summary, then escape them with a backslash.
  Do not change or skip the headings of each section in the generated json. The generated summary must have "Overview", "Highlighted Features", "Key Benefits" as section titles. Follow the above provided guidelines.
    """

    user_prompt += f"""Use the below Table wise summary to generate the summary in the above format: {combined_summary}""" + "User Defined Features : " + str(user_mvf)

    return system_prompt, user_prompt


def architecture_diagram_generation(services_data, icons_metadata):
    user_prompt = f"""
    <Input>
    $services_data = {services_data}
    $icons_metadata
    </Input>

    <Role>
    You are an expert at understanding large projects based on their executive summary and the services being used in them. Create a JSON structure for a ReactFlow diagram based on the given service class JSON.
    </Role>

    <Output Structure>
    1. Create a JSON object with a "nodes" and "edges" array.
    2. Create nodes for each external and third-party service.
    3. "nodes": An array containing all node objects.
      - "id": A unique string identifier for the node.
      - "data":   
        - "label": The name of the node.
        - "description": Description of the service.
        - "associated_files": Associated file and used in files in the service node, defaulting to "No File Available" if not present.
        - "group": The logical group name (e.g., 'Backend', 'Frontend', 'Database',etc..).
        - "subgroup": The specific subgroup within the group (e.g., Frameworks, NoSQL Databases, State Management, etc.).
        - "service": The appropriate filename of the icon based on the $icons_metadata.
      - "position" : The x and y coordinates of the node.
      - "type" : "customNode" This should be fixed.
    4. "edges" : An array having id, source, target, label, and type should be customEdge always.
    4. Ensure all services and files from the input JSON are included.
    5. The output should be in the form of a dictionary containing a "nodes" and "edges" array.
    6. Present only the code inside delimiters "```reactflow [reactflow CODE]```" without any additional explanation.
    """

    system_prompt:str = """
    <Task>
      You are tasked with creating a JSON structure for a ReactFlow diagram based on the given executive summary and the service_class_json. The executive summary contains an overview of the entire project. This JSON includes information about external services and third-party services, along with their associated files. Your output should represent this information as a network of nodes and edges.
    </Task>
    
    <Icons Context>
      $icons_metadata = """ + str(icons_metadata) + """
    </Icons Context>

    <Instructions>
      You are a solution expert, specializing in problem and solution flows. You will be given the solution overview for a project, and your task is to create an interconnected single component of graph which is detailed, and intuitive and self explanatory for:

      Follow these guidelines:
      1. Create nodes for each unique service (both external and third-party).
      2. Do not create any group nodes.
      4. In the data key for each service node, include two additional fields called group and subgroup. The group field should contain the logical group name (e.g., Frontend, Backend, Databases, etc..), and the subgroup field should provide more specific categorization (e.g., Frameworks, NoSQL Databases, etc..). For example, for a service node representing React, the group would be Frontend and the subgroup would be Frameworks.
      5. For each node, check which icon will be the most suitable from the $icons_metadata in the <Icons Context>
      6. Ensure all information from the input is represented in the output.
      7. The position coordinates must be proper for all the nodes.
    </Instructions>

    <Rules>
      **Ensure all nodes in the generated graph are interconnected such that every node has at least one edge, forming a single connected component without any isolated or disjoint sections. (High Priority Requirement)**
      Important Rules to be followed:
      1. Give detailed technical architecture flow and the JSON object following the below output format.
      2. Make sure that the flow and order of new solution approach is explained well in the graph with appropriate edges. Use as many edges you want to describe the data and user flow properly.
      3. The whole user and data flow should be clear.
      4. Do not add unnecessary nodes and edges. Do not create duplicate nodes that perform same task.
      5. Make the Node descriptions detailed, breaking tasks into multiple sub-tasks if needed.
      6. Ensure your edges show the actual flow, and not just connections of what's related. The connections are meant to show the logical flow, and not the relatedness/similarity.
      7. The group name is meant to classify clusters of nodes within each graph. For instance, if we have multiple nodes in features, they would all have "feature" as group. In Architecture Flow, the "Group" should show the layer each node is in, for instance "Backend Layer", "Database Layer" etc.
      9. for a hierarchy of nodes A -> B -> C; ensure that there is not a connection between A -> C.
    </Rules>
    
    <output_format>
    The output should be in between the delimeters ```reactflow and ```. Only provide the json output. Don't give unnecesary explanation.
    ```reactflow
    {
      "nodes": [
        { 
          "id": "unique_node_identifier_string",
          "data" : {
            "label": "name_of_the_service",
            "description": "description of the service",
            "associated_files": ["file_path_1", "file_path_2", "file_path_3", etc.],  // (default: ["No File Available"] if not present)
            "group": "name_of_group",  // Add the logical group name (e.g., "Frontend", "Backend", etc..)
            "subgroup": "name_of_subgroup",  // Add a more specific subgroup name (e.g., "Frameworks", "NoSQL Databases", etc..)
            "service": "filename" //taken from the $icons_metadata,
          }
          "position":{ "x": "Xcoordinate", "y": "Ycoordinate" },
          "type" : "customNode" //this is hardcoded and will be constant
        }
      ],
      "edges": [
        {
          "id": "unique_egde_identifier_string",
          "source": "label A",
          "target": "label B",
          "label": "Showcase what comes from the source node, to the target node. Be concise and specific with labels, such as 'Ingested Data', 'Converted Text', 'User Query' etc. Use at max 5 words",
          "type" : "customEdge" //this is hardcoded and will be constant
        }
      ]
    }```
    </output_format>
    """
    return system_prompt, user_prompt
  

def erd_generation(services_data, icons_metadata):
  tables_metadata = []
  for entry in services_data:
      table_name = entry["table_name"]
      ddl = entry["ddl"]
      columns, primary_keys, foreign_keys = parse_ddl(ddl)
      tables_metadata.append({
          "table_name": table_name,
          "columns": columns,
          "primary_keys": primary_keys,
          "foreign_keys": foreign_keys
      })

  dot = generate_combined_graph(tables_metadata)

  system_prompt:str = """
    You are tasked with creating a JSON structure for a ReactFlow diagram based on the given database ER diagram and schema JSON. This JSON includes information about database columns and their relationships.Your output should represent this information as a network of nodes and edges.
    </Task>
    
    <Icons Context>
      $icons_metadata = """ + str(icons_metadata) + """
    </Icons Context>

    <Instructions>
      You are a solution expert, specializing in problem and solution flows. You will be given the database schema information of a database, and your task is to create an interconnected single component of graph which is detailed, and intuitive and self explanatory for:

      Follow these guidelines:
      1. Create nodes for each unique service (both external and third-party).
      2. Do not create any group nodes.
      4. In the data key for each service node, include two additional fields called group and subgroup. The group field should contain the logical group name (e.g.,Databases, etc..), and the subgroup field should provide more specific categorization (e.g., 'Transactional Tables', 'Reference Tables' etc..). For example, for a service node representing daily transactions, the group would be Database and the subgroup would be Transactional Tables.
      5. For each node, check which icon will be the most suitable from the $icons_metadata in the <Icons Context>
      6. Ensure all information from the input is represented in the output.
      7. The position coordinates must be proper for all the nodes.
    </Instructions>

    <Rules>
      Important Rules to be followed:
      1. Give detailed technical architecture flow and the JSON object following the below output format.
      2. Make sure that the flow and order of new solution approach is explained well in the graph with appropriate edges. Use as many edges you want to describe the data and user flow properly.
      3. The whole user and data flow should be clear.
      4. Do not add unnecessary nodes and edges. Do not create duplicate nodes that perform same task.
      5. Make the Node descriptions detailed, breaking tasks into multiple sub-tasks if needed.
      6. Ensure your edges show the actual flow, and not just connections of what's related. The connections are meant to show the logical flow, and not the relatedness/similarity.
      7. The group name is meant to classify clusters of nodes within each graph. For instance, if we have multiple nodes in features, they would all have "feature" as group. In Architecture Flow, the "Group" should show the layer each node is in, for instance "Database Layer" etc.
      9. for a hierarchy of nodes A -> B -> C; ensure that there is not a connection between A -> C.
    </Rules>
    
    <output_format>
    The output should be in between the delimeters ```reactflow and ```. Only provide the json output. Don't give unnecesary explanation.
    ```reactflow
    {
      "nodes": [
        { 
          "id": "unique_node_identifier_string",
          "data" : {
            "label": "name_of_the_table",
            "description": "description of the table",
  	    "columns": ["order_id [PK]", "product_sku [PK]", "quantity", "unit_price"]
            "group": "name_of_group",  // Add the logical group name (e.g., "Database", etc..)
            "subgroup": "name_of_subgroup",  // Add a more specific subgroup name (e.g., 'Transactional Tables', 'Reference Tables', etc..)
            "service": "filename" //taken from the $icons_metadata,
          }
          "position":{ "x": "Xcoordinate", "y": "Ycoordinate" },
          "type" : "customNode" //this is hardcoded and will be constant
        }
      ],
      "edges": [
        {
          "id": "unique_egde_identifier_string",
          "source": "label A",
          "target": "label B",
          "label": "Showcase what comes from the source node, to the target node. Be concise and specific with labels, such as 'Ingested Data', 'Converted Text', 'User Query' etc. Use at max 5 words",
          "type" : "customEdge" //this is hardcoded and will be constant
        }
      ]
    }```
    </output_format>
    """
    
  user_prompt:str = f"""
    <Input>
    $database_tables = {dot}
    $icons_metadata
    </Input>

    <Role>
    You are an expert at understanding database architecture based on ER diagrams and relational structures. Create a JSON structure for a ReactFlow diagram based on the given database schema.
    </Role>
    <Output Structure>
      1. Create a JSON object with a "nodes" and "edges" array.
      2. Create nodes for each table in the schema.
      3. "nodes": An array containing all node objects.
      - "id": A unique string identifier for the node.
      - "data":  
        - "label": The name of the table.
        - "description": A brief summary of the table's role or content.
        - "columns": List of column names (mark primary keys with [PK], foreign keys with [FK]).
        - "group": The logical group name (e.g., 'Database').
        - "subgroup": The specific subgroup within the group (e.g., 'Transactional Tables', 'Reference Tables').
        - "service": The appropriate filename of the icon based on the $icons_metadata.
      - "position" : The x and y coordinates of the node.
      - "type" : "customNode" This should be fixed.
      4. "edges" : An array having id, source, target, label, and type should be customEdge always.
      5. The label of the edge should describe the relationship, like "order_id â†’ order_id". 
      6. The output should be in the form of a dictionary containing a "nodes" and "edges" array.
      7. Present only the code inside delimiters "```reactflow [reactflow CODE]```" without any additional explanation.
    """
    
  return system_prompt, user_prompt
    

def feature_summary_generation(formatted_data, user_mvf, executive_summary):
    # if input_type is None:
    #     formatted_data = file_summary_list
    # elif input_type == "batch_summary":
    #     formatted_data = format_batchwise_summary_metadata_for_services(file_summary_list)
    # else:
    #     formatted_data = format_file_summaries(file_summary_list)

    user_prompt = """
    Role: You are an AI code analyst specializing in creating concise, feature-level summaries of codebases.

    Objective: Provide a comprehensive yet concise feature-level summary of a given codebase, highlighting key components, functionality, and the project's overall workflow.

    Input: You will receive information about a codebase, which may include an executive summary or other project details.

    Steps:
    1. Analyze the provided codebase information.
    2. Identify the main features (maximum 5) of the project from the executive summary (if provided in same order)
    3. Create a summary following the specified format, including:
        a. An overview of the project
        b. A list of key features with brief descriptions
        c. A closure statement
    4. Self-evaluate the generated summary and assign a confidence score.
    5. Format the output as specified in the instructions.

    Output Format:
    ```json
    {
        "data": "generated_summary in string format adhering to the Detailed Instructions for Output Format",
        "confidence_score": 90
    }
    ```

    Detailed Instructions for Output Format:

    **Overview**
    <empty line>
    < 
        Summarize all features in 2-3 sentences, introducing the project and its purpose.
        Provide a 2-3 sentence summary of key benefits, highlighting core architecture and value proposition.
    >
    <empty line>
    **Key Features**
    <empty line>
    <   
        List a maximum of 5 main features.
        For each feature, provide up to 2 sub-points describing its functionality.
        Ensure clear explanation of how features interact and contribute to the project's goals.
        1. ***<Key Feature Title>*** : 
        * <Sub point 1 description>
        * <Sub point 2 description>
        <empty line>
    >
    <empty line>
    < 
        Summarize the overall impact and value proposition of the project in one sentence as a conclusion statement.
    >
    <empty line>
    
    -> Self-Evaluation:
        - Score the summary out of 100 based on clarity, precision, detail, knowledge, accuracy, technical correctness, and understanding of the data.

    -> Formatting Requirements:
        - Replace all newline characters (\n) with \\n in the JSON output.
        - Ensure the complete JSON is less than 7500 tokens.
        - Start the output with "```json" and end with "```".
        - If an executive summary is provided, use only the highlighted features from it.

    Example Output Structure:
    ```json
    {
        "data": "**Overview**\\n\\n[Project overview]\\n\\n[Benefits summary]\\n\\n**Key Features**\\n\\n1. *Feature 1*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n2. *Feature 2*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n[...continue for up to 5 features...]\\n\\n[Closure statement]",
        "confidence_score": 90
    }
    ```

    Remember: Adhere strictly to the output format and instructions to maintain consistency and accuracy in your summary.
    """

    user_prompt += "User Defined Features : " + str(user_mvf)

    system_prompt = f"""
        <role>
        You are an assistant to a Senior Software Engineer. You are very capable in reading and understanding huge codebases.
        There is no edge-case, no mistake, no functionality no matter how small goes unnoticed by you.
        You will be given a large codebase and be asked queries regarding it.
        </role>

        <Task>
        You will be given relevant files from a production codebase. The Senior Engineer will consult you to clear his doubts and ask for critical code-level and functionality level analysis of the same.
        <Important>
        1. You will be clear. Feel free to be descriptive but Avoid Jargon
        2. You shall perform critical analysis on the code before responding.
        3. Note that the codebase will be quite complex and have dependencies everywhere, be mindful of them all.
        4. Enclose code in (triple backticks)``` code ```
        </Important>
        </Task>

        Files from Codebase goes here :
        <Repo Structure>
        {formatted_data}
        </Repo Structure>
    """

    start_index = executive_summary.find("Highlighted Features")
    end_index = executive_summary.find("Key Benefits")

    if start_index != -1 and end_index != -1:
        executive_summary = executive_summary[start_index:end_index].strip()

    user_prompt += "Executive Summary : " + str(executive_summary)

    return system_prompt, user_prompt

def feature_summary_generation_db(formatted_data, user_mvf, executive_summary):
    # if input_type is None:
    #     formatted_data = file_summary_list
    # elif input_type == "batch_summary":
    #     formatted_data = format_batchwise_summary_metadata_for_services(file_summary_list)
    # else:
    #     formatted_data = format_file_summaries(file_summary_list)

    user_prompt = """
    Role: You are an AI Database Analyst specializing in creating concise, feature-level summaries of complex database schemas and architectures.

    Objective: Provide a comprehensive yet concise feature-level summary of a given database schema information, highlighting key components, entities, relationships, and the overall data architecture workflow.

    Input: You will receive information about a database design, which may include an executive summary or other schema-level details.

    Steps:
    1. Analyze the provided database schema information.
    2. Identify the main features (maximum 5) of the database from the executive summary (if provided in same order)
    3. Create a summary following the specified format, including:
        a. An overview of the database
        b. A list of key features with brief descriptions
        c. A closure statement
    4. Self-evaluate the generated summary and assign a confidence score.
    5. Format the output as specified in the instructions.

    Output Format:
    ```json
    {
        "data": "generated_summary in string format adhering to the Detailed Instructions for Output Format",
        "confidence_score": 90
    }
    ```

    Detailed Instructions for Output Format:

    **Overview**
    <empty line>
    < 
        Summarize all features in 2-3 sentences, introducing the database and its purpose.
        Provide a 2-3 sentence summary of key benefits, highlighting schema structure, normalization or denormalization logic, and value proposition in handling data.
    >
    <empty line>
    **Key Features**
    <empty line>
    <   
        List a maximum of 5 main features.
        For each feature, provide up to 2 sub-points describing its data handling, relationships, or optimization logic.
        Ensure clear explanation of how features contribute to performance, consistency, and data integrity.
        1. ***<Key Feature Title>*** : 
        * <Sub point 1 description>
        * <Sub point 2 description>
        <empty line>
    >
    <empty line>
    < 
        Summarize the overall impact and value proposition of the database in one sentence as a conclusion statement.
    >
    <empty line>
    
    -> Self-Evaluation:
        - Score the summary out of 100 based on clarity, precision, detail, knowledge, accuracy, technical correctness, and understanding of the schema information.

    -> Formatting Requirements:
        - Replace all newline characters (\n) with \\n in the JSON output.
        - Ensure the complete JSON is less than 7500 tokens.
        - Start the output with "```json" and end with "```".
        - If an executive summary is provided, use only the highlighted features from it.

    Example Output Structure:
    ```json
    {
        "data": "**Overview**\\n\\n[Database overview]\\n\\n[Benefits summary]\\n\\n**Key Features**\\n\\n1. *Feature 1*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n2. *Feature 2*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n[...continue for up to 5 features...]\\n\\n[Closure statement]",
        "confidence_score": 90
    }
    ```

    Remember: Adhere strictly to the output format and instructions to maintain consistency and accuracy in your summary.
    """

    user_prompt += "User Defined Features : " + str(user_mvf)

    system_prompt = f"""
        <role>
        You are an assistant to a Senior Data Architect. You are very capable in reading, analyzing, and understanding complex database schemas and data models.
        No entity, constraint, relationship, or optimization logic goes unnoticed by you.
        You will be given a comprehensive database structure or schema information and will be asked to analyze, explain, and summarize it at a structural and functional level.
        </role>

        <Task>
        You will be given relevant database schema files or DDL definitions. The Senior Data Architect will consult you to clear doubts and ask for critical schema-level and data model-level analysis.
        <Important>
        1. You will be clear. Feel free to be descriptive but Avoid Jargon
        2. Perform a critical and deep analysis of the schema and the information given before responding.
        3. The schema will often involve multiple tables, foreign keys, views, procedures, and indexing strategies â€” be mindful of their dependencies and relationships.
        4. Enclose code or schema in (triple backticks)``` code ```
        </Important>
        </Task>

        Files from Database schema goes here :
        <Database Structure>
        {formatted_data}
        </Database Structure>
    """

    start_index = executive_summary.find("Highlighted Features")
    end_index = executive_summary.find("Key Benefits")

    if start_index != -1 and end_index != -1:
        executive_summary = executive_summary[start_index:end_index].strip()

    user_prompt += "Executive Summary : " + str(executive_summary)

    return system_prompt, user_prompt


#FEATURE HIERARCHY:
generate_features_system_prompt = """
  <Role>
    You are a Software Architect with expertise in analyzing large summaries from code files of an application. 
    You can comprehend summaries from code files that are complex, production-grade and are written in various programming languages to generate most important features, their description and the subfeatures with their description belonging to the most important features along with the other relevant information requested below.
    
    You will follow 2 Events before responding : 
    1. Generation of Feature Hierarchy as given in "Output_Format".
    2. Critical Evaluation of Every Confidence Score.  
  </Role> 

    <Task 1>
    You are provided with multiple relative file paths and file-wise code summaries from a application codebase.
    1. Analyze the file summaries carefully, leveraging your expertise to deduce the frameworks, functionality, and features.
    2. Perform a critical assessment of the code's functionality and interdependencies before responding.
    3. The codebase is complex and likely contains dependencies across various modules. Be mindful of these.
    4. Analyse every file summary and assign the features and sub-features based on the information provided.
    5. Respond strictly in the structured JSON format provided below.
    6. In each sub-feature's 'file_path' array:
        - Set 'critical: true' ONLY for files that are CORE & NON-REPLACEABLE to the sub-feature's main functionality.
        - Set 'critical: false' for ALL supporting, secondary, or replaceable files  
        - Each sub-feature should have both true and false entries.
        - If unsure, default to false (be EXTREMELY selective with 'true')
        - Make sure each sub-feature atleast have one file as true.

    Explanation of the Output terms:
    Feature - Features are most valuable and high level features extracted from the list of summaries that are provided to you. 
    Feature description - Description of the features explaining the high level value and impact that it creates for the project. Define the Feature. The description should be crisp, precise, well formatted and must be between 2-3 lines.
    Subfeature - Subfeatures are micro most valuable features that are extracted from the list of summaries and belong to the Most related and similar Features.
    Subfeature description - Description of the subfeatures explaining the specific value, technical and non-technical functionalites that it provided to the project. Define the subfeature and also explain how its related to the feature. The description should be crisp, precise, well formatted and must be between 2-3 lines.
    
    Points to Remember:
    1. Do not extract any feature or subfeature where there are no reference/citations from the application summaries.
    2. The description must be precise, valuable, well-formatted and must be between 2-3 lines.
    3. The Feature titles should be precise, specific, self explanaible, independent and not have similar feature titles. The Feature titles should not be highly generalized.
    4. The SubFeatures titles should be precise, self explanaible and not have similar subfeature titles. The SubFeature titles should not be highly generalized.
    5. SubFeatures should not be very low level that it explains code functions, code process like 'Json handling', 'Reading csv', readME etc.
    6. If similar subfeatures are present, then group them under one common Feature itself. Do not create multuple Features for similar subfeatures.
    6. If Unit testing related summaries are found, then create that as another Feature named 'Unit Testing' and assign the specific testing subfeatures under this feature.
    </Task 1>

  <Task 2>
  You shall now Assign and Justify Confidence Scores for each feature.

  <Critical Evaluation of Confidence Scores> 

  <Evaluation MODE>
  - You will now Forget everything that was done beforehand and act as an unbiased judge.
  - $Project-Summaries-&-Paths (INPUT).
  </Evaluation MODE>
  <Important>
  Critically analyze every "Feature" and "SubFeature" based on the following metrics. 
  You shall generate a confidence score between 0-100 for each of the following :
  1. Is the "Feature" & "SubFeature" name accurate to its functionality ? (Accuracy)
  2. Does the "Feature" & "SubFeature" include files with an unrelated function ? (Feature Dilution Rate)
  3. Important : Does this "Feature" & "SubFeature" make sense given the Overall Purpose of the Application ? (Consistency)
  4. Are all the files in "Feature" & "SubFeature" included ? (Completeness)

  <Strict>
  1. You will now generate a list of 4 confidence scores between 0-100 for above criteria under "confidence_score" key.
  2. Based on above criteria, you shall provide a VERY BRIEF logical explanation (10-20 words) for Confidence Score under "confidence_score_justification" key.
  3. Make sure to mention the entire filepath without omitting the prefix.
  4. Make sure all the filepaths are present.
  <Important> STRICTLY Don't Comment on Missing Files. Don't Overestimate. Don't Underestimate.</Important> 
  </Strict>

  </Important>

  </Critical Evaluation of Confidence Scores> 
  </Step 2>


      <Output_Format>
    Return a response in JSON format. Do not include any extra information or explanations. Strictly DON'T deviate from mentioned KEYS.
    Example:
```json
[
  {
    "name": "User Authentication and Management",
    "feature_description": "Comprehensive user account system with secure login, registration, profile management, and role-based access control.",
    "feature_description_confidence_score": [95, 70, 100, 70],
    "sub_features": [
      {
        "name": "User Registration",
        "description": "Allows new users to create accounts by providing necessary information such as username, email, and password. Implements email verification, password strength checks, and duplicate account prevention. Stores user data securely in the database with password hashing.",
        "file_path": [
          {
            "module_name": "RegistrationController",
            "path": "Controllers/Account/RegistrationController.cs",
            "critical": true
          },
          {
            "module_name": "RegisterView",
            "path": "Views/Account/Register.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [75, 80, 85, 65],
        "sub_feature_confidence_score_justification": "No feature dilution, might have missed some file."
      },
      {
        "name": "User Login",
        "description": "Authenticates users using their credentials, creates and manages user sessions, and implements security measures such as login attempt limiting and two-factor authentication (2FA). Provides password reset functionality for forgotten passwords.",
        "file_path": [
          {
            "module_name": "LoginController",
            "path": "Controllers/Account/LoginController.cs",
            "critical": true
          },
          {
            "module_name": "LoginView",
            "path": "Views/Account/Login.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [80, 100, 80, 75],
        "sub_feature_confidence_score_justification": "High chance of missing files."
      }
    ],
    "feature_confidence_score_justification": "No feature dilution, duplication or missing files. Accurate Naming."
  },
  {
    "name": "Product Catalog Management",
    "feature_description": "Comprehensive system for managing product listings, categories, and inventory across the e-commerce platform.",
    "feature_description_confidence_score": [95, 65, 70, 80],
    "sub_features": [
      {
        "name": "Product CRUD Operations",
        "description": "Enables administrators to create, read, update, and delete product listings. Includes functionality for managing product details such as name, description, price, images, and inventory levels. Implements validation to ensure data integrity and consistency across the product catalog.",
        "file_path": [
          {
            "module_name": "ProductController",
            "path": "Controllers/ProductController.cs",
            "critical": true
          },
          {
            "module_name": "ProductView",
            "path": "Views/Product/Index.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [90, 85, 100, 70],
        "sub_feature_confidence_score_justification": "High confidence with no duplication or dilution."
      },
      {
        "name": "Category Management",
        "description": "Allows for the creation and management of product categories and subcategories. Implements a hierarchical structure for organizing products, enabling efficient navigation and filtering of the product catalog for both administrators and customers.",
        "file_path": [
          {
            "module_name": "CategoryController",
            "path": "Controllers/CategoryController.cs",
            "critical": true
          },
          {
            "module_name": "CategoryView",
            "path": "Views/Category/Index.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [85, 75, 90, 95],
        "sub_feature_confidence_score_justification": "High confidence without any duplication or dilution."
      }
    ],
    "feature_confidence_score_justification": "All files refer to single overall functionality. Might have missed some files."
  }
]
```
  </Output_Format>

"""

generate_features_user_message = """
<Strictly Remember>
1. As input you will be given a batch of `file_path` and `file_summary` from a production codebase. Keep it in mind that it could be a file from a very large repository with lot of inter-dependencies.
2. Understand all the file description first, then try to determine the feature, sub-features and their description. For **each file** it should have a feature or sub-features whenever the conditions are met.
3. The response should contain all the fields given in the example output format. The response should be strictly in json format.
4. The description of features/subfeatures must be in the length of 2-3 lines. The response should be structured and well-formatted.
5. Don't generate any additional explanation or description. Provide the structured response in json only.
</Strictly Remember>
  
<Input file wise summary>
{file_summary}
</Input file wise summary>
<Response>
"""

merge_features_in_hierarchy_user_prompt = """You are a software feature analyzer. Given a list of related features that have been clustered together, create a merged feature that encompasses all the functionality.

Features to merge:
{feature_list}

Generate a JSON response that includes:
1. A name for the merged feature representing accurate feature name. Do not mention its merged or unified or anything as such. The feature name should accurately represent a major funcationality of a repository.
2. A detailed description that covers all functionality
3. A confidence score (0-100) for the merge
4. A justification for the confidence score

Respond with a JSON object in the following format:
```json
{{
    "name": "Merged feature name",
    "description": "Comprehensive description",
    "confidence_score": 85,
    "confidence_justification": "Reason for the confidence score"
}}
```
Give only JSON and nothing else. Do not include any explanations or additional text outside the JSON block. Make sure to start with ```json and end with ``` only.
"""

mapping_names_for_merged_features_user_prompt = """  <Role>
    You are a smart AI cassistant with strong expertise in Software Engineering. You can understand complex, production-grade codebases written in various programming languages and summarize them effectively.
  </Role>
  <Task>
  You will be given a brief description of  features of a large codebase and your task is to generate a relevant feature name, brief description, and priority level.
  <Important>
   1. The feature name should be brief, relevant and should represent the entire description provided.
   2. Generate a relevant description which is basically a overall summary of the description provided.
   3. Assign a priority level (high, medium, low) based on the significance, importance and complexity of the feature to the overall system. 
  </important>
  </Task>
  <Example output>
  ```json
    {
        "name": <feature_name>, //string
        "feature_description": <feature_description>, //string
        "priority": <priority> //string (high, medium, or low)
    }
    ```
  </Example output>
  <Strictly Remember>
1. The feature name should be relevant and at the same time interpretable, easy to understand.
2. The feature description should represnt the entire description given for summarisation, it should be simple and easy to understant.
3. The priority should be one of: high, medium, or low.
4. The response should be strictly in json format specified above.
5. Strictly make sure Feature Description is not more than 200 words.
  </Strictly Remember>

<code summary>
The code summary is given below:
"""


reducing_sub_features_user_prompt = """
    You are a software feature consolidation expert. Your task is to merge similar sub-features into one comprehensive sub-feature.

    Here are the sub-features that need to be merged:
    {sub_features_list}

    For each sub-feature, we have:
    - Name: The sub-feature name
    - Description: The sub-feature description (if available)
    - Confidence Score: The confidence score (if available)

    Your output should be a JSON object containing:
    1. A unified sub-feature name that encompasses all the input sub-features
    2. A comprehensive description that covers all aspects of the input sub-features
    3. A confidence score (use the highest available from input sub-features)
    4. A justification for the confidence score

    Return the output in JSON format starting with ```json and ending with ```.

    Example output format:
    ```json
    {{
        "name": "Unified Sub-Feature Name",
        "description": "Comprehensive description covering all aspects",
        "sub_feature_confidence_score": 95,
        "sub_feature_confidence_score_justification": "Merged from similar sub-features with high semantic similarity"
    }}
    ```
    """


post_processing_feature_name_description_system_prompt="""
  <Role>
    You are a smart AI assistant with strong expertise in Software Engineering. You can understand complex, production-grade codebases written in various programming languages and summarize them effectively.
  </Role>
  <Task>
  You will be given a brief description of modules or features of a large codebase and your task is to generate a relevant feature name and brief description.
  <Important>
   1. The feature name should be brief, relevant and should represent the entire description provided.
   2. Generate a relevant description which is basically a overall summary of the description provided.
   3. Also generate a confidence score in a scale of 0 - 100.
  </important>
  </Task>
  <Example output>
  ```json
    {
        "name": <feature_name>,
        "feature_description_confidence_score": <score 0 - 100>,
        "feature_description": <feature_description>
    }```
  </Example output>"""

post_processing_feature_name_description_user_prompt = """<Strictly Remember>
1. The feature name should be relevant and at the same time interpretable, easy to understant.
2. The confidence score should represent the ability to summarise the description.
3. The feature description should represnt the entire description given for summarisation, it should be simple and easy to understant.
4. The response should be strictly in json format specified above.
</Strictly Remember>
<code summary>
The code summary is given below: \n
{feature_description}
</code_summary>
<response>
Your response in json goes here:
"""

merge_similar_features_system_prompt = """You are a solution architect. Your task is to carefully review each feature and its description, and combine them into a single high-level feature.

The final high-level features should represent what an end user would perceive, e.g., Messenger, Google Chat, Messaging, Reels, etc.

Based on the generated features provided, identify which features can be merged into a single high-level feature. 
Strictly output them in the following format:
{{ 
  <High-Level Feature Name 1>: [<Merged Feature 1>, <Merged Feature 2>, <Merged Feature 3>, ...],
  <High-Level Feature Name 2>: [<Merged Feature 1>, <Merged Feature 2>, <Merged Feature 3>, ...],
  ...
}}

INPUT:
Feature names and descriptions are provided in the format: 
[1. Feature name: <feature name> 
Feature description: <feature description>, 
2. ...]

{feature_texts}

MVFS:
{total_MVFs}

Points to remember:
1. While merging features and naming high-level features, always prefer names from the user-defined MVFs provided. All relevant features can be grouped under these high-level features.
2. If certain features do not fit under the user-defined MVFs, choose a better name than the existing one for the new high-level feature if necessary.
3. The names of the features being merged must remain exactly as provided in the INPUT section; do not modify them. Do not consider Feature description in Feature Names.
4. Follow the output structure strictly: high-level feature names as dictionary keys and merged features as values in list format.
5. If a feature is already a high-level feature, you do not need to forcibly merge it. If a feature seems to be function-level/low-level  features, merge them into a High-level feature.
6. Merge similar features into a single high-level feature based on their names and descriptions, when applicable. Each final high-level feature should be independent of the others.
7. Do not assign the same feature to multiple high-level features.
8. If user-defined MVFs are empty, skip point 1 and begin with point 2.
9. Do **not** include any Feature descriptions in the final output."""


merging_description_user_prompt = """You are a Solution Architect. Your task is to summarize the multiple feature descriptions provided into a brief, coherent summary of **no more than two sentences**.

  The summary must:
  - Accurately capture all key components from the provided descriptions.
  - Align clearly with the given high-level feature name.
  - Serve as the final description of the high-level feature.

  Only the final summarized description should be included in the output â€” no additional commentary or formatting.

  INPUT:
  Multiple descriptions: {merging_feature_description}

  High-Level Feature Name: {high_level_feature}
  """


micro_sub_feature_prompt = """You are an expert system analyst specializing in decomposing SubFeatures into granular, logically independent components. You support **two levels** of splitting:

1. **Horizontal splitting**: Split a subfeature into multiple *same-level subfeatures* when it encompasses multiple independently meaningful functionalities. The subfeatures created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.
2. **Vertical splitting**: Further break each of those subfeatures into *microsubfeatures* (if applicable), ensuring each micro-sub-features/micro-user-story describes a single goal or operation. The micro-sub-features/micro-user-story created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.

---

### ðŸ”§ TASK OVERVIEW

Given a Macro-Feature, Subfeature, its description, associated module files and its summary:

- Decide if the subfeature should be split horizontally into multiple same-level subfeatures.
- For each resulting subfeature (or original if not split), analyze whether it can be split vertically into **microsubfeatures** (fine-grained user stories).
- Provide the confidence scores for the subfeature that is split, whether horizontally or vertically.
- Provide the files that are related to the sub_features too, not just the micro_sub_features.
- Each leaf user-story must have files assigned to them, else you should not create/split these subfeatures.
- Provide description of generated subfeature/sub-user-stories in 2-4 lines but only valid information. Do not assume or hallucinate to generate description.
Apply this recursively: if horizontal splitting occurs, then attempt vertical splitting for each. But remember, not to create any duplicates in the process. 

---

### SPLITTING DECISIONS

#### Horizontal Splitting (Same-level Subfeatures):
Split if:
- The subfeature covers multiple high-level functionalities
- Each function could be planned, developed, and deployed independently
- Each component has a clear boundary and responsibility

#### Vertical Splitting (Microsubfeatures):
Split further if:
- A subfeature contains multiple independent operations or logical stages
- These operations can be implemented, tested, or tracked separately
- Each micro-subfeature represents one atomic, non-overlapping functionality

---

### DO NOT SPLIT IF:
- sub-user-stories are tightly coupled in the Subfeature and cannot function independently.
- Do not split subfeatures into sub-user-stories that are hardly single line of code and cannot be considered as a proper functionality, but just a config/parameter.
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across actions are too complex to isolate.
- There are no files that can be mapped to the generated user-story.
- Do not split if the user-story is barely a functionality. The split user-stories must have independent functionality that contributes to the subfeature and feature and if not, do not split.
- Don not split ReadMe & .md files into sub-user-stories.
- Do not split horizontall for granullar subfeatures as they are not user stories but mid level features.
---

### FILE MAPPING RULES:
- For each subfeature or microsubfeature, cite only directly relevant files.
- Use only the provided input data to match files â€” no guessing.
- Avoid duplication unless a file is clearly shared between components.

Each `file_path` entry must include:
```json
{
  "module_name": "<Name>",
  "path": "<Path>",
  "critical": <true/false>,
  "git_url": "<Git URL>"
}

OUTPUT FORMAT
If the subfeature should NOT be split:
Return: "None"

If the subfeature should be split, return a list of Parent User Stories with subfeatures inside.
If a subfeature itself can be further split into microsubfeatures, nest them under micro_sub_features like so:

[
  {
    "name": "Parent User Story Title 1",
    "description": "Full description of the original or updated user story and its purpose.",
    "file_path": [...],
    "sub_feature_confidence_score":"confidence score of the subfeature with respect to the Feature, as a percentage (e.g., 80)"
    "micro_sub_features": [
      {
        "name": "Sub-User Story Title 1",
        "description": "Standalone description of a single functionality.",
        "file_path": [...],
        "micro_sub_feature_confidence_score":"confidence score of the micro_sub_feature with respect to the sub_feature, as a percentage (e.g., 90)"
        }
          ...
        ]
      },
      ...
    ]
  }
]
Each layer must preserve independence, clarity, and singular focus of each story.

VALIDATION CHECKLIST
- Each title must express one functionality only (no imperative phrasing)
- description must avoid assumptions and describe the real function. It must be as detailled as possible.
- Each story must make sense independently and fit in the broader feature flow
- if there are multiple user-story under the subfeature, it needs to be in sequence of business logic.
- File mappings must be relevant and scoped accurately
- Do no miss/skip any values in the output json. The output structure must be maintained strictly.
- All subfeature and sub-user-story names and descriptions must be strictly in a declarative tone, not imperative.

* Use generic or speculative statements
"""


db_micro_sub_feature_prompt = """
<Role>
You are an expert Database analyst specializing in decomposing SubFeatures into granular, logically independent components. You support **two levels** of splitting:
You shall ALWAYS process features from a Database perspective ONLY. 
There can be more than one Table in the DB context provided to you.
</Role>

1. **Horizontal splitting**: Split a subfeature into multiple *same-level subfeatures* when it encompasses multiple independently meaningful functionalities. The subfeatures created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.
2. **Vertical splitting**: Further break each of those subfeatures into *microsubfeatures* (if applicable), ensuring each micro-sub-features/micro-user-story describes a single goal or operation. The micro-sub-features/micro-user-story created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.

<Strict Constraints> 
- You are dealing with Database Information. 
- No matter what, STRICTLY use Database-Specific Language ALWAYS. 
- Use words like Columns / Fields / Schema / DataTypes / Constraints / Foreign Keys / Primary Keys etc.
- Strictly Do not start descriptions with or start with "this micro-feature" / or "this sub-feature".
- You shall do this regardless of the input context and nature.
Remember : Every "FILE" given to you is information of a table. Therefore in your response, ALWAYS refer to "Table" instead of "File".

</Strict Constraints> 


### ðŸ”§ TASK OVERVIEW

Given a Macro-Feature, Subfeature, its description, associated module files and its summary:

- Decide if the subfeature should be split horizontally into multiple same-level subfeatures.
- For each resulting subfeature (or original if not split), analyze whether it can be split vertically into **microsubfeatures** (fine-grained user stories).
- Provide the confidence scores for the subfeature that is split, whether horizontally or vertically.
- Provide the files that are related to the sub_features too, not just the micro_sub_features.
- Each leaf user-story must have files assigned to them, else you should not create/split these subfeatures.
- Provide description of generated subfeature/sub-user-stories in 2-4 lines but only valid information. Do not assume or hallucinate to generate description.
Apply this recursively: if horizontal splitting occurs, then attempt vertical splitting for each. But remember, not to create any duplicates in the process. 

---

### SPLITTING DECISIONS

#### Horizontal Splitting (Same-level Subfeatures):
Split if:
- The subfeature covers ONE / MORE THAN ONE high-level functionalities
- Each function could be planned and developed independently
- Each component has some clear boundaries and responsibilities

#### Vertical Splitting (Microsubfeatures):
Split further if:
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across actions are too complex to isolate.
- There are no tables that can be mapped to the generated user-story.
- The subfeature is too complex to be planned, developed, and deployed independently
- Each micro-subfeature represents one atomic, non-overlapping functionality
Note: Maintain at least 2 subfeatures unless the database has only one table.
- Prioritize brevity, consistency and no informaiton leakage across subfeatures.
- Ensure crisp segregation.
---

### DO NOT SPLIT IF:
- sub-user-stories are tightly coupled in the Subfeature and cannot function independently.
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across tables in two features are too complex to isolate.
- There are no tables that can be mapped to the generated user-story.
Note: Maintain at least 2 subfeatures and 1 or more microsubfeatures per subfeature, Unless the database has only one table.
Note : Maintain brevity during splitting at the same level. Do NOT overload the a single feature with too many subfeatures.
---


### FILE MAPPING RULES:
- For each subfeature or microsubfeature, cite only directly relevant tables.
- Use only the provided input data to match files â€” no guessing.
- Avoid duplication unless a file is clearly shared between components.

Each `file_path` entry must include:
```json
{
  "module_name": "<Name>",
  "path": "<Path>",
  "critical": <true/false>,
  "git_url": "<Git URL>"
}

OUTPUT FORMAT
If the subfeature should NOT be split:
Return: "None"

If the subfeature should be split, return a list of Parent User Stories with subfeatures inside.
If a subfeature itself can be further split into microsubfeatures, nest them under micro_sub_features like so:

[
  {
    "name": "Parent User Story Title 1",
    "description": "Full description of the original or updated user story and its purpose.",
    "file_path": [...],
    "sub_feature_confidence_score":"confidence score of the subfeature with respect to the Feature, as a percentage (e.g., 80)"
    "micro_sub_features": [
      {
        "name": "Sub-User Story Title 1",
        "description": "Standalone description of a single functionality.",
        "file_path": [...],
        "micro_sub_feature_confidence_score":"confidence score of the micro_sub_feature with respect to the sub_feature, as a percentage (e.g., 90)"
        }
          ...
        ]
      },
      ...
    ]
  }
]
Each layer must preserve independence, clarity, and singular focus of each story.

VALIDATION CHECKLIST
- Each title must express one functionality only (no imperative phrasing)
- description must avoid assumptions and describe the real function. It must be as detailled as possible.
- Each story must make sense independently and fit in the broader feature flow
- if there are multiple user-story under the subfeature, it needs to be in sequence of business logic.
- File mappings must be relevant and scoped accurately
- Do no miss/skip any values in the output json. The output structure must be maintained strictly.
- All subfeature and sub-user-story names and descriptions must be strictly in a declarative tone, not imperative.
- Use Database-specific schema only. Do not include words like "Attributes" / "Code Files" in your response. 
- Strictly Do not start descriptions with or start with "this micro-feature" / or "this sub-feature".
* Use generic or speculative statements

"""import os
from graphviz import Digraph
import re 
import json

def parse_ddl(ddl: str):
    """
    Parse the DDL to extract columns, primary keys, and foreign keys.
    """
    lines = ddl.splitlines()
    column_lines = []

    for line in lines:
        line = line.strip()
        if (
            line.upper().startswith("CREATE")
            or line.upper().startswith("PRIMARY")
            or line.upper().startswith("FOREIGN")
            or line.upper().startswith(")")
            or line == ""
        ):
            continue

        match = re.match(r'(\w+)\s+\w+', line)
        if match:
            column_lines.append(match.group(1))

    pk_match = re.search(r'PRIMARY KEY\s*\((.*?)\)', ddl)
    primary_keys = [key.strip() for key in pk_match.group(1).split(",")] if pk_match else []

    foreign_keys = []
    for match in re.finditer(r'FOREIGN KEY\s*\(([^)]+)\)\s+REFERENCES\s+`?[\w]+\.(\w+)`\(([^)]+)\)', ddl):
        fk_col = match.group(1).strip()
        ref_table = match.group(2).strip()
        ref_col = match.group(3).strip()
        foreign_keys.append((fk_col, ref_table, ref_col))

    return column_lines, primary_keys, foreign_keys


def generate_combined_graph(tables_data):
    """
    Generate a single combined graph from multiple tables.
    """
    dot = Digraph(comment='Combined Table Diagram')
    dot.attr(rankdir='LR')

    # Store individual table nodes
    for table in tables_data:
        table_name = table['table_name']
        columns = table['columns']
        primary_keys = table['primary_keys']
        
        label_lines = []
        for col in columns:
            if col in primary_keys:
                label_lines.append(f"{col} [PK]")
            else:
                label_lines.append(col)
        dot.node(table_name, shape='box', label=f'{table_name}\\n' + "\\n".join(label_lines))

    # Add relationships
    for table in tables_data:
        table_name = table['table_name']
        for fk_col, ref_table, ref_col in table['foreign_keys']:
            dot.edge(table_name, ref_table, label=f'{fk_col} â†’ {ref_col}')

    return dot

def folder_summary_generation_prompts(
        total_allocated_tokens, 
        file_list, folder_name, 
        folder_path,
        subfolder_list,
        formatted_file_summaries,
        formatted_file_services,
        formatted_subfolder_summaries,
        formatted_subfolder_services,
        formatted_subfolder_features
    ):
    
    system_prompt = f"""
        You are an expert code analyst specialized in creating detailed, informative summaries of software project folders. Your task is to thoroughly analyze files and subfolders to provide a comprehensive understanding of the application or project and provide combined summaries along with required details. These summaries must be detailled enough for further summarization.

        Follow these guidelines:
        1. Conduct a deep analysis of the features to identify its core purpose and functionality
        2. Provide detailed explanation of key implementations and technical approaches of the features
        3. Thoroughly examine the summaries based on files and folders to understand relationship between features and combined smaller features into larger high level application level features.
        4. Explain the features within the broader project architecture with specific connections
        5. Describe technical patterns, design decisions, and architectural choices evident in the code
        6. Include specific functions, classes, and methods that define the feature's behavior
        7. Note dependencies, imports, and external connections that shape the folder's functionality
        8. Identify potential architectural strengths and areas for improvement when evident
        9. Identify all services represented in this folder based on file and subfolder services information
        10. Identify and articulate high-level features or functionalities represented by the folder into the feature_details section, when consolidating multiple subfolders or lower-level files. Derive these insights from both file-level and subfolder-level summaries. Also under each feature, mention which file/folder was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
        11. Do not miss any features that could be formed based on these summaries as this information is required to understand the application's buisness logic.
        12. Gather insights from the summaries provided to generate a high level detailled executive summary that could be used by business stakeholders to understand the folder/project.
        13. When analyzing the root folder, both the executive summary and the features must be strictly formed in a high level business logic standpoint of an application.
        
        IMPORTANT: 
        - Your summary should be thorough and detailed({total_allocated_tokens}) while maintaining technical/business precision and depth. Focus on providing insights that would help both stakeholders and developers understand the application better.
        - feature_details must contain high level feature name and feature description(value of the files/folders) strictly in concise bullet points. The feature inforamtion must be in detail to capture the complete high level knowledge for that feature but not the function level details. Feature names cannot be programmatic function names like Dependency management, json handling etc. instead it should be inventory management, order processing etc. 
        - Your services list should be comprehensive and include all services represented in this folder.
        - is_reuasble_lib if a folder is used as reusable lib make it True otherwise False
        - lib_name if is_reusable_lib is True then provide the name of the reusable lib/component If is_reusable_lib False then add Not Applicable
        - category if is_reusable_lib is True then provide category only between 'Frontend' and 'Backend' If is_reusable_lib False then add Not Applicable
        - sub_category if is_reusable_lib is True then provide sub category only between 'UI Component','Custom Hooks', 'http_client', 'Utils', 'Others' In Frontend & 'Middleware', 'Error Handling', 'Auth', 'Utils', 'Others' In Backend If is_reusable_lib False then add Not Applicable
        - when_to_use if is_reusable_lib is True then provide where this reusable lib/component can be used If is_reusable_lib False then add Not Applicable 
        - associated_files if is_reusable_lib is True then provide the list of files associated(give complete path for the assosciated file) with this reusable lib/component If is_reusable_lib False then add Not Applicable
        - summary must not be technical and only explain the high level details of the folder/project. Understand the file and folder summaries provided to combine the knowledge to form the executive summary. Make it as detailled as possible.
        - Use clear and concise language, avoiding jargon where possible.
        
        - You must provide your response in this exact format:
        ```summary
        [Your detailled high-level executive summary for the folder for business stakeholders]
        ```
        ```feature_details
        [List of high-level features or functionalities represented in this folder]
        ```
        ```services_namess
        [Comma-separated list of all services represented in this folder]
        ```
        ```is_reuasble_lib
        Boolean Value
        ```
        ```lib_name
        [Name of the reusable library if applicable]
        ```
        ```category
        [Category of the reusable library if applicable]
        ```
        ```sub_category
            [Sub category of the reusable library if applicable]
        ```
        ```when_to_use
        [Your detailed use case where or when this reuasble_lib can be usefull]
        ```
        ```associated_files
            [Comma-separated list of associated files with the reusable library, Give the Complete file path as mentioned in the file list]
        ```
        ```example_usage
            [Example code snippet of how to use this reusable library]
        ```
    """

    user_prompt = f"""
        Generate a summary and services list for the folder: "{folder_name}" (Path: {folder_path})

        FOLDER CONTENTS:
        - Files ({len(file_list)}): {", ".join(file_list) if file_list else "None"}
        - Subfolders ({len(subfolder_list)}): {", ".join(subfolder_list) if subfolder_list else "None"}

        FILE SUMMARIES:
        {os.linesep.join(formatted_file_summaries) if formatted_file_summaries else "No file summaries available"}

        FILE SERVICES:
        {os.linesep.join(formatted_file_services) if formatted_file_services else "No file services available"}

        SUBFOLDER SUMMARIES:
        {os.linesep.join(formatted_subfolder_summaries) if formatted_subfolder_summaries else "No subfolder summaries available"}

        SUBFOLDER SERVICES:
        {os.linesep.join(formatted_subfolder_services) if formatted_subfolder_services else "No subfolder services available"}

        SUBFOLDER FEATURES:
        {os.linesep.join(formatted_subfolder_features) if formatted_subfolder_features else "No subfolder features available"}
        
        Based on these components:
        1. Provide a thorough technical summary explaining the folder's purpose, implementation details, and architectural significance
        2. Compile a comprehensive list of all services represented in this folder based on file and subfolder services information
        
        Follow the exact format specified in the system instructions for your response.
    """

    return system_prompt, user_prompt

def services_generation():
    system_prompt = """
        <Task>
        Create an architectural blueprint of the given repository by identifying and classifying both external services and third-party services with no overlap between categories.
        </Task>

        <Definitions>
        - External services: Company-provided services hosted outside the application (AWS S3, Google Cloud, Stripe, Twilio)
        - Third-party services: Libraries, frameworks, and SDKs that are part of the core application stack (Django, React, MongoDB, Redux)
        </Definitions>

        <Output_Format>
        {
        "external_services": [
            {
            "external_service_name": "string",
            "description": "string",
            "associated_files": ["string"],
            "service_class": "string",
            "used_in_files": ["string"]
            }
        ],
        "thirdparty_services": [
            {
            "thirdparty_service_name": "string",
            "description": "string",
            "associated_files": ["string"],
            "service_class": "string",
            "used_in_files": ["string"]
            }
        ]
        }
        </Output_Format>

        <Instructions>
        1. Conduct a thorough repository analysis to identify all services
        2. Classify each service into exactly ONE category:
        - External services: Cloud platforms, payment processors, authentication providers
        - Third-party services: Frameworks, libraries, SDKs integrated into the codebase
        3. For each service, provide:
        - Name: Exact service name
        - Description: Concise explanation of functionality and purpose
        - Associated files: All files directly importing or using the service
        - Service class: Category (e.g., "cloud storage", "web framework", "database")
        - Used in files: Complete paths of files utilizing the service
        4. Ensure ZERO overlap between categories
        5. Prioritize accuracy over comprehensiveness
        6. Validate that identified services are actively used in the project
        7. Include only services with clear evidence of implementation
        8. Do not create a lot of services which are redundant. Keep it to a maximum of 50 services only.
        </Instructions>

        <Examples>
        Good External Service Entry:
        {
        "external_service_name": "AWS S3",
        "description": "Cloud storage service used for storing user-uploaded files",
        "associated_files": ["src/services/storage.js", "src/config/aws.js"],
        "service_class": "cloud storage",
        "used_in_files": ["src/components/FileUpload.js", "src/pages/UserProfile.js"]
        }

        Good Third-Party Service Entry:
        {
        "thirdparty_service_name": "React",
        "description": "Frontend JavaScript library for building user interfaces",
        "associated_files": ["package.json", "src/index.js"],
        "service_class": "frontend framework",
        "used_in_files": ["src/App.js", "src/components/*.js"]
        }
        </Examples>

        Analyze the repository and provide the complete architectural blueprint in the specified format.
    """

    user_prompt = ""

    return system_prompt, user_prompt

def executive_summary_generation(combined_summary, user_mvf):
    system_prompt = """
    Your Role:
    You are an expert software architect tasked with understanding a codebase and creating an executive summary that clearly articulates the main purpose of this application,
    the core problem that the application is solving, and the prioritized list of the most valuable features, solely based on the provided folder wise summary. Do not hallucinate and create the most valuable features and its description on assumption. This needs to be based on facts.

    Task:
    1. Analyze provided folder wise summary and the services used and the user defined features (if provided).
    2. Understand component interactions and functions.
    3. Prioritize the User Defined Features (if provided) in the summary.
    4. Identify and prioritize the most valuable features based on their importance and relevance to the overall project, as evidenced in the code.
    5. Create a comprehensive executive summary.

    Steps:
    1. Review folder wise summary.
    2. Analyze folder wise summary:
    - Identify key components and their roles
    - Note data operations, design patterns, and architectural decisions
    3. Create summary:
    - Describe the specific problem the codebase solves, based on folder wise summary
    - Explain component interactions
    - Outline data workflow
    4. Identify and prioritize main features:
    - Determine which feature(s) address the core problem of the application, based on code implementation
    - Rank features based on their importance and relevance to solving the main problem, as evidenced in the code
    - The feature should be major components of the codebase and not minor functions like "Modular Architecture" or "Code Reusability", these are not features but design principles.

    Focus Areas:
    - Precised feature prioritization and importance
    - High-level functionality
    - Clear, concise technical language
    - Objective description
    - Capture entire workflow

    Guidelines:
    - Only use the folder wise summary provided
    - Use precise technical terms
    - Include user-defined features if provided and evidenced in the code
    - Prioritize features based on their importance to the core problem, as shown in the folder wise summary

    Feature Identification and Prioritization:
    - Carefully analyze the folder wise summary to identify features actually present in the folder wise summary
    - Do not assume or infer features that are not explicitly mentioned in the folder wise summary
    - Identify the top feature that solves the majority of the problem based on code evidence
    - Rank subsequent features in descending order of importance, ensuring they are present in the folder wise summary
    - Ensure the feature list reflects the codebase's focus and structure
    - Only include features that have substantial implementation in the codebase that is evident from folder wise summary

    Output Format - Adhering to this format is crucial
    ```json
    {
    "data": "generated_summary in string format adhering to the Expected Output Format for Generated Summary",
    "confidence_score": 90,
    "traceback": {
    "Feature 1 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 1 Title' is included, as the 'phrase' is an evidence that this feature is part of the codebase.",
    "Feature 2 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 2 Title' is included, as the 'phrase' is an evidence that this feature is part of the codebase.",
    ...
    }
    }
    ```

    Requirements:
    - Replace \n with \\n in JSON
    - Limit upto 5 main features (max 2 sub-features each) or 7500 tokens
    - If due to any reason such as codebase being small, you are unable to provide 5 features, then provide as many high-level features as possible between the range of 1 to 5.
    - Don't assume features or include minor features due to inability to provide 5 features, lesser number of features is acceptable.
    - Use specified JSON format only
    - Start with "```json" and end with "```"
    - Ensure the top feature in the prioritized list addresses the core problem and is present in the folder wise summary
    - Rank features in descending order of importance to the main problem, based on actual code implementation
    - Do NOT include features that are NOT evidenced in the provided folder wise summary
    - Evaluate the folder wise summary objectively, considering all conclusions on the actual code provided
    - Do NOT make any assumptions about organizational goals or intentions beyond what is explicitly shown in the code
    - Focus solely on the technical aspects and implemented functionality, avoiding speculation about business objectives or future plans
    - Both the keys data, confidence score, and traceback should be present in the output JSON
    - The generated summary should be in string format only and be contained inside the "data" key
    - The "traceback" key should contain a dictionary with feature names as keys and justifications for including these features based on exact phrases from the input
    - Do not include any feature that could potentially be part of the folder wise summary without explicit evidence
    - Every feature mentioned must be driven by clear evidence from the provided input
    """
    user_prompt = """
    Expected Output Format for Generated Summary:

  **Overview**
  <empty line>
  <A brief introduction to the codebase and its main purpose; in paragraph format only, not in points.
  This paragraph should provide a concise yet comprehensive overview of the codebase, its primary functionality, solution provided by the project and its intended use case.
  Aim for 3-5 sentences that capture the essence of the project.>
  <empty line>
  **Highlighted Features**
  <empty line>
  <
  List and briefly explain the key features that are significant components of the codebase and would serve as selling points.
  These features should be presented as follows:
  1. Use numbered points for each feature.
  2. Provide a brief explanation for each feature in 1-2 sentences, highlighting its importance and benefit to the end user.
  3. Focus on features that are central to the codebase's functionality and most important to the end user.
  4. Dont include generic features like "Modular Architecture" or "Code Reusability", these are not features but design principles.
  5. Do not include sub-points under any feature.
  6. Prioritize User Defined Features (if provided) at the beginning of the list.
  7. If User Defined Features are given, list them first before including any features identified through your analysis.
  8. Aim to provide upto of 1 to 5 key features, after each feature add an empty line for formatting purposes.
  9. Ensure that the features listed represent the core functionality and unique selling points based on the folder wise summary.
  10. Use clear, concise language that emphasizes the value proposition of each feature.
  11. Also under each feature, mention which file/folder was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
  12. Do not add features into Highlighted Features if they dont have value for buisness stakeholder about the application. Also do not repeat adding similar feature in this section.

  Output Structure:
  1. ***<Feature 1 Title>***: <Description of the feature in one to two sentences.\n
  2. ***<Feature 2 Title>***: <Description of the feature in one to two sentences.>\n
  >
  <empty line>
  **Key Benefits**
  <empty line>
  <Summarize the key benefits of the codebase in one to two sentences.
  This summary should encapsulate the overall value proposition of the codebase and its potential impact on users or the organization.>
  <empty line>
  <Highlight the most significant key benefits the codebase has to offer in bulleted points. The format should be:
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  Aim for 3-5 bullet points that capture the most compelling advantages of using this codebase, after each point add an empty line for formatting purposes.
  Each benefit should be distinct and provide a clear value proposition.>

  <Final Output Format>
  Output Format - Adhering to this format is crucial, the output should be in parsable JSON format:
  ```json
  {{
    "data": "<generated_summary in string format adhering to the Expected Output Format for Generated Summary>",
    "confidence_score": 90,
    "traceback": {{
      "Feature 1 Title": "Since it mentions about <exact phrase from the folder wise summary>, the 'Feature 1 Title' is included, as the "phrase" is an evidence that this feature is part of the folder wise summary.",
      "Feature 2 Title": "Since it mentions about <exact phrase from the folder wise summary>, the 'Feature 2 Title' is included, as the "phrase" is an evidence that this feature is part of the folder wise summary.",
      ...
    }}
  }}
  ```
  </Final Output Format>
  Note: If the traceback includes phrases that are not present in the folder wise summary then you would be penalized 10000 points.
  The output should be having data, confidence score, and traceback keys, and the entire content inside "```json" and "```" should be parsable by json.
  The "data" key should contain the generated summary and it should be in string format only, allowing the parsing of the entire json.
  If there are any inverted commas inside the generated summary, then escape them with a backslash.
  Do not change or skip the headings of each section in the generated json. The generated summary must have "Overview", "Highlighted Features", "Key Benefits" as section titles. Follow the above provided guidelines."""
    user_prompt += f"""Use the below folder wise summary to generate the summary in the above format: {combined_summary}""" + "User Defined Features : " + str(user_mvf)
    return system_prompt, user_prompt

def db_executive_summary_generation(combined_summary, user_mvf): 
    system_prompt = """
    Role:
    You are an expert Database Architect tasked with understanding the contents of all tables and schema of the database. 
    You shall Articulate a proper executive summary that clearly captures all the main & high-level features of this database.
    The core use-case that this database is intended for, and the prioritized list of the most valuable features, solely based on the provided Table-Level summaries. 
    Do not hallucinate. Do NOT create the most valuable features and its description on pure assumptions. This needs to be based on facts, with proper backing.

    Task:
    1. Analyze provided Table wise summaries.
    2. Understand component interactions and functions.
    3. Prioritize the User Defined Features (if provided) in the summary.
    4. Identify and prioritize the most valuable features based on their importance to the core use-case the Database is solving.
    5. Create a comprehensive executive summary.

    Steps:
    1. Review Table wise summary.
    2. Analyze Table wise summary:
      - Identify all tables. 
      - Take into consideration the foreign keys, primary keys, is-a, has-a, and many-to-many relationships.
      - Deeply understand the intended-use-case of each table.
      - Note data operations, design patterns, and architectural decisions
    3. Create summary:
      - Describe the specific problem the Database is solving, based on Table wise summary
      - Explain high-level interactions and dependencies
      - Outline data workflow
    4. Identify and prioritize main features:
      - Determine which feature(s) address the core problem of the Database, based on SQL implementation and Table wise summary
      - Rank features based on their importance and relevance to solving the main problem, as evidenced in the Database
      - The feature should be major components of the Database and not minor functions like Many-to-Many Relationships, or "Foreign Keys". 
        These are implementation concepts. Not core features.

    Focus Areas:
    - Precised feature prioritization and importance
    - High-level functionality of this Database
    - Clear, concise technical language with Database-specific Language
    - Objective description
    - Capture entire data workflow

    Guidelines:
    - Only use the Table wise summary provided
    - Use precise Database-relevant technical terms
    - Include user-defined features if provided and evidenced in the Table wise summary
    - Prioritize features based on their importance to the core problem, as shown in the Table wise summary

    Feature Identification and Prioritization:
    - Carefully analyze the Table wise summary to identify features actually present in the Table wise summary
    - Do not assume or infer features that are not explicitly mentioned in the Table wise summary
    - Identify the top feature that solves the majority of the problem based on Database and SQL evidence
    - Rank subsequent features in descending order of importance, ensuring they are present in the Table wise summary
    - Ensure the feature list reflects the Database's focus and structure
    - Only include features that have substantial implementation in the Database that is evident from Table wise summary

    Output Format - Adhering to this format is crucial
    ```json
    {
    "data": "generated_summary in string format adhering to the Expected Output Format for Generated Summary",
    "confidence_score": 90,
    "traceback": {
    "Feature 1 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 1 Title' is included, as the 'phrase' is an evidence that this feature is part of the Database.",
    "Feature 2 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 2 Title' is included, as the 'phrase' is an evidence that this feature is part of the Database.",
    ...
    }
    }
    ```

    Requirements:
    - Replace \n with \\n in JSON
    - Limit upto 5 main features (max 2 sub-features each) or 7500 tokens
    - If due to any reason such as Database being small, you are unable to provide 5 features, then provide as many high-level features as possible between the range of 1 to 5.
    - Don't assume features or include minor features due to inability to provide 5 features, lesser number of features is acceptable.
    - Use specified JSON format only
    - Start with "```json" and end with "```"
    - Ensure the top feature in the prioritized list addresses the core problem and is present in the Table wise summary
    - Rank features in descending order of importance to the main problem, based on actual Database and SQL implementation
    - Do NOT include features that are NOT evidenced in the provided Table wise summary
    - Evaluate the Table wise summary objectively, considering all conclusions on the actual Database and SQL provided
    - Do NOT make any assumptions about organizational goals or intentions beyond what is explicitly shown in the Database and SQL
    - Focus solely on the technical aspects and implemented functionality, avoiding speculation about business objectives or future plans
    - Both the keys data, confidence score, and traceback should be present in the output JSON
    - The generated summary should be in string format only and be contained inside the "data" key
    - The "traceback" key should contain a dictionary with feature names as keys and justifications for including these features based on exact phrases from the input
    - Do not include any feature that could potentially be part of the Table wise summary without explicit evidence
    - Every feature mentioned must be driven by clear evidence from the provided input.
    - Strictly use an assertive and objective tone in your response. 
    - Do not be unsure about anything.
    - Do not include the "Folder Name" in your response. Ignore "dbanalysis" folder. Provide Executive Summary of the Database-ONLY.
    """

    user_prompt = """
  Expected Output Format for Generated Summary:

  **Overview**
  <empty line>
  <A brief introduction to the Database and its main purpose; in paragraph format only, not in points.
  This paragraph should provide a concise yet comprehensive overview of the Database, its primary functionality, and its intended use case.
  Aim for 3-5 sentences that capture the essence of the Database.>
  <empty line>
  **Highlighted Features**
  <empty line>
  <
  List and briefly explain the key features that are significant components of the Database and would serve as selling points.
  These features should be presented as follows:
  1. Use numbered points for each feature.
  2. Provide a brief explanation for each feature in 1-2 sentences, highlighting its importance and benefit to the END USER.
  3. Focus on features that are central to the Database's functionality and most important to the END USER.
  4. Dont include generic features like  Many-to-Many Relationships, or "Foreign Keys", these are not features but Design Principles.
  5. Do not include sub-points under any feature.
  6. Prioritize User Defined Features (if provided) at the beginning of the list.
  7. If User Defined Features are given, list them first before including any features identified through your analysis.
  8. Aim to provide upto of 1 to 5 key features, after each feature add an empty line for formatting purposes.
  9. Ensure that the features listed represent the core functionality and unique selling points based on the Table wise summary.
  10. Use clear, concise language that emphasizes the value proposition of each feature.
  11. Also under each feature, mention which file/Table was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
  12. Do not add features into Highlighted Features if they dont have value for buisness stakeholder about the application. Also do not repeat adding similar feature in this section.

  Output Structure:
  1. ***<Feature 1 Title>***: <Description of the feature in one to two sentences.\n
  2. ***<Feature 2 Title>***: <Description of the feature in one to two sentences.>\n
  >
  <empty line>
  **Key Benefits**
  <empty line>
  <Summarize the key benefits of the Database in one to two sentences.
  This summary should encapsulate the overall value proposition of the Database and its potential impact on users or the organization.>
  <empty line>
  <Highlight the most significant key benefits the Database has to offer in bulleted points. The format should be:
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  Aim for 3-5 bullet points that capture the most compelling advantages of using this Database, after each point add an empty line for formatting purposes.
  Each benefit should be distinct and provide a clear value proposition.>

  <Final Output Format>
  Output Format - Adhering to this format is crucial, the output should be in parsable JSON format:
  ```json
  {{
    "data": "<generated_summary in string format adhering to the Expected Output Format for Generated Summary>",
    "confidence_score": 90,
    "traceback": {{
      "Feature 1 Title": "Since it mentions about <exact phrase from the Table wise summary>, the 'Feature 1 Title' is included, as the "phrase" is an evidence that this feature is part of the Table wise summary.",
      "Feature 2 Title": "Since it mentions about <exact phrase from the Table wise summary>, the 'Feature 2 Title' is included, as the "phrase" is an evidence that this feature is part of the Table wise summary.",
      ...
    }}
  }}
  ```
  </Final Output Format>
  Note: If the traceback includes phrases that are not present in the Table wise summary then you would be penalized 10000 points.
  The output should be having data, confidence score, and traceback keys, and the entire content inside "```json" and "```" should be parsable by json.
  The "data" key should contain the generated summary and it should be in string format only, allowing the parsing of the entire json.
  If there are any inverted commas inside the generated summary, then escape them with a backslash.
  Do not change or skip the headings of each section in the generated json. The generated summary must have "Overview", "Highlighted Features", "Key Benefits" as section titles. Follow the above provided guidelines.
    """

    user_prompt += f"""Use the below Table wise summary to generate the summary in the above format: {combined_summary}""" + "User Defined Features : " + str(user_mvf)

    return system_prompt, user_prompt


def architecture_diagram_generation(services_data, icons_metadata):
    user_prompt = f"""
    <Input>
    $services_data = {services_data}
    $icons_metadata
    </Input>

    <Role>
    You are an expert at understanding large projects based on their executive summary and the services being used in them. Create a JSON structure for a ReactFlow diagram based on the given service class JSON.
    </Role>

    <Output Structure>
    1. Create a JSON object with a "nodes" and "edges" array.
    2. Create nodes for each external and third-party service.
    3. "nodes": An array containing all node objects.
      - "id": A unique string identifier for the node.
      - "data":   
        - "label": The name of the node.
        - "description": Description of the service.
        - "associated_files": Associated file and used in files in the service node, defaulting to "No File Available" if not present.
        - "group": The logical group name (e.g., 'Backend', 'Frontend', 'Database',etc..).
        - "subgroup": The specific subgroup within the group (e.g., Frameworks, NoSQL Databases, State Management, etc.).
        - "service": The appropriate filename of the icon based on the $icons_metadata.
      - "position" : The x and y coordinates of the node.
      - "type" : "customNode" This should be fixed.
    4. "edges" : An array having id, source, target, label, and type should be customEdge always.
    4. Ensure all services and files from the input JSON are included.
    5. The output should be in the form of a dictionary containing a "nodes" and "edges" array.
    6. Present only the code inside delimiters "```reactflow [reactflow CODE]```" without any additional explanation.
    """

    system_prompt:str = """
    <Task>
      You are tasked with creating a JSON structure for a ReactFlow diagram based on the given executive summary and the service_class_json. The executive summary contains an overview of the entire project. This JSON includes information about external services and third-party services, along with their associated files. Your output should represent this information as a network of nodes and edges.
    </Task>
    
    <Icons Context>
      $icons_metadata = """ + str(icons_metadata) + """
    </Icons Context>

    <Instructions>
      You are a solution expert, specializing in problem and solution flows. You will be given the solution overview for a project, and your task is to create an interconnected single component of graph which is detailed, and intuitive and self explanatory for:

      Follow these guidelines:
      1. Create nodes for each unique service (both external and third-party).
      2. Do not create any group nodes.
      4. In the data key for each service node, include two additional fields called group and subgroup. The group field should contain the logical group name (e.g., Frontend, Backend, Databases, etc..), and the subgroup field should provide more specific categorization (e.g., Frameworks, NoSQL Databases, etc..). For example, for a service node representing React, the group would be Frontend and the subgroup would be Frameworks.
      5. For each node, check which icon will be the most suitable from the $icons_metadata in the <Icons Context>
      6. Ensure all information from the input is represented in the output.
      7. The position coordinates must be proper for all the nodes.
    </Instructions>

    <Rules>
      **Ensure all nodes in the generated graph are interconnected such that every node has at least one edge, forming a single connected component without any isolated or disjoint sections. (High Priority Requirement)**
      Important Rules to be followed:
      1. Give detailed technical architecture flow and the JSON object following the below output format.
      2. Make sure that the flow and order of new solution approach is explained well in the graph with appropriate edges. Use as many edges you want to describe the data and user flow properly.
      3. The whole user and data flow should be clear.
      4. Do not add unnecessary nodes and edges. Do not create duplicate nodes that perform same task.
      5. Make the Node descriptions detailed, breaking tasks into multiple sub-tasks if needed.
      6. Ensure your edges show the actual flow, and not just connections of what's related. The connections are meant to show the logical flow, and not the relatedness/similarity.
      7. The group name is meant to classify clusters of nodes within each graph. For instance, if we have multiple nodes in features, they would all have "feature" as group. In Architecture Flow, the "Group" should show the layer each node is in, for instance "Backend Layer", "Database Layer" etc.
      9. for a hierarchy of nodes A -> B -> C; ensure that there is not a connection between A -> C.
    </Rules>
    
    <output_format>
    The output should be in between the delimeters ```reactflow and ```. Only provide the json output. Don't give unnecesary explanation.
    ```reactflow
    {
      "nodes": [
        { 
          "id": "unique_node_identifier_string",
          "data" : {
            "label": "name_of_the_service",
            "description": "description of the service",
            "associated_files": ["file_path_1", "file_path_2", "file_path_3", etc.],  // (default: ["No File Available"] if not present)
            "group": "name_of_group",  // Add the logical group name (e.g., "Frontend", "Backend", etc..)
            "subgroup": "name_of_subgroup",  // Add a more specific subgroup name (e.g., "Frameworks", "NoSQL Databases", etc..)
            "service": "filename" //taken from the $icons_metadata,
          }
          "position":{ "x": "Xcoordinate", "y": "Ycoordinate" },
          "type" : "customNode" //this is hardcoded and will be constant
        }
      ],
      "edges": [
        {
          "id": "unique_egde_identifier_string",
          "source": "label A",
          "target": "label B",
          "label": "Showcase what comes from the source node, to the target node. Be concise and specific with labels, such as 'Ingested Data', 'Converted Text', 'User Query' etc. Use at max 5 words",
          "type" : "customEdge" //this is hardcoded and will be constant
        }
      ]
    }```
    </output_format>
    """
    return system_prompt, user_prompt
  

def erd_generation(services_data, icons_metadata):
  tables_metadata = []
  for entry in services_data:
      table_name = entry["table_name"]
      ddl = entry["ddl"]
      columns, primary_keys, foreign_keys = parse_ddl(ddl)
      tables_metadata.append({
          "table_name": table_name,
          "columns": columns,
          "primary_keys": primary_keys,
          "foreign_keys": foreign_keys
      })

  dot = generate_combined_graph(tables_metadata)

  system_prompt:str = """
    You are tasked with creating a JSON structure for a ReactFlow diagram based on the given database ER diagram and schema JSON. This JSON includes information about database columns and their relationships.Your output should represent this information as a network of nodes and edges.
    </Task>
    
    <Icons Context>
      $icons_metadata = """ + str(icons_metadata) + """
    </Icons Context>

    <Instructions>
      You are a solution expert, specializing in problem and solution flows. You will be given the database schema information of a database, and your task is to create an interconnected single component of graph which is detailed, and intuitive and self explanatory for:

      Follow these guidelines:
      1. Create nodes for each unique service (both external and third-party).
      2. Do not create any group nodes.
      4. In the data key for each service node, include two additional fields called group and subgroup. The group field should contain the logical group name (e.g.,Databases, etc..), and the subgroup field should provide more specific categorization (e.g., 'Transactional Tables', 'Reference Tables' etc..). For example, for a service node representing daily transactions, the group would be Database and the subgroup would be Transactional Tables.
      5. For each node, check which icon will be the most suitable from the $icons_metadata in the <Icons Context>
      6. Ensure all information from the input is represented in the output.
      7. The position coordinates must be proper for all the nodes.
    </Instructions>

    <Rules>
      Important Rules to be followed:
      1. Give detailed technical architecture flow and the JSON object following the below output format.
      2. Make sure that the flow and order of new solution approach is explained well in the graph with appropriate edges. Use as many edges you want to describe the data and user flow properly.
      3. The whole user and data flow should be clear.
      4. Do not add unnecessary nodes and edges. Do not create duplicate nodes that perform same task.
      5. Make the Node descriptions detailed, breaking tasks into multiple sub-tasks if needed.
      6. Ensure your edges show the actual flow, and not just connections of what's related. The connections are meant to show the logical flow, and not the relatedness/similarity.
      7. The group name is meant to classify clusters of nodes within each graph. For instance, if we have multiple nodes in features, they would all have "feature" as group. In Architecture Flow, the "Group" should show the layer each node is in, for instance "Database Layer" etc.
      9. for a hierarchy of nodes A -> B -> C; ensure that there is not a connection between A -> C.
    </Rules>
    
    <output_format>
    The output should be in between the delimeters ```reactflow and ```. Only provide the json output. Don't give unnecesary explanation.
    ```reactflow
    {
      "nodes": [
        { 
          "id": "unique_node_identifier_string",
          "data" : {
            "label": "name_of_the_table",
            "description": "description of the table",
  	    "columns": ["order_id [PK]", "product_sku [PK]", "quantity", "unit_price"]
            "group": "name_of_group",  // Add the logical group name (e.g., "Database", etc..)
            "subgroup": "name_of_subgroup",  // Add a more specific subgroup name (e.g., 'Transactional Tables', 'Reference Tables', etc..)
            "service": "filename" //taken from the $icons_metadata,
          }
          "position":{ "x": "Xcoordinate", "y": "Ycoordinate" },
          "type" : "customNode" //this is hardcoded and will be constant
        }
      ],
      "edges": [
        {
          "id": "unique_egde_identifier_string",
          "source": "label A",
          "target": "label B",
          "label": "Showcase what comes from the source node, to the target node. Be concise and specific with labels, such as 'Ingested Data', 'Converted Text', 'User Query' etc. Use at max 5 words",
          "type" : "customEdge" //this is hardcoded and will be constant
        }
      ]
    }```
    </output_format>
    """
    
  user_prompt:str = f"""
    <Input>
    $database_tables = {dot}
    $icons_metadata
    </Input>

    <Role>
    You are an expert at understanding database architecture based on ER diagrams and relational structures. Create a JSON structure for a ReactFlow diagram based on the given database schema.
    </Role>
    <Output Structure>
      1. Create a JSON object with a "nodes" and "edges" array.
      2. Create nodes for each table in the schema.
      3. "nodes": An array containing all node objects.
      - "id": A unique string identifier for the node.
      - "data":  
        - "label": The name of the table.
        - "description": A brief summary of the table's role or content.
        - "columns": List of column names (mark primary keys with [PK], foreign keys with [FK]).
        - "group": The logical group name (e.g., 'Database').
        - "subgroup": The specific subgroup within the group (e.g., 'Transactional Tables', 'Reference Tables').
        - "service": The appropriate filename of the icon based on the $icons_metadata.
      - "position" : The x and y coordinates of the node.
      - "type" : "customNode" This should be fixed.
      4. "edges" : An array having id, source, target, label, and type should be customEdge always.
      5. The label of the edge should describe the relationship, like "order_id â†’ order_id". 
      6. The output should be in the form of a dictionary containing a "nodes" and "edges" array.
      7. Present only the code inside delimiters "```reactflow [reactflow CODE]```" without any additional explanation.
    """
    
  return system_prompt, user_prompt
    

def feature_summary_generation(formatted_data, user_mvf, executive_summary):
    # if input_type is None:
    #     formatted_data = file_summary_list
    # elif input_type == "batch_summary":
    #     formatted_data = format_batchwise_summary_metadata_for_services(file_summary_list)
    # else:
    #     formatted_data = format_file_summaries(file_summary_list)

    user_prompt = """
    Role: You are an AI code analyst specializing in creating concise, feature-level summaries of codebases.

    Objective: Provide a comprehensive yet concise feature-level summary of a given codebase, highlighting key components, functionality, and the project's overall workflow.

    Input: You will receive information about a codebase, which may include an executive summary or other project details.

    Steps:
    1. Analyze the provided codebase information.
    2. Identify the main features (maximum 5) of the project from the executive summary (if provided in same order)
    3. Create a summary following the specified format, including:
        a. An overview of the project
        b. A list of key features with brief descriptions
        c. A closure statement
    4. Self-evaluate the generated summary and assign a confidence score.
    5. Format the output as specified in the instructions.

    Output Format:
    ```json
    {
        "data": "generated_summary in string format adhering to the Detailed Instructions for Output Format",
        "confidence_score": 90
    }
    ```

    Detailed Instructions for Output Format:

    **Overview**
    <empty line>
    < 
        Summarize all features in 2-3 sentences, introducing the project and its purpose.
        Provide a 2-3 sentence summary of key benefits, highlighting core architecture and value proposition.
    >
    <empty line>
    **Key Features**
    <empty line>
    <   
        List a maximum of 5 main features.
        For each feature, provide up to 2 sub-points describing its functionality.
        Ensure clear explanation of how features interact and contribute to the project's goals.
        1. ***<Key Feature Title>*** : 
        * <Sub point 1 description>
        * <Sub point 2 description>
        <empty line>
    >
    <empty line>
    < 
        Summarize the overall impact and value proposition of the project in one sentence as a conclusion statement.
    >
    <empty line>
    
    -> Self-Evaluation:
        - Score the summary out of 100 based on clarity, precision, detail, knowledge, accuracy, technical correctness, and understanding of the data.

    -> Formatting Requirements:
        - Replace all newline characters (\n) with \\n in the JSON output.
        - Ensure the complete JSON is less than 7500 tokens.
        - Start the output with "```json" and end with "```".
        - If an executive summary is provided, use only the highlighted features from it.

    Example Output Structure:
    ```json
    {
        "data": "**Overview**\\n\\n[Project overview]\\n\\n[Benefits summary]\\n\\n**Key Features**\\n\\n1. *Feature 1*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n2. *Feature 2*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n[...continue for up to 5 features...]\\n\\n[Closure statement]",
        "confidence_score": 90
    }
    ```

    Remember: Adhere strictly to the output format and instructions to maintain consistency and accuracy in your summary.
    """

    user_prompt += "User Defined Features : " + str(user_mvf)

    system_prompt = f"""
        <role>
        You are an assistant to a Senior Software Engineer. You are very capable in reading and understanding huge codebases.
        There is no edge-case, no mistake, no functionality no matter how small goes unnoticed by you.
        You will be given a large codebase and be asked queries regarding it.
        </role>

        <Task>
        You will be given relevant files from a production codebase. The Senior Engineer will consult you to clear his doubts and ask for critical code-level and functionality level analysis of the same.
        <Important>
        1. You will be clear. Feel free to be descriptive but Avoid Jargon
        2. You shall perform critical analysis on the code before responding.
        3. Note that the codebase will be quite complex and have dependencies everywhere, be mindful of them all.
        4. Enclose code in (triple backticks)``` code ```
        </Important>
        </Task>

        Files from Codebase goes here :
        <Repo Structure>
        {formatted_data}
        </Repo Structure>
    """

    start_index = executive_summary.find("Highlighted Features")
    end_index = executive_summary.find("Key Benefits")

    if start_index != -1 and end_index != -1:
        executive_summary = executive_summary[start_index:end_index].strip()

    user_prompt += "Executive Summary : " + str(executive_summary)

    return system_prompt, user_prompt

def feature_summary_generation_db(formatted_data, user_mvf, executive_summary):
    # if input_type is None:
    #     formatted_data = file_summary_list
    # elif input_type == "batch_summary":
    #     formatted_data = format_batchwise_summary_metadata_for_services(file_summary_list)
    # else:
    #     formatted_data = format_file_summaries(file_summary_list)

    user_prompt = """
    Role: You are an AI Database Analyst specializing in creating concise, feature-level summaries of complex database schemas and architectures.

    Objective: Provide a comprehensive yet concise feature-level summary of a given database schema information, highlighting key components, entities, relationships, and the overall data architecture workflow.

    Input: You will receive information about a database design, which may include an executive summary or other schema-level details.

    Steps:
    1. Analyze the provided database schema information.
    2. Identify the main features (maximum 5) of the database from the executive summary (if provided in same order)
    3. Create a summary following the specified format, including:
        a. An overview of the database
        b. A list of key features with brief descriptions
        c. A closure statement
    4. Self-evaluate the generated summary and assign a confidence score.
    5. Format the output as specified in the instructions.

    Output Format:
    ```json
    {
        "data": "generated_summary in string format adhering to the Detailed Instructions for Output Format",
        "confidence_score": 90
    }
    ```

    Detailed Instructions for Output Format:

    **Overview**
    <empty line>
    < 
        Summarize all features in 2-3 sentences, introducing the database and its purpose.
        Provide a 2-3 sentence summary of key benefits, highlighting schema structure, normalization or denormalization logic, and value proposition in handling data.
    >
    <empty line>
    **Key Features**
    <empty line>
    <   
        List a maximum of 5 main features.
        For each feature, provide up to 2 sub-points describing its data handling, relationships, or optimization logic.
        Ensure clear explanation of how features contribute to performance, consistency, and data integrity.
        1. ***<Key Feature Title>*** : 
        * <Sub point 1 description>
        * <Sub point 2 description>
        <empty line>
    >
    <empty line>
    < 
        Summarize the overall impact and value proposition of the database in one sentence as a conclusion statement.
    >
    <empty line>
    
    -> Self-Evaluation:
        - Score the summary out of 100 based on clarity, precision, detail, knowledge, accuracy, technical correctness, and understanding of the schema information.

    -> Formatting Requirements:
        - Replace all newline characters (\n) with \\n in the JSON output.
        - Ensure the complete JSON is less than 7500 tokens.
        - Start the output with "```json" and end with "```".
        - If an executive summary is provided, use only the highlighted features from it.

    Example Output Structure:
    ```json
    {
        "data": "**Overview**\\n\\n[Database overview]\\n\\n[Benefits summary]\\n\\n**Key Features**\\n\\n1. *Feature 1*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n2. *Feature 2*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n[...continue for up to 5 features...]\\n\\n[Closure statement]",
        "confidence_score": 90
    }
    ```

    Remember: Adhere strictly to the output format and instructions to maintain consistency and accuracy in your summary.
    """

    user_prompt += "User Defined Features : " + str(user_mvf)

    system_prompt = f"""
        <role>
        You are an assistant to a Senior Data Architect. You are very capable in reading, analyzing, and understanding complex database schemas and data models.
        No entity, constraint, relationship, or optimization logic goes unnoticed by you.
        You will be given a comprehensive database structure or schema information and will be asked to analyze, explain, and summarize it at a structural and functional level.
        </role>

        <Task>
        You will be given relevant database schema files or DDL definitions. The Senior Data Architect will consult you to clear doubts and ask for critical schema-level and data model-level analysis.
        <Important>
        1. You will be clear. Feel free to be descriptive but Avoid Jargon
        2. Perform a critical and deep analysis of the schema and the information given before responding.
        3. The schema will often involve multiple tables, foreign keys, views, procedures, and indexing strategies â€” be mindful of their dependencies and relationships.
        4. Enclose code or schema in (triple backticks)``` code ```
        </Important>
        </Task>

        Files from Database schema goes here :
        <Database Structure>
        {formatted_data}
        </Database Structure>
    """

    start_index = executive_summary.find("Highlighted Features")
    end_index = executive_summary.find("Key Benefits")

    if start_index != -1 and end_index != -1:
        executive_summary = executive_summary[start_index:end_index].strip()

    user_prompt += "Executive Summary : " + str(executive_summary)

    return system_prompt, user_prompt


#FEATURE HIERARCHY:
generate_features_system_prompt = """
  <Role>
    You are a Software Architect with expertise in analyzing large summaries from code files of an application. 
    You can comprehend summaries from code files that are complex, production-grade and are written in various programming languages to generate most important features, their description and the subfeatures with their description belonging to the most important features along with the other relevant information requested below.
    
    You will follow 2 Events before responding : 
    1. Generation of Feature Hierarchy as given in "Output_Format".
    2. Critical Evaluation of Every Confidence Score.  
  </Role> 

    <Task 1>
    You are provided with multiple relative file paths and file-wise code summaries from a application codebase.
    1. Analyze the file summaries carefully, leveraging your expertise to deduce the frameworks, functionality, and features.
    2. Perform a critical assessment of the code's functionality and interdependencies before responding.
    3. The codebase is complex and likely contains dependencies across various modules. Be mindful of these.
    4. Analyse every file summary and assign the features and sub-features based on the information provided.
    5. Respond strictly in the structured JSON format provided below.
    6. In each sub-feature's 'file_path' array:
        - Set 'critical: true' ONLY for files that are CORE & NON-REPLACEABLE to the sub-feature's main functionality.
        - Set 'critical: false' for ALL supporting, secondary, or replaceable files  
        - Each sub-feature should have both true and false entries.
        - If unsure, default to false (be EXTREMELY selective with 'true')
        - Make sure each sub-feature atleast have one file as true.

    Explanation of the Output terms:
    Feature - Features are most valuable and high level features extracted from the list of summaries that are provided to you. 
    Feature description - Description of the features explaining the high level value and impact that it creates for the project. Define the Feature. The description should be crisp, precise, well formatted and must be between 2-3 lines.
    Subfeature - Subfeatures are micro most valuable features that are extracted from the list of summaries and belong to the Most related and similar Features.
    Subfeature description - Description of the subfeatures explaining the specific value, technical and non-technical functionalites that it provided to the project. Define the subfeature and also explain how its related to the feature. The description should be crisp, precise, well formatted and must be between 2-3 lines.
    
    Points to Remember:
    1. Do not extract any feature or subfeature where there are no reference/citations from the application summaries.
    2. The description must be precise, valuable, well-formatted and must be between 2-3 lines.
    3. The Feature titles should be precise, specific, self explanaible, independent and not have similar feature titles. The Feature titles should not be highly generalized.
    4. The SubFeatures titles should be precise, self explanaible and not have similar subfeature titles. The SubFeature titles should not be highly generalized.
    5. SubFeatures should not be very low level that it explains code functions, code process like 'Json handling', 'Reading csv', readME etc.
    6. If similar subfeatures are present, then group them under one common Feature itself. Do not create multuple Features for similar subfeatures.
    6. If Unit testing related summaries are found, then create that as another Feature named 'Unit Testing' and assign the specific testing subfeatures under this feature.
    </Task 1>

  <Task 2>
  You shall now Assign and Justify Confidence Scores for each feature.

  <Critical Evaluation of Confidence Scores> 

  <Evaluation MODE>
  - You will now Forget everything that was done beforehand and act as an unbiased judge.
  - $Project-Summaries-&-Paths (INPUT).
  </Evaluation MODE>
  <Important>
  Critically analyze every "Feature" and "SubFeature" based on the following metrics. 
  You shall generate a confidence score between 0-100 for each of the following :
  1. Is the "Feature" & "SubFeature" name accurate to its functionality ? (Accuracy)
  2. Does the "Feature" & "SubFeature" include files with an unrelated function ? (Feature Dilution Rate)
  3. Important : Does this "Feature" & "SubFeature" make sense given the Overall Purpose of the Application ? (Consistency)
  4. Are all the files in "Feature" & "SubFeature" included ? (Completeness)

  <Strict>
  1. You will now generate a list of 4 confidence scores between 0-100 for above criteria under "confidence_score" key.
  2. Based on above criteria, you shall provide a VERY BRIEF logical explanation (10-20 words) for Confidence Score under "confidence_score_justification" key.
  3. Make sure to mention the entire filepath without omitting the prefix.
  4. Make sure all the filepaths are present.
  <Important> STRICTLY Don't Comment on Missing Files. Don't Overestimate. Don't Underestimate.</Important> 
  </Strict>

  </Important>

  </Critical Evaluation of Confidence Scores> 
  </Step 2>


      <Output_Format>
    Return a response in JSON format. Do not include any extra information or explanations. Strictly DON'T deviate from mentioned KEYS.
    Example:
```json
[
  {
    "name": "User Authentication and Management",
    "feature_description": "Comprehensive user account system with secure login, registration, profile management, and role-based access control.",
    "feature_description_confidence_score": [95, 70, 100, 70],
    "sub_features": [
      {
        "name": "User Registration",
        "description": "Allows new users to create accounts by providing necessary information such as username, email, and password. Implements email verification, password strength checks, and duplicate account prevention. Stores user data securely in the database with password hashing.",
        "file_path": [
          {
            "module_name": "RegistrationController",
            "path": "Controllers/Account/RegistrationController.cs",
            "critical": true
          },
          {
            "module_name": "RegisterView",
            "path": "Views/Account/Register.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [75, 80, 85, 65],
        "sub_feature_confidence_score_justification": "No feature dilution, might have missed some file."
      },
      {
        "name": "User Login",
        "description": "Authenticates users using their credentials, creates and manages user sessions, and implements security measures such as login attempt limiting and two-factor authentication (2FA). Provides password reset functionality for forgotten passwords.",
        "file_path": [
          {
            "module_name": "LoginController",
            "path": "Controllers/Account/LoginController.cs",
            "critical": true
          },
          {
            "module_name": "LoginView",
            "path": "Views/Account/Login.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [80, 100, 80, 75],
        "sub_feature_confidence_score_justification": "High chance of missing files."
      }
    ],
    "feature_confidence_score_justification": "No feature dilution, duplication or missing files. Accurate Naming."
  },
  {
    "name": "Product Catalog Management",
    "feature_description": "Comprehensive system for managing product listings, categories, and inventory across the e-commerce platform.",
    "feature_description_confidence_score": [95, 65, 70, 80],
    "sub_features": [
      {
        "name": "Product CRUD Operations",
        "description": "Enables administrators to create, read, update, and delete product listings. Includes functionality for managing product details such as name, description, price, images, and inventory levels. Implements validation to ensure data integrity and consistency across the product catalog.",
        "file_path": [
          {
            "module_name": "ProductController",
            "path": "Controllers/ProductController.cs",
            "critical": true
          },
          {
            "module_name": "ProductView",
            "path": "Views/Product/Index.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [90, 85, 100, 70],
        "sub_feature_confidence_score_justification": "High confidence with no duplication or dilution."
      },
      {
        "name": "Category Management",
        "description": "Allows for the creation and management of product categories and subcategories. Implements a hierarchical structure for organizing products, enabling efficient navigation and filtering of the product catalog for both administrators and customers.",
        "file_path": [
          {
            "module_name": "CategoryController",
            "path": "Controllers/CategoryController.cs",
            "critical": true
          },
          {
            "module_name": "CategoryView",
            "path": "Views/Category/Index.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [85, 75, 90, 95],
        "sub_feature_confidence_score_justification": "High confidence without any duplication or dilution."
      }
    ],
    "feature_confidence_score_justification": "All files refer to single overall functionality. Might have missed some files."
  }
]
```
  </Output_Format>

"""

generate_features_user_message = """
<Strictly Remember>
1. As input you will be given a batch of `file_path` and `file_summary` from a production codebase. Keep it in mind that it could be a file from a very large repository with lot of inter-dependencies.
2. Understand all the file description first, then try to determine the feature, sub-features and their description. For **each file** it should have a feature or sub-features whenever the conditions are met.
3. The response should contain all the fields given in the example output format. The response should be strictly in json format.
4. The description of features/subfeatures must be in the length of 2-3 lines. The response should be structured and well-formatted.
5. Don't generate any additional explanation or description. Provide the structured response in json only.
</Strictly Remember>
  
<Input file wise summary>
{file_summary}
</Input file wise summary>
<Response>
"""

merge_features_in_hierarchy_user_prompt = """You are a software feature analyzer. Given a list of related features that have been clustered together, create a merged feature that encompasses all the functionality.

Features to merge:
{feature_list}

Generate a JSON response that includes:
1. A name for the merged feature representing accurate feature name. Do not mention its merged or unified or anything as such. The feature name should accurately represent a major funcationality of a repository.
2. A detailed description that covers all functionality
3. A confidence score (0-100) for the merge
4. A justification for the confidence score

Respond with a JSON object in the following format:
```json
{{
    "name": "Merged feature name",
    "description": "Comprehensive description",
    "confidence_score": 85,
    "confidence_justification": "Reason for the confidence score"
}}
```
Give only JSON and nothing else. Do not include any explanations or additional text outside the JSON block. Make sure to start with ```json and end with ``` only.
"""

mapping_names_for_merged_features_user_prompt = """  <Role>
    You are a smart AI cassistant with strong expertise in Software Engineering. You can understand complex, production-grade codebases written in various programming languages and summarize them effectively.
  </Role>
  <Task>
  You will be given a brief description of  features of a large codebase and your task is to generate a relevant feature name, brief description, and priority level.
  <Important>
   1. The feature name should be brief, relevant and should represent the entire description provided.
   2. Generate a relevant description which is basically a overall summary of the description provided.
   3. Assign a priority level (high, medium, low) based on the significance, importance and complexity of the feature to the overall system. 
  </important>
  </Task>
  <Example output>
  ```json
    {
        "name": <feature_name>, //string
        "feature_description": <feature_description>, //string
        "priority": <priority> //string (high, medium, or low)
    }
    ```
  </Example output>
  <Strictly Remember>
1. The feature name should be relevant and at the same time interpretable, easy to understand.
2. The feature description should represnt the entire description given for summarisation, it should be simple and easy to understant.
3. The priority should be one of: high, medium, or low.
4. The response should be strictly in json format specified above.
5. Strictly make sure Feature Description is not more than 200 words.
  </Strictly Remember>

<code summary>
The code summary is given below:
"""


reducing_sub_features_user_prompt = """
    You are a software feature consolidation expert. Your task is to merge similar sub-features into one comprehensive sub-feature.

    Here are the sub-features that need to be merged:
    {sub_features_list}

    For each sub-feature, we have:
    - Name: The sub-feature name
    - Description: The sub-feature description (if available)
    - Confidence Score: The confidence score (if available)

    Your output should be a JSON object containing:
    1. A unified sub-feature name that encompasses all the input sub-features
    2. A comprehensive description that covers all aspects of the input sub-features
    3. A confidence score (use the highest available from input sub-features)
    4. A justification for the confidence score

    Return the output in JSON format starting with ```json and ending with ```.

    Example output format:
    ```json
    {{
        "name": "Unified Sub-Feature Name",
        "description": "Comprehensive description covering all aspects",
        "sub_feature_confidence_score": 95,
        "sub_feature_confidence_score_justification": "Merged from similar sub-features with high semantic similarity"
    }}
    ```
    """


post_processing_feature_name_description_system_prompt="""
  <Role>
    You are a smart AI assistant with strong expertise in Software Engineering. You can understand complex, production-grade codebases written in various programming languages and summarize them effectively.
  </Role>
  <Task>
  You will be given a brief description of modules or features of a large codebase and your task is to generate a relevant feature name and brief description.
  <Important>
   1. The feature name should be brief, relevant and should represent the entire description provided.
   2. Generate a relevant description which is basically a overall summary of the description provided.
   3. Also generate a confidence score in a scale of 0 - 100.
  </important>
  </Task>
  <Example output>
  ```json
    {
        "name": <feature_name>,
        "feature_description_confidence_score": <score 0 - 100>,
        "feature_description": <feature_description>
    }```
  </Example output>"""

post_processing_feature_name_description_user_prompt = """<Strictly Remember>
1. The feature name should be relevant and at the same time interpretable, easy to understant.
2. The confidence score should represent the ability to summarise the description.
3. The feature description should represnt the entire description given for summarisation, it should be simple and easy to understant.
4. The response should be strictly in json format specified above.
</Strictly Remember>
<code summary>
The code summary is given below: \n
{feature_description}
</code_summary>
<response>
Your response in json goes here:
"""

merge_similar_features_system_prompt = """You are a solution architect. Your task is to carefully review each feature and its description, and combine them into a single high-level feature.

The final high-level features should represent what an end user would perceive, e.g., Messenger, Google Chat, Messaging, Reels, etc.

Based on the generated features provided, identify which features can be merged into a single high-level feature. 
Strictly output them in the following format:
{{ 
  <High-Level Feature Name 1>: [<Merged Feature 1>, <Merged Feature 2>, <Merged Feature 3>, ...],
  <High-Level Feature Name 2>: [<Merged Feature 1>, <Merged Feature 2>, <Merged Feature 3>, ...],
  ...
}}

INPUT:
Feature names and descriptions are provided in the format: 
[1. Feature name: <feature name> 
Feature description: <feature description>, 
2. ...]

{feature_texts}

MVFS:
{total_MVFs}

Points to remember:
1. While merging features and naming high-level features, always prefer names from the user-defined MVFs provided. All relevant features can be grouped under these high-level features.
2. If certain features do not fit under the user-defined MVFs, choose a better name than the existing one for the new high-level feature if necessary.
3. The names of the features being merged must remain exactly as provided in the INPUT section; do not modify them. Do not consider Feature description in Feature Names.
4. Follow the output structure strictly: high-level feature names as dictionary keys and merged features as values in list format.
5. If a feature is already a high-level feature, you do not need to forcibly merge it. If a feature seems to be function-level/low-level  features, merge them into a High-level feature.
6. Merge similar features into a single high-level feature based on their names and descriptions, when applicable. Each final high-level feature should be independent of the others.
7. Do not assign the same feature to multiple high-level features.
8. If user-defined MVFs are empty, skip point 1 and begin with point 2.
9. Do **not** include any Feature descriptions in the final output."""


merging_description_user_prompt = """You are a Solution Architect. Your task is to summarize the multiple feature descriptions provided into a brief, coherent summary of **no more than two sentences**.

  The summary must:
  - Accurately capture all key components from the provided descriptions.
  - Align clearly with the given high-level feature name.
  - Serve as the final description of the high-level feature.

  Only the final summarized description should be included in the output â€” no additional commentary or formatting.

  INPUT:
  Multiple descriptions: {merging_feature_description}

  High-Level Feature Name: {high_level_feature}
  """


micro_sub_feature_prompt = """You are an expert system analyst specializing in decomposing SubFeatures into granular, logically independent components. You support **two levels** of splitting:

1. **Horizontal splitting**: Split a subfeature into multiple *same-level subfeatures* when it encompasses multiple independently meaningful functionalities. The subfeatures created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.
2. **Vertical splitting**: Further break each of those subfeatures into *microsubfeatures* (if applicable), ensuring each micro-sub-features/micro-user-story describes a single goal or operation. The micro-sub-features/micro-user-story created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.

---

### ðŸ”§ TASK OVERVIEW

Given a Macro-Feature, Subfeature, its description, associated module files and its summary:

- Decide if the subfeature should be split horizontally into multiple same-level subfeatures.
- For each resulting subfeature (or original if not split), analyze whether it can be split vertically into **microsubfeatures** (fine-grained user stories).
- Provide the confidence scores for the subfeature that is split, whether horizontally or vertically.
- Provide the files that are related to the sub_features too, not just the micro_sub_features.
- Each leaf user-story must have files assigned to them, else you should not create/split these subfeatures.
- Provide description of generated subfeature/sub-user-stories in 2-4 lines but only valid information. Do not assume or hallucinate to generate description.
Apply this recursively: if horizontal splitting occurs, then attempt vertical splitting for each. But remember, not to create any duplicates in the process. 

---

### SPLITTING DECISIONS

#### Horizontal Splitting (Same-level Subfeatures):
Split if:
- The subfeature covers multiple high-level functionalities
- Each function could be planned, developed, and deployed independently
- Each component has a clear boundary and responsibility

#### Vertical Splitting (Microsubfeatures):
Split further if:
- A subfeature contains multiple independent operations or logical stages
- These operations can be implemented, tested, or tracked separately
- Each micro-subfeature represents one atomic, non-overlapping functionality

---

### DO NOT SPLIT IF:
- sub-user-stories are tightly coupled in the Subfeature and cannot function independently.
- Do not split subfeatures into sub-user-stories that are hardly single line of code and cannot be considered as a proper functionality, but just a config/parameter.
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across actions are too complex to isolate.
- There are no files that can be mapped to the generated user-story.
- Do not split if the user-story is barely a functionality. The split user-stories must have independent functionality that contributes to the subfeature and feature and if not, do not split.
- Don not split ReadMe & .md files into sub-user-stories.
- Do not split horizontall for granullar subfeatures as they are not user stories but mid level features.
---

### FILE MAPPING RULES:
- For each subfeature or microsubfeature, cite only directly relevant files.
- Use only the provided input data to match files â€” no guessing.
- Avoid duplication unless a file is clearly shared between components.

Each `file_path` entry must include:
```json
{
  "module_name": "<Name>",
  "path": "<Path>",
  "critical": <true/false>,
  "git_url": "<Git URL>"
}

OUTPUT FORMAT
If the subfeature should NOT be split:
Return: "None"

If the subfeature should be split, return a list of Parent User Stories with subfeatures inside.
If a subfeature itself can be further split into microsubfeatures, nest them under micro_sub_features like so:

[
  {
    "name": "Parent User Story Title 1",
    "description": "Full description of the original or updated user story and its purpose.",
    "file_path": [...],
    "sub_feature_confidence_score":"confidence score of the subfeature with respect to the Feature, as a percentage (e.g., 80)"
    "micro_sub_features": [
      {
        "name": "Sub-User Story Title 1",
        "description": "Standalone description of a single functionality.",
        "file_path": [...],
        "micro_sub_feature_confidence_score":"confidence score of the micro_sub_feature with respect to the sub_feature, as a percentage (e.g., 90)"
        }
          ...
        ]
      },
      ...
    ]
  }
]
Each layer must preserve independence, clarity, and singular focus of each story.

VALIDATION CHECKLIST
- Each title must express one functionality only (no imperative phrasing)
- description must avoid assumptions and describe the real function. It must be as detailled as possible.
- Each story must make sense independently and fit in the broader feature flow
- if there are multiple user-story under the subfeature, it needs to be in sequence of business logic.
- File mappings must be relevant and scoped accurately
- Do no miss/skip any values in the output json. The output structure must be maintained strictly.
- All subfeature and sub-user-story names and descriptions must be strictly in a declarative tone, not imperative.

* Use generic or speculative statements
"""


db_micro_sub_feature_prompt = """
<Role>
You are an expert Database analyst specializing in decomposing SubFeatures into granular, logically independent components. You support **two levels** of splitting:
You shall ALWAYS process features from a Database perspective ONLY. 
There can be more than one Table in the DB context provided to you.
</Role>

1. **Horizontal splitting**: Split a subfeature into multiple *same-level subfeatures* when it encompasses multiple independently meaningful functionalities. The subfeatures created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.
2. **Vertical splitting**: Further break each of those subfeatures into *microsubfeatures* (if applicable), ensuring each micro-sub-features/micro-user-story describes a single goal or operation. The micro-sub-features/micro-user-story created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.

<Strict Constraints> 
- You are dealing with Database Information. 
- No matter what, STRICTLY use Database-Specific Language ALWAYS. 
- Use words like Columns / Fields / Schema / DataTypes / Constraints / Foreign Keys / Primary Keys etc.
- Strictly Do not start descriptions with or start with "this micro-feature" / or "this sub-feature".
- You shall do this regardless of the input context and nature.
Remember : Every "FILE" given to you is information of a table. Therefore in your response, ALWAYS refer to "Table" instead of "File".

</Strict Constraints> 


### ðŸ”§ TASK OVERVIEW

Given a Macro-Feature, Subfeature, its description, associated module files and its summary:

- Decide if the subfeature should be split horizontally into multiple same-level subfeatures.
- For each resulting subfeature (or original if not split), analyze whether it can be split vertically into **microsubfeatures** (fine-grained user stories).
- Provide the confidence scores for the subfeature that is split, whether horizontally or vertically.
- Provide the files that are related to the sub_features too, not just the micro_sub_features.
- Each leaf user-story must have files assigned to them, else you should not create/split these subfeatures.
- Provide description of generated subfeature/sub-user-stories in 2-4 lines but only valid information. Do not assume or hallucinate to generate description.
Apply this recursively: if horizontal splitting occurs, then attempt vertical splitting for each. But remember, not to create any duplicates in the process. 

---

### SPLITTING DECISIONS

#### Horizontal Splitting (Same-level Subfeatures):
Split if:
- The subfeature covers ONE / MORE THAN ONE high-level functionalities
- Each function could be planned and developed independently
- Each component has some clear boundaries and responsibilities

#### Vertical Splitting (Microsubfeatures):
Split further if:
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across actions are too complex to isolate.
- There are no tables that can be mapped to the generated user-story.
- The subfeature is too complex to be planned, developed, and deployed independently
- Each micro-subfeature represents one atomic, non-overlapping functionality
Note: Maintain at least 2 subfeatures unless the database has only one table.
- Prioritize brevity, consistency and no informaiton leakage across subfeatures.
- Ensure crisp segregation.
---

### DO NOT SPLIT IF:
- sub-user-stories are tightly coupled in the Subfeature and cannot function independently.
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across tables in two features are too complex to isolate.
- There are no tables that can be mapped to the generated user-story.
Note: Maintain at least 2 subfeatures and 1 or more microsubfeatures per subfeature, Unless the database has only one table.
Note : Maintain brevity during splitting at the same level. Do NOT overload the a single feature with too many subfeatures.
---


### FILE MAPPING RULES:
- For each subfeature or microsubfeature, cite only directly relevant tables.
- Use only the provided input data to match files â€” no guessing.
- Avoid duplication unless a file is clearly shared between components.

Each `file_path` entry must include:
```json
{
  "module_name": "<Name>",
  "path": "<Path>",
  "critical": <true/false>,
  "git_url": "<Git URL>"
}

OUTPUT FORMAT
If the subfeature should NOT be split:
Return: "None"

If the subfeature should be split, return a list of Parent User Stories with subfeatures inside.
If a subfeature itself can be further split into microsubfeatures, nest them under micro_sub_features like so:

[
  {
    "name": "Parent User Story Title 1",
    "description": "Full description of the original or updated user story and its purpose.",
    "file_path": [...],
    "sub_feature_confidence_score":"confidence score of the subfeature with respect to the Feature, as a percentage (e.g., 80)"
    "micro_sub_features": [
      {
        "name": "Sub-User Story Title 1",
        "description": "Standalone description of a single functionality.",
        "file_path": [...],
        "micro_sub_feature_confidence_score":"confidence score of the micro_sub_feature with respect to the sub_feature, as a percentage (e.g., 90)"
        }
          ...
        ]
      },
      ...
    ]
  }
]
Each layer must preserve independence, clarity, and singular focus of each story.

VALIDATION CHECKLIST
- Each title must express one functionality only (no imperative phrasing)
- description must avoid assumptions and describe the real function. It must be as detailled as possible.
- Each story must make sense independently and fit in the broader feature flow
- if there are multiple user-story under the subfeature, it needs to be in sequence of business logic.
- File mappings must be relevant and scoped accurately
- Do no miss/skip any values in the output json. The output structure must be maintained strictly.
- All subfeature and sub-user-story names and descriptions must be strictly in a declarative tone, not imperative.
- Use Database-specific schema only. Do not include words like "Attributes" / "Code Files" in your response. 
- Strictly Do not start descriptions with or start with "this micro-feature" / or "this sub-feature".
* Use generic or speculative statements

"""import os
from graphviz import Digraph
import re 
import json

def parse_ddl(ddl: str):
    """
    Parse the DDL to extract columns, primary keys, and foreign keys.
    """
    lines = ddl.splitlines()
    column_lines = []

    for line in lines:
        line = line.strip()
        if (
            line.upper().startswith("CREATE")
            or line.upper().startswith("PRIMARY")
            or line.upper().startswith("FOREIGN")
            or line.upper().startswith(")")
            or line == ""
        ):
            continue

        match = re.match(r'(\w+)\s+\w+', line)
        if match:
            column_lines.append(match.group(1))

    pk_match = re.search(r'PRIMARY KEY\s*\((.*?)\)', ddl)
    primary_keys = [key.strip() for key in pk_match.group(1).split(",")] if pk_match else []

    foreign_keys = []
    for match in re.finditer(r'FOREIGN KEY\s*\(([^)]+)\)\s+REFERENCES\s+`?[\w]+\.(\w+)`\(([^)]+)\)', ddl):
        fk_col = match.group(1).strip()
        ref_table = match.group(2).strip()
        ref_col = match.group(3).strip()
        foreign_keys.append((fk_col, ref_table, ref_col))

    return column_lines, primary_keys, foreign_keys


def generate_combined_graph(tables_data):
    """
    Generate a single combined graph from multiple tables.
    """
    dot = Digraph(comment='Combined Table Diagram')
    dot.attr(rankdir='LR')

    # Store individual table nodes
    for table in tables_data:
        table_name = table['table_name']
        columns = table['columns']
        primary_keys = table['primary_keys']
        
        label_lines = []
        for col in columns:
            if col in primary_keys:
                label_lines.append(f"{col} [PK]")
            else:
                label_lines.append(col)
        dot.node(table_name, shape='box', label=f'{table_name}\\n' + "\\n".join(label_lines))

    # Add relationships
    for table in tables_data:
        table_name = table['table_name']
        for fk_col, ref_table, ref_col in table['foreign_keys']:
            dot.edge(table_name, ref_table, label=f'{fk_col} â†’ {ref_col}')

    return dot

def folder_summary_generation_prompts(
        total_allocated_tokens, 
        file_list, folder_name, 
        folder_path,
        subfolder_list,
        formatted_file_summaries,
        formatted_file_services,
        formatted_subfolder_summaries,
        formatted_subfolder_services,
        formatted_subfolder_features
    ):
    
    system_prompt = f"""
        You are an expert code analyst specialized in creating detailed, informative summaries of software project folders. Your task is to thoroughly analyze files and subfolders to provide a comprehensive understanding of the application or project and provide combined summaries along with required details. These summaries must be detailled enough for further summarization.

        Follow these guidelines:
        1. Conduct a deep analysis of the features to identify its core purpose and functionality
        2. Provide detailed explanation of key implementations and technical approaches of the features
        3. Thoroughly examine the summaries based on files and folders to understand relationship between features and combined smaller features into larger high level application level features.
        4. Explain the features within the broader project architecture with specific connections
        5. Describe technical patterns, design decisions, and architectural choices evident in the code
        6. Include specific functions, classes, and methods that define the feature's behavior
        7. Note dependencies, imports, and external connections that shape the folder's functionality
        8. Identify potential architectural strengths and areas for improvement when evident
        9. Identify all services represented in this folder based on file and subfolder services information
        10. Identify and articulate high-level features or functionalities represented by the folder into the feature_details section, when consolidating multiple subfolders or lower-level files. Derive these insights from both file-level and subfolder-level summaries. Also under each feature, mention which file/folder was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
        11. Do not miss any features that could be formed based on these summaries as this information is required to understand the application's buisness logic.
        12. Gather insights from the summaries provided to generate a high level detailled executive summary that could be used by business stakeholders to understand the folder/project.
        13. When analyzing the root folder, both the executive summary and the features must be strictly formed in a high level business logic standpoint of an application.
        
        IMPORTANT: 
        - Your summary should be thorough and detailed({total_allocated_tokens}) while maintaining technical/business precision and depth. Focus on providing insights that would help both stakeholders and developers understand the application better.
        - feature_details must contain high level feature name and feature description(value of the files/folders) strictly in concise bullet points. The feature inforamtion must be in detail to capture the complete high level knowledge for that feature but not the function level details. Feature names cannot be programmatic function names like Dependency management, json handling etc. instead it should be inventory management, order processing etc. 
        - Your services list should be comprehensive and include all services represented in this folder.
        - is_reuasble_lib if a folder is used as reusable lib make it True otherwise False
        - lib_name if is_reusable_lib is True then provide the name of the reusable lib/component If is_reusable_lib False then add Not Applicable
        - category if is_reusable_lib is True then provide category only between 'Frontend' and 'Backend' If is_reusable_lib False then add Not Applicable
        - sub_category if is_reusable_lib is True then provide sub category only between 'UI Component','Custom Hooks', 'http_client', 'Utils', 'Others' In Frontend & 'Middleware', 'Error Handling', 'Auth', 'Utils', 'Others' In Backend If is_reusable_lib False then add Not Applicable
        - when_to_use if is_reusable_lib is True then provide where this reusable lib/component can be used If is_reusable_lib False then add Not Applicable 
        - associated_files if is_reusable_lib is True then provide the list of files associated(give complete path for the assosciated file) with this reusable lib/component If is_reusable_lib False then add Not Applicable
        - summary must not be technical and only explain the high level details of the folder/project. Understand the file and folder summaries provided to combine the knowledge to form the executive summary. Make it as detailled as possible.
        - Use clear and concise language, avoiding jargon where possible.
        
        - You must provide your response in this exact format:
        ```summary
        [Your detailled high-level executive summary for the folder for business stakeholders]
        ```
        ```feature_details
        [List of high-level features or functionalities represented in this folder]
        ```
        ```services_namess
        [Comma-separated list of all services represented in this folder]
        ```
        ```is_reuasble_lib
        Boolean Value
        ```
        ```lib_name
        [Name of the reusable library if applicable]
        ```
        ```category
        [Category of the reusable library if applicable]
        ```
        ```sub_category
            [Sub category of the reusable library if applicable]
        ```
        ```when_to_use
        [Your detailed use case where or when this reuasble_lib can be usefull]
        ```
        ```associated_files
            [Comma-separated list of associated files with the reusable library, Give the Complete file path as mentioned in the file list]
        ```
        ```example_usage
            [Example code snippet of how to use this reusable library]
        ```
    """

    user_prompt = f"""
        Generate a summary and services list for the folder: "{folder_name}" (Path: {folder_path})

        FOLDER CONTENTS:
        - Files ({len(file_list)}): {", ".join(file_list) if file_list else "None"}
        - Subfolders ({len(subfolder_list)}): {", ".join(subfolder_list) if subfolder_list else "None"}

        FILE SUMMARIES:
        {os.linesep.join(formatted_file_summaries) if formatted_file_summaries else "No file summaries available"}

        FILE SERVICES:
        {os.linesep.join(formatted_file_services) if formatted_file_services else "No file services available"}

        SUBFOLDER SUMMARIES:
        {os.linesep.join(formatted_subfolder_summaries) if formatted_subfolder_summaries else "No subfolder summaries available"}

        SUBFOLDER SERVICES:
        {os.linesep.join(formatted_subfolder_services) if formatted_subfolder_services else "No subfolder services available"}

        SUBFOLDER FEATURES:
        {os.linesep.join(formatted_subfolder_features) if formatted_subfolder_features else "No subfolder features available"}
        
        Based on these components:
        1. Provide a thorough technical summary explaining the folder's purpose, implementation details, and architectural significance
        2. Compile a comprehensive list of all services represented in this folder based on file and subfolder services information
        
        Follow the exact format specified in the system instructions for your response.
    """

    return system_prompt, user_prompt

def services_generation():
    system_prompt = """
        <Task>
        Create an architectural blueprint of the given repository by identifying and classifying both external services and third-party services with no overlap between categories.
        </Task>

        <Definitions>
        - External services: Company-provided services hosted outside the application (AWS S3, Google Cloud, Stripe, Twilio)
        - Third-party services: Libraries, frameworks, and SDKs that are part of the core application stack (Django, React, MongoDB, Redux)
        </Definitions>

        <Output_Format>
        {
        "external_services": [
            {
            "external_service_name": "string",
            "description": "string",
            "associated_files": ["string"],
            "service_class": "string",
            "used_in_files": ["string"]
            }
        ],
        "thirdparty_services": [
            {
            "thirdparty_service_name": "string",
            "description": "string",
            "associated_files": ["string"],
            "service_class": "string",
            "used_in_files": ["string"]
            }
        ]
        }
        </Output_Format>

        <Instructions>
        1. Conduct a thorough repository analysis to identify all services
        2. Classify each service into exactly ONE category:
        - External services: Cloud platforms, payment processors, authentication providers
        - Third-party services: Frameworks, libraries, SDKs integrated into the codebase
        3. For each service, provide:
        - Name: Exact service name
        - Description: Concise explanation of functionality and purpose
        - Associated files: All files directly importing or using the service
        - Service class: Category (e.g., "cloud storage", "web framework", "database")
        - Used in files: Complete paths of files utilizing the service
        4. Ensure ZERO overlap between categories
        5. Prioritize accuracy over comprehensiveness
        6. Validate that identified services are actively used in the project
        7. Include only services with clear evidence of implementation
        8. Do not create a lot of services which are redundant. Keep it to a maximum of 50 services only.
        </Instructions>

        <Examples>
        Good External Service Entry:
        {
        "external_service_name": "AWS S3",
        "description": "Cloud storage service used for storing user-uploaded files",
        "associated_files": ["src/services/storage.js", "src/config/aws.js"],
        "service_class": "cloud storage",
        "used_in_files": ["src/components/FileUpload.js", "src/pages/UserProfile.js"]
        }

        Good Third-Party Service Entry:
        {
        "thirdparty_service_name": "React",
        "description": "Frontend JavaScript library for building user interfaces",
        "associated_files": ["package.json", "src/index.js"],
        "service_class": "frontend framework",
        "used_in_files": ["src/App.js", "src/components/*.js"]
        }
        </Examples>

        Analyze the repository and provide the complete architectural blueprint in the specified format.
    """

    user_prompt = ""

    return system_prompt, user_prompt

def executive_summary_generation(combined_summary, user_mvf):
    system_prompt = """
    Your Role:
    You are an expert software architect tasked with understanding a codebase and creating an executive summary that clearly articulates the main purpose of this application,
    the core problem that the application is solving, and the prioritized list of the most valuable features, solely based on the provided folder wise summary. Do not hallucinate and create the most valuable features and its description on assumption. This needs to be based on facts.

    Task:
    1. Analyze provided folder wise summary and the services used and the user defined features (if provided).
    2. Understand component interactions and functions.
    3. Prioritize the User Defined Features (if provided) in the summary.
    4. Identify and prioritize the most valuable features based on their importance and relevance to the overall project, as evidenced in the code.
    5. Create a comprehensive executive summary.

    Steps:
    1. Review folder wise summary.
    2. Analyze folder wise summary:
    - Identify key components and their roles
    - Note data operations, design patterns, and architectural decisions
    3. Create summary:
    - Describe the specific problem the codebase solves, based on folder wise summary
    - Explain component interactions
    - Outline data workflow
    4. Identify and prioritize main features:
    - Determine which feature(s) address the core problem of the application, based on code implementation
    - Rank features based on their importance and relevance to solving the main problem, as evidenced in the code
    - The feature should be major components of the codebase and not minor functions like "Modular Architecture" or "Code Reusability", these are not features but design principles.

    Focus Areas:
    - Precised feature prioritization and importance
    - High-level functionality
    - Clear, concise technical language
    - Objective description
    - Capture entire workflow

    Guidelines:
    - Only use the folder wise summary provided
    - Use precise technical terms
    - Include user-defined features if provided and evidenced in the code
    - Prioritize features based on their importance to the core problem, as shown in the folder wise summary

    Feature Identification and Prioritization:
    - Carefully analyze the folder wise summary to identify features actually present in the folder wise summary
    - Do not assume or infer features that are not explicitly mentioned in the folder wise summary
    - Identify the top feature that solves the majority of the problem based on code evidence
    - Rank subsequent features in descending order of importance, ensuring they are present in the folder wise summary
    - Ensure the feature list reflects the codebase's focus and structure
    - Only include features that have substantial implementation in the codebase that is evident from folder wise summary

    Output Format - Adhering to this format is crucial
    ```json
    {
    "data": "generated_summary in string format adhering to the Expected Output Format for Generated Summary",
    "confidence_score": 90,
    "traceback": {
    "Feature 1 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 1 Title' is included, as the 'phrase' is an evidence that this feature is part of the codebase.",
    "Feature 2 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 2 Title' is included, as the 'phrase' is an evidence that this feature is part of the codebase.",
    ...
    }
    }
    ```

    Requirements:
    - Replace \n with \\n in JSON
    - Limit upto 5 main features (max 2 sub-features each) or 7500 tokens
    - If due to any reason such as codebase being small, you are unable to provide 5 features, then provide as many high-level features as possible between the range of 1 to 5.
    - Don't assume features or include minor features due to inability to provide 5 features, lesser number of features is acceptable.
    - Use specified JSON format only
    - Start with "```json" and end with "```"
    - Ensure the top feature in the prioritized list addresses the core problem and is present in the folder wise summary
    - Rank features in descending order of importance to the main problem, based on actual code implementation
    - Do NOT include features that are NOT evidenced in the provided folder wise summary
    - Evaluate the folder wise summary objectively, considering all conclusions on the actual code provided
    - Do NOT make any assumptions about organizational goals or intentions beyond what is explicitly shown in the code
    - Focus solely on the technical aspects and implemented functionality, avoiding speculation about business objectives or future plans
    - Both the keys data, confidence score, and traceback should be present in the output JSON
    - The generated summary should be in string format only and be contained inside the "data" key
    - The "traceback" key should contain a dictionary with feature names as keys and justifications for including these features based on exact phrases from the input
    - Do not include any feature that could potentially be part of the folder wise summary without explicit evidence
    - Every feature mentioned must be driven by clear evidence from the provided input
    """
    user_prompt = """
    Expected Output Format for Generated Summary:

  **Overview**
  <empty line>
  <A brief introduction to the codebase and its main purpose; in paragraph format only, not in points.
  This paragraph should provide a concise yet comprehensive overview of the codebase, its primary functionality, solution provided by the project and its intended use case.
  Aim for 3-5 sentences that capture the essence of the project.>
  <empty line>
  **Highlighted Features**
  <empty line>
  <
  List and briefly explain the key features that are significant components of the codebase and would serve as selling points.
  These features should be presented as follows:
  1. Use numbered points for each feature.
  2. Provide a brief explanation for each feature in 1-2 sentences, highlighting its importance and benefit to the end user.
  3. Focus on features that are central to the codebase's functionality and most important to the end user.
  4. Dont include generic features like "Modular Architecture" or "Code Reusability", these are not features but design principles.
  5. Do not include sub-points under any feature.
  6. Prioritize User Defined Features (if provided) at the beginning of the list.
  7. If User Defined Features are given, list them first before including any features identified through your analysis.
  8. Aim to provide upto of 1 to 5 key features, after each feature add an empty line for formatting purposes.
  9. Ensure that the features listed represent the core functionality and unique selling points based on the folder wise summary.
  10. Use clear, concise language that emphasizes the value proposition of each feature.
  11. Also under each feature, mention which file/folder was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
  12. Do not add features into Highlighted Features if they dont have value for buisness stakeholder about the application. Also do not repeat adding similar feature in this section.

  Output Structure:
  1. ***<Feature 1 Title>***: <Description of the feature in one to two sentences.\n
  2. ***<Feature 2 Title>***: <Description of the feature in one to two sentences.>\n
  >
  <empty line>
  **Key Benefits**
  <empty line>
  <Summarize the key benefits of the codebase in one to two sentences.
  This summary should encapsulate the overall value proposition of the codebase and its potential impact on users or the organization.>
  <empty line>
  <Highlight the most significant key benefits the codebase has to offer in bulleted points. The format should be:
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  Aim for 3-5 bullet points that capture the most compelling advantages of using this codebase, after each point add an empty line for formatting purposes.
  Each benefit should be distinct and provide a clear value proposition.>

  <Final Output Format>
  Output Format - Adhering to this format is crucial, the output should be in parsable JSON format:
  ```json
  {{
    "data": "<generated_summary in string format adhering to the Expected Output Format for Generated Summary>",
    "confidence_score": 90,
    "traceback": {{
      "Feature 1 Title": "Since it mentions about <exact phrase from the folder wise summary>, the 'Feature 1 Title' is included, as the "phrase" is an evidence that this feature is part of the folder wise summary.",
      "Feature 2 Title": "Since it mentions about <exact phrase from the folder wise summary>, the 'Feature 2 Title' is included, as the "phrase" is an evidence that this feature is part of the folder wise summary.",
      ...
    }}
  }}
  ```
  </Final Output Format>
  Note: If the traceback includes phrases that are not present in the folder wise summary then you would be penalized 10000 points.
  The output should be having data, confidence score, and traceback keys, and the entire content inside "```json" and "```" should be parsable by json.
  The "data" key should contain the generated summary and it should be in string format only, allowing the parsing of the entire json.
  If there are any inverted commas inside the generated summary, then escape them with a backslash.
  Do not change or skip the headings of each section in the generated json. The generated summary must have "Overview", "Highlighted Features", "Key Benefits" as section titles. Follow the above provided guidelines."""
    user_prompt += f"""Use the below folder wise summary to generate the summary in the above format: {combined_summary}""" + "User Defined Features : " + str(user_mvf)
    return system_prompt, user_prompt

def db_executive_summary_generation(combined_summary, user_mvf): 
    system_prompt = """
    Role:
    You are an expert Database Architect tasked with understanding the contents of all tables and schema of the database. 
    You shall Articulate a proper executive summary that clearly captures all the main & high-level features of this database.
    The core use-case that this database is intended for, and the prioritized list of the most valuable features, solely based on the provided Table-Level summaries. 
    Do not hallucinate. Do NOT create the most valuable features and its description on pure assumptions. This needs to be based on facts, with proper backing.

    Task:
    1. Analyze provided Table wise summaries.
    2. Understand component interactions and functions.
    3. Prioritize the User Defined Features (if provided) in the summary.
    4. Identify and prioritize the most valuable features based on their importance to the core use-case the Database is solving.
    5. Create a comprehensive executive summary.

    Steps:
    1. Review Table wise summary.
    2. Analyze Table wise summary:
      - Identify all tables. 
      - Take into consideration the foreign keys, primary keys, is-a, has-a, and many-to-many relationships.
      - Deeply understand the intended-use-case of each table.
      - Note data operations, design patterns, and architectural decisions
    3. Create summary:
      - Describe the specific problem the Database is solving, based on Table wise summary
      - Explain high-level interactions and dependencies
      - Outline data workflow
    4. Identify and prioritize main features:
      - Determine which feature(s) address the core problem of the Database, based on SQL implementation and Table wise summary
      - Rank features based on their importance and relevance to solving the main problem, as evidenced in the Database
      - The feature should be major components of the Database and not minor functions like Many-to-Many Relationships, or "Foreign Keys". 
        These are implementation concepts. Not core features.

    Focus Areas:
    - Precised feature prioritization and importance
    - High-level functionality of this Database
    - Clear, concise technical language with Database-specific Language
    - Objective description
    - Capture entire data workflow

    Guidelines:
    - Only use the Table wise summary provided
    - Use precise Database-relevant technical terms
    - Include user-defined features if provided and evidenced in the Table wise summary
    - Prioritize features based on their importance to the core problem, as shown in the Table wise summary

    Feature Identification and Prioritization:
    - Carefully analyze the Table wise summary to identify features actually present in the Table wise summary
    - Do not assume or infer features that are not explicitly mentioned in the Table wise summary
    - Identify the top feature that solves the majority of the problem based on Database and SQL evidence
    - Rank subsequent features in descending order of importance, ensuring they are present in the Table wise summary
    - Ensure the feature list reflects the Database's focus and structure
    - Only include features that have substantial implementation in the Database that is evident from Table wise summary

    Output Format - Adhering to this format is crucial
    ```json
    {
    "data": "generated_summary in string format adhering to the Expected Output Format for Generated Summary",
    "confidence_score": 90,
    "traceback": {
    "Feature 1 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 1 Title' is included, as the 'phrase' is an evidence that this feature is part of the Database.",
    "Feature 2 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 2 Title' is included, as the 'phrase' is an evidence that this feature is part of the Database.",
    ...
    }
    }
    ```

    Requirements:
    - Replace \n with \\n in JSON
    - Limit upto 5 main features (max 2 sub-features each) or 7500 tokens
    - If due to any reason such as Database being small, you are unable to provide 5 features, then provide as many high-level features as possible between the range of 1 to 5.
    - Don't assume features or include minor features due to inability to provide 5 features, lesser number of features is acceptable.
    - Use specified JSON format only
    - Start with "```json" and end with "```"
    - Ensure the top feature in the prioritized list addresses the core problem and is present in the Table wise summary
    - Rank features in descending order of importance to the main problem, based on actual Database and SQL implementation
    - Do NOT include features that are NOT evidenced in the provided Table wise summary
    - Evaluate the Table wise summary objectively, considering all conclusions on the actual Database and SQL provided
    - Do NOT make any assumptions about organizational goals or intentions beyond what is explicitly shown in the Database and SQL
    - Focus solely on the technical aspects and implemented functionality, avoiding speculation about business objectives or future plans
    - Both the keys data, confidence score, and traceback should be present in the output JSON
    - The generated summary should be in string format only and be contained inside the "data" key
    - The "traceback" key should contain a dictionary with feature names as keys and justifications for including these features based on exact phrases from the input
    - Do not include any feature that could potentially be part of the Table wise summary without explicit evidence
    - Every feature mentioned must be driven by clear evidence from the provided input.
    - Strictly use an assertive and objective tone in your response. 
    - Do not be unsure about anything.
    - Do not include the "Folder Name" in your response. Ignore "dbanalysis" folder. Provide Executive Summary of the Database-ONLY.
    """

    user_prompt = """
  Expected Output Format for Generated Summary:

  **Overview**
  <empty line>
  <A brief introduction to the Database and its main purpose; in paragraph format only, not in points.
  This paragraph should provide a concise yet comprehensive overview of the Database, its primary functionality, and its intended use case.
  Aim for 3-5 sentences that capture the essence of the Database.>
  <empty line>
  **Highlighted Features**
  <empty line>
  <
  List and briefly explain the key features that are significant components of the Database and would serve as selling points.
  These features should be presented as follows:
  1. Use numbered points for each feature.
  2. Provide a brief explanation for each feature in 1-2 sentences, highlighting its importance and benefit to the END USER.
  3. Focus on features that are central to the Database's functionality and most important to the END USER.
  4. Dont include generic features like  Many-to-Many Relationships, or "Foreign Keys", these are not features but Design Principles.
  5. Do not include sub-points under any feature.
  6. Prioritize User Defined Features (if provided) at the beginning of the list.
  7. If User Defined Features are given, list them first before including any features identified through your analysis.
  8. Aim to provide upto of 1 to 5 key features, after each feature add an empty line for formatting purposes.
  9. Ensure that the features listed represent the core functionality and unique selling points based on the Table wise summary.
  10. Use clear, concise language that emphasizes the value proposition of each feature.
  11. Also under each feature, mention which file/Table was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
  12. Do not add features into Highlighted Features if they dont have value for buisness stakeholder about the application. Also do not repeat adding similar feature in this section.

  Output Structure:
  1. ***<Feature 1 Title>***: <Description of the feature in one to two sentences.\n
  2. ***<Feature 2 Title>***: <Description of the feature in one to two sentences.>\n
  >
  <empty line>
  **Key Benefits**
  <empty line>
  <Summarize the key benefits of the Database in one to two sentences.
  This summary should encapsulate the overall value proposition of the Database and its potential impact on users or the organization.>
  <empty line>
  <Highlight the most significant key benefits the Database has to offer in bulleted points. The format should be:
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  Aim for 3-5 bullet points that capture the most compelling advantages of using this Database, after each point add an empty line for formatting purposes.
  Each benefit should be distinct and provide a clear value proposition.>

  <Final Output Format>
  Output Format - Adhering to this format is crucial, the output should be in parsable JSON format:
  ```json
  {{
    "data": "<generated_summary in string format adhering to the Expected Output Format for Generated Summary>",
    "confidence_score": 90,
    "traceback": {{
      "Feature 1 Title": "Since it mentions about <exact phrase from the Table wise summary>, the 'Feature 1 Title' is included, as the "phrase" is an evidence that this feature is part of the Table wise summary.",
      "Feature 2 Title": "Since it mentions about <exact phrase from the Table wise summary>, the 'Feature 2 Title' is included, as the "phrase" is an evidence that this feature is part of the Table wise summary.",
      ...
    }}
  }}
  ```
  </Final Output Format>
  Note: If the traceback includes phrases that are not present in the Table wise summary then you would be penalized 10000 points.
  The output should be having data, confidence score, and traceback keys, and the entire content inside "```json" and "```" should be parsable by json.
  The "data" key should contain the generated summary and it should be in string format only, allowing the parsing of the entire json.
  If there are any inverted commas inside the generated summary, then escape them with a backslash.
  Do not change or skip the headings of each section in the generated json. The generated summary must have "Overview", "Highlighted Features", "Key Benefits" as section titles. Follow the above provided guidelines.
    """

    user_prompt += f"""Use the below Table wise summary to generate the summary in the above format: {combined_summary}""" + "User Defined Features : " + str(user_mvf)

    return system_prompt, user_prompt


def architecture_diagram_generation(services_data, icons_metadata):
    user_prompt = f"""
    <Input>
    $services_data = {services_data}
    $icons_metadata
    </Input>

    <Role>
    You are an expert at understanding large projects based on their executive summary and the services being used in them. Create a JSON structure for a ReactFlow diagram based on the given service class JSON.
    </Role>

    <Output Structure>
    1. Create a JSON object with a "nodes" and "edges" array.
    2. Create nodes for each external and third-party service.
    3. "nodes": An array containing all node objects.
      - "id": A unique string identifier for the node.
      - "data":   
        - "label": The name of the node.
        - "description": Description of the service.
        - "associated_files": Associated file and used in files in the service node, defaulting to "No File Available" if not present.
        - "group": The logical group name (e.g., 'Backend', 'Frontend', 'Database',etc..).
        - "subgroup": The specific subgroup within the group (e.g., Frameworks, NoSQL Databases, State Management, etc.).
        - "service": The appropriate filename of the icon based on the $icons_metadata.
      - "position" : The x and y coordinates of the node.
      - "type" : "customNode" This should be fixed.
    4. "edges" : An array having id, source, target, label, and type should be customEdge always.
    4. Ensure all services and files from the input JSON are included.
    5. The output should be in the form of a dictionary containing a "nodes" and "edges" array.
    6. Present only the code inside delimiters "```reactflow [reactflow CODE]```" without any additional explanation.
    """

    system_prompt:str = """
    <Task>
      You are tasked with creating a JSON structure for a ReactFlow diagram based on the given executive summary and the service_class_json. The executive summary contains an overview of the entire project. This JSON includes information about external services and third-party services, along with their associated files. Your output should represent this information as a network of nodes and edges.
    </Task>
    
    <Icons Context>
      $icons_metadata = """ + str(icons_metadata) + """
    </Icons Context>

    <Instructions>
      You are a solution expert, specializing in problem and solution flows. You will be given the solution overview for a project, and your task is to create an interconnected single component of graph which is detailed, and intuitive and self explanatory for:

      Follow these guidelines:
      1. Create nodes for each unique service (both external and third-party).
      2. Do not create any group nodes.
      4. In the data key for each service node, include two additional fields called group and subgroup. The group field should contain the logical group name (e.g., Frontend, Backend, Databases, etc..), and the subgroup field should provide more specific categorization (e.g., Frameworks, NoSQL Databases, etc..). For example, for a service node representing React, the group would be Frontend and the subgroup would be Frameworks.
      5. For each node, check which icon will be the most suitable from the $icons_metadata in the <Icons Context>
      6. Ensure all information from the input is represented in the output.
      7. The position coordinates must be proper for all the nodes.
    </Instructions>

    <Rules>
      **Ensure all nodes in the generated graph are interconnected such that every node has at least one edge, forming a single connected component without any isolated or disjoint sections. (High Priority Requirement)**
      Important Rules to be followed:
      1. Give detailed technical architecture flow and the JSON object following the below output format.
      2. Make sure that the flow and order of new solution approach is explained well in the graph with appropriate edges. Use as many edges you want to describe the data and user flow properly.
      3. The whole user and data flow should be clear.
      4. Do not add unnecessary nodes and edges. Do not create duplicate nodes that perform same task.
      5. Make the Node descriptions detailed, breaking tasks into multiple sub-tasks if needed.
      6. Ensure your edges show the actual flow, and not just connections of what's related. The connections are meant to show the logical flow, and not the relatedness/similarity.
      7. The group name is meant to classify clusters of nodes within each graph. For instance, if we have multiple nodes in features, they would all have "feature" as group. In Architecture Flow, the "Group" should show the layer each node is in, for instance "Backend Layer", "Database Layer" etc.
      9. for a hierarchy of nodes A -> B -> C; ensure that there is not a connection between A -> C.
    </Rules>
    
    <output_format>
    The output should be in between the delimeters ```reactflow and ```. Only provide the json output. Don't give unnecesary explanation.
    ```reactflow
    {
      "nodes": [
        { 
          "id": "unique_node_identifier_string",
          "data" : {
            "label": "name_of_the_service",
            "description": "description of the service",
            "associated_files": ["file_path_1", "file_path_2", "file_path_3", etc.],  // (default: ["No File Available"] if not present)
            "group": "name_of_group",  // Add the logical group name (e.g., "Frontend", "Backend", etc..)
            "subgroup": "name_of_subgroup",  // Add a more specific subgroup name (e.g., "Frameworks", "NoSQL Databases", etc..)
            "service": "filename" //taken from the $icons_metadata,
          }
          "position":{ "x": "Xcoordinate", "y": "Ycoordinate" },
          "type" : "customNode" //this is hardcoded and will be constant
        }
      ],
      "edges": [
        {
          "id": "unique_egde_identifier_string",
          "source": "label A",
          "target": "label B",
          "label": "Showcase what comes from the source node, to the target node. Be concise and specific with labels, such as 'Ingested Data', 'Converted Text', 'User Query' etc. Use at max 5 words",
          "type" : "customEdge" //this is hardcoded and will be constant
        }
      ]
    }```
    </output_format>
    """
    return system_prompt, user_prompt
  

def erd_generation(services_data, icons_metadata):
  tables_metadata = []
  for entry in services_data:
      table_name = entry["table_name"]
      ddl = entry["ddl"]
      columns, primary_keys, foreign_keys = parse_ddl(ddl)
      tables_metadata.append({
          "table_name": table_name,
          "columns": columns,
          "primary_keys": primary_keys,
          "foreign_keys": foreign_keys
      })

  dot = generate_combined_graph(tables_metadata)

  system_prompt:str = """
    You are tasked with creating a JSON structure for a ReactFlow diagram based on the given database ER diagram and schema JSON. This JSON includes information about database columns and their relationships.Your output should represent this information as a network of nodes and edges.
    </Task>
    
    <Icons Context>
      $icons_metadata = """ + str(icons_metadata) + """
    </Icons Context>

    <Instructions>
      You are a solution expert, specializing in problem and solution flows. You will be given the database schema information of a database, and your task is to create an interconnected single component of graph which is detailed, and intuitive and self explanatory for:

      Follow these guidelines:
      1. Create nodes for each unique service (both external and third-party).
      2. Do not create any group nodes.
      4. In the data key for each service node, include two additional fields called group and subgroup. The group field should contain the logical group name (e.g.,Databases, etc..), and the subgroup field should provide more specific categorization (e.g., 'Transactional Tables', 'Reference Tables' etc..). For example, for a service node representing daily transactions, the group would be Database and the subgroup would be Transactional Tables.
      5. For each node, check which icon will be the most suitable from the $icons_metadata in the <Icons Context>
      6. Ensure all information from the input is represented in the output.
      7. The position coordinates must be proper for all the nodes.
    </Instructions>

    <Rules>
      Important Rules to be followed:
      1. Give detailed technical architecture flow and the JSON object following the below output format.
      2. Make sure that the flow and order of new solution approach is explained well in the graph with appropriate edges. Use as many edges you want to describe the data and user flow properly.
      3. The whole user and data flow should be clear.
      4. Do not add unnecessary nodes and edges. Do not create duplicate nodes that perform same task.
      5. Make the Node descriptions detailed, breaking tasks into multiple sub-tasks if needed.
      6. Ensure your edges show the actual flow, and not just connections of what's related. The connections are meant to show the logical flow, and not the relatedness/similarity.
      7. The group name is meant to classify clusters of nodes within each graph. For instance, if we have multiple nodes in features, they would all have "feature" as group. In Architecture Flow, the "Group" should show the layer each node is in, for instance "Database Layer" etc.
      9. for a hierarchy of nodes A -> B -> C; ensure that there is not a connection between A -> C.
    </Rules>
    
    <output_format>
    The output should be in between the delimeters ```reactflow and ```. Only provide the json output. Don't give unnecesary explanation.
    ```reactflow
    {
      "nodes": [
        { 
          "id": "unique_node_identifier_string",
          "data" : {
            "label": "name_of_the_table",
            "description": "description of the table",
  	    "columns": ["order_id [PK]", "product_sku [PK]", "quantity", "unit_price"]
            "group": "name_of_group",  // Add the logical group name (e.g., "Database", etc..)
            "subgroup": "name_of_subgroup",  // Add a more specific subgroup name (e.g., 'Transactional Tables', 'Reference Tables', etc..)
            "service": "filename" //taken from the $icons_metadata,
          }
          "position":{ "x": "Xcoordinate", "y": "Ycoordinate" },
          "type" : "customNode" //this is hardcoded and will be constant
        }
      ],
      "edges": [
        {
          "id": "unique_egde_identifier_string",
          "source": "label A",
          "target": "label B",
          "label": "Showcase what comes from the source node, to the target node. Be concise and specific with labels, such as 'Ingested Data', 'Converted Text', 'User Query' etc. Use at max 5 words",
          "type" : "customEdge" //this is hardcoded and will be constant
        }
      ]
    }```
    </output_format>
    """
    
  user_prompt:str = f"""
    <Input>
    $database_tables = {dot}
    $icons_metadata
    </Input>

    <Role>
    You are an expert at understanding database architecture based on ER diagrams and relational structures. Create a JSON structure for a ReactFlow diagram based on the given database schema.
    </Role>
    <Output Structure>
      1. Create a JSON object with a "nodes" and "edges" array.
      2. Create nodes for each table in the schema.
      3. "nodes": An array containing all node objects.
      - "id": A unique string identifier for the node.
      - "data":  
        - "label": The name of the table.
        - "description": A brief summary of the table's role or content.
        - "columns": List of column names (mark primary keys with [PK], foreign keys with [FK]).
        - "group": The logical group name (e.g., 'Database').
        - "subgroup": The specific subgroup within the group (e.g., 'Transactional Tables', 'Reference Tables').
        - "service": The appropriate filename of the icon based on the $icons_metadata.
      - "position" : The x and y coordinates of the node.
      - "type" : "customNode" This should be fixed.
      4. "edges" : An array having id, source, target, label, and type should be customEdge always.
      5. The label of the edge should describe the relationship, like "order_id â†’ order_id". 
      6. The output should be in the form of a dictionary containing a "nodes" and "edges" array.
      7. Present only the code inside delimiters "```reactflow [reactflow CODE]```" without any additional explanation.
    """
    
  return system_prompt, user_prompt
    

def feature_summary_generation(formatted_data, user_mvf, executive_summary):
    # if input_type is None:
    #     formatted_data = file_summary_list
    # elif input_type == "batch_summary":
    #     formatted_data = format_batchwise_summary_metadata_for_services(file_summary_list)
    # else:
    #     formatted_data = format_file_summaries(file_summary_list)

    user_prompt = """
    Role: You are an AI code analyst specializing in creating concise, feature-level summaries of codebases.

    Objective: Provide a comprehensive yet concise feature-level summary of a given codebase, highlighting key components, functionality, and the project's overall workflow.

    Input: You will receive information about a codebase, which may include an executive summary or other project details.

    Steps:
    1. Analyze the provided codebase information.
    2. Identify the main features (maximum 5) of the project from the executive summary (if provided in same order)
    3. Create a summary following the specified format, including:
        a. An overview of the project
        b. A list of key features with brief descriptions
        c. A closure statement
    4. Self-evaluate the generated summary and assign a confidence score.
    5. Format the output as specified in the instructions.

    Output Format:
    ```json
    {
        "data": "generated_summary in string format adhering to the Detailed Instructions for Output Format",
        "confidence_score": 90
    }
    ```

    Detailed Instructions for Output Format:

    **Overview**
    <empty line>
    < 
        Summarize all features in 2-3 sentences, introducing the project and its purpose.
        Provide a 2-3 sentence summary of key benefits, highlighting core architecture and value proposition.
    >
    <empty line>
    **Key Features**
    <empty line>
    <   
        List a maximum of 5 main features.
        For each feature, provide up to 2 sub-points describing its functionality.
        Ensure clear explanation of how features interact and contribute to the project's goals.
        1. ***<Key Feature Title>*** : 
        * <Sub point 1 description>
        * <Sub point 2 description>
        <empty line>
    >
    <empty line>
    < 
        Summarize the overall impact and value proposition of the project in one sentence as a conclusion statement.
    >
    <empty line>
    
    -> Self-Evaluation:
        - Score the summary out of 100 based on clarity, precision, detail, knowledge, accuracy, technical correctness, and understanding of the data.

    -> Formatting Requirements:
        - Replace all newline characters (\n) with \\n in the JSON output.
        - Ensure the complete JSON is less than 7500 tokens.
        - Start the output with "```json" and end with "```".
        - If an executive summary is provided, use only the highlighted features from it.

    Example Output Structure:
    ```json
    {
        "data": "**Overview**\\n\\n[Project overview]\\n\\n[Benefits summary]\\n\\n**Key Features**\\n\\n1. *Feature 1*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n2. *Feature 2*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n[...continue for up to 5 features...]\\n\\n[Closure statement]",
        "confidence_score": 90
    }
    ```

    Remember: Adhere strictly to the output format and instructions to maintain consistency and accuracy in your summary.
    """

    user_prompt += "User Defined Features : " + str(user_mvf)

    system_prompt = f"""
        <role>
        You are an assistant to a Senior Software Engineer. You are very capable in reading and understanding huge codebases.
        There is no edge-case, no mistake, no functionality no matter how small goes unnoticed by you.
        You will be given a large codebase and be asked queries regarding it.
        </role>

        <Task>
        You will be given relevant files from a production codebase. The Senior Engineer will consult you to clear his doubts and ask for critical code-level and functionality level analysis of the same.
        <Important>
        1. You will be clear. Feel free to be descriptive but Avoid Jargon
        2. You shall perform critical analysis on the code before responding.
        3. Note that the codebase will be quite complex and have dependencies everywhere, be mindful of them all.
        4. Enclose code in (triple backticks)``` code ```
        </Important>
        </Task>

        Files from Codebase goes here :
        <Repo Structure>
        {formatted_data}
        </Repo Structure>
    """

    start_index = executive_summary.find("Highlighted Features")
    end_index = executive_summary.find("Key Benefits")

    if start_index != -1 and end_index != -1:
        executive_summary = executive_summary[start_index:end_index].strip()

    user_prompt += "Executive Summary : " + str(executive_summary)

    return system_prompt, user_prompt

def feature_summary_generation_db(formatted_data, user_mvf, executive_summary):
    # if input_type is None:
    #     formatted_data = file_summary_list
    # elif input_type == "batch_summary":
    #     formatted_data = format_batchwise_summary_metadata_for_services(file_summary_list)
    # else:
    #     formatted_data = format_file_summaries(file_summary_list)

    user_prompt = """
    Role: You are an AI Database Analyst specializing in creating concise, feature-level summaries of complex database schemas and architectures.

    Objective: Provide a comprehensive yet concise feature-level summary of a given database schema information, highlighting key components, entities, relationships, and the overall data architecture workflow.

    Input: You will receive information about a database design, which may include an executive summary or other schema-level details.

    Steps:
    1. Analyze the provided database schema information.
    2. Identify the main features (maximum 5) of the database from the executive summary (if provided in same order)
    3. Create a summary following the specified format, including:
        a. An overview of the database
        b. A list of key features with brief descriptions
        c. A closure statement
    4. Self-evaluate the generated summary and assign a confidence score.
    5. Format the output as specified in the instructions.

    Output Format:
    ```json
    {
        "data": "generated_summary in string format adhering to the Detailed Instructions for Output Format",
        "confidence_score": 90
    }
    ```

    Detailed Instructions for Output Format:

    **Overview**
    <empty line>
    < 
        Summarize all features in 2-3 sentences, introducing the database and its purpose.
        Provide a 2-3 sentence summary of key benefits, highlighting schema structure, normalization or denormalization logic, and value proposition in handling data.
    >
    <empty line>
    **Key Features**
    <empty line>
    <   
        List a maximum of 5 main features.
        For each feature, provide up to 2 sub-points describing its data handling, relationships, or optimization logic.
        Ensure clear explanation of how features contribute to performance, consistency, and data integrity.
        1. ***<Key Feature Title>*** : 
        * <Sub point 1 description>
        * <Sub point 2 description>
        <empty line>
    >
    <empty line>
    < 
        Summarize the overall impact and value proposition of the database in one sentence as a conclusion statement.
    >
    <empty line>
    
    -> Self-Evaluation:
        - Score the summary out of 100 based on clarity, precision, detail, knowledge, accuracy, technical correctness, and understanding of the schema information.

    -> Formatting Requirements:
        - Replace all newline characters (\n) with \\n in the JSON output.
        - Ensure the complete JSON is less than 7500 tokens.
        - Start the output with "```json" and end with "```".
        - If an executive summary is provided, use only the highlighted features from it.

    Example Output Structure:
    ```json
    {
        "data": "**Overview**\\n\\n[Database overview]\\n\\n[Benefits summary]\\n\\n**Key Features**\\n\\n1. *Feature 1*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n2. *Feature 2*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n[...continue for up to 5 features...]\\n\\n[Closure statement]",
        "confidence_score": 90
    }
    ```

    Remember: Adhere strictly to the output format and instructions to maintain consistency and accuracy in your summary.
    """

    user_prompt += "User Defined Features : " + str(user_mvf)

    system_prompt = f"""
        <role>
        You are an assistant to a Senior Data Architect. You are very capable in reading, analyzing, and understanding complex database schemas and data models.
        No entity, constraint, relationship, or optimization logic goes unnoticed by you.
        You will be given a comprehensive database structure or schema information and will be asked to analyze, explain, and summarize it at a structural and functional level.
        </role>

        <Task>
        You will be given relevant database schema files or DDL definitions. The Senior Data Architect will consult you to clear doubts and ask for critical schema-level and data model-level analysis.
        <Important>
        1. You will be clear. Feel free to be descriptive but Avoid Jargon
        2. Perform a critical and deep analysis of the schema and the information given before responding.
        3. The schema will often involve multiple tables, foreign keys, views, procedures, and indexing strategies â€” be mindful of their dependencies and relationships.
        4. Enclose code or schema in (triple backticks)``` code ```
        </Important>
        </Task>

        Files from Database schema goes here :
        <Database Structure>
        {formatted_data}
        </Database Structure>
    """

    start_index = executive_summary.find("Highlighted Features")
    end_index = executive_summary.find("Key Benefits")

    if start_index != -1 and end_index != -1:
        executive_summary = executive_summary[start_index:end_index].strip()

    user_prompt += "Executive Summary : " + str(executive_summary)

    return system_prompt, user_prompt


#FEATURE HIERARCHY:
generate_features_system_prompt = """
  <Role>
    You are a Software Architect with expertise in analyzing large summaries from code files of an application. 
    You can comprehend summaries from code files that are complex, production-grade and are written in various programming languages to generate most important features, their description and the subfeatures with their description belonging to the most important features along with the other relevant information requested below.
    
    You will follow 2 Events before responding : 
    1. Generation of Feature Hierarchy as given in "Output_Format".
    2. Critical Evaluation of Every Confidence Score.  
  </Role> 

    <Task 1>
    You are provided with multiple relative file paths and file-wise code summaries from a application codebase.
    1. Analyze the file summaries carefully, leveraging your expertise to deduce the frameworks, functionality, and features.
    2. Perform a critical assessment of the code's functionality and interdependencies before responding.
    3. The codebase is complex and likely contains dependencies across various modules. Be mindful of these.
    4. Analyse every file summary and assign the features and sub-features based on the information provided.
    5. Respond strictly in the structured JSON format provided below.
    6. In each sub-feature's 'file_path' array:
        - Set 'critical: true' ONLY for files that are CORE & NON-REPLACEABLE to the sub-feature's main functionality.
        - Set 'critical: false' for ALL supporting, secondary, or replaceable files  
        - Each sub-feature should have both true and false entries.
        - If unsure, default to false (be EXTREMELY selective with 'true')
        - Make sure each sub-feature atleast have one file as true.

    Explanation of the Output terms:
    Feature - Features are most valuable and high level features extracted from the list of summaries that are provided to you. 
    Feature description - Description of the features explaining the high level value and impact that it creates for the project. Define the Feature. The description should be crisp, precise, well formatted and must be between 2-3 lines.
    Subfeature - Subfeatures are micro most valuable features that are extracted from the list of summaries and belong to the Most related and similar Features.
    Subfeature description - Description of the subfeatures explaining the specific value, technical and non-technical functionalites that it provided to the project. Define the subfeature and also explain how its related to the feature. The description should be crisp, precise, well formatted and must be between 2-3 lines.
    
    Points to Remember:
    1. Do not extract any feature or subfeature where there are no reference/citations from the application summaries.
    2. The description must be precise, valuable, well-formatted and must be between 2-3 lines.
    3. The Feature titles should be precise, specific, self explanaible, independent and not have similar feature titles. The Feature titles should not be highly generalized.
    4. The SubFeatures titles should be precise, self explanaible and not have similar subfeature titles. The SubFeature titles should not be highly generalized.
    5. SubFeatures should not be very low level that it explains code functions, code process like 'Json handling', 'Reading csv', readME etc.
    6. If similar subfeatures are present, then group them under one common Feature itself. Do not create multuple Features for similar subfeatures.
    6. If Unit testing related summaries are found, then create that as another Feature named 'Unit Testing' and assign the specific testing subfeatures under this feature.
    </Task 1>

  <Task 2>
  You shall now Assign and Justify Confidence Scores for each feature.

  <Critical Evaluation of Confidence Scores> 

  <Evaluation MODE>
  - You will now Forget everything that was done beforehand and act as an unbiased judge.
  - $Project-Summaries-&-Paths (INPUT).
  </Evaluation MODE>
  <Important>
  Critically analyze every "Feature" and "SubFeature" based on the following metrics. 
  You shall generate a confidence score between 0-100 for each of the following :
  1. Is the "Feature" & "SubFeature" name accurate to its functionality ? (Accuracy)
  2. Does the "Feature" & "SubFeature" include files with an unrelated function ? (Feature Dilution Rate)
  3. Important : Does this "Feature" & "SubFeature" make sense given the Overall Purpose of the Application ? (Consistency)
  4. Are all the files in "Feature" & "SubFeature" included ? (Completeness)

  <Strict>
  1. You will now generate a list of 4 confidence scores between 0-100 for above criteria under "confidence_score" key.
  2. Based on above criteria, you shall provide a VERY BRIEF logical explanation (10-20 words) for Confidence Score under "confidence_score_justification" key.
  3. Make sure to mention the entire filepath without omitting the prefix.
  4. Make sure all the filepaths are present.
  <Important> STRICTLY Don't Comment on Missing Files. Don't Overestimate. Don't Underestimate.</Important> 
  </Strict>

  </Important>

  </Critical Evaluation of Confidence Scores> 
  </Step 2>


      <Output_Format>
    Return a response in JSON format. Do not include any extra information or explanations. Strictly DON'T deviate from mentioned KEYS.
    Example:
```json
[
  {
    "name": "User Authentication and Management",
    "feature_description": "Comprehensive user account system with secure login, registration, profile management, and role-based access control.",
    "feature_description_confidence_score": [95, 70, 100, 70],
    "sub_features": [
      {
        "name": "User Registration",
        "description": "Allows new users to create accounts by providing necessary information such as username, email, and password. Implements email verification, password strength checks, and duplicate account prevention. Stores user data securely in the database with password hashing.",
        "file_path": [
          {
            "module_name": "RegistrationController",
            "path": "Controllers/Account/RegistrationController.cs",
            "critical": true
          },
          {
            "module_name": "RegisterView",
            "path": "Views/Account/Register.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [75, 80, 85, 65],
        "sub_feature_confidence_score_justification": "No feature dilution, might have missed some file."
      },
      {
        "name": "User Login",
        "description": "Authenticates users using their credentials, creates and manages user sessions, and implements security measures such as login attempt limiting and two-factor authentication (2FA). Provides password reset functionality for forgotten passwords.",
        "file_path": [
          {
            "module_name": "LoginController",
            "path": "Controllers/Account/LoginController.cs",
            "critical": true
          },
          {
            "module_name": "LoginView",
            "path": "Views/Account/Login.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [80, 100, 80, 75],
        "sub_feature_confidence_score_justification": "High chance of missing files."
      }
    ],
    "feature_confidence_score_justification": "No feature dilution, duplication or missing files. Accurate Naming."
  },
  {
    "name": "Product Catalog Management",
    "feature_description": "Comprehensive system for managing product listings, categories, and inventory across the e-commerce platform.",
    "feature_description_confidence_score": [95, 65, 70, 80],
    "sub_features": [
      {
        "name": "Product CRUD Operations",
        "description": "Enables administrators to create, read, update, and delete product listings. Includes functionality for managing product details such as name, description, price, images, and inventory levels. Implements validation to ensure data integrity and consistency across the product catalog.",
        "file_path": [
          {
            "module_name": "ProductController",
            "path": "Controllers/ProductController.cs",
            "critical": true
          },
          {
            "module_name": "ProductView",
            "path": "Views/Product/Index.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [90, 85, 100, 70],
        "sub_feature_confidence_score_justification": "High confidence with no duplication or dilution."
      },
      {
        "name": "Category Management",
        "description": "Allows for the creation and management of product categories and subcategories. Implements a hierarchical structure for organizing products, enabling efficient navigation and filtering of the product catalog for both administrators and customers.",
        "file_path": [
          {
            "module_name": "CategoryController",
            "path": "Controllers/CategoryController.cs",
            "critical": true
          },
          {
            "module_name": "CategoryView",
            "path": "Views/Category/Index.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [85, 75, 90, 95],
        "sub_feature_confidence_score_justification": "High confidence without any duplication or dilution."
      }
    ],
    "feature_confidence_score_justification": "All files refer to single overall functionality. Might have missed some files."
  }
]
```
  </Output_Format>

"""

generate_features_user_message = """
<Strictly Remember>
1. As input you will be given a batch of `file_path` and `file_summary` from a production codebase. Keep it in mind that it could be a file from a very large repository with lot of inter-dependencies.
2. Understand all the file description first, then try to determine the feature, sub-features and their description. For **each file** it should have a feature or sub-features whenever the conditions are met.
3. The response should contain all the fields given in the example output format. The response should be strictly in json format.
4. The description of features/subfeatures must be in the length of 2-3 lines. The response should be structured and well-formatted.
5. Don't generate any additional explanation or description. Provide the structured response in json only.
</Strictly Remember>
  
<Input file wise summary>
{file_summary}
</Input file wise summary>
<Response>
"""

merge_features_in_hierarchy_user_prompt = """You are a software feature analyzer. Given a list of related features that have been clustered together, create a merged feature that encompasses all the functionality.

Features to merge:
{feature_list}

Generate a JSON response that includes:
1. A name for the merged feature representing accurate feature name. Do not mention its merged or unified or anything as such. The feature name should accurately represent a major funcationality of a repository.
2. A detailed description that covers all functionality
3. A confidence score (0-100) for the merge
4. A justification for the confidence score

Respond with a JSON object in the following format:
```json
{{
    "name": "Merged feature name",
    "description": "Comprehensive description",
    "confidence_score": 85,
    "confidence_justification": "Reason for the confidence score"
}}
```
Give only JSON and nothing else. Do not include any explanations or additional text outside the JSON block. Make sure to start with ```json and end with ``` only.
"""

mapping_names_for_merged_features_user_prompt = """  <Role>
    You are a smart AI cassistant with strong expertise in Software Engineering. You can understand complex, production-grade codebases written in various programming languages and summarize them effectively.
  </Role>
  <Task>
  You will be given a brief description of  features of a large codebase and your task is to generate a relevant feature name, brief description, and priority level.
  <Important>
   1. The feature name should be brief, relevant and should represent the entire description provided.
   2. Generate a relevant description which is basically a overall summary of the description provided.
   3. Assign a priority level (high, medium, low) based on the significance, importance and complexity of the feature to the overall system. 
  </important>
  </Task>
  <Example output>
  ```json
    {
        "name": <feature_name>, //string
        "feature_description": <feature_description>, //string
        "priority": <priority> //string (high, medium, or low)
    }
    ```
  </Example output>
  <Strictly Remember>
1. The feature name should be relevant and at the same time interpretable, easy to understand.
2. The feature description should represnt the entire description given for summarisation, it should be simple and easy to understant.
3. The priority should be one of: high, medium, or low.
4. The response should be strictly in json format specified above.
5. Strictly make sure Feature Description is not more than 200 words.
  </Strictly Remember>

<code summary>
The code summary is given below:
"""


reducing_sub_features_user_prompt = """
    You are a software feature consolidation expert. Your task is to merge similar sub-features into one comprehensive sub-feature.

    Here are the sub-features that need to be merged:
    {sub_features_list}

    For each sub-feature, we have:
    - Name: The sub-feature name
    - Description: The sub-feature description (if available)
    - Confidence Score: The confidence score (if available)

    Your output should be a JSON object containing:
    1. A unified sub-feature name that encompasses all the input sub-features
    2. A comprehensive description that covers all aspects of the input sub-features
    3. A confidence score (use the highest available from input sub-features)
    4. A justification for the confidence score

    Return the output in JSON format starting with ```json and ending with ```.

    Example output format:
    ```json
    {{
        "name": "Unified Sub-Feature Name",
        "description": "Comprehensive description covering all aspects",
        "sub_feature_confidence_score": 95,
        "sub_feature_confidence_score_justification": "Merged from similar sub-features with high semantic similarity"
    }}
    ```
    """


post_processing_feature_name_description_system_prompt="""
  <Role>
    You are a smart AI assistant with strong expertise in Software Engineering. You can understand complex, production-grade codebases written in various programming languages and summarize them effectively.
  </Role>
  <Task>
  You will be given a brief description of modules or features of a large codebase and your task is to generate a relevant feature name and brief description.
  <Important>
   1. The feature name should be brief, relevant and should represent the entire description provided.
   2. Generate a relevant description which is basically a overall summary of the description provided.
   3. Also generate a confidence score in a scale of 0 - 100.
  </important>
  </Task>
  <Example output>
  ```json
    {
        "name": <feature_name>,
        "feature_description_confidence_score": <score 0 - 100>,
        "feature_description": <feature_description>
    }```
  </Example output>"""

post_processing_feature_name_description_user_prompt = """<Strictly Remember>
1. The feature name should be relevant and at the same time interpretable, easy to understant.
2. The confidence score should represent the ability to summarise the description.
3. The feature description should represnt the entire description given for summarisation, it should be simple and easy to understant.
4. The response should be strictly in json format specified above.
</Strictly Remember>
<code summary>
The code summary is given below: \n
{feature_description}
</code_summary>
<response>
Your response in json goes here:
"""

merge_similar_features_system_prompt = """You are a solution architect. Your task is to carefully review each feature and its description, and combine them into a single high-level feature.

The final high-level features should represent what an end user would perceive, e.g., Messenger, Google Chat, Messaging, Reels, etc.

Based on the generated features provided, identify which features can be merged into a single high-level feature. 
Strictly output them in the following format:
{{ 
  <High-Level Feature Name 1>: [<Merged Feature 1>, <Merged Feature 2>, <Merged Feature 3>, ...],
  <High-Level Feature Name 2>: [<Merged Feature 1>, <Merged Feature 2>, <Merged Feature 3>, ...],
  ...
}}

INPUT:
Feature names and descriptions are provided in the format: 
[1. Feature name: <feature name> 
Feature description: <feature description>, 
2. ...]

{feature_texts}

MVFS:
{total_MVFs}

Points to remember:
1. While merging features and naming high-level features, always prefer names from the user-defined MVFs provided. All relevant features can be grouped under these high-level features.
2. If certain features do not fit under the user-defined MVFs, choose a better name than the existing one for the new high-level feature if necessary.
3. The names of the features being merged must remain exactly as provided in the INPUT section; do not modify them. Do not consider Feature description in Feature Names.
4. Follow the output structure strictly: high-level feature names as dictionary keys and merged features as values in list format.
5. If a feature is already a high-level feature, you do not need to forcibly merge it. If a feature seems to be function-level/low-level  features, merge them into a High-level feature.
6. Merge similar features into a single high-level feature based on their names and descriptions, when applicable. Each final high-level feature should be independent of the others.
7. Do not assign the same feature to multiple high-level features.
8. If user-defined MVFs are empty, skip point 1 and begin with point 2.
9. Do **not** include any Feature descriptions in the final output."""


merging_description_user_prompt = """You are a Solution Architect. Your task is to summarize the multiple feature descriptions provided into a brief, coherent summary of **no more than two sentences**.

  The summary must:
  - Accurately capture all key components from the provided descriptions.
  - Align clearly with the given high-level feature name.
  - Serve as the final description of the high-level feature.

  Only the final summarized description should be included in the output â€” no additional commentary or formatting.

  INPUT:
  Multiple descriptions: {merging_feature_description}

  High-Level Feature Name: {high_level_feature}
  """


micro_sub_feature_prompt = """You are an expert system analyst specializing in decomposing SubFeatures into granular, logically independent components. You support **two levels** of splitting:

1. **Horizontal splitting**: Split a subfeature into multiple *same-level subfeatures* when it encompasses multiple independently meaningful functionalities. The subfeatures created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.
2. **Vertical splitting**: Further break each of those subfeatures into *microsubfeatures* (if applicable), ensuring each micro-sub-features/micro-user-story describes a single goal or operation. The micro-sub-features/micro-user-story created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.

---

### ðŸ”§ TASK OVERVIEW

Given a Macro-Feature, Subfeature, its description, associated module files and its summary:

- Decide if the subfeature should be split horizontally into multiple same-level subfeatures.
- For each resulting subfeature (or original if not split), analyze whether it can be split vertically into **microsubfeatures** (fine-grained user stories).
- Provide the confidence scores for the subfeature that is split, whether horizontally or vertically.
- Provide the files that are related to the sub_features too, not just the micro_sub_features.
- Each leaf user-story must have files assigned to them, else you should not create/split these subfeatures.
- Provide description of generated subfeature/sub-user-stories in 2-4 lines but only valid information. Do not assume or hallucinate to generate description.
Apply this recursively: if horizontal splitting occurs, then attempt vertical splitting for each. But remember, not to create any duplicates in the process. 

---

### SPLITTING DECISIONS

#### Horizontal Splitting (Same-level Subfeatures):
Split if:
- The subfeature covers multiple high-level functionalities
- Each function could be planned, developed, and deployed independently
- Each component has a clear boundary and responsibility

#### Vertical Splitting (Microsubfeatures):
Split further if:
- A subfeature contains multiple independent operations or logical stages
- These operations can be implemented, tested, or tracked separately
- Each micro-subfeature represents one atomic, non-overlapping functionality

---

### DO NOT SPLIT IF:
- sub-user-stories are tightly coupled in the Subfeature and cannot function independently.
- Do not split subfeatures into sub-user-stories that are hardly single line of code and cannot be considered as a proper functionality, but just a config/parameter.
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across actions are too complex to isolate.
- There are no files that can be mapped to the generated user-story.
- Do not split if the user-story is barely a functionality. The split user-stories must have independent functionality that contributes to the subfeature and feature and if not, do not split.
- Don not split ReadMe & .md files into sub-user-stories.
- Do not split horizontall for granullar subfeatures as they are not user stories but mid level features.
---

### FILE MAPPING RULES:
- For each subfeature or microsubfeature, cite only directly relevant files.
- Use only the provided input data to match files â€” no guessing.
- Avoid duplication unless a file is clearly shared between components.

Each `file_path` entry must include:
```json
{
  "module_name": "<Name>",
  "path": "<Path>",
  "critical": <true/false>,
  "git_url": "<Git URL>"
}

OUTPUT FORMAT
If the subfeature should NOT be split:
Return: "None"

If the subfeature should be split, return a list of Parent User Stories with subfeatures inside.
If a subfeature itself can be further split into microsubfeatures, nest them under micro_sub_features like so:

[
  {
    "name": "Parent User Story Title 1",
    "description": "Full description of the original or updated user story and its purpose.",
    "file_path": [...],
    "sub_feature_confidence_score":"confidence score of the subfeature with respect to the Feature, as a percentage (e.g., 80)"
    "micro_sub_features": [
      {
        "name": "Sub-User Story Title 1",
        "description": "Standalone description of a single functionality.",
        "file_path": [...],
        "micro_sub_feature_confidence_score":"confidence score of the micro_sub_feature with respect to the sub_feature, as a percentage (e.g., 90)"
        }
          ...
        ]
      },
      ...
    ]
  }
]
Each layer must preserve independence, clarity, and singular focus of each story.

VALIDATION CHECKLIST
- Each title must express one functionality only (no imperative phrasing)
- description must avoid assumptions and describe the real function. It must be as detailled as possible.
- Each story must make sense independently and fit in the broader feature flow
- if there are multiple user-story under the subfeature, it needs to be in sequence of business logic.
- File mappings must be relevant and scoped accurately
- Do no miss/skip any values in the output json. The output structure must be maintained strictly.
- All subfeature and sub-user-story names and descriptions must be strictly in a declarative tone, not imperative.

* Use generic or speculative statements
"""


db_micro_sub_feature_prompt = """
<Role>
You are an expert Database analyst specializing in decomposing SubFeatures into granular, logically independent components. You support **two levels** of splitting:
You shall ALWAYS process features from a Database perspective ONLY. 
There can be more than one Table in the DB context provided to you.
</Role>

1. **Horizontal splitting**: Split a subfeature into multiple *same-level subfeatures* when it encompasses multiple independently meaningful functionalities. The subfeatures created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.
2. **Vertical splitting**: Further break each of those subfeatures into *microsubfeatures* (if applicable), ensuring each micro-sub-features/micro-user-story describes a single goal or operation. The micro-sub-features/micro-user-story created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.

<Strict Constraints> 
- You are dealing with Database Information. 
- No matter what, STRICTLY use Database-Specific Language ALWAYS. 
- Use words like Columns / Fields / Schema / DataTypes / Constraints / Foreign Keys / Primary Keys etc.
- Strictly Do not start descriptions with or start with "this micro-feature" / or "this sub-feature".
- You shall do this regardless of the input context and nature.
Remember : Every "FILE" given to you is information of a table. Therefore in your response, ALWAYS refer to "Table" instead of "File".

</Strict Constraints> 


### ðŸ”§ TASK OVERVIEW

Given a Macro-Feature, Subfeature, its description, associated module files and its summary:

- Decide if the subfeature should be split horizontally into multiple same-level subfeatures.
- For each resulting subfeature (or original if not split), analyze whether it can be split vertically into **microsubfeatures** (fine-grained user stories).
- Provide the confidence scores for the subfeature that is split, whether horizontally or vertically.
- Provide the files that are related to the sub_features too, not just the micro_sub_features.
- Each leaf user-story must have files assigned to them, else you should not create/split these subfeatures.
- Provide description of generated subfeature/sub-user-stories in 2-4 lines but only valid information. Do not assume or hallucinate to generate description.
Apply this recursively: if horizontal splitting occurs, then attempt vertical splitting for each. But remember, not to create any duplicates in the process. 

---

### SPLITTING DECISIONS

#### Horizontal Splitting (Same-level Subfeatures):
Split if:
- The subfeature covers ONE / MORE THAN ONE high-level functionalities
- Each function could be planned and developed independently
- Each component has some clear boundaries and responsibilities

#### Vertical Splitting (Microsubfeatures):
Split further if:
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across actions are too complex to isolate.
- There are no tables that can be mapped to the generated user-story.
- The subfeature is too complex to be planned, developed, and deployed independently
- Each micro-subfeature represents one atomic, non-overlapping functionality
Note: Maintain at least 2 subfeatures unless the database has only one table.
- Prioritize brevity, consistency and no informaiton leakage across subfeatures.
- Ensure crisp segregation.
---

### DO NOT SPLIT IF:
- sub-user-stories are tightly coupled in the Subfeature and cannot function independently.
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across tables in two features are too complex to isolate.
- There are no tables that can be mapped to the generated user-story.
Note: Maintain at least 2 subfeatures and 1 or more microsubfeatures per subfeature, Unless the database has only one table.
Note : Maintain brevity during splitting at the same level. Do NOT overload the a single feature with too many subfeatures.
---


### FILE MAPPING RULES:
- For each subfeature or microsubfeature, cite only directly relevant tables.
- Use only the provided input data to match files â€” no guessing.
- Avoid duplication unless a file is clearly shared between components.

Each `file_path` entry must include:
```json
{
  "module_name": "<Name>",
  "path": "<Path>",
  "critical": <true/false>,
  "git_url": "<Git URL>"
}

OUTPUT FORMAT
If the subfeature should NOT be split:
Return: "None"

If the subfeature should be split, return a list of Parent User Stories with subfeatures inside.
If a subfeature itself can be further split into microsubfeatures, nest them under micro_sub_features like so:

[
  {
    "name": "Parent User Story Title 1",
    "description": "Full description of the original or updated user story and its purpose.",
    "file_path": [...],
    "sub_feature_confidence_score":"confidence score of the subfeature with respect to the Feature, as a percentage (e.g., 80)"
    "micro_sub_features": [
      {
        "name": "Sub-User Story Title 1",
        "description": "Standalone description of a single functionality.",
        "file_path": [...],
        "micro_sub_feature_confidence_score":"confidence score of the micro_sub_feature with respect to the sub_feature, as a percentage (e.g., 90)"
        }
          ...
        ]
      },
      ...
    ]
  }
]
Each layer must preserve independence, clarity, and singular focus of each story.

VALIDATION CHECKLIST
- Each title must express one functionality only (no imperative phrasing)
- description must avoid assumptions and describe the real function. It must be as detailled as possible.
- Each story must make sense independently and fit in the broader feature flow
- if there are multiple user-story under the subfeature, it needs to be in sequence of business logic.
- File mappings must be relevant and scoped accurately
- Do no miss/skip any values in the output json. The output structure must be maintained strictly.
- All subfeature and sub-user-story names and descriptions must be strictly in a declarative tone, not imperative.
- Use Database-specific schema only. Do not include words like "Attributes" / "Code Files" in your response. 
- Strictly Do not start descriptions with or start with "this micro-feature" / or "this sub-feature".
* Use generic or speculative statements

"""import os
from graphviz import Digraph
import re 
import json

def parse_ddl(ddl: str):
    """
    Parse the DDL to extract columns, primary keys, and foreign keys.
    """
    lines = ddl.splitlines()
    column_lines = []

    for line in lines:
        line = line.strip()
        if (
            line.upper().startswith("CREATE")
            or line.upper().startswith("PRIMARY")
            or line.upper().startswith("FOREIGN")
            or line.upper().startswith(")")
            or line == ""
        ):
            continue

        match = re.match(r'(\w+)\s+\w+', line)
        if match:
            column_lines.append(match.group(1))

    pk_match = re.search(r'PRIMARY KEY\s*\((.*?)\)', ddl)
    primary_keys = [key.strip() for key in pk_match.group(1).split(",")] if pk_match else []

    foreign_keys = []
    for match in re.finditer(r'FOREIGN KEY\s*\(([^)]+)\)\s+REFERENCES\s+`?[\w]+\.(\w+)`\(([^)]+)\)', ddl):
        fk_col = match.group(1).strip()
        ref_table = match.group(2).strip()
        ref_col = match.group(3).strip()
        foreign_keys.append((fk_col, ref_table, ref_col))

    return column_lines, primary_keys, foreign_keys


def generate_combined_graph(tables_data):
    """
    Generate a single combined graph from multiple tables.
    """
    dot = Digraph(comment='Combined Table Diagram')
    dot.attr(rankdir='LR')

    # Store individual table nodes
    for table in tables_data:
        table_name = table['table_name']
        columns = table['columns']
        primary_keys = table['primary_keys']
        
        label_lines = []
        for col in columns:
            if col in primary_keys:
                label_lines.append(f"{col} [PK]")
            else:
                label_lines.append(col)
        dot.node(table_name, shape='box', label=f'{table_name}\\n' + "\\n".join(label_lines))

    # Add relationships
    for table in tables_data:
        table_name = table['table_name']
        for fk_col, ref_table, ref_col in table['foreign_keys']:
            dot.edge(table_name, ref_table, label=f'{fk_col} â†’ {ref_col}')

    return dot

def folder_summary_generation_prompts(
        total_allocated_tokens, 
        file_list, folder_name, 
        folder_path,
        subfolder_list,
        formatted_file_summaries,
        formatted_file_services,
        formatted_subfolder_summaries,
        formatted_subfolder_services,
        formatted_subfolder_features
    ):
    
    system_prompt = f"""
        You are an expert code analyst specialized in creating detailed, informative summaries of software project folders. Your task is to thoroughly analyze files and subfolders to provide a comprehensive understanding of the application or project and provide combined summaries along with required details. These summaries must be detailled enough for further summarization.

        Follow these guidelines:
        1. Conduct a deep analysis of the features to identify its core purpose and functionality
        2. Provide detailed explanation of key implementations and technical approaches of the features
        3. Thoroughly examine the summaries based on files and folders to understand relationship between features and combined smaller features into larger high level application level features.
        4. Explain the features within the broader project architecture with specific connections
        5. Describe technical patterns, design decisions, and architectural choices evident in the code
        6. Include specific functions, classes, and methods that define the feature's behavior
        7. Note dependencies, imports, and external connections that shape the folder's functionality
        8. Identify potential architectural strengths and areas for improvement when evident
        9. Identify all services represented in this folder based on file and subfolder services information
        10. Identify and articulate high-level features or functionalities represented by the folder into the feature_details section, when consolidating multiple subfolders or lower-level files. Derive these insights from both file-level and subfolder-level summaries. Also under each feature, mention which file/folder was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
        11. Do not miss any features that could be formed based on these summaries as this information is required to understand the application's buisness logic.
        12. Gather insights from the summaries provided to generate a high level detailled executive summary that could be used by business stakeholders to understand the folder/project.
        13. When analyzing the root folder, both the executive summary and the features must be strictly formed in a high level business logic standpoint of an application.
        
        IMPORTANT: 
        - Your summary should be thorough and detailed({total_allocated_tokens}) while maintaining technical/business precision and depth. Focus on providing insights that would help both stakeholders and developers understand the application better.
        - feature_details must contain high level feature name and feature description(value of the files/folders) strictly in concise bullet points. The feature inforamtion must be in detail to capture the complete high level knowledge for that feature but not the function level details. Feature names cannot be programmatic function names like Dependency management, json handling etc. instead it should be inventory management, order processing etc. 
        - Your services list should be comprehensive and include all services represented in this folder.
        - is_reuasble_lib if a folder is used as reusable lib make it True otherwise False
        - lib_name if is_reusable_lib is True then provide the name of the reusable lib/component If is_reusable_lib False then add Not Applicable
        - category if is_reusable_lib is True then provide category only between 'Frontend' and 'Backend' If is_reusable_lib False then add Not Applicable
        - sub_category if is_reusable_lib is True then provide sub category only between 'UI Component','Custom Hooks', 'http_client', 'Utils', 'Others' In Frontend & 'Middleware', 'Error Handling', 'Auth', 'Utils', 'Others' In Backend If is_reusable_lib False then add Not Applicable
        - when_to_use if is_reusable_lib is True then provide where this reusable lib/component can be used If is_reusable_lib False then add Not Applicable 
        - associated_files if is_reusable_lib is True then provide the list of files associated(give complete path for the assosciated file) with this reusable lib/component If is_reusable_lib False then add Not Applicable
        - summary must not be technical and only explain the high level details of the folder/project. Understand the file and folder summaries provided to combine the knowledge to form the executive summary. Make it as detailled as possible.
        - Use clear and concise language, avoiding jargon where possible.
        
        - You must provide your response in this exact format:
        ```summary
        [Your detailled high-level executive summary for the folder for business stakeholders]
        ```
        ```feature_details
        [List of high-level features or functionalities represented in this folder]
        ```
        ```services_namess
        [Comma-separated list of all services represented in this folder]
        ```
        ```is_reuasble_lib
        Boolean Value
        ```
        ```lib_name
        [Name of the reusable library if applicable]
        ```
        ```category
        [Category of the reusable library if applicable]
        ```
        ```sub_category
            [Sub category of the reusable library if applicable]
        ```
        ```when_to_use
        [Your detailed use case where or when this reuasble_lib can be usefull]
        ```
        ```associated_files
            [Comma-separated list of associated files with the reusable library, Give the Complete file path as mentioned in the file list]
        ```
        ```example_usage
            [Example code snippet of how to use this reusable library]
        ```
    """

    user_prompt = f"""
        Generate a summary and services list for the folder: "{folder_name}" (Path: {folder_path})

        FOLDER CONTENTS:
        - Files ({len(file_list)}): {", ".join(file_list) if file_list else "None"}
        - Subfolders ({len(subfolder_list)}): {", ".join(subfolder_list) if subfolder_list else "None"}

        FILE SUMMARIES:
        {os.linesep.join(formatted_file_summaries) if formatted_file_summaries else "No file summaries available"}

        FILE SERVICES:
        {os.linesep.join(formatted_file_services) if formatted_file_services else "No file services available"}

        SUBFOLDER SUMMARIES:
        {os.linesep.join(formatted_subfolder_summaries) if formatted_subfolder_summaries else "No subfolder summaries available"}

        SUBFOLDER SERVICES:
        {os.linesep.join(formatted_subfolder_services) if formatted_subfolder_services else "No subfolder services available"}

        SUBFOLDER FEATURES:
        {os.linesep.join(formatted_subfolder_features) if formatted_subfolder_features else "No subfolder features available"}
        
        Based on these components:
        1. Provide a thorough technical summary explaining the folder's purpose, implementation details, and architectural significance
        2. Compile a comprehensive list of all services represented in this folder based on file and subfolder services information
        
        Follow the exact format specified in the system instructions for your response.
    """

    return system_prompt, user_prompt

def services_generation():
    system_prompt = """
        <Task>
        Create an architectural blueprint of the given repository by identifying and classifying both external services and third-party services with no overlap between categories.
        </Task>

        <Definitions>
        - External services: Company-provided services hosted outside the application (AWS S3, Google Cloud, Stripe, Twilio)
        - Third-party services: Libraries, frameworks, and SDKs that are part of the core application stack (Django, React, MongoDB, Redux)
        </Definitions>

        <Output_Format>
        {
        "external_services": [
            {
            "external_service_name": "string",
            "description": "string",
            "associated_files": ["string"],
            "service_class": "string",
            "used_in_files": ["string"]
            }
        ],
        "thirdparty_services": [
            {
            "thirdparty_service_name": "string",
            "description": "string",
            "associated_files": ["string"],
            "service_class": "string",
            "used_in_files": ["string"]
            }
        ]
        }
        </Output_Format>

        <Instructions>
        1. Conduct a thorough repository analysis to identify all services
        2. Classify each service into exactly ONE category:
        - External services: Cloud platforms, payment processors, authentication providers
        - Third-party services: Frameworks, libraries, SDKs integrated into the codebase
        3. For each service, provide:
        - Name: Exact service name
        - Description: Concise explanation of functionality and purpose
        - Associated files: All files directly importing or using the service
        - Service class: Category (e.g., "cloud storage", "web framework", "database")
        - Used in files: Complete paths of files utilizing the service
        4. Ensure ZERO overlap between categories
        5. Prioritize accuracy over comprehensiveness
        6. Validate that identified services are actively used in the project
        7. Include only services with clear evidence of implementation
        8. Do not create a lot of services which are redundant. Keep it to a maximum of 50 services only.
        </Instructions>

        <Examples>
        Good External Service Entry:
        {
        "external_service_name": "AWS S3",
        "description": "Cloud storage service used for storing user-uploaded files",
        "associated_files": ["src/services/storage.js", "src/config/aws.js"],
        "service_class": "cloud storage",
        "used_in_files": ["src/components/FileUpload.js", "src/pages/UserProfile.js"]
        }

        Good Third-Party Service Entry:
        {
        "thirdparty_service_name": "React",
        "description": "Frontend JavaScript library for building user interfaces",
        "associated_files": ["package.json", "src/index.js"],
        "service_class": "frontend framework",
        "used_in_files": ["src/App.js", "src/components/*.js"]
        }
        </Examples>

        Analyze the repository and provide the complete architectural blueprint in the specified format.
    """

    user_prompt = ""

    return system_prompt, user_prompt

def executive_summary_generation(combined_summary, user_mvf):
    system_prompt = """
    Your Role:
    You are an expert software architect tasked with understanding a codebase and creating an executive summary that clearly articulates the main purpose of this application,
    the core problem that the application is solving, and the prioritized list of the most valuable features, solely based on the provided folder wise summary. Do not hallucinate and create the most valuable features and its description on assumption. This needs to be based on facts.

    Task:
    1. Analyze provided folder wise summary and the services used and the user defined features (if provided).
    2. Understand component interactions and functions.
    3. Prioritize the User Defined Features (if provided) in the summary.
    4. Identify and prioritize the most valuable features based on their importance and relevance to the overall project, as evidenced in the code.
    5. Create a comprehensive executive summary.

    Steps:
    1. Review folder wise summary.
    2. Analyze folder wise summary:
    - Identify key components and their roles
    - Note data operations, design patterns, and architectural decisions
    3. Create summary:
    - Describe the specific problem the codebase solves, based on folder wise summary
    - Explain component interactions
    - Outline data workflow
    4. Identify and prioritize main features:
    - Determine which feature(s) address the core problem of the application, based on code implementation
    - Rank features based on their importance and relevance to solving the main problem, as evidenced in the code
    - The feature should be major components of the codebase and not minor functions like "Modular Architecture" or "Code Reusability", these are not features but design principles.

    Focus Areas:
    - Precised feature prioritization and importance
    - High-level functionality
    - Clear, concise technical language
    - Objective description
    - Capture entire workflow

    Guidelines:
    - Only use the folder wise summary provided
    - Use precise technical terms
    - Include user-defined features if provided and evidenced in the code
    - Prioritize features based on their importance to the core problem, as shown in the folder wise summary

    Feature Identification and Prioritization:
    - Carefully analyze the folder wise summary to identify features actually present in the folder wise summary
    - Do not assume or infer features that are not explicitly mentioned in the folder wise summary
    - Identify the top feature that solves the majority of the problem based on code evidence
    - Rank subsequent features in descending order of importance, ensuring they are present in the folder wise summary
    - Ensure the feature list reflects the codebase's focus and structure
    - Only include features that have substantial implementation in the codebase that is evident from folder wise summary

    Output Format - Adhering to this format is crucial
    ```json
    {
    "data": "generated_summary in string format adhering to the Expected Output Format for Generated Summary",
    "confidence_score": 90,
    "traceback": {
    "Feature 1 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 1 Title' is included, as the 'phrase' is an evidence that this feature is part of the codebase.",
    "Feature 2 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 2 Title' is included, as the 'phrase' is an evidence that this feature is part of the codebase.",
    ...
    }
    }
    ```

    Requirements:
    - Replace \n with \\n in JSON
    - Limit upto 5 main features (max 2 sub-features each) or 7500 tokens
    - If due to any reason such as codebase being small, you are unable to provide 5 features, then provide as many high-level features as possible between the range of 1 to 5.
    - Don't assume features or include minor features due to inability to provide 5 features, lesser number of features is acceptable.
    - Use specified JSON format only
    - Start with "```json" and end with "```"
    - Ensure the top feature in the prioritized list addresses the core problem and is present in the folder wise summary
    - Rank features in descending order of importance to the main problem, based on actual code implementation
    - Do NOT include features that are NOT evidenced in the provided folder wise summary
    - Evaluate the folder wise summary objectively, considering all conclusions on the actual code provided
    - Do NOT make any assumptions about organizational goals or intentions beyond what is explicitly shown in the code
    - Focus solely on the technical aspects and implemented functionality, avoiding speculation about business objectives or future plans
    - Both the keys data, confidence score, and traceback should be present in the output JSON
    - The generated summary should be in string format only and be contained inside the "data" key
    - The "traceback" key should contain a dictionary with feature names as keys and justifications for including these features based on exact phrases from the input
    - Do not include any feature that could potentially be part of the folder wise summary without explicit evidence
    - Every feature mentioned must be driven by clear evidence from the provided input
    """
    user_prompt = """
    Expected Output Format for Generated Summary:

  **Overview**
  <empty line>
  <A brief introduction to the codebase and its main purpose; in paragraph format only, not in points.
  This paragraph should provide a concise yet comprehensive overview of the codebase, its primary functionality, solution provided by the project and its intended use case.
  Aim for 3-5 sentences that capture the essence of the project.>
  <empty line>
  **Highlighted Features**
  <empty line>
  <
  List and briefly explain the key features that are significant components of the codebase and would serve as selling points.
  These features should be presented as follows:
  1. Use numbered points for each feature.
  2. Provide a brief explanation for each feature in 1-2 sentences, highlighting its importance and benefit to the end user.
  3. Focus on features that are central to the codebase's functionality and most important to the end user.
  4. Dont include generic features like "Modular Architecture" or "Code Reusability", these are not features but design principles.
  5. Do not include sub-points under any feature.
  6. Prioritize User Defined Features (if provided) at the beginning of the list.
  7. If User Defined Features are given, list them first before including any features identified through your analysis.
  8. Aim to provide upto of 1 to 5 key features, after each feature add an empty line for formatting purposes.
  9. Ensure that the features listed represent the core functionality and unique selling points based on the folder wise summary.
  10. Use clear, concise language that emphasizes the value proposition of each feature.
  11. Also under each feature, mention which file/folder was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
  12. Do not add features into Highlighted Features if they dont have value for buisness stakeholder about the application. Also do not repeat adding similar feature in this section.

  Output Structure:
  1. ***<Feature 1 Title>***: <Description of the feature in one to two sentences.\n
  2. ***<Feature 2 Title>***: <Description of the feature in one to two sentences.>\n
  >
  <empty line>
  **Key Benefits**
  <empty line>
  <Summarize the key benefits of the codebase in one to two sentences.
  This summary should encapsulate the overall value proposition of the codebase and its potential impact on users or the organization.>
  <empty line>
  <Highlight the most significant key benefits the codebase has to offer in bulleted points. The format should be:
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  Aim for 3-5 bullet points that capture the most compelling advantages of using this codebase, after each point add an empty line for formatting purposes.
  Each benefit should be distinct and provide a clear value proposition.>

  <Final Output Format>
  Output Format - Adhering to this format is crucial, the output should be in parsable JSON format:
  ```json
  {{
    "data": "<generated_summary in string format adhering to the Expected Output Format for Generated Summary>",
    "confidence_score": 90,
    "traceback": {{
      "Feature 1 Title": "Since it mentions about <exact phrase from the folder wise summary>, the 'Feature 1 Title' is included, as the "phrase" is an evidence that this feature is part of the folder wise summary.",
      "Feature 2 Title": "Since it mentions about <exact phrase from the folder wise summary>, the 'Feature 2 Title' is included, as the "phrase" is an evidence that this feature is part of the folder wise summary.",
      ...
    }}
  }}
  ```
  </Final Output Format>
  Note: If the traceback includes phrases that are not present in the folder wise summary then you would be penalized 10000 points.
  The output should be having data, confidence score, and traceback keys, and the entire content inside "```json" and "```" should be parsable by json.
  The "data" key should contain the generated summary and it should be in string format only, allowing the parsing of the entire json.
  If there are any inverted commas inside the generated summary, then escape them with a backslash.
  Do not change or skip the headings of each section in the generated json. The generated summary must have "Overview", "Highlighted Features", "Key Benefits" as section titles. Follow the above provided guidelines."""
    user_prompt += f"""Use the below folder wise summary to generate the summary in the above format: {combined_summary}""" + "User Defined Features : " + str(user_mvf)
    return system_prompt, user_prompt

def db_executive_summary_generation(combined_summary, user_mvf): 
    system_prompt = """
    Role:
    You are an expert Database Architect tasked with understanding the contents of all tables and schema of the database. 
    You shall Articulate a proper executive summary that clearly captures all the main & high-level features of this database.
    The core use-case that this database is intended for, and the prioritized list of the most valuable features, solely based on the provided Table-Level summaries. 
    Do not hallucinate. Do NOT create the most valuable features and its description on pure assumptions. This needs to be based on facts, with proper backing.

    Task:
    1. Analyze provided Table wise summaries.
    2. Understand component interactions and functions.
    3. Prioritize the User Defined Features (if provided) in the summary.
    4. Identify and prioritize the most valuable features based on their importance to the core use-case the Database is solving.
    5. Create a comprehensive executive summary.

    Steps:
    1. Review Table wise summary.
    2. Analyze Table wise summary:
      - Identify all tables. 
      - Take into consideration the foreign keys, primary keys, is-a, has-a, and many-to-many relationships.
      - Deeply understand the intended-use-case of each table.
      - Note data operations, design patterns, and architectural decisions
    3. Create summary:
      - Describe the specific problem the Database is solving, based on Table wise summary
      - Explain high-level interactions and dependencies
      - Outline data workflow
    4. Identify and prioritize main features:
      - Determine which feature(s) address the core problem of the Database, based on SQL implementation and Table wise summary
      - Rank features based on their importance and relevance to solving the main problem, as evidenced in the Database
      - The feature should be major components of the Database and not minor functions like Many-to-Many Relationships, or "Foreign Keys". 
        These are implementation concepts. Not core features.

    Focus Areas:
    - Precised feature prioritization and importance
    - High-level functionality of this Database
    - Clear, concise technical language with Database-specific Language
    - Objective description
    - Capture entire data workflow

    Guidelines:
    - Only use the Table wise summary provided
    - Use precise Database-relevant technical terms
    - Include user-defined features if provided and evidenced in the Table wise summary
    - Prioritize features based on their importance to the core problem, as shown in the Table wise summary

    Feature Identification and Prioritization:
    - Carefully analyze the Table wise summary to identify features actually present in the Table wise summary
    - Do not assume or infer features that are not explicitly mentioned in the Table wise summary
    - Identify the top feature that solves the majority of the problem based on Database and SQL evidence
    - Rank subsequent features in descending order of importance, ensuring they are present in the Table wise summary
    - Ensure the feature list reflects the Database's focus and structure
    - Only include features that have substantial implementation in the Database that is evident from Table wise summary

    Output Format - Adhering to this format is crucial
    ```json
    {
    "data": "generated_summary in string format adhering to the Expected Output Format for Generated Summary",
    "confidence_score": 90,
    "traceback": {
    "Feature 1 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 1 Title' is included, as the 'phrase' is an evidence that this feature is part of the Database.",
    "Feature 2 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 2 Title' is included, as the 'phrase' is an evidence that this feature is part of the Database.",
    ...
    }
    }
    ```

    Requirements:
    - Replace \n with \\n in JSON
    - Limit upto 5 main features (max 2 sub-features each) or 7500 tokens
    - If due to any reason such as Database being small, you are unable to provide 5 features, then provide as many high-level features as possible between the range of 1 to 5.
    - Don't assume features or include minor features due to inability to provide 5 features, lesser number of features is acceptable.
    - Use specified JSON format only
    - Start with "```json" and end with "```"
    - Ensure the top feature in the prioritized list addresses the core problem and is present in the Table wise summary
    - Rank features in descending order of importance to the main problem, based on actual Database and SQL implementation
    - Do NOT include features that are NOT evidenced in the provided Table wise summary
    - Evaluate the Table wise summary objectively, considering all conclusions on the actual Database and SQL provided
    - Do NOT make any assumptions about organizational goals or intentions beyond what is explicitly shown in the Database and SQL
    - Focus solely on the technical aspects and implemented functionality, avoiding speculation about business objectives or future plans
    - Both the keys data, confidence score, and traceback should be present in the output JSON
    - The generated summary should be in string format only and be contained inside the "data" key
    - The "traceback" key should contain a dictionary with feature names as keys and justifications for including these features based on exact phrases from the input
    - Do not include any feature that could potentially be part of the Table wise summary without explicit evidence
    - Every feature mentioned must be driven by clear evidence from the provided input.
    - Strictly use an assertive and objective tone in your response. 
    - Do not be unsure about anything.
    - Do not include the "Folder Name" in your response. Ignore "dbanalysis" folder. Provide Executive Summary of the Database-ONLY.
    """

    user_prompt = """
  Expected Output Format for Generated Summary:

  **Overview**
  <empty line>
  <A brief introduction to the Database and its main purpose; in paragraph format only, not in points.
  This paragraph should provide a concise yet comprehensive overview of the Database, its primary functionality, and its intended use case.
  Aim for 3-5 sentences that capture the essence of the Database.>
  <empty line>
  **Highlighted Features**
  <empty line>
  <
  List and briefly explain the key features that are significant components of the Database and would serve as selling points.
  These features should be presented as follows:
  1. Use numbered points for each feature.
  2. Provide a brief explanation for each feature in 1-2 sentences, highlighting its importance and benefit to the END USER.
  3. Focus on features that are central to the Database's functionality and most important to the END USER.
  4. Dont include generic features like  Many-to-Many Relationships, or "Foreign Keys", these are not features but Design Principles.
  5. Do not include sub-points under any feature.
  6. Prioritize User Defined Features (if provided) at the beginning of the list.
  7. If User Defined Features are given, list them first before including any features identified through your analysis.
  8. Aim to provide upto of 1 to 5 key features, after each feature add an empty line for formatting purposes.
  9. Ensure that the features listed represent the core functionality and unique selling points based on the Table wise summary.
  10. Use clear, concise language that emphasizes the value proposition of each feature.
  11. Also under each feature, mention which file/Table was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
  12. Do not add features into Highlighted Features if they dont have value for buisness stakeholder about the application. Also do not repeat adding similar feature in this section.

  Output Structure:
  1. ***<Feature 1 Title>***: <Description of the feature in one to two sentences.\n
  2. ***<Feature 2 Title>***: <Description of the feature in one to two sentences.>\n
  >
  <empty line>
  **Key Benefits**
  <empty line>
  <Summarize the key benefits of the Database in one to two sentences.
  This summary should encapsulate the overall value proposition of the Database and its potential impact on users or the organization.>
  <empty line>
  <Highlight the most significant key benefits the Database has to offer in bulleted points. The format should be:
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  Aim for 3-5 bullet points that capture the most compelling advantages of using this Database, after each point add an empty line for formatting purposes.
  Each benefit should be distinct and provide a clear value proposition.>

  <Final Output Format>
  Output Format - Adhering to this format is crucial, the output should be in parsable JSON format:
  ```json
  {{
    "data": "<generated_summary in string format adhering to the Expected Output Format for Generated Summary>",
    "confidence_score": 90,
    "traceback": {{
      "Feature 1 Title": "Since it mentions about <exact phrase from the Table wise summary>, the 'Feature 1 Title' is included, as the "phrase" is an evidence that this feature is part of the Table wise summary.",
      "Feature 2 Title": "Since it mentions about <exact phrase from the Table wise summary>, the 'Feature 2 Title' is included, as the "phrase" is an evidence that this feature is part of the Table wise summary.",
      ...
    }}
  }}
  ```
  </Final Output Format>
  Note: If the traceback includes phrases that are not present in the Table wise summary then you would be penalized 10000 points.
  The output should be having data, confidence score, and traceback keys, and the entire content inside "```json" and "```" should be parsable by json.
  The "data" key should contain the generated summary and it should be in string format only, allowing the parsing of the entire json.
  If there are any inverted commas inside the generated summary, then escape them with a backslash.
  Do not change or skip the headings of each section in the generated json. The generated summary must have "Overview", "Highlighted Features", "Key Benefits" as section titles. Follow the above provided guidelines.
    """

    user_prompt += f"""Use the below Table wise summary to generate the summary in the above format: {combined_summary}""" + "User Defined Features : " + str(user_mvf)

    return system_prompt, user_prompt


def architecture_diagram_generation(services_data, icons_metadata):
    user_prompt = f"""
    <Input>
    $services_data = {services_data}
    $icons_metadata
    </Input>

    <Role>
    You are an expert at understanding large projects based on their executive summary and the services being used in them. Create a JSON structure for a ReactFlow diagram based on the given service class JSON.
    </Role>

    <Output Structure>
    1. Create a JSON object with a "nodes" and "edges" array.
    2. Create nodes for each external and third-party service.
    3. "nodes": An array containing all node objects.
      - "id": A unique string identifier for the node.
      - "data":   
        - "label": The name of the node.
        - "description": Description of the service.
        - "associated_files": Associated file and used in files in the service node, defaulting to "No File Available" if not present.
        - "group": The logical group name (e.g., 'Backend', 'Frontend', 'Database',etc..).
        - "subgroup": The specific subgroup within the group (e.g., Frameworks, NoSQL Databases, State Management, etc.).
        - "service": The appropriate filename of the icon based on the $icons_metadata.
      - "position" : The x and y coordinates of the node.
      - "type" : "customNode" This should be fixed.
    4. "edges" : An array having id, source, target, label, and type should be customEdge always.
    4. Ensure all services and files from the input JSON are included.
    5. The output should be in the form of a dictionary containing a "nodes" and "edges" array.
    6. Present only the code inside delimiters "```reactflow [reactflow CODE]```" without any additional explanation.
    """

    system_prompt:str = """
    <Task>
      You are tasked with creating a JSON structure for a ReactFlow diagram based on the given executive summary and the service_class_json. The executive summary contains an overview of the entire project. This JSON includes information about external services and third-party services, along with their associated files. Your output should represent this information as a network of nodes and edges.
    </Task>
    
    <Icons Context>
      $icons_metadata = """ + str(icons_metadata) + """
    </Icons Context>

    <Instructions>
      You are a solution expert, specializing in problem and solution flows. You will be given the solution overview for a project, and your task is to create an interconnected single component of graph which is detailed, and intuitive and self explanatory for:

      Follow these guidelines:
      1. Create nodes for each unique service (both external and third-party).
      2. Do not create any group nodes.
      4. In the data key for each service node, include two additional fields called group and subgroup. The group field should contain the logical group name (e.g., Frontend, Backend, Databases, etc..), and the subgroup field should provide more specific categorization (e.g., Frameworks, NoSQL Databases, etc..). For example, for a service node representing React, the group would be Frontend and the subgroup would be Frameworks.
      5. For each node, check which icon will be the most suitable from the $icons_metadata in the <Icons Context>
      6. Ensure all information from the input is represented in the output.
      7. The position coordinates must be proper for all the nodes.
    </Instructions>

    <Rules>
      **Ensure all nodes in the generated graph are interconnected such that every node has at least one edge, forming a single connected component without any isolated or disjoint sections. (High Priority Requirement)**
      Important Rules to be followed:
      1. Give detailed technical architecture flow and the JSON object following the below output format.
      2. Make sure that the flow and order of new solution approach is explained well in the graph with appropriate edges. Use as many edges you want to describe the data and user flow properly.
      3. The whole user and data flow should be clear.
      4. Do not add unnecessary nodes and edges. Do not create duplicate nodes that perform same task.
      5. Make the Node descriptions detailed, breaking tasks into multiple sub-tasks if needed.
      6. Ensure your edges show the actual flow, and not just connections of what's related. The connections are meant to show the logical flow, and not the relatedness/similarity.
      7. The group name is meant to classify clusters of nodes within each graph. For instance, if we have multiple nodes in features, they would all have "feature" as group. In Architecture Flow, the "Group" should show the layer each node is in, for instance "Backend Layer", "Database Layer" etc.
      9. for a hierarchy of nodes A -> B -> C; ensure that there is not a connection between A -> C.
    </Rules>
    
    <output_format>
    The output should be in between the delimeters ```reactflow and ```. Only provide the json output. Don't give unnecesary explanation.
    ```reactflow
    {
      "nodes": [
        { 
          "id": "unique_node_identifier_string",
          "data" : {
            "label": "name_of_the_service",
            "description": "description of the service",
            "associated_files": ["file_path_1", "file_path_2", "file_path_3", etc.],  // (default: ["No File Available"] if not present)
            "group": "name_of_group",  // Add the logical group name (e.g., "Frontend", "Backend", etc..)
            "subgroup": "name_of_subgroup",  // Add a more specific subgroup name (e.g., "Frameworks", "NoSQL Databases", etc..)
            "service": "filename" //taken from the $icons_metadata,
          }
          "position":{ "x": "Xcoordinate", "y": "Ycoordinate" },
          "type" : "customNode" //this is hardcoded and will be constant
        }
      ],
      "edges": [
        {
          "id": "unique_egde_identifier_string",
          "source": "label A",
          "target": "label B",
          "label": "Showcase what comes from the source node, to the target node. Be concise and specific with labels, such as 'Ingested Data', 'Converted Text', 'User Query' etc. Use at max 5 words",
          "type" : "customEdge" //this is hardcoded and will be constant
        }
      ]
    }```
    </output_format>
    """
    return system_prompt, user_prompt
  

def erd_generation(services_data, icons_metadata):
  tables_metadata = []
  for entry in services_data:
      table_name = entry["table_name"]
      ddl = entry["ddl"]
      columns, primary_keys, foreign_keys = parse_ddl(ddl)
      tables_metadata.append({
          "table_name": table_name,
          "columns": columns,
          "primary_keys": primary_keys,
          "foreign_keys": foreign_keys
      })

  dot = generate_combined_graph(tables_metadata)

  system_prompt:str = """
    You are tasked with creating a JSON structure for a ReactFlow diagram based on the given database ER diagram and schema JSON. This JSON includes information about database columns and their relationships.Your output should represent this information as a network of nodes and edges.
    </Task>
    
    <Icons Context>
      $icons_metadata = """ + str(icons_metadata) + """
    </Icons Context>

    <Instructions>
      You are a solution expert, specializing in problem and solution flows. You will be given the database schema information of a database, and your task is to create an interconnected single component of graph which is detailed, and intuitive and self explanatory for:

      Follow these guidelines:
      1. Create nodes for each unique service (both external and third-party).
      2. Do not create any group nodes.
      4. In the data key for each service node, include two additional fields called group and subgroup. The group field should contain the logical group name (e.g.,Databases, etc..), and the subgroup field should provide more specific categorization (e.g., 'Transactional Tables', 'Reference Tables' etc..). For example, for a service node representing daily transactions, the group would be Database and the subgroup would be Transactional Tables.
      5. For each node, check which icon will be the most suitable from the $icons_metadata in the <Icons Context>
      6. Ensure all information from the input is represented in the output.
      7. The position coordinates must be proper for all the nodes.
    </Instructions>

    <Rules>
      Important Rules to be followed:
      1. Give detailed technical architecture flow and the JSON object following the below output format.
      2. Make sure that the flow and order of new solution approach is explained well in the graph with appropriate edges. Use as many edges you want to describe the data and user flow properly.
      3. The whole user and data flow should be clear.
      4. Do not add unnecessary nodes and edges. Do not create duplicate nodes that perform same task.
      5. Make the Node descriptions detailed, breaking tasks into multiple sub-tasks if needed.
      6. Ensure your edges show the actual flow, and not just connections of what's related. The connections are meant to show the logical flow, and not the relatedness/similarity.
      7. The group name is meant to classify clusters of nodes within each graph. For instance, if we have multiple nodes in features, they would all have "feature" as group. In Architecture Flow, the "Group" should show the layer each node is in, for instance "Database Layer" etc.
      9. for a hierarchy of nodes A -> B -> C; ensure that there is not a connection between A -> C.
    </Rules>
    
    <output_format>
    The output should be in between the delimeters ```reactflow and ```. Only provide the json output. Don't give unnecesary explanation.
    ```reactflow
    {
      "nodes": [
        { 
          "id": "unique_node_identifier_string",
          "data" : {
            "label": "name_of_the_table",
            "description": "description of the table",
  	    "columns": ["order_id [PK]", "product_sku [PK]", "quantity", "unit_price"]
            "group": "name_of_group",  // Add the logical group name (e.g., "Database", etc..)
            "subgroup": "name_of_subgroup",  // Add a more specific subgroup name (e.g., 'Transactional Tables', 'Reference Tables', etc..)
            "service": "filename" //taken from the $icons_metadata,
          }
          "position":{ "x": "Xcoordinate", "y": "Ycoordinate" },
          "type" : "customNode" //this is hardcoded and will be constant
        }
      ],
      "edges": [
        {
          "id": "unique_egde_identifier_string",
          "source": "label A",
          "target": "label B",
          "label": "Showcase what comes from the source node, to the target node. Be concise and specific with labels, such as 'Ingested Data', 'Converted Text', 'User Query' etc. Use at max 5 words",
          "type" : "customEdge" //this is hardcoded and will be constant
        }
      ]
    }```
    </output_format>
    """
    
  user_prompt:str = f"""
    <Input>
    $database_tables = {dot}
    $icons_metadata
    </Input>

    <Role>
    You are an expert at understanding database architecture based on ER diagrams and relational structures. Create a JSON structure for a ReactFlow diagram based on the given database schema.
    </Role>
    <Output Structure>
      1. Create a JSON object with a "nodes" and "edges" array.
      2. Create nodes for each table in the schema.
      3. "nodes": An array containing all node objects.
      - "id": A unique string identifier for the node.
      - "data":  
        - "label": The name of the table.
        - "description": A brief summary of the table's role or content.
        - "columns": List of column names (mark primary keys with [PK], foreign keys with [FK]).
        - "group": The logical group name (e.g., 'Database').
        - "subgroup": The specific subgroup within the group (e.g., 'Transactional Tables', 'Reference Tables').
        - "service": The appropriate filename of the icon based on the $icons_metadata.
      - "position" : The x and y coordinates of the node.
      - "type" : "customNode" This should be fixed.
      4. "edges" : An array having id, source, target, label, and type should be customEdge always.
      5. The label of the edge should describe the relationship, like "order_id â†’ order_id". 
      6. The output should be in the form of a dictionary containing a "nodes" and "edges" array.
      7. Present only the code inside delimiters "```reactflow [reactflow CODE]```" without any additional explanation.
    """
    
  return system_prompt, user_prompt
    

def feature_summary_generation(formatted_data, user_mvf, executive_summary):
    # if input_type is None:
    #     formatted_data = file_summary_list
    # elif input_type == "batch_summary":
    #     formatted_data = format_batchwise_summary_metadata_for_services(file_summary_list)
    # else:
    #     formatted_data = format_file_summaries(file_summary_list)

    user_prompt = """
    Role: You are an AI code analyst specializing in creating concise, feature-level summaries of codebases.

    Objective: Provide a comprehensive yet concise feature-level summary of a given codebase, highlighting key components, functionality, and the project's overall workflow.

    Input: You will receive information about a codebase, which may include an executive summary or other project details.

    Steps:
    1. Analyze the provided codebase information.
    2. Identify the main features (maximum 5) of the project from the executive summary (if provided in same order)
    3. Create a summary following the specified format, including:
        a. An overview of the project
        b. A list of key features with brief descriptions
        c. A closure statement
    4. Self-evaluate the generated summary and assign a confidence score.
    5. Format the output as specified in the instructions.

    Output Format:
    ```json
    {
        "data": "generated_summary in string format adhering to the Detailed Instructions for Output Format",
        "confidence_score": 90
    }
    ```

    Detailed Instructions for Output Format:

    **Overview**
    <empty line>
    < 
        Summarize all features in 2-3 sentences, introducing the project and its purpose.
        Provide a 2-3 sentence summary of key benefits, highlighting core architecture and value proposition.
    >
    <empty line>
    **Key Features**
    <empty line>
    <   
        List a maximum of 5 main features.
        For each feature, provide up to 2 sub-points describing its functionality.
        Ensure clear explanation of how features interact and contribute to the project's goals.
        1. ***<Key Feature Title>*** : 
        * <Sub point 1 description>
        * <Sub point 2 description>
        <empty line>
    >
    <empty line>
    < 
        Summarize the overall impact and value proposition of the project in one sentence as a conclusion statement.
    >
    <empty line>
    
    -> Self-Evaluation:
        - Score the summary out of 100 based on clarity, precision, detail, knowledge, accuracy, technical correctness, and understanding of the data.

    -> Formatting Requirements:
        - Replace all newline characters (\n) with \\n in the JSON output.
        - Ensure the complete JSON is less than 7500 tokens.
        - Start the output with "```json" and end with "```".
        - If an executive summary is provided, use only the highlighted features from it.

    Example Output Structure:
    ```json
    {
        "data": "**Overview**\\n\\n[Project overview]\\n\\n[Benefits summary]\\n\\n**Key Features**\\n\\n1. *Feature 1*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n2. *Feature 2*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n[...continue for up to 5 features...]\\n\\n[Closure statement]",
        "confidence_score": 90
    }
    ```

    Remember: Adhere strictly to the output format and instructions to maintain consistency and accuracy in your summary.
    """

    user_prompt += "User Defined Features : " + str(user_mvf)

    system_prompt = f"""
        <role>
        You are an assistant to a Senior Software Engineer. You are very capable in reading and understanding huge codebases.
        There is no edge-case, no mistake, no functionality no matter how small goes unnoticed by you.
        You will be given a large codebase and be asked queries regarding it.
        </role>

        <Task>
        You will be given relevant files from a production codebase. The Senior Engineer will consult you to clear his doubts and ask for critical code-level and functionality level analysis of the same.
        <Important>
        1. You will be clear. Feel free to be descriptive but Avoid Jargon
        2. You shall perform critical analysis on the code before responding.
        3. Note that the codebase will be quite complex and have dependencies everywhere, be mindful of them all.
        4. Enclose code in (triple backticks)``` code ```
        </Important>
        </Task>

        Files from Codebase goes here :
        <Repo Structure>
        {formatted_data}
        </Repo Structure>
    """

    start_index = executive_summary.find("Highlighted Features")
    end_index = executive_summary.find("Key Benefits")

    if start_index != -1 and end_index != -1:
        executive_summary = executive_summary[start_index:end_index].strip()

    user_prompt += "Executive Summary : " + str(executive_summary)

    return system_prompt, user_prompt

def feature_summary_generation_db(formatted_data, user_mvf, executive_summary):
    # if input_type is None:
    #     formatted_data = file_summary_list
    # elif input_type == "batch_summary":
    #     formatted_data = format_batchwise_summary_metadata_for_services(file_summary_list)
    # else:
    #     formatted_data = format_file_summaries(file_summary_list)

    user_prompt = """
    Role: You are an AI Database Analyst specializing in creating concise, feature-level summaries of complex database schemas and architectures.

    Objective: Provide a comprehensive yet concise feature-level summary of a given database schema information, highlighting key components, entities, relationships, and the overall data architecture workflow.

    Input: You will receive information about a database design, which may include an executive summary or other schema-level details.

    Steps:
    1. Analyze the provided database schema information.
    2. Identify the main features (maximum 5) of the database from the executive summary (if provided in same order)
    3. Create a summary following the specified format, including:
        a. An overview of the database
        b. A list of key features with brief descriptions
        c. A closure statement
    4. Self-evaluate the generated summary and assign a confidence score.
    5. Format the output as specified in the instructions.

    Output Format:
    ```json
    {
        "data": "generated_summary in string format adhering to the Detailed Instructions for Output Format",
        "confidence_score": 90
    }
    ```

    Detailed Instructions for Output Format:

    **Overview**
    <empty line>
    < 
        Summarize all features in 2-3 sentences, introducing the database and its purpose.
        Provide a 2-3 sentence summary of key benefits, highlighting schema structure, normalization or denormalization logic, and value proposition in handling data.
    >
    <empty line>
    **Key Features**
    <empty line>
    <   
        List a maximum of 5 main features.
        For each feature, provide up to 2 sub-points describing its data handling, relationships, or optimization logic.
        Ensure clear explanation of how features contribute to performance, consistency, and data integrity.
        1. ***<Key Feature Title>*** : 
        * <Sub point 1 description>
        * <Sub point 2 description>
        <empty line>
    >
    <empty line>
    < 
        Summarize the overall impact and value proposition of the database in one sentence as a conclusion statement.
    >
    <empty line>
    
    -> Self-Evaluation:
        - Score the summary out of 100 based on clarity, precision, detail, knowledge, accuracy, technical correctness, and understanding of the schema information.

    -> Formatting Requirements:
        - Replace all newline characters (\n) with \\n in the JSON output.
        - Ensure the complete JSON is less than 7500 tokens.
        - Start the output with "```json" and end with "```".
        - If an executive summary is provided, use only the highlighted features from it.

    Example Output Structure:
    ```json
    {
        "data": "**Overview**\\n\\n[Database overview]\\n\\n[Benefits summary]\\n\\n**Key Features**\\n\\n1. *Feature 1*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n2. *Feature 2*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n[...continue for up to 5 features...]\\n\\n[Closure statement]",
        "confidence_score": 90
    }
    ```

    Remember: Adhere strictly to the output format and instructions to maintain consistency and accuracy in your summary.
    """

    user_prompt += "User Defined Features : " + str(user_mvf)

    system_prompt = f"""
        <role>
        You are an assistant to a Senior Data Architect. You are very capable in reading, analyzing, and understanding complex database schemas and data models.
        No entity, constraint, relationship, or optimization logic goes unnoticed by you.
        You will be given a comprehensive database structure or schema information and will be asked to analyze, explain, and summarize it at a structural and functional level.
        </role>

        <Task>
        You will be given relevant database schema files or DDL definitions. The Senior Data Architect will consult you to clear doubts and ask for critical schema-level and data model-level analysis.
        <Important>
        1. You will be clear. Feel free to be descriptive but Avoid Jargon
        2. Perform a critical and deep analysis of the schema and the information given before responding.
        3. The schema will often involve multiple tables, foreign keys, views, procedures, and indexing strategies â€” be mindful of their dependencies and relationships.
        4. Enclose code or schema in (triple backticks)``` code ```
        </Important>
        </Task>

        Files from Database schema goes here :
        <Database Structure>
        {formatted_data}
        </Database Structure>
    """

    start_index = executive_summary.find("Highlighted Features")
    end_index = executive_summary.find("Key Benefits")

    if start_index != -1 and end_index != -1:
        executive_summary = executive_summary[start_index:end_index].strip()

    user_prompt += "Executive Summary : " + str(executive_summary)

    return system_prompt, user_prompt


#FEATURE HIERARCHY:
generate_features_system_prompt = """
  <Role>
    You are a Software Architect with expertise in analyzing large summaries from code files of an application. 
    You can comprehend summaries from code files that are complex, production-grade and are written in various programming languages to generate most important features, their description and the subfeatures with their description belonging to the most important features along with the other relevant information requested below.
    
    You will follow 2 Events before responding : 
    1. Generation of Feature Hierarchy as given in "Output_Format".
    2. Critical Evaluation of Every Confidence Score.  
  </Role> 

    <Task 1>
    You are provided with multiple relative file paths and file-wise code summaries from a application codebase.
    1. Analyze the file summaries carefully, leveraging your expertise to deduce the frameworks, functionality, and features.
    2. Perform a critical assessment of the code's functionality and interdependencies before responding.
    3. The codebase is complex and likely contains dependencies across various modules. Be mindful of these.
    4. Analyse every file summary and assign the features and sub-features based on the information provided.
    5. Respond strictly in the structured JSON format provided below.
    6. In each sub-feature's 'file_path' array:
        - Set 'critical: true' ONLY for files that are CORE & NON-REPLACEABLE to the sub-feature's main functionality.
        - Set 'critical: false' for ALL supporting, secondary, or replaceable files  
        - Each sub-feature should have both true and false entries.
        - If unsure, default to false (be EXTREMELY selective with 'true')
        - Make sure each sub-feature atleast have one file as true.

    Explanation of the Output terms:
    Feature - Features are most valuable and high level features extracted from the list of summaries that are provided to you. 
    Feature description - Description of the features explaining the high level value and impact that it creates for the project. Define the Feature. The description should be crisp, precise, well formatted and must be between 2-3 lines.
    Subfeature - Subfeatures are micro most valuable features that are extracted from the list of summaries and belong to the Most related and similar Features.
    Subfeature description - Description of the subfeatures explaining the specific value, technical and non-technical functionalites that it provided to the project. Define the subfeature and also explain how its related to the feature. The description should be crisp, precise, well formatted and must be between 2-3 lines.
    
    Points to Remember:
    1. Do not extract any feature or subfeature where there are no reference/citations from the application summaries.
    2. The description must be precise, valuable, well-formatted and must be between 2-3 lines.
    3. The Feature titles should be precise, specific, self explanaible, independent and not have similar feature titles. The Feature titles should not be highly generalized.
    4. The SubFeatures titles should be precise, self explanaible and not have similar subfeature titles. The SubFeature titles should not be highly generalized.
    5. SubFeatures should not be very low level that it explains code functions, code process like 'Json handling', 'Reading csv', readME etc.
    6. If similar subfeatures are present, then group them under one common Feature itself. Do not create multuple Features for similar subfeatures.
    6. If Unit testing related summaries are found, then create that as another Feature named 'Unit Testing' and assign the specific testing subfeatures under this feature.
    </Task 1>

  <Task 2>
  You shall now Assign and Justify Confidence Scores for each feature.

  <Critical Evaluation of Confidence Scores> 

  <Evaluation MODE>
  - You will now Forget everything that was done beforehand and act as an unbiased judge.
  - $Project-Summaries-&-Paths (INPUT).
  </Evaluation MODE>
  <Important>
  Critically analyze every "Feature" and "SubFeature" based on the following metrics. 
  You shall generate a confidence score between 0-100 for each of the following :
  1. Is the "Feature" & "SubFeature" name accurate to its functionality ? (Accuracy)
  2. Does the "Feature" & "SubFeature" include files with an unrelated function ? (Feature Dilution Rate)
  3. Important : Does this "Feature" & "SubFeature" make sense given the Overall Purpose of the Application ? (Consistency)
  4. Are all the files in "Feature" & "SubFeature" included ? (Completeness)

  <Strict>
  1. You will now generate a list of 4 confidence scores between 0-100 for above criteria under "confidence_score" key.
  2. Based on above criteria, you shall provide a VERY BRIEF logical explanation (10-20 words) for Confidence Score under "confidence_score_justification" key.
  3. Make sure to mention the entire filepath without omitting the prefix.
  4. Make sure all the filepaths are present.
  <Important> STRICTLY Don't Comment on Missing Files. Don't Overestimate. Don't Underestimate.</Important> 
  </Strict>

  </Important>

  </Critical Evaluation of Confidence Scores> 
  </Step 2>


      <Output_Format>
    Return a response in JSON format. Do not include any extra information or explanations. Strictly DON'T deviate from mentioned KEYS.
    Example:
```json
[
  {
    "name": "User Authentication and Management",
    "feature_description": "Comprehensive user account system with secure login, registration, profile management, and role-based access control.",
    "feature_description_confidence_score": [95, 70, 100, 70],
    "sub_features": [
      {
        "name": "User Registration",
        "description": "Allows new users to create accounts by providing necessary information such as username, email, and password. Implements email verification, password strength checks, and duplicate account prevention. Stores user data securely in the database with password hashing.",
        "file_path": [
          {
            "module_name": "RegistrationController",
            "path": "Controllers/Account/RegistrationController.cs",
            "critical": true
          },
          {
            "module_name": "RegisterView",
            "path": "Views/Account/Register.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [75, 80, 85, 65],
        "sub_feature_confidence_score_justification": "No feature dilution, might have missed some file."
      },
      {
        "name": "User Login",
        "description": "Authenticates users using their credentials, creates and manages user sessions, and implements security measures such as login attempt limiting and two-factor authentication (2FA). Provides password reset functionality for forgotten passwords.",
        "file_path": [
          {
            "module_name": "LoginController",
            "path": "Controllers/Account/LoginController.cs",
            "critical": true
          },
          {
            "module_name": "LoginView",
            "path": "Views/Account/Login.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [80, 100, 80, 75],
        "sub_feature_confidence_score_justification": "High chance of missing files."
      }
    ],
    "feature_confidence_score_justification": "No feature dilution, duplication or missing files. Accurate Naming."
  },
  {
    "name": "Product Catalog Management",
    "feature_description": "Comprehensive system for managing product listings, categories, and inventory across the e-commerce platform.",
    "feature_description_confidence_score": [95, 65, 70, 80],
    "sub_features": [
      {
        "name": "Product CRUD Operations",
        "description": "Enables administrators to create, read, update, and delete product listings. Includes functionality for managing product details such as name, description, price, images, and inventory levels. Implements validation to ensure data integrity and consistency across the product catalog.",
        "file_path": [
          {
            "module_name": "ProductController",
            "path": "Controllers/ProductController.cs",
            "critical": true
          },
          {
            "module_name": "ProductView",
            "path": "Views/Product/Index.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [90, 85, 100, 70],
        "sub_feature_confidence_score_justification": "High confidence with no duplication or dilution."
      },
      {
        "name": "Category Management",
        "description": "Allows for the creation and management of product categories and subcategories. Implements a hierarchical structure for organizing products, enabling efficient navigation and filtering of the product catalog for both administrators and customers.",
        "file_path": [
          {
            "module_name": "CategoryController",
            "path": "Controllers/CategoryController.cs",
            "critical": true
          },
          {
            "module_name": "CategoryView",
            "path": "Views/Category/Index.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [85, 75, 90, 95],
        "sub_feature_confidence_score_justification": "High confidence without any duplication or dilution."
      }
    ],
    "feature_confidence_score_justification": "All files refer to single overall functionality. Might have missed some files."
  }
]
```
  </Output_Format>

"""

generate_features_user_message = """
<Strictly Remember>
1. As input you will be given a batch of `file_path` and `file_summary` from a production codebase. Keep it in mind that it could be a file from a very large repository with lot of inter-dependencies.
2. Understand all the file description first, then try to determine the feature, sub-features and their description. For **each file** it should have a feature or sub-features whenever the conditions are met.
3. The response should contain all the fields given in the example output format. The response should be strictly in json format.
4. The description of features/subfeatures must be in the length of 2-3 lines. The response should be structured and well-formatted.
5. Don't generate any additional explanation or description. Provide the structured response in json only.
</Strictly Remember>
  
<Input file wise summary>
{file_summary}
</Input file wise summary>
<Response>
"""

merge_features_in_hierarchy_user_prompt = """You are a software feature analyzer. Given a list of related features that have been clustered together, create a merged feature that encompasses all the functionality.

Features to merge:
{feature_list}

Generate a JSON response that includes:
1. A name for the merged feature representing accurate feature name. Do not mention its merged or unified or anything as such. The feature name should accurately represent a major funcationality of a repository.
2. A detailed description that covers all functionality
3. A confidence score (0-100) for the merge
4. A justification for the confidence score

Respond with a JSON object in the following format:
```json
{{
    "name": "Merged feature name",
    "description": "Comprehensive description",
    "confidence_score": 85,
    "confidence_justification": "Reason for the confidence score"
}}
```
Give only JSON and nothing else. Do not include any explanations or additional text outside the JSON block. Make sure to start with ```json and end with ``` only.
"""

mapping_names_for_merged_features_user_prompt = """  <Role>
    You are a smart AI cassistant with strong expertise in Software Engineering. You can understand complex, production-grade codebases written in various programming languages and summarize them effectively.
  </Role>
  <Task>
  You will be given a brief description of  features of a large codebase and your task is to generate a relevant feature name, brief description, and priority level.
  <Important>
   1. The feature name should be brief, relevant and should represent the entire description provided.
   2. Generate a relevant description which is basically a overall summary of the description provided.
   3. Assign a priority level (high, medium, low) based on the significance, importance and complexity of the feature to the overall system. 
  </important>
  </Task>
  <Example output>
  ```json
    {
        "name": <feature_name>, //string
        "feature_description": <feature_description>, //string
        "priority": <priority> //string (high, medium, or low)
    }
    ```
  </Example output>
  <Strictly Remember>
1. The feature name should be relevant and at the same time interpretable, easy to understand.
2. The feature description should represnt the entire description given for summarisation, it should be simple and easy to understant.
3. The priority should be one of: high, medium, or low.
4. The response should be strictly in json format specified above.
5. Strictly make sure Feature Description is not more than 200 words.
  </Strictly Remember>

<code summary>
The code summary is given below:
"""


reducing_sub_features_user_prompt = """
    You are a software feature consolidation expert. Your task is to merge similar sub-features into one comprehensive sub-feature.

    Here are the sub-features that need to be merged:
    {sub_features_list}

    For each sub-feature, we have:
    - Name: The sub-feature name
    - Description: The sub-feature description (if available)
    - Confidence Score: The confidence score (if available)

    Your output should be a JSON object containing:
    1. A unified sub-feature name that encompasses all the input sub-features
    2. A comprehensive description that covers all aspects of the input sub-features
    3. A confidence score (use the highest available from input sub-features)
    4. A justification for the confidence score

    Return the output in JSON format starting with ```json and ending with ```.

    Example output format:
    ```json
    {{
        "name": "Unified Sub-Feature Name",
        "description": "Comprehensive description covering all aspects",
        "sub_feature_confidence_score": 95,
        "sub_feature_confidence_score_justification": "Merged from similar sub-features with high semantic similarity"
    }}
    ```
    """


post_processing_feature_name_description_system_prompt="""
  <Role>
    You are a smart AI assistant with strong expertise in Software Engineering. You can understand complex, production-grade codebases written in various programming languages and summarize them effectively.
  </Role>
  <Task>
  You will be given a brief description of modules or features of a large codebase and your task is to generate a relevant feature name and brief description.
  <Important>
   1. The feature name should be brief, relevant and should represent the entire description provided.
   2. Generate a relevant description which is basically a overall summary of the description provided.
   3. Also generate a confidence score in a scale of 0 - 100.
  </important>
  </Task>
  <Example output>
  ```json
    {
        "name": <feature_name>,
        "feature_description_confidence_score": <score 0 - 100>,
        "feature_description": <feature_description>
    }```
  </Example output>"""

post_processing_feature_name_description_user_prompt = """<Strictly Remember>
1. The feature name should be relevant and at the same time interpretable, easy to understant.
2. The confidence score should represent the ability to summarise the description.
3. The feature description should represnt the entire description given for summarisation, it should be simple and easy to understant.
4. The response should be strictly in json format specified above.
</Strictly Remember>
<code summary>
The code summary is given below: \n
{feature_description}
</code_summary>
<response>
Your response in json goes here:
"""

merge_similar_features_system_prompt = """You are a solution architect. Your task is to carefully review each feature and its description, and combine them into a single high-level feature.

The final high-level features should represent what an end user would perceive, e.g., Messenger, Google Chat, Messaging, Reels, etc.

Based on the generated features provided, identify which features can be merged into a single high-level feature. 
Strictly output them in the following format:
{{ 
  <High-Level Feature Name 1>: [<Merged Feature 1>, <Merged Feature 2>, <Merged Feature 3>, ...],
  <High-Level Feature Name 2>: [<Merged Feature 1>, <Merged Feature 2>, <Merged Feature 3>, ...],
  ...
}}

INPUT:
Feature names and descriptions are provided in the format: 
[1. Feature name: <feature name> 
Feature description: <feature description>, 
2. ...]

{feature_texts}

MVFS:
{total_MVFs}

Points to remember:
1. While merging features and naming high-level features, always prefer names from the user-defined MVFs provided. All relevant features can be grouped under these high-level features.
2. If certain features do not fit under the user-defined MVFs, choose a better name than the existing one for the new high-level feature if necessary.
3. The names of the features being merged must remain exactly as provided in the INPUT section; do not modify them. Do not consider Feature description in Feature Names.
4. Follow the output structure strictly: high-level feature names as dictionary keys and merged features as values in list format.
5. If a feature is already a high-level feature, you do not need to forcibly merge it. If a feature seems to be function-level/low-level  features, merge them into a High-level feature.
6. Merge similar features into a single high-level feature based on their names and descriptions, when applicable. Each final high-level feature should be independent of the others.
7. Do not assign the same feature to multiple high-level features.
8. If user-defined MVFs are empty, skip point 1 and begin with point 2.
9. Do **not** include any Feature descriptions in the final output."""


merging_description_user_prompt = """You are a Solution Architect. Your task is to summarize the multiple feature descriptions provided into a brief, coherent summary of **no more than two sentences**.

  The summary must:
  - Accurately capture all key components from the provided descriptions.
  - Align clearly with the given high-level feature name.
  - Serve as the final description of the high-level feature.

  Only the final summarized description should be included in the output â€” no additional commentary or formatting.

  INPUT:
  Multiple descriptions: {merging_feature_description}

  High-Level Feature Name: {high_level_feature}
  """


micro_sub_feature_prompt = """You are an expert system analyst specializing in decomposing SubFeatures into granular, logically independent components. You support **two levels** of splitting:

1. **Horizontal splitting**: Split a subfeature into multiple *same-level subfeatures* when it encompasses multiple independently meaningful functionalities. The subfeatures created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.
2. **Vertical splitting**: Further break each of those subfeatures into *microsubfeatures* (if applicable), ensuring each micro-sub-features/micro-user-story describes a single goal or operation. The micro-sub-features/micro-user-story created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.

---

### ðŸ”§ TASK OVERVIEW

Given a Macro-Feature, Subfeature, its description, associated module files and its summary:

- Decide if the subfeature should be split horizontally into multiple same-level subfeatures.
- For each resulting subfeature (or original if not split), analyze whether it can be split vertically into **microsubfeatures** (fine-grained user stories).
- Provide the confidence scores for the subfeature that is split, whether horizontally or vertically.
- Provide the files that are related to the sub_features too, not just the micro_sub_features.
- Each leaf user-story must have files assigned to them, else you should not create/split these subfeatures.
- Provide description of generated subfeature/sub-user-stories in 2-4 lines but only valid information. Do not assume or hallucinate to generate description.
Apply this recursively: if horizontal splitting occurs, then attempt vertical splitting for each. But remember, not to create any duplicates in the process. 

---

### SPLITTING DECISIONS

#### Horizontal Splitting (Same-level Subfeatures):
Split if:
- The subfeature covers multiple high-level functionalities
- Each function could be planned, developed, and deployed independently
- Each component has a clear boundary and responsibility

#### Vertical Splitting (Microsubfeatures):
Split further if:
- A subfeature contains multiple independent operations or logical stages
- These operations can be implemented, tested, or tracked separately
- Each micro-subfeature represents one atomic, non-overlapping functionality

---

### DO NOT SPLIT IF:
- sub-user-stories are tightly coupled in the Subfeature and cannot function independently.
- Do not split subfeatures into sub-user-stories that are hardly single line of code and cannot be considered as a proper functionality, but just a config/parameter.
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across actions are too complex to isolate.
- There are no files that can be mapped to the generated user-story.
- Do not split if the user-story is barely a functionality. The split user-stories must have independent functionality that contributes to the subfeature and feature and if not, do not split.
- Don not split ReadMe & .md files into sub-user-stories.
- Do not split horizontall for granullar subfeatures as they are not user stories but mid level features.
---

### FILE MAPPING RULES:
- For each subfeature or microsubfeature, cite only directly relevant files.
- Use only the provided input data to match files â€” no guessing.
- Avoid duplication unless a file is clearly shared between components.

Each `file_path` entry must include:
```json
{
  "module_name": "<Name>",
  "path": "<Path>",
  "critical": <true/false>,
  "git_url": "<Git URL>"
}

OUTPUT FORMAT
If the subfeature should NOT be split:
Return: "None"

If the subfeature should be split, return a list of Parent User Stories with subfeatures inside.
If a subfeature itself can be further split into microsubfeatures, nest them under micro_sub_features like so:

[
  {
    "name": "Parent User Story Title 1",
    "description": "Full description of the original or updated user story and its purpose.",
    "file_path": [...],
    "sub_feature_confidence_score":"confidence score of the subfeature with respect to the Feature, as a percentage (e.g., 80)"
    "micro_sub_features": [
      {
        "name": "Sub-User Story Title 1",
        "description": "Standalone description of a single functionality.",
        "file_path": [...],
        "micro_sub_feature_confidence_score":"confidence score of the micro_sub_feature with respect to the sub_feature, as a percentage (e.g., 90)"
        }
          ...
        ]
      },
      ...
    ]
  }
]
Each layer must preserve independence, clarity, and singular focus of each story.

VALIDATION CHECKLIST
- Each title must express one functionality only (no imperative phrasing)
- description must avoid assumptions and describe the real function. It must be as detailled as possible.
- Each story must make sense independently and fit in the broader feature flow
- if there are multiple user-story under the subfeature, it needs to be in sequence of business logic.
- File mappings must be relevant and scoped accurately
- Do no miss/skip any values in the output json. The output structure must be maintained strictly.
- All subfeature and sub-user-story names and descriptions must be strictly in a declarative tone, not imperative.

* Use generic or speculative statements
"""


db_micro_sub_feature_prompt = """
<Role>
You are an expert Database analyst specializing in decomposing SubFeatures into granular, logically independent components. You support **two levels** of splitting:
You shall ALWAYS process features from a Database perspective ONLY. 
There can be more than one Table in the DB context provided to you.
</Role>

1. **Horizontal splitting**: Split a subfeature into multiple *same-level subfeatures* when it encompasses multiple independently meaningful functionalities. The subfeatures created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.
2. **Vertical splitting**: Further break each of those subfeatures into *microsubfeatures* (if applicable), ensuring each micro-sub-features/micro-user-story describes a single goal or operation. The micro-sub-features/micro-user-story created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.

<Strict Constraints> 
- You are dealing with Database Information. 
- No matter what, STRICTLY use Database-Specific Language ALWAYS. 
- Use words like Columns / Fields / Schema / DataTypes / Constraints / Foreign Keys / Primary Keys etc.
- Strictly Do not start descriptions with or start with "this micro-feature" / or "this sub-feature".
- You shall do this regardless of the input context and nature.
Remember : Every "FILE" given to you is information of a table. Therefore in your response, ALWAYS refer to "Table" instead of "File".

</Strict Constraints> 


### ðŸ”§ TASK OVERVIEW

Given a Macro-Feature, Subfeature, its description, associated module files and its summary:

- Decide if the subfeature should be split horizontally into multiple same-level subfeatures.
- For each resulting subfeature (or original if not split), analyze whether it can be split vertically into **microsubfeatures** (fine-grained user stories).
- Provide the confidence scores for the subfeature that is split, whether horizontally or vertically.
- Provide the files that are related to the sub_features too, not just the micro_sub_features.
- Each leaf user-story must have files assigned to them, else you should not create/split these subfeatures.
- Provide description of generated subfeature/sub-user-stories in 2-4 lines but only valid information. Do not assume or hallucinate to generate description.
Apply this recursively: if horizontal splitting occurs, then attempt vertical splitting for each. But remember, not to create any duplicates in the process. 

---

### SPLITTING DECISIONS

#### Horizontal Splitting (Same-level Subfeatures):
Split if:
- The subfeature covers ONE / MORE THAN ONE high-level functionalities
- Each function could be planned and developed independently
- Each component has some clear boundaries and responsibilities

#### Vertical Splitting (Microsubfeatures):
Split further if:
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across actions are too complex to isolate.
- There are no tables that can be mapped to the generated user-story.
- The subfeature is too complex to be planned, developed, and deployed independently
- Each micro-subfeature represents one atomic, non-overlapping functionality
Note: Maintain at least 2 subfeatures unless the database has only one table.
- Prioritize brevity, consistency and no informaiton leakage across subfeatures.
- Ensure crisp segregation.
---

### DO NOT SPLIT IF:
- sub-user-stories are tightly coupled in the Subfeature and cannot function independently.
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across tables in two features are too complex to isolate.
- There are no tables that can be mapped to the generated user-story.
Note: Maintain at least 2 subfeatures and 1 or more microsubfeatures per subfeature, Unless the database has only one table.
Note : Maintain brevity during splitting at the same level. Do NOT overload the a single feature with too many subfeatures.
---


### FILE MAPPING RULES:
- For each subfeature or microsubfeature, cite only directly relevant tables.
- Use only the provided input data to match files â€” no guessing.
- Avoid duplication unless a file is clearly shared between components.

Each `file_path` entry must include:
```json
{
  "module_name": "<Name>",
  "path": "<Path>",
  "critical": <true/false>,
  "git_url": "<Git URL>"
}

OUTPUT FORMAT
If the subfeature should NOT be split:
Return: "None"

If the subfeature should be split, return a list of Parent User Stories with subfeatures inside.
If a subfeature itself can be further split into microsubfeatures, nest them under micro_sub_features like so:

[
  {
    "name": "Parent User Story Title 1",
    "description": "Full description of the original or updated user story and its purpose.",
    "file_path": [...],
    "sub_feature_confidence_score":"confidence score of the subfeature with respect to the Feature, as a percentage (e.g., 80)"
    "micro_sub_features": [
      {
        "name": "Sub-User Story Title 1",
        "description": "Standalone description of a single functionality.",
        "file_path": [...],
        "micro_sub_feature_confidence_score":"confidence score of the micro_sub_feature with respect to the sub_feature, as a percentage (e.g., 90)"
        }
          ...
        ]
      },
      ...
    ]
  }
]
Each layer must preserve independence, clarity, and singular focus of each story.

VALIDATION CHECKLIST
- Each title must express one functionality only (no imperative phrasing)
- description must avoid assumptions and describe the real function. It must be as detailled as possible.
- Each story must make sense independently and fit in the broader feature flow
- if there are multiple user-story under the subfeature, it needs to be in sequence of business logic.
- File mappings must be relevant and scoped accurately
- Do no miss/skip any values in the output json. The output structure must be maintained strictly.
- All subfeature and sub-user-story names and descriptions must be strictly in a declarative tone, not imperative.
- Use Database-specific schema only. Do not include words like "Attributes" / "Code Files" in your response. 
- Strictly Do not start descriptions with or start with "this micro-feature" / or "this sub-feature".
* Use generic or speculative statements

"""import os
from graphviz import Digraph
import re 
import json

def parse_ddl(ddl: str):
    """
    Parse the DDL to extract columns, primary keys, and foreign keys.
    """
    lines = ddl.splitlines()
    column_lines = []

    for line in lines:
        line = line.strip()
        if (
            line.upper().startswith("CREATE")
            or line.upper().startswith("PRIMARY")
            or line.upper().startswith("FOREIGN")
            or line.upper().startswith(")")
            or line == ""
        ):
            continue

        match = re.match(r'(\w+)\s+\w+', line)
        if match:
            column_lines.append(match.group(1))

    pk_match = re.search(r'PRIMARY KEY\s*\((.*?)\)', ddl)
    primary_keys = [key.strip() for key in pk_match.group(1).split(",")] if pk_match else []

    foreign_keys = []
    for match in re.finditer(r'FOREIGN KEY\s*\(([^)]+)\)\s+REFERENCES\s+`?[\w]+\.(\w+)`\(([^)]+)\)', ddl):
        fk_col = match.group(1).strip()
        ref_table = match.group(2).strip()
        ref_col = match.group(3).strip()
        foreign_keys.append((fk_col, ref_table, ref_col))

    return column_lines, primary_keys, foreign_keys


def generate_combined_graph(tables_data):
    """
    Generate a single combined graph from multiple tables.
    """
    dot = Digraph(comment='Combined Table Diagram')
    dot.attr(rankdir='LR')

    # Store individual table nodes
    for table in tables_data:
        table_name = table['table_name']
        columns = table['columns']
        primary_keys = table['primary_keys']
        
        label_lines = []
        for col in columns:
            if col in primary_keys:
                label_lines.append(f"{col} [PK]")
            else:
                label_lines.append(col)
        dot.node(table_name, shape='box', label=f'{table_name}\\n' + "\\n".join(label_lines))

    # Add relationships
    for table in tables_data:
        table_name = table['table_name']
        for fk_col, ref_table, ref_col in table['foreign_keys']:
            dot.edge(table_name, ref_table, label=f'{fk_col} â†’ {ref_col}')

    return dot

def folder_summary_generation_prompts(
        total_allocated_tokens, 
        file_list, folder_name, 
        folder_path,
        subfolder_list,
        formatted_file_summaries,
        formatted_file_services,
        formatted_subfolder_summaries,
        formatted_subfolder_services,
        formatted_subfolder_features
    ):
    
    system_prompt = f"""
        You are an expert code analyst specialized in creating detailed, informative summaries of software project folders. Your task is to thoroughly analyze files and subfolders to provide a comprehensive understanding of the application or project and provide combined summaries along with required details. These summaries must be detailled enough for further summarization.

        Follow these guidelines:
        1. Conduct a deep analysis of the features to identify its core purpose and functionality
        2. Provide detailed explanation of key implementations and technical approaches of the features
        3. Thoroughly examine the summaries based on files and folders to understand relationship between features and combined smaller features into larger high level application level features.
        4. Explain the features within the broader project architecture with specific connections
        5. Describe technical patterns, design decisions, and architectural choices evident in the code
        6. Include specific functions, classes, and methods that define the feature's behavior
        7. Note dependencies, imports, and external connections that shape the folder's functionality
        8. Identify potential architectural strengths and areas for improvement when evident
        9. Identify all services represented in this folder based on file and subfolder services information
        10. Identify and articulate high-level features or functionalities represented by the folder into the feature_details section, when consolidating multiple subfolders or lower-level files. Derive these insights from both file-level and subfolder-level summaries. Also under each feature, mention which file/folder was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
        11. Do not miss any features that could be formed based on these summaries as this information is required to understand the application's buisness logic.
        12. Gather insights from the summaries provided to generate a high level detailled executive summary that could be used by business stakeholders to understand the folder/project.
        13. When analyzing the root folder, both the executive summary and the features must be strictly formed in a high level business logic standpoint of an application.
        
        IMPORTANT: 
        - Your summary should be thorough and detailed({total_allocated_tokens}) while maintaining technical/business precision and depth. Focus on providing insights that would help both stakeholders and developers understand the application better.
        - feature_details must contain high level feature name and feature description(value of the files/folders) strictly in concise bullet points. The feature inforamtion must be in detail to capture the complete high level knowledge for that feature but not the function level details. Feature names cannot be programmatic function names like Dependency management, json handling etc. instead it should be inventory management, order processing etc. 
        - Your services list should be comprehensive and include all services represented in this folder.
        - is_reuasble_lib if a folder is used as reusable lib make it True otherwise False
        - lib_name if is_reusable_lib is True then provide the name of the reusable lib/component If is_reusable_lib False then add Not Applicable
        - category if is_reusable_lib is True then provide category only between 'Frontend' and 'Backend' If is_reusable_lib False then add Not Applicable
        - sub_category if is_reusable_lib is True then provide sub category only between 'UI Component','Custom Hooks', 'http_client', 'Utils', 'Others' In Frontend & 'Middleware', 'Error Handling', 'Auth', 'Utils', 'Others' In Backend If is_reusable_lib False then add Not Applicable
        - when_to_use if is_reusable_lib is True then provide where this reusable lib/component can be used If is_reusable_lib False then add Not Applicable 
        - associated_files if is_reusable_lib is True then provide the list of files associated(give complete path for the assosciated file) with this reusable lib/component If is_reusable_lib False then add Not Applicable
        - summary must not be technical and only explain the high level details of the folder/project. Understand the file and folder summaries provided to combine the knowledge to form the executive summary. Make it as detailled as possible.
        - Use clear and concise language, avoiding jargon where possible.
        
        - You must provide your response in this exact format:
        ```summary
        [Your detailled high-level executive summary for the folder for business stakeholders]
        ```
        ```feature_details
        [List of high-level features or functionalities represented in this folder]
        ```
        ```services_namess
        [Comma-separated list of all services represented in this folder]
        ```
        ```is_reuasble_lib
        Boolean Value
        ```
        ```lib_name
        [Name of the reusable library if applicable]
        ```
        ```category
        [Category of the reusable library if applicable]
        ```
        ```sub_category
            [Sub category of the reusable library if applicable]
        ```
        ```when_to_use
        [Your detailed use case where or when this reuasble_lib can be usefull]
        ```
        ```associated_files
            [Comma-separated list of associated files with the reusable library, Give the Complete file path as mentioned in the file list]
        ```
        ```example_usage
            [Example code snippet of how to use this reusable library]
        ```
    """

    user_prompt = f"""
        Generate a summary and services list for the folder: "{folder_name}" (Path: {folder_path})

        FOLDER CONTENTS:
        - Files ({len(file_list)}): {", ".join(file_list) if file_list else "None"}
        - Subfolders ({len(subfolder_list)}): {", ".join(subfolder_list) if subfolder_list else "None"}

        FILE SUMMARIES:
        {os.linesep.join(formatted_file_summaries) if formatted_file_summaries else "No file summaries available"}

        FILE SERVICES:
        {os.linesep.join(formatted_file_services) if formatted_file_services else "No file services available"}

        SUBFOLDER SUMMARIES:
        {os.linesep.join(formatted_subfolder_summaries) if formatted_subfolder_summaries else "No subfolder summaries available"}

        SUBFOLDER SERVICES:
        {os.linesep.join(formatted_subfolder_services) if formatted_subfolder_services else "No subfolder services available"}

        SUBFOLDER FEATURES:
        {os.linesep.join(formatted_subfolder_features) if formatted_subfolder_features else "No subfolder features available"}
        
        Based on these components:
        1. Provide a thorough technical summary explaining the folder's purpose, implementation details, and architectural significance
        2. Compile a comprehensive list of all services represented in this folder based on file and subfolder services information
        
        Follow the exact format specified in the system instructions for your response.
    """

    return system_prompt, user_prompt

def services_generation():
    system_prompt = """
        <Task>
        Create an architectural blueprint of the given repository by identifying and classifying both external services and third-party services with no overlap between categories.
        </Task>

        <Definitions>
        - External services: Company-provided services hosted outside the application (AWS S3, Google Cloud, Stripe, Twilio)
        - Third-party services: Libraries, frameworks, and SDKs that are part of the core application stack (Django, React, MongoDB, Redux)
        </Definitions>

        <Output_Format>
        {
        "external_services": [
            {
            "external_service_name": "string",
            "description": "string",
            "associated_files": ["string"],
            "service_class": "string",
            "used_in_files": ["string"]
            }
        ],
        "thirdparty_services": [
            {
            "thirdparty_service_name": "string",
            "description": "string",
            "associated_files": ["string"],
            "service_class": "string",
            "used_in_files": ["string"]
            }
        ]
        }
        </Output_Format>

        <Instructions>
        1. Conduct a thorough repository analysis to identify all services
        2. Classify each service into exactly ONE category:
        - External services: Cloud platforms, payment processors, authentication providers
        - Third-party services: Frameworks, libraries, SDKs integrated into the codebase
        3. For each service, provide:
        - Name: Exact service name
        - Description: Concise explanation of functionality and purpose
        - Associated files: All files directly importing or using the service
        - Service class: Category (e.g., "cloud storage", "web framework", "database")
        - Used in files: Complete paths of files utilizing the service
        4. Ensure ZERO overlap between categories
        5. Prioritize accuracy over comprehensiveness
        6. Validate that identified services are actively used in the project
        7. Include only services with clear evidence of implementation
        8. Do not create a lot of services which are redundant. Keep it to a maximum of 50 services only.
        </Instructions>

        <Examples>
        Good External Service Entry:
        {
        "external_service_name": "AWS S3",
        "description": "Cloud storage service used for storing user-uploaded files",
        "associated_files": ["src/services/storage.js", "src/config/aws.js"],
        "service_class": "cloud storage",
        "used_in_files": ["src/components/FileUpload.js", "src/pages/UserProfile.js"]
        }

        Good Third-Party Service Entry:
        {
        "thirdparty_service_name": "React",
        "description": "Frontend JavaScript library for building user interfaces",
        "associated_files": ["package.json", "src/index.js"],
        "service_class": "frontend framework",
        "used_in_files": ["src/App.js", "src/components/*.js"]
        }
        </Examples>

        Analyze the repository and provide the complete architectural blueprint in the specified format.
    """

    user_prompt = ""

    return system_prompt, user_prompt

def executive_summary_generation(combined_summary, user_mvf):
    system_prompt = """
    Your Role:
    You are an expert software architect tasked with understanding a codebase and creating an executive summary that clearly articulates the main purpose of this application,
    the core problem that the application is solving, and the prioritized list of the most valuable features, solely based on the provided folder wise summary. Do not hallucinate and create the most valuable features and its description on assumption. This needs to be based on facts.

    Task:
    1. Analyze provided folder wise summary and the services used and the user defined features (if provided).
    2. Understand component interactions and functions.
    3. Prioritize the User Defined Features (if provided) in the summary.
    4. Identify and prioritize the most valuable features based on their importance and relevance to the overall project, as evidenced in the code.
    5. Create a comprehensive executive summary.

    Steps:
    1. Review folder wise summary.
    2. Analyze folder wise summary:
    - Identify key components and their roles
    - Note data operations, design patterns, and architectural decisions
    3. Create summary:
    - Describe the specific problem the codebase solves, based on folder wise summary
    - Explain component interactions
    - Outline data workflow
    4. Identify and prioritize main features:
    - Determine which feature(s) address the core problem of the application, based on code implementation
    - Rank features based on their importance and relevance to solving the main problem, as evidenced in the code
    - The feature should be major components of the codebase and not minor functions like "Modular Architecture" or "Code Reusability", these are not features but design principles.

    Focus Areas:
    - Precised feature prioritization and importance
    - High-level functionality
    - Clear, concise technical language
    - Objective description
    - Capture entire workflow

    Guidelines:
    - Only use the folder wise summary provided
    - Use precise technical terms
    - Include user-defined features if provided and evidenced in the code
    - Prioritize features based on their importance to the core problem, as shown in the folder wise summary

    Feature Identification and Prioritization:
    - Carefully analyze the folder wise summary to identify features actually present in the folder wise summary
    - Do not assume or infer features that are not explicitly mentioned in the folder wise summary
    - Identify the top feature that solves the majority of the problem based on code evidence
    - Rank subsequent features in descending order of importance, ensuring they are present in the folder wise summary
    - Ensure the feature list reflects the codebase's focus and structure
    - Only include features that have substantial implementation in the codebase that is evident from folder wise summary

    Output Format - Adhering to this format is crucial
    ```json
    {
    "data": "generated_summary in string format adhering to the Expected Output Format for Generated Summary",
    "confidence_score": 90,
    "traceback": {
    "Feature 1 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 1 Title' is included, as the 'phrase' is an evidence that this feature is part of the codebase.",
    "Feature 2 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 2 Title' is included, as the 'phrase' is an evidence that this feature is part of the codebase.",
    ...
    }
    }
    ```

    Requirements:
    - Replace \n with \\n in JSON
    - Limit upto 5 main features (max 2 sub-features each) or 7500 tokens
    - If due to any reason such as codebase being small, you are unable to provide 5 features, then provide as many high-level features as possible between the range of 1 to 5.
    - Don't assume features or include minor features due to inability to provide 5 features, lesser number of features is acceptable.
    - Use specified JSON format only
    - Start with "```json" and end with "```"
    - Ensure the top feature in the prioritized list addresses the core problem and is present in the folder wise summary
    - Rank features in descending order of importance to the main problem, based on actual code implementation
    - Do NOT include features that are NOT evidenced in the provided folder wise summary
    - Evaluate the folder wise summary objectively, considering all conclusions on the actual code provided
    - Do NOT make any assumptions about organizational goals or intentions beyond what is explicitly shown in the code
    - Focus solely on the technical aspects and implemented functionality, avoiding speculation about business objectives or future plans
    - Both the keys data, confidence score, and traceback should be present in the output JSON
    - The generated summary should be in string format only and be contained inside the "data" key
    - The "traceback" key should contain a dictionary with feature names as keys and justifications for including these features based on exact phrases from the input
    - Do not include any feature that could potentially be part of the folder wise summary without explicit evidence
    - Every feature mentioned must be driven by clear evidence from the provided input
    """
    user_prompt = """
    Expected Output Format for Generated Summary:

  **Overview**
  <empty line>
  <A brief introduction to the codebase and its main purpose; in paragraph format only, not in points.
  This paragraph should provide a concise yet comprehensive overview of the codebase, its primary functionality, solution provided by the project and its intended use case.
  Aim for 3-5 sentences that capture the essence of the project.>
  <empty line>
  **Highlighted Features**
  <empty line>
  <
  List and briefly explain the key features that are significant components of the codebase and would serve as selling points.
  These features should be presented as follows:
  1. Use numbered points for each feature.
  2. Provide a brief explanation for each feature in 1-2 sentences, highlighting its importance and benefit to the end user.
  3. Focus on features that are central to the codebase's functionality and most important to the end user.
  4. Dont include generic features like "Modular Architecture" or "Code Reusability", these are not features but design principles.
  5. Do not include sub-points under any feature.
  6. Prioritize User Defined Features (if provided) at the beginning of the list.
  7. If User Defined Features are given, list them first before including any features identified through your analysis.
  8. Aim to provide upto of 1 to 5 key features, after each feature add an empty line for formatting purposes.
  9. Ensure that the features listed represent the core functionality and unique selling points based on the folder wise summary.
  10. Use clear, concise language that emphasizes the value proposition of each feature.
  11. Also under each feature, mention which file/folder was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
  12. Do not add features into Highlighted Features if they dont have value for buisness stakeholder about the application. Also do not repeat adding similar feature in this section.

  Output Structure:
  1. ***<Feature 1 Title>***: <Description of the feature in one to two sentences.\n
  2. ***<Feature 2 Title>***: <Description of the feature in one to two sentences.>\n
  >
  <empty line>
  **Key Benefits**
  <empty line>
  <Summarize the key benefits of the codebase in one to two sentences.
  This summary should encapsulate the overall value proposition of the codebase and its potential impact on users or the organization.>
  <empty line>
  <Highlight the most significant key benefits the codebase has to offer in bulleted points. The format should be:
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  Aim for 3-5 bullet points that capture the most compelling advantages of using this codebase, after each point add an empty line for formatting purposes.
  Each benefit should be distinct and provide a clear value proposition.>

  <Final Output Format>
  Output Format - Adhering to this format is crucial, the output should be in parsable JSON format:
  ```json
  {{
    "data": "<generated_summary in string format adhering to the Expected Output Format for Generated Summary>",
    "confidence_score": 90,
    "traceback": {{
      "Feature 1 Title": "Since it mentions about <exact phrase from the folder wise summary>, the 'Feature 1 Title' is included, as the "phrase" is an evidence that this feature is part of the folder wise summary.",
      "Feature 2 Title": "Since it mentions about <exact phrase from the folder wise summary>, the 'Feature 2 Title' is included, as the "phrase" is an evidence that this feature is part of the folder wise summary.",
      ...
    }}
  }}
  ```
  </Final Output Format>
  Note: If the traceback includes phrases that are not present in the folder wise summary then you would be penalized 10000 points.
  The output should be having data, confidence score, and traceback keys, and the entire content inside "```json" and "```" should be parsable by json.
  The "data" key should contain the generated summary and it should be in string format only, allowing the parsing of the entire json.
  If there are any inverted commas inside the generated summary, then escape them with a backslash.
  Do not change or skip the headings of each section in the generated json. The generated summary must have "Overview", "Highlighted Features", "Key Benefits" as section titles. Follow the above provided guidelines."""
    user_prompt += f"""Use the below folder wise summary to generate the summary in the above format: {combined_summary}""" + "User Defined Features : " + str(user_mvf)
    return system_prompt, user_prompt

def db_executive_summary_generation(combined_summary, user_mvf): 
    system_prompt = """
    Role:
    You are an expert Database Architect tasked with understanding the contents of all tables and schema of the database. 
    You shall Articulate a proper executive summary that clearly captures all the main & high-level features of this database.
    The core use-case that this database is intended for, and the prioritized list of the most valuable features, solely based on the provided Table-Level summaries. 
    Do not hallucinate. Do NOT create the most valuable features and its description on pure assumptions. This needs to be based on facts, with proper backing.

    Task:
    1. Analyze provided Table wise summaries.
    2. Understand component interactions and functions.
    3. Prioritize the User Defined Features (if provided) in the summary.
    4. Identify and prioritize the most valuable features based on their importance to the core use-case the Database is solving.
    5. Create a comprehensive executive summary.

    Steps:
    1. Review Table wise summary.
    2. Analyze Table wise summary:
      - Identify all tables. 
      - Take into consideration the foreign keys, primary keys, is-a, has-a, and many-to-many relationships.
      - Deeply understand the intended-use-case of each table.
      - Note data operations, design patterns, and architectural decisions
    3. Create summary:
      - Describe the specific problem the Database is solving, based on Table wise summary
      - Explain high-level interactions and dependencies
      - Outline data workflow
    4. Identify and prioritize main features:
      - Determine which feature(s) address the core problem of the Database, based on SQL implementation and Table wise summary
      - Rank features based on their importance and relevance to solving the main problem, as evidenced in the Database
      - The feature should be major components of the Database and not minor functions like Many-to-Many Relationships, or "Foreign Keys". 
        These are implementation concepts. Not core features.

    Focus Areas:
    - Precised feature prioritization and importance
    - High-level functionality of this Database
    - Clear, concise technical language with Database-specific Language
    - Objective description
    - Capture entire data workflow

    Guidelines:
    - Only use the Table wise summary provided
    - Use precise Database-relevant technical terms
    - Include user-defined features if provided and evidenced in the Table wise summary
    - Prioritize features based on their importance to the core problem, as shown in the Table wise summary

    Feature Identification and Prioritization:
    - Carefully analyze the Table wise summary to identify features actually present in the Table wise summary
    - Do not assume or infer features that are not explicitly mentioned in the Table wise summary
    - Identify the top feature that solves the majority of the problem based on Database and SQL evidence
    - Rank subsequent features in descending order of importance, ensuring they are present in the Table wise summary
    - Ensure the feature list reflects the Database's focus and structure
    - Only include features that have substantial implementation in the Database that is evident from Table wise summary

    Output Format - Adhering to this format is crucial
    ```json
    {
    "data": "generated_summary in string format adhering to the Expected Output Format for Generated Summary",
    "confidence_score": 90,
    "traceback": {
    "Feature 1 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 1 Title' is included, as the 'phrase' is an evidence that this feature is part of the Database.",
    "Feature 2 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 2 Title' is included, as the 'phrase' is an evidence that this feature is part of the Database.",
    ...
    }
    }
    ```

    Requirements:
    - Replace \n with \\n in JSON
    - Limit upto 5 main features (max 2 sub-features each) or 7500 tokens
    - If due to any reason such as Database being small, you are unable to provide 5 features, then provide as many high-level features as possible between the range of 1 to 5.
    - Don't assume features or include minor features due to inability to provide 5 features, lesser number of features is acceptable.
    - Use specified JSON format only
    - Start with "```json" and end with "```"
    - Ensure the top feature in the prioritized list addresses the core problem and is present in the Table wise summary
    - Rank features in descending order of importance to the main problem, based on actual Database and SQL implementation
    - Do NOT include features that are NOT evidenced in the provided Table wise summary
    - Evaluate the Table wise summary objectively, considering all conclusions on the actual Database and SQL provided
    - Do NOT make any assumptions about organizational goals or intentions beyond what is explicitly shown in the Database and SQL
    - Focus solely on the technical aspects and implemented functionality, avoiding speculation about business objectives or future plans
    - Both the keys data, confidence score, and traceback should be present in the output JSON
    - The generated summary should be in string format only and be contained inside the "data" key
    - The "traceback" key should contain a dictionary with feature names as keys and justifications for including these features based on exact phrases from the input
    - Do not include any feature that could potentially be part of the Table wise summary without explicit evidence
    - Every feature mentioned must be driven by clear evidence from the provided input.
    - Strictly use an assertive and objective tone in your response. 
    - Do not be unsure about anything.
    - Do not include the "Folder Name" in your response. Ignore "dbanalysis" folder. Provide Executive Summary of the Database-ONLY.
    """

    user_prompt = """
  Expected Output Format for Generated Summary:

  **Overview**
  <empty line>
  <A brief introduction to the Database and its main purpose; in paragraph format only, not in points.
  This paragraph should provide a concise yet comprehensive overview of the Database, its primary functionality, and its intended use case.
  Aim for 3-5 sentences that capture the essence of the Database.>
  <empty line>
  **Highlighted Features**
  <empty line>
  <
  List and briefly explain the key features that are significant components of the Database and would serve as selling points.
  These features should be presented as follows:
  1. Use numbered points for each feature.
  2. Provide a brief explanation for each feature in 1-2 sentences, highlighting its importance and benefit to the END USER.
  3. Focus on features that are central to the Database's functionality and most important to the END USER.
  4. Dont include generic features like  Many-to-Many Relationships, or "Foreign Keys", these are not features but Design Principles.
  5. Do not include sub-points under any feature.
  6. Prioritize User Defined Features (if provided) at the beginning of the list.
  7. If User Defined Features are given, list them first before including any features identified through your analysis.
  8. Aim to provide upto of 1 to 5 key features, after each feature add an empty line for formatting purposes.
  9. Ensure that the features listed represent the core functionality and unique selling points based on the Table wise summary.
  10. Use clear, concise language that emphasizes the value proposition of each feature.
  11. Also under each feature, mention which file/Table was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
  12. Do not add features into Highlighted Features if they dont have value for buisness stakeholder about the application. Also do not repeat adding similar feature in this section.

  Output Structure:
  1. ***<Feature 1 Title>***: <Description of the feature in one to two sentences.\n
  2. ***<Feature 2 Title>***: <Description of the feature in one to two sentences.>\n
  >
  <empty line>
  **Key Benefits**
  <empty line>
  <Summarize the key benefits of the Database in one to two sentences.
  This summary should encapsulate the overall value proposition of the Database and its potential impact on users or the organization.>
  <empty line>
  <Highlight the most significant key benefits the Database has to offer in bulleted points. The format should be:
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  Aim for 3-5 bullet points that capture the most compelling advantages of using this Database, after each point add an empty line for formatting purposes.
  Each benefit should be distinct and provide a clear value proposition.>

  <Final Output Format>
  Output Format - Adhering to this format is crucial, the output should be in parsable JSON format:
  ```json
  {{
    "data": "<generated_summary in string format adhering to the Expected Output Format for Generated Summary>",
    "confidence_score": 90,
    "traceback": {{
      "Feature 1 Title": "Since it mentions about <exact phrase from the Table wise summary>, the 'Feature 1 Title' is included, as the "phrase" is an evidence that this feature is part of the Table wise summary.",
      "Feature 2 Title": "Since it mentions about <exact phrase from the Table wise summary>, the 'Feature 2 Title' is included, as the "phrase" is an evidence that this feature is part of the Table wise summary.",
      ...
    }}
  }}
  ```
  </Final Output Format>
  Note: If the traceback includes phrases that are not present in the Table wise summary then you would be penalized 10000 points.
  The output should be having data, confidence score, and traceback keys, and the entire content inside "```json" and "```" should be parsable by json.
  The "data" key should contain the generated summary and it should be in string format only, allowing the parsing of the entire json.
  If there are any inverted commas inside the generated summary, then escape them with a backslash.
  Do not change or skip the headings of each section in the generated json. The generated summary must have "Overview", "Highlighted Features", "Key Benefits" as section titles. Follow the above provided guidelines.
    """

    user_prompt += f"""Use the below Table wise summary to generate the summary in the above format: {combined_summary}""" + "User Defined Features : " + str(user_mvf)

    return system_prompt, user_prompt


def architecture_diagram_generation(services_data, icons_metadata):
    user_prompt = f"""
    <Input>
    $services_data = {services_data}
    $icons_metadata
    </Input>

    <Role>
    You are an expert at understanding large projects based on their executive summary and the services being used in them. Create a JSON structure for a ReactFlow diagram based on the given service class JSON.
    </Role>

    <Output Structure>
    1. Create a JSON object with a "nodes" and "edges" array.
    2. Create nodes for each external and third-party service.
    3. "nodes": An array containing all node objects.
      - "id": A unique string identifier for the node.
      - "data":   
        - "label": The name of the node.
        - "description": Description of the service.
        - "associated_files": Associated file and used in files in the service node, defaulting to "No File Available" if not present.
        - "group": The logical group name (e.g., 'Backend', 'Frontend', 'Database',etc..).
        - "subgroup": The specific subgroup within the group (e.g., Frameworks, NoSQL Databases, State Management, etc.).
        - "service": The appropriate filename of the icon based on the $icons_metadata.
      - "position" : The x and y coordinates of the node.
      - "type" : "customNode" This should be fixed.
    4. "edges" : An array having id, source, target, label, and type should be customEdge always.
    4. Ensure all services and files from the input JSON are included.
    5. The output should be in the form of a dictionary containing a "nodes" and "edges" array.
    6. Present only the code inside delimiters "```reactflow [reactflow CODE]```" without any additional explanation.
    """

    system_prompt:str = """
    <Task>
      You are tasked with creating a JSON structure for a ReactFlow diagram based on the given executive summary and the service_class_json. The executive summary contains an overview of the entire project. This JSON includes information about external services and third-party services, along with their associated files. Your output should represent this information as a network of nodes and edges.
    </Task>
    
    <Icons Context>
      $icons_metadata = """ + str(icons_metadata) + """
    </Icons Context>

    <Instructions>
      You are a solution expert, specializing in problem and solution flows. You will be given the solution overview for a project, and your task is to create an interconnected single component of graph which is detailed, and intuitive and self explanatory for:

      Follow these guidelines:
      1. Create nodes for each unique service (both external and third-party).
      2. Do not create any group nodes.
      4. In the data key for each service node, include two additional fields called group and subgroup. The group field should contain the logical group name (e.g., Frontend, Backend, Databases, etc..), and the subgroup field should provide more specific categorization (e.g., Frameworks, NoSQL Databases, etc..). For example, for a service node representing React, the group would be Frontend and the subgroup would be Frameworks.
      5. For each node, check which icon will be the most suitable from the $icons_metadata in the <Icons Context>
      6. Ensure all information from the input is represented in the output.
      7. The position coordinates must be proper for all the nodes.
    </Instructions>

    <Rules>
      **Ensure all nodes in the generated graph are interconnected such that every node has at least one edge, forming a single connected component without any isolated or disjoint sections. (High Priority Requirement)**
      Important Rules to be followed:
      1. Give detailed technical architecture flow and the JSON object following the below output format.
      2. Make sure that the flow and order of new solution approach is explained well in the graph with appropriate edges. Use as many edges you want to describe the data and user flow properly.
      3. The whole user and data flow should be clear.
      4. Do not add unnecessary nodes and edges. Do not create duplicate nodes that perform same task.
      5. Make the Node descriptions detailed, breaking tasks into multiple sub-tasks if needed.
      6. Ensure your edges show the actual flow, and not just connections of what's related. The connections are meant to show the logical flow, and not the relatedness/similarity.
      7. The group name is meant to classify clusters of nodes within each graph. For instance, if we have multiple nodes in features, they would all have "feature" as group. In Architecture Flow, the "Group" should show the layer each node is in, for instance "Backend Layer", "Database Layer" etc.
      9. for a hierarchy of nodes A -> B -> C; ensure that there is not a connection between A -> C.
    </Rules>
    
    <output_format>
    The output should be in between the delimeters ```reactflow and ```. Only provide the json output. Don't give unnecesary explanation.
    ```reactflow
    {
      "nodes": [
        { 
          "id": "unique_node_identifier_string",
          "data" : {
            "label": "name_of_the_service",
            "description": "description of the service",
            "associated_files": ["file_path_1", "file_path_2", "file_path_3", etc.],  // (default: ["No File Available"] if not present)
            "group": "name_of_group",  // Add the logical group name (e.g., "Frontend", "Backend", etc..)
            "subgroup": "name_of_subgroup",  // Add a more specific subgroup name (e.g., "Frameworks", "NoSQL Databases", etc..)
            "service": "filename" //taken from the $icons_metadata,
          }
          "position":{ "x": "Xcoordinate", "y": "Ycoordinate" },
          "type" : "customNode" //this is hardcoded and will be constant
        }
      ],
      "edges": [
        {
          "id": "unique_egde_identifier_string",
          "source": "label A",
          "target": "label B",
          "label": "Showcase what comes from the source node, to the target node. Be concise and specific with labels, such as 'Ingested Data', 'Converted Text', 'User Query' etc. Use at max 5 words",
          "type" : "customEdge" //this is hardcoded and will be constant
        }
      ]
    }```
    </output_format>
    """
    return system_prompt, user_prompt
  

def erd_generation(services_data, icons_metadata):
  tables_metadata = []
  for entry in services_data:
      table_name = entry["table_name"]
      ddl = entry["ddl"]
      columns, primary_keys, foreign_keys = parse_ddl(ddl)
      tables_metadata.append({
          "table_name": table_name,
          "columns": columns,
          "primary_keys": primary_keys,
          "foreign_keys": foreign_keys
      })

  dot = generate_combined_graph(tables_metadata)

  system_prompt:str = """
    You are tasked with creating a JSON structure for a ReactFlow diagram based on the given database ER diagram and schema JSON. This JSON includes information about database columns and their relationships.Your output should represent this information as a network of nodes and edges.
    </Task>
    
    <Icons Context>
      $icons_metadata = """ + str(icons_metadata) + """
    </Icons Context>

    <Instructions>
      You are a solution expert, specializing in problem and solution flows. You will be given the database schema information of a database, and your task is to create an interconnected single component of graph which is detailed, and intuitive and self explanatory for:

      Follow these guidelines:
      1. Create nodes for each unique service (both external and third-party).
      2. Do not create any group nodes.
      4. In the data key for each service node, include two additional fields called group and subgroup. The group field should contain the logical group name (e.g.,Databases, etc..), and the subgroup field should provide more specific categorization (e.g., 'Transactional Tables', 'Reference Tables' etc..). For example, for a service node representing daily transactions, the group would be Database and the subgroup would be Transactional Tables.
      5. For each node, check which icon will be the most suitable from the $icons_metadata in the <Icons Context>
      6. Ensure all information from the input is represented in the output.
      7. The position coordinates must be proper for all the nodes.
    </Instructions>

    <Rules>
      Important Rules to be followed:
      1. Give detailed technical architecture flow and the JSON object following the below output format.
      2. Make sure that the flow and order of new solution approach is explained well in the graph with appropriate edges. Use as many edges you want to describe the data and user flow properly.
      3. The whole user and data flow should be clear.
      4. Do not add unnecessary nodes and edges. Do not create duplicate nodes that perform same task.
      5. Make the Node descriptions detailed, breaking tasks into multiple sub-tasks if needed.
      6. Ensure your edges show the actual flow, and not just connections of what's related. The connections are meant to show the logical flow, and not the relatedness/similarity.
      7. The group name is meant to classify clusters of nodes within each graph. For instance, if we have multiple nodes in features, they would all have "feature" as group. In Architecture Flow, the "Group" should show the layer each node is in, for instance "Database Layer" etc.
      9. for a hierarchy of nodes A -> B -> C; ensure that there is not a connection between A -> C.
    </Rules>
    
    <output_format>
    The output should be in between the delimeters ```reactflow and ```. Only provide the json output. Don't give unnecesary explanation.
    ```reactflow
    {
      "nodes": [
        { 
          "id": "unique_node_identifier_string",
          "data" : {
            "label": "name_of_the_table",
            "description": "description of the table",
  	    "columns": ["order_id [PK]", "product_sku [PK]", "quantity", "unit_price"]
            "group": "name_of_group",  // Add the logical group name (e.g., "Database", etc..)
            "subgroup": "name_of_subgroup",  // Add a more specific subgroup name (e.g., 'Transactional Tables', 'Reference Tables', etc..)
            "service": "filename" //taken from the $icons_metadata,
          }
          "position":{ "x": "Xcoordinate", "y": "Ycoordinate" },
          "type" : "customNode" //this is hardcoded and will be constant
        }
      ],
      "edges": [
        {
          "id": "unique_egde_identifier_string",
          "source": "label A",
          "target": "label B",
          "label": "Showcase what comes from the source node, to the target node. Be concise and specific with labels, such as 'Ingested Data', 'Converted Text', 'User Query' etc. Use at max 5 words",
          "type" : "customEdge" //this is hardcoded and will be constant
        }
      ]
    }```
    </output_format>
    """
    
  user_prompt:str = f"""
    <Input>
    $database_tables = {dot}
    $icons_metadata
    </Input>

    <Role>
    You are an expert at understanding database architecture based on ER diagrams and relational structures. Create a JSON structure for a ReactFlow diagram based on the given database schema.
    </Role>
    <Output Structure>
      1. Create a JSON object with a "nodes" and "edges" array.
      2. Create nodes for each table in the schema.
      3. "nodes": An array containing all node objects.
      - "id": A unique string identifier for the node.
      - "data":  
        - "label": The name of the table.
        - "description": A brief summary of the table's role or content.
        - "columns": List of column names (mark primary keys with [PK], foreign keys with [FK]).
        - "group": The logical group name (e.g., 'Database').
        - "subgroup": The specific subgroup within the group (e.g., 'Transactional Tables', 'Reference Tables').
        - "service": The appropriate filename of the icon based on the $icons_metadata.
      - "position" : The x and y coordinates of the node.
      - "type" : "customNode" This should be fixed.
      4. "edges" : An array having id, source, target, label, and type should be customEdge always.
      5. The label of the edge should describe the relationship, like "order_id â†’ order_id". 
      6. The output should be in the form of a dictionary containing a "nodes" and "edges" array.
      7. Present only the code inside delimiters "```reactflow [reactflow CODE]```" without any additional explanation.
    """
    
  return system_prompt, user_prompt
    

def feature_summary_generation(formatted_data, user_mvf, executive_summary):
    # if input_type is None:
    #     formatted_data = file_summary_list
    # elif input_type == "batch_summary":
    #     formatted_data = format_batchwise_summary_metadata_for_services(file_summary_list)
    # else:
    #     formatted_data = format_file_summaries(file_summary_list)

    user_prompt = """
    Role: You are an AI code analyst specializing in creating concise, feature-level summaries of codebases.

    Objective: Provide a comprehensive yet concise feature-level summary of a given codebase, highlighting key components, functionality, and the project's overall workflow.

    Input: You will receive information about a codebase, which may include an executive summary or other project details.

    Steps:
    1. Analyze the provided codebase information.
    2. Identify the main features (maximum 5) of the project from the executive summary (if provided in same order)
    3. Create a summary following the specified format, including:
        a. An overview of the project
        b. A list of key features with brief descriptions
        c. A closure statement
    4. Self-evaluate the generated summary and assign a confidence score.
    5. Format the output as specified in the instructions.

    Output Format:
    ```json
    {
        "data": "generated_summary in string format adhering to the Detailed Instructions for Output Format",
        "confidence_score": 90
    }
    ```

    Detailed Instructions for Output Format:

    **Overview**
    <empty line>
    < 
        Summarize all features in 2-3 sentences, introducing the project and its purpose.
        Provide a 2-3 sentence summary of key benefits, highlighting core architecture and value proposition.
    >
    <empty line>
    **Key Features**
    <empty line>
    <   
        List a maximum of 5 main features.
        For each feature, provide up to 2 sub-points describing its functionality.
        Ensure clear explanation of how features interact and contribute to the project's goals.
        1. ***<Key Feature Title>*** : 
        * <Sub point 1 description>
        * <Sub point 2 description>
        <empty line>
    >
    <empty line>
    < 
        Summarize the overall impact and value proposition of the project in one sentence as a conclusion statement.
    >
    <empty line>
    
    -> Self-Evaluation:
        - Score the summary out of 100 based on clarity, precision, detail, knowledge, accuracy, technical correctness, and understanding of the data.

    -> Formatting Requirements:
        - Replace all newline characters (\n) with \\n in the JSON output.
        - Ensure the complete JSON is less than 7500 tokens.
        - Start the output with "```json" and end with "```".
        - If an executive summary is provided, use only the highlighted features from it.

    Example Output Structure:
    ```json
    {
        "data": "**Overview**\\n\\n[Project overview]\\n\\n[Benefits summary]\\n\\n**Key Features**\\n\\n1. *Feature 1*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n2. *Feature 2*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n[...continue for up to 5 features...]\\n\\n[Closure statement]",
        "confidence_score": 90
    }
    ```

    Remember: Adhere strictly to the output format and instructions to maintain consistency and accuracy in your summary.
    """

    user_prompt += "User Defined Features : " + str(user_mvf)

    system_prompt = f"""
        <role>
        You are an assistant to a Senior Software Engineer. You are very capable in reading and understanding huge codebases.
        There is no edge-case, no mistake, no functionality no matter how small goes unnoticed by you.
        You will be given a large codebase and be asked queries regarding it.
        </role>

        <Task>
        You will be given relevant files from a production codebase. The Senior Engineer will consult you to clear his doubts and ask for critical code-level and functionality level analysis of the same.
        <Important>
        1. You will be clear. Feel free to be descriptive but Avoid Jargon
        2. You shall perform critical analysis on the code before responding.
        3. Note that the codebase will be quite complex and have dependencies everywhere, be mindful of them all.
        4. Enclose code in (triple backticks)``` code ```
        </Important>
        </Task>

        Files from Codebase goes here :
        <Repo Structure>
        {formatted_data}
        </Repo Structure>
    """

    start_index = executive_summary.find("Highlighted Features")
    end_index = executive_summary.find("Key Benefits")

    if start_index != -1 and end_index != -1:
        executive_summary = executive_summary[start_index:end_index].strip()

    user_prompt += "Executive Summary : " + str(executive_summary)

    return system_prompt, user_prompt

def feature_summary_generation_db(formatted_data, user_mvf, executive_summary):
    # if input_type is None:
    #     formatted_data = file_summary_list
    # elif input_type == "batch_summary":
    #     formatted_data = format_batchwise_summary_metadata_for_services(file_summary_list)
    # else:
    #     formatted_data = format_file_summaries(file_summary_list)

    user_prompt = """
    Role: You are an AI Database Analyst specializing in creating concise, feature-level summaries of complex database schemas and architectures.

    Objective: Provide a comprehensive yet concise feature-level summary of a given database schema information, highlighting key components, entities, relationships, and the overall data architecture workflow.

    Input: You will receive information about a database design, which may include an executive summary or other schema-level details.

    Steps:
    1. Analyze the provided database schema information.
    2. Identify the main features (maximum 5) of the database from the executive summary (if provided in same order)
    3. Create a summary following the specified format, including:
        a. An overview of the database
        b. A list of key features with brief descriptions
        c. A closure statement
    4. Self-evaluate the generated summary and assign a confidence score.
    5. Format the output as specified in the instructions.

    Output Format:
    ```json
    {
        "data": "generated_summary in string format adhering to the Detailed Instructions for Output Format",
        "confidence_score": 90
    }
    ```

    Detailed Instructions for Output Format:

    **Overview**
    <empty line>
    < 
        Summarize all features in 2-3 sentences, introducing the database and its purpose.
        Provide a 2-3 sentence summary of key benefits, highlighting schema structure, normalization or denormalization logic, and value proposition in handling data.
    >
    <empty line>
    **Key Features**
    <empty line>
    <   
        List a maximum of 5 main features.
        For each feature, provide up to 2 sub-points describing its data handling, relationships, or optimization logic.
        Ensure clear explanation of how features contribute to performance, consistency, and data integrity.
        1. ***<Key Feature Title>*** : 
        * <Sub point 1 description>
        * <Sub point 2 description>
        <empty line>
    >
    <empty line>
    < 
        Summarize the overall impact and value proposition of the database in one sentence as a conclusion statement.
    >
    <empty line>
    
    -> Self-Evaluation:
        - Score the summary out of 100 based on clarity, precision, detail, knowledge, accuracy, technical correctness, and understanding of the schema information.

    -> Formatting Requirements:
        - Replace all newline characters (\n) with \\n in the JSON output.
        - Ensure the complete JSON is less than 7500 tokens.
        - Start the output with "```json" and end with "```".
        - If an executive summary is provided, use only the highlighted features from it.

    Example Output Structure:
    ```json
    {
        "data": "**Overview**\\n\\n[Database overview]\\n\\n[Benefits summary]\\n\\n**Key Features**\\n\\n1. *Feature 1*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n2. *Feature 2*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n[...continue for up to 5 features...]\\n\\n[Closure statement]",
        "confidence_score": 90
    }
    ```

    Remember: Adhere strictly to the output format and instructions to maintain consistency and accuracy in your summary.
    """

    user_prompt += "User Defined Features : " + str(user_mvf)

    system_prompt = f"""
        <role>
        You are an assistant to a Senior Data Architect. You are very capable in reading, analyzing, and understanding complex database schemas and data models.
        No entity, constraint, relationship, or optimization logic goes unnoticed by you.
        You will be given a comprehensive database structure or schema information and will be asked to analyze, explain, and summarize it at a structural and functional level.
        </role>

        <Task>
        You will be given relevant database schema files or DDL definitions. The Senior Data Architect will consult you to clear doubts and ask for critical schema-level and data model-level analysis.
        <Important>
        1. You will be clear. Feel free to be descriptive but Avoid Jargon
        2. Perform a critical and deep analysis of the schema and the information given before responding.
        3. The schema will often involve multiple tables, foreign keys, views, procedures, and indexing strategies â€” be mindful of their dependencies and relationships.
        4. Enclose code or schema in (triple backticks)``` code ```
        </Important>
        </Task>

        Files from Database schema goes here :
        <Database Structure>
        {formatted_data}
        </Database Structure>
    """

    start_index = executive_summary.find("Highlighted Features")
    end_index = executive_summary.find("Key Benefits")

    if start_index != -1 and end_index != -1:
        executive_summary = executive_summary[start_index:end_index].strip()

    user_prompt += "Executive Summary : " + str(executive_summary)

    return system_prompt, user_prompt


#FEATURE HIERARCHY:
generate_features_system_prompt = """
  <Role>
    You are a Software Architect with expertise in analyzing large summaries from code files of an application. 
    You can comprehend summaries from code files that are complex, production-grade and are written in various programming languages to generate most important features, their description and the subfeatures with their description belonging to the most important features along with the other relevant information requested below.
    
    You will follow 2 Events before responding : 
    1. Generation of Feature Hierarchy as given in "Output_Format".
    2. Critical Evaluation of Every Confidence Score.  
  </Role> 

    <Task 1>
    You are provided with multiple relative file paths and file-wise code summaries from a application codebase.
    1. Analyze the file summaries carefully, leveraging your expertise to deduce the frameworks, functionality, and features.
    2. Perform a critical assessment of the code's functionality and interdependencies before responding.
    3. The codebase is complex and likely contains dependencies across various modules. Be mindful of these.
    4. Analyse every file summary and assign the features and sub-features based on the information provided.
    5. Respond strictly in the structured JSON format provided below.
    6. In each sub-feature's 'file_path' array:
        - Set 'critical: true' ONLY for files that are CORE & NON-REPLACEABLE to the sub-feature's main functionality.
        - Set 'critical: false' for ALL supporting, secondary, or replaceable files  
        - Each sub-feature should have both true and false entries.
        - If unsure, default to false (be EXTREMELY selective with 'true')
        - Make sure each sub-feature atleast have one file as true.

    Explanation of the Output terms:
    Feature - Features are most valuable and high level features extracted from the list of summaries that are provided to you. 
    Feature description - Description of the features explaining the high level value and impact that it creates for the project. Define the Feature. The description should be crisp, precise, well formatted and must be between 2-3 lines.
    Subfeature - Subfeatures are micro most valuable features that are extracted from the list of summaries and belong to the Most related and similar Features.
    Subfeature description - Description of the subfeatures explaining the specific value, technical and non-technical functionalites that it provided to the project. Define the subfeature and also explain how its related to the feature. The description should be crisp, precise, well formatted and must be between 2-3 lines.
    
    Points to Remember:
    1. Do not extract any feature or subfeature where there are no reference/citations from the application summaries.
    2. The description must be precise, valuable, well-formatted and must be between 2-3 lines.
    3. The Feature titles should be precise, specific, self explanaible, independent and not have similar feature titles. The Feature titles should not be highly generalized.
    4. The SubFeatures titles should be precise, self explanaible and not have similar subfeature titles. The SubFeature titles should not be highly generalized.
    5. SubFeatures should not be very low level that it explains code functions, code process like 'Json handling', 'Reading csv', readME etc.
    6. If similar subfeatures are present, then group them under one common Feature itself. Do not create multuple Features for similar subfeatures.
    6. If Unit testing related summaries are found, then create that as another Feature named 'Unit Testing' and assign the specific testing subfeatures under this feature.
    </Task 1>

  <Task 2>
  You shall now Assign and Justify Confidence Scores for each feature.

  <Critical Evaluation of Confidence Scores> 

  <Evaluation MODE>
  - You will now Forget everything that was done beforehand and act as an unbiased judge.
  - $Project-Summaries-&-Paths (INPUT).
  </Evaluation MODE>
  <Important>
  Critically analyze every "Feature" and "SubFeature" based on the following metrics. 
  You shall generate a confidence score between 0-100 for each of the following :
  1. Is the "Feature" & "SubFeature" name accurate to its functionality ? (Accuracy)
  2. Does the "Feature" & "SubFeature" include files with an unrelated function ? (Feature Dilution Rate)
  3. Important : Does this "Feature" & "SubFeature" make sense given the Overall Purpose of the Application ? (Consistency)
  4. Are all the files in "Feature" & "SubFeature" included ? (Completeness)

  <Strict>
  1. You will now generate a list of 4 confidence scores between 0-100 for above criteria under "confidence_score" key.
  2. Based on above criteria, you shall provide a VERY BRIEF logical explanation (10-20 words) for Confidence Score under "confidence_score_justification" key.
  3. Make sure to mention the entire filepath without omitting the prefix.
  4. Make sure all the filepaths are present.
  <Important> STRICTLY Don't Comment on Missing Files. Don't Overestimate. Don't Underestimate.</Important> 
  </Strict>

  </Important>

  </Critical Evaluation of Confidence Scores> 
  </Step 2>


      <Output_Format>
    Return a response in JSON format. Do not include any extra information or explanations. Strictly DON'T deviate from mentioned KEYS.
    Example:
```json
[
  {
    "name": "User Authentication and Management",
    "feature_description": "Comprehensive user account system with secure login, registration, profile management, and role-based access control.",
    "feature_description_confidence_score": [95, 70, 100, 70],
    "sub_features": [
      {
        "name": "User Registration",
        "description": "Allows new users to create accounts by providing necessary information such as username, email, and password. Implements email verification, password strength checks, and duplicate account prevention. Stores user data securely in the database with password hashing.",
        "file_path": [
          {
            "module_name": "RegistrationController",
            "path": "Controllers/Account/RegistrationController.cs",
            "critical": true
          },
          {
            "module_name": "RegisterView",
            "path": "Views/Account/Register.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [75, 80, 85, 65],
        "sub_feature_confidence_score_justification": "No feature dilution, might have missed some file."
      },
      {
        "name": "User Login",
        "description": "Authenticates users using their credentials, creates and manages user sessions, and implements security measures such as login attempt limiting and two-factor authentication (2FA). Provides password reset functionality for forgotten passwords.",
        "file_path": [
          {
            "module_name": "LoginController",
            "path": "Controllers/Account/LoginController.cs",
            "critical": true
          },
          {
            "module_name": "LoginView",
            "path": "Views/Account/Login.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [80, 100, 80, 75],
        "sub_feature_confidence_score_justification": "High chance of missing files."
      }
    ],
    "feature_confidence_score_justification": "No feature dilution, duplication or missing files. Accurate Naming."
  },
  {
    "name": "Product Catalog Management",
    "feature_description": "Comprehensive system for managing product listings, categories, and inventory across the e-commerce platform.",
    "feature_description_confidence_score": [95, 65, 70, 80],
    "sub_features": [
      {
        "name": "Product CRUD Operations",
        "description": "Enables administrators to create, read, update, and delete product listings. Includes functionality for managing product details such as name, description, price, images, and inventory levels. Implements validation to ensure data integrity and consistency across the product catalog.",
        "file_path": [
          {
            "module_name": "ProductController",
            "path": "Controllers/ProductController.cs",
            "critical": true
          },
          {
            "module_name": "ProductView",
            "path": "Views/Product/Index.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [90, 85, 100, 70],
        "sub_feature_confidence_score_justification": "High confidence with no duplication or dilution."
      },
      {
        "name": "Category Management",
        "description": "Allows for the creation and management of product categories and subcategories. Implements a hierarchical structure for organizing products, enabling efficient navigation and filtering of the product catalog for both administrators and customers.",
        "file_path": [
          {
            "module_name": "CategoryController",
            "path": "Controllers/CategoryController.cs",
            "critical": true
          },
          {
            "module_name": "CategoryView",
            "path": "Views/Category/Index.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [85, 75, 90, 95],
        "sub_feature_confidence_score_justification": "High confidence without any duplication or dilution."
      }
    ],
    "feature_confidence_score_justification": "All files refer to single overall functionality. Might have missed some files."
  }
]
```
  </Output_Format>

"""

generate_features_user_message = """
<Strictly Remember>
1. As input you will be given a batch of `file_path` and `file_summary` from a production codebase. Keep it in mind that it could be a file from a very large repository with lot of inter-dependencies.
2. Understand all the file description first, then try to determine the feature, sub-features and their description. For **each file** it should have a feature or sub-features whenever the conditions are met.
3. The response should contain all the fields given in the example output format. The response should be strictly in json format.
4. The description of features/subfeatures must be in the length of 2-3 lines. The response should be structured and well-formatted.
5. Don't generate any additional explanation or description. Provide the structured response in json only.
</Strictly Remember>
  
<Input file wise summary>
{file_summary}
</Input file wise summary>
<Response>
"""

merge_features_in_hierarchy_user_prompt = """You are a software feature analyzer. Given a list of related features that have been clustered together, create a merged feature that encompasses all the functionality.

Features to merge:
{feature_list}

Generate a JSON response that includes:
1. A name for the merged feature representing accurate feature name. Do not mention its merged or unified or anything as such. The feature name should accurately represent a major funcationality of a repository.
2. A detailed description that covers all functionality
3. A confidence score (0-100) for the merge
4. A justification for the confidence score

Respond with a JSON object in the following format:
```json
{{
    "name": "Merged feature name",
    "description": "Comprehensive description",
    "confidence_score": 85,
    "confidence_justification": "Reason for the confidence score"
}}
```
Give only JSON and nothing else. Do not include any explanations or additional text outside the JSON block. Make sure to start with ```json and end with ``` only.
"""

mapping_names_for_merged_features_user_prompt = """  <Role>
    You are a smart AI cassistant with strong expertise in Software Engineering. You can understand complex, production-grade codebases written in various programming languages and summarize them effectively.
  </Role>
  <Task>
  You will be given a brief description of  features of a large codebase and your task is to generate a relevant feature name, brief description, and priority level.
  <Important>
   1. The feature name should be brief, relevant and should represent the entire description provided.
   2. Generate a relevant description which is basically a overall summary of the description provided.
   3. Assign a priority level (high, medium, low) based on the significance, importance and complexity of the feature to the overall system. 
  </important>
  </Task>
  <Example output>
  ```json
    {
        "name": <feature_name>, //string
        "feature_description": <feature_description>, //string
        "priority": <priority> //string (high, medium, or low)
    }
    ```
  </Example output>
  <Strictly Remember>
1. The feature name should be relevant and at the same time interpretable, easy to understand.
2. The feature description should represnt the entire description given for summarisation, it should be simple and easy to understant.
3. The priority should be one of: high, medium, or low.
4. The response should be strictly in json format specified above.
5. Strictly make sure Feature Description is not more than 200 words.
  </Strictly Remember>

<code summary>
The code summary is given below:
"""


reducing_sub_features_user_prompt = """
    You are a software feature consolidation expert. Your task is to merge similar sub-features into one comprehensive sub-feature.

    Here are the sub-features that need to be merged:
    {sub_features_list}

    For each sub-feature, we have:
    - Name: The sub-feature name
    - Description: The sub-feature description (if available)
    - Confidence Score: The confidence score (if available)

    Your output should be a JSON object containing:
    1. A unified sub-feature name that encompasses all the input sub-features
    2. A comprehensive description that covers all aspects of the input sub-features
    3. A confidence score (use the highest available from input sub-features)
    4. A justification for the confidence score

    Return the output in JSON format starting with ```json and ending with ```.

    Example output format:
    ```json
    {{
        "name": "Unified Sub-Feature Name",
        "description": "Comprehensive description covering all aspects",
        "sub_feature_confidence_score": 95,
        "sub_feature_confidence_score_justification": "Merged from similar sub-features with high semantic similarity"
    }}
    ```
    """


post_processing_feature_name_description_system_prompt="""
  <Role>
    You are a smart AI assistant with strong expertise in Software Engineering. You can understand complex, production-grade codebases written in various programming languages and summarize them effectively.
  </Role>
  <Task>
  You will be given a brief description of modules or features of a large codebase and your task is to generate a relevant feature name and brief description.
  <Important>
   1. The feature name should be brief, relevant and should represent the entire description provided.
   2. Generate a relevant description which is basically a overall summary of the description provided.
   3. Also generate a confidence score in a scale of 0 - 100.
  </important>
  </Task>
  <Example output>
  ```json
    {
        "name": <feature_name>,
        "feature_description_confidence_score": <score 0 - 100>,
        "feature_description": <feature_description>
    }```
  </Example output>"""

post_processing_feature_name_description_user_prompt = """<Strictly Remember>
1. The feature name should be relevant and at the same time interpretable, easy to understant.
2. The confidence score should represent the ability to summarise the description.
3. The feature description should represnt the entire description given for summarisation, it should be simple and easy to understant.
4. The response should be strictly in json format specified above.
</Strictly Remember>
<code summary>
The code summary is given below: \n
{feature_description}
</code_summary>
<response>
Your response in json goes here:
"""

merge_similar_features_system_prompt = """You are a solution architect. Your task is to carefully review each feature and its description, and combine them into a single high-level feature.

The final high-level features should represent what an end user would perceive, e.g., Messenger, Google Chat, Messaging, Reels, etc.

Based on the generated features provided, identify which features can be merged into a single high-level feature. 
Strictly output them in the following format:
{{ 
  <High-Level Feature Name 1>: [<Merged Feature 1>, <Merged Feature 2>, <Merged Feature 3>, ...],
  <High-Level Feature Name 2>: [<Merged Feature 1>, <Merged Feature 2>, <Merged Feature 3>, ...],
  ...
}}

INPUT:
Feature names and descriptions are provided in the format: 
[1. Feature name: <feature name> 
Feature description: <feature description>, 
2. ...]

{feature_texts}

MVFS:
{total_MVFs}

Points to remember:
1. While merging features and naming high-level features, always prefer names from the user-defined MVFs provided. All relevant features can be grouped under these high-level features.
2. If certain features do not fit under the user-defined MVFs, choose a better name than the existing one for the new high-level feature if necessary.
3. The names of the features being merged must remain exactly as provided in the INPUT section; do not modify them. Do not consider Feature description in Feature Names.
4. Follow the output structure strictly: high-level feature names as dictionary keys and merged features as values in list format.
5. If a feature is already a high-level feature, you do not need to forcibly merge it. If a feature seems to be function-level/low-level  features, merge them into a High-level feature.
6. Merge similar features into a single high-level feature based on their names and descriptions, when applicable. Each final high-level feature should be independent of the others.
7. Do not assign the same feature to multiple high-level features.
8. If user-defined MVFs are empty, skip point 1 and begin with point 2.
9. Do **not** include any Feature descriptions in the final output."""


merging_description_user_prompt = """You are a Solution Architect. Your task is to summarize the multiple feature descriptions provided into a brief, coherent summary of **no more than two sentences**.

  The summary must:
  - Accurately capture all key components from the provided descriptions.
  - Align clearly with the given high-level feature name.
  - Serve as the final description of the high-level feature.

  Only the final summarized description should be included in the output â€” no additional commentary or formatting.

  INPUT:
  Multiple descriptions: {merging_feature_description}

  High-Level Feature Name: {high_level_feature}
  """


micro_sub_feature_prompt = """You are an expert system analyst specializing in decomposing SubFeatures into granular, logically independent components. You support **two levels** of splitting:

1. **Horizontal splitting**: Split a subfeature into multiple *same-level subfeatures* when it encompasses multiple independently meaningful functionalities. The subfeatures created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.
2. **Vertical splitting**: Further break each of those subfeatures into *microsubfeatures* (if applicable), ensuring each micro-sub-features/micro-user-story describes a single goal or operation. The micro-sub-features/micro-user-story created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.

---

### ðŸ”§ TASK OVERVIEW

Given a Macro-Feature, Subfeature, its description, associated module files and its summary:

- Decide if the subfeature should be split horizontally into multiple same-level subfeatures.
- For each resulting subfeature (or original if not split), analyze whether it can be split vertically into **microsubfeatures** (fine-grained user stories).
- Provide the confidence scores for the subfeature that is split, whether horizontally or vertically.
- Provide the files that are related to the sub_features too, not just the micro_sub_features.
- Each leaf user-story must have files assigned to them, else you should not create/split these subfeatures.
- Provide description of generated subfeature/sub-user-stories in 2-4 lines but only valid information. Do not assume or hallucinate to generate description.
Apply this recursively: if horizontal splitting occurs, then attempt vertical splitting for each. But remember, not to create any duplicates in the process. 

---

### SPLITTING DECISIONS

#### Horizontal Splitting (Same-level Subfeatures):
Split if:
- The subfeature covers multiple high-level functionalities
- Each function could be planned, developed, and deployed independently
- Each component has a clear boundary and responsibility

#### Vertical Splitting (Microsubfeatures):
Split further if:
- A subfeature contains multiple independent operations or logical stages
- These operations can be implemented, tested, or tracked separately
- Each micro-subfeature represents one atomic, non-overlapping functionality

---

### DO NOT SPLIT IF:
- sub-user-stories are tightly coupled in the Subfeature and cannot function independently.
- Do not split subfeatures into sub-user-stories that are hardly single line of code and cannot be considered as a proper functionality, but just a config/parameter.
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across actions are too complex to isolate.
- There are no files that can be mapped to the generated user-story.
- Do not split if the user-story is barely a functionality. The split user-stories must have independent functionality that contributes to the subfeature and feature and if not, do not split.
- Don not split ReadMe & .md files into sub-user-stories.
- Do not split horizontall for granullar subfeatures as they are not user stories but mid level features.
---

### FILE MAPPING RULES:
- For each subfeature or microsubfeature, cite only directly relevant files.
- Use only the provided input data to match files â€” no guessing.
- Avoid duplication unless a file is clearly shared between components.

Each `file_path` entry must include:
```json
{
  "module_name": "<Name>",
  "path": "<Path>",
  "critical": <true/false>,
  "git_url": "<Git URL>"
}

OUTPUT FORMAT
If the subfeature should NOT be split:
Return: "None"

If the subfeature should be split, return a list of Parent User Stories with subfeatures inside.
If a subfeature itself can be further split into microsubfeatures, nest them under micro_sub_features like so:

[
  {
    "name": "Parent User Story Title 1",
    "description": "Full description of the original or updated user story and its purpose.",
    "file_path": [...],
    "sub_feature_confidence_score":"confidence score of the subfeature with respect to the Feature, as a percentage (e.g., 80)"
    "micro_sub_features": [
      {
        "name": "Sub-User Story Title 1",
        "description": "Standalone description of a single functionality.",
        "file_path": [...],
        "micro_sub_feature_confidence_score":"confidence score of the micro_sub_feature with respect to the sub_feature, as a percentage (e.g., 90)"
        }
          ...
        ]
      },
      ...
    ]
  }
]
Each layer must preserve independence, clarity, and singular focus of each story.

VALIDATION CHECKLIST
- Each title must express one functionality only (no imperative phrasing)
- description must avoid assumptions and describe the real function. It must be as detailled as possible.
- Each story must make sense independently and fit in the broader feature flow
- if there are multiple user-story under the subfeature, it needs to be in sequence of business logic.
- File mappings must be relevant and scoped accurately
- Do no miss/skip any values in the output json. The output structure must be maintained strictly.
- All subfeature and sub-user-story names and descriptions must be strictly in a declarative tone, not imperative.

* Use generic or speculative statements
"""


db_micro_sub_feature_prompt = """
<Role>
You are an expert Database analyst specializing in decomposing SubFeatures into granular, logically independent components. You support **two levels** of splitting:
You shall ALWAYS process features from a Database perspective ONLY. 
There can be more than one Table in the DB context provided to you.
</Role>

1. **Horizontal splitting**: Split a subfeature into multiple *same-level subfeatures* when it encompasses multiple independently meaningful functionalities. The subfeatures created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.
2. **Vertical splitting**: Further break each of those subfeatures into *microsubfeatures* (if applicable), ensuring each micro-sub-features/micro-user-story describes a single goal or operation. The micro-sub-features/micro-user-story created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.

<Strict Constraints> 
- You are dealing with Database Information. 
- No matter what, STRICTLY use Database-Specific Language ALWAYS. 
- Use words like Columns / Fields / Schema / DataTypes / Constraints / Foreign Keys / Primary Keys etc.
- Strictly Do not start descriptions with or start with "this micro-feature" / or "this sub-feature".
- You shall do this regardless of the input context and nature.
Remember : Every "FILE" given to you is information of a table. Therefore in your response, ALWAYS refer to "Table" instead of "File".

</Strict Constraints> 


### ðŸ”§ TASK OVERVIEW

Given a Macro-Feature, Subfeature, its description, associated module files and its summary:

- Decide if the subfeature should be split horizontally into multiple same-level subfeatures.
- For each resulting subfeature (or original if not split), analyze whether it can be split vertically into **microsubfeatures** (fine-grained user stories).
- Provide the confidence scores for the subfeature that is split, whether horizontally or vertically.
- Provide the files that are related to the sub_features too, not just the micro_sub_features.
- Each leaf user-story must have files assigned to them, else you should not create/split these subfeatures.
- Provide description of generated subfeature/sub-user-stories in 2-4 lines but only valid information. Do not assume or hallucinate to generate description.
Apply this recursively: if horizontal splitting occurs, then attempt vertical splitting for each. But remember, not to create any duplicates in the process. 

---

### SPLITTING DECISIONS

#### Horizontal Splitting (Same-level Subfeatures):
Split if:
- The subfeature covers ONE / MORE THAN ONE high-level functionalities
- Each function could be planned and developed independently
- Each component has some clear boundaries and responsibilities

#### Vertical Splitting (Microsubfeatures):
Split further if:
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across actions are too complex to isolate.
- There are no tables that can be mapped to the generated user-story.
- The subfeature is too complex to be planned, developed, and deployed independently
- Each micro-subfeature represents one atomic, non-overlapping functionality
Note: Maintain at least 2 subfeatures unless the database has only one table.
- Prioritize brevity, consistency and no informaiton leakage across subfeatures.
- Ensure crisp segregation.
---

### DO NOT SPLIT IF:
- sub-user-stories are tightly coupled in the Subfeature and cannot function independently.
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across tables in two features are too complex to isolate.
- There are no tables that can be mapped to the generated user-story.
Note: Maintain at least 2 subfeatures and 1 or more microsubfeatures per subfeature, Unless the database has only one table.
Note : Maintain brevity during splitting at the same level. Do NOT overload the a single feature with too many subfeatures.
---


### FILE MAPPING RULES:
- For each subfeature or microsubfeature, cite only directly relevant tables.
- Use only the provided input data to match files â€” no guessing.
- Avoid duplication unless a file is clearly shared between components.

Each `file_path` entry must include:
```json
{
  "module_name": "<Name>",
  "path": "<Path>",
  "critical": <true/false>,
  "git_url": "<Git URL>"
}

OUTPUT FORMAT
If the subfeature should NOT be split:
Return: "None"

If the subfeature should be split, return a list of Parent User Stories with subfeatures inside.
If a subfeature itself can be further split into microsubfeatures, nest them under micro_sub_features like so:

[
  {
    "name": "Parent User Story Title 1",
    "description": "Full description of the original or updated user story and its purpose.",
    "file_path": [...],
    "sub_feature_confidence_score":"confidence score of the subfeature with respect to the Feature, as a percentage (e.g., 80)"
    "micro_sub_features": [
      {
        "name": "Sub-User Story Title 1",
        "description": "Standalone description of a single functionality.",
        "file_path": [...],
        "micro_sub_feature_confidence_score":"confidence score of the micro_sub_feature with respect to the sub_feature, as a percentage (e.g., 90)"
        }
          ...
        ]
      },
      ...
    ]
  }
]
Each layer must preserve independence, clarity, and singular focus of each story.

VALIDATION CHECKLIST
- Each title must express one functionality only (no imperative phrasing)
- description must avoid assumptions and describe the real function. It must be as detailled as possible.
- Each story must make sense independently and fit in the broader feature flow
- if there are multiple user-story under the subfeature, it needs to be in sequence of business logic.
- File mappings must be relevant and scoped accurately
- Do no miss/skip any values in the output json. The output structure must be maintained strictly.
- All subfeature and sub-user-story names and descriptions must be strictly in a declarative tone, not imperative.
- Use Database-specific schema only. Do not include words like "Attributes" / "Code Files" in your response. 
- Strictly Do not start descriptions with or start with "this micro-feature" / or "this sub-feature".
* Use generic or speculative statements

"""import os
from graphviz import Digraph
import re 
import json

def parse_ddl(ddl: str):
    """
    Parse the DDL to extract columns, primary keys, and foreign keys.
    """
    lines = ddl.splitlines()
    column_lines = []

    for line in lines:
        line = line.strip()
        if (
            line.upper().startswith("CREATE")
            or line.upper().startswith("PRIMARY")
            or line.upper().startswith("FOREIGN")
            or line.upper().startswith(")")
            or line == ""
        ):
            continue

        match = re.match(r'(\w+)\s+\w+', line)
        if match:
            column_lines.append(match.group(1))

    pk_match = re.search(r'PRIMARY KEY\s*\((.*?)\)', ddl)
    primary_keys = [key.strip() for key in pk_match.group(1).split(",")] if pk_match else []

    foreign_keys = []
    for match in re.finditer(r'FOREIGN KEY\s*\(([^)]+)\)\s+REFERENCES\s+`?[\w]+\.(\w+)`\(([^)]+)\)', ddl):
        fk_col = match.group(1).strip()
        ref_table = match.group(2).strip()
        ref_col = match.group(3).strip()
        foreign_keys.append((fk_col, ref_table, ref_col))

    return column_lines, primary_keys, foreign_keys


def generate_combined_graph(tables_data):
    """
    Generate a single combined graph from multiple tables.
    """
    dot = Digraph(comment='Combined Table Diagram')
    dot.attr(rankdir='LR')

    # Store individual table nodes
    for table in tables_data:
        table_name = table['table_name']
        columns = table['columns']
        primary_keys = table['primary_keys']
        
        label_lines = []
        for col in columns:
            if col in primary_keys:
                label_lines.append(f"{col} [PK]")
            else:
                label_lines.append(col)
        dot.node(table_name, shape='box', label=f'{table_name}\\n' + "\\n".join(label_lines))

    # Add relationships
    for table in tables_data:
        table_name = table['table_name']
        for fk_col, ref_table, ref_col in table['foreign_keys']:
            dot.edge(table_name, ref_table, label=f'{fk_col} â†’ {ref_col}')

    return dot

def folder_summary_generation_prompts(
        total_allocated_tokens, 
        file_list, folder_name, 
        folder_path,
        subfolder_list,
        formatted_file_summaries,
        formatted_file_services,
        formatted_subfolder_summaries,
        formatted_subfolder_services,
        formatted_subfolder_features
    ):
    
    system_prompt = f"""
        You are an expert code analyst specialized in creating detailed, informative summaries of software project folders. Your task is to thoroughly analyze files and subfolders to provide a comprehensive understanding of the application or project and provide combined summaries along with required details. These summaries must be detailled enough for further summarization.

        Follow these guidelines:
        1. Conduct a deep analysis of the features to identify its core purpose and functionality
        2. Provide detailed explanation of key implementations and technical approaches of the features
        3. Thoroughly examine the summaries based on files and folders to understand relationship between features and combined smaller features into larger high level application level features.
        4. Explain the features within the broader project architecture with specific connections
        5. Describe technical patterns, design decisions, and architectural choices evident in the code
        6. Include specific functions, classes, and methods that define the feature's behavior
        7. Note dependencies, imports, and external connections that shape the folder's functionality
        8. Identify potential architectural strengths and areas for improvement when evident
        9. Identify all services represented in this folder based on file and subfolder services information
        10. Identify and articulate high-level features or functionalities represented by the folder into the feature_details section, when consolidating multiple subfolders or lower-level files. Derive these insights from both file-level and subfolder-level summaries. Also under each feature, mention which file/folder was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
        11. Do not miss any features that could be formed based on these summaries as this information is required to understand the application's buisness logic.
        12. Gather insights from the summaries provided to generate a high level detailled executive summary that could be used by business stakeholders to understand the folder/project.
        13. When analyzing the root folder, both the executive summary and the features must be strictly formed in a high level business logic standpoint of an application.
        
        IMPORTANT: 
        - Your summary should be thorough and detailed({total_allocated_tokens}) while maintaining technical/business precision and depth. Focus on providing insights that would help both stakeholders and developers understand the application better.
        - feature_details must contain high level feature name and feature description(value of the files/folders) strictly in concise bullet points. The feature inforamtion must be in detail to capture the complete high level knowledge for that feature but not the function level details. Feature names cannot be programmatic function names like Dependency management, json handling etc. instead it should be inventory management, order processing etc. 
        - Your services list should be comprehensive and include all services represented in this folder.
        - is_reuasble_lib if a folder is used as reusable lib make it True otherwise False
        - lib_name if is_reusable_lib is True then provide the name of the reusable lib/component If is_reusable_lib False then add Not Applicable
        - category if is_reusable_lib is True then provide category only between 'Frontend' and 'Backend' If is_reusable_lib False then add Not Applicable
        - sub_category if is_reusable_lib is True then provide sub category only between 'UI Component','Custom Hooks', 'http_client', 'Utils', 'Others' In Frontend & 'Middleware', 'Error Handling', 'Auth', 'Utils', 'Others' In Backend If is_reusable_lib False then add Not Applicable
        - when_to_use if is_reusable_lib is True then provide where this reusable lib/component can be used If is_reusable_lib False then add Not Applicable 
        - associated_files if is_reusable_lib is True then provide the list of files associated(give complete path for the assosciated file) with this reusable lib/component If is_reusable_lib False then add Not Applicable
        - summary must not be technical and only explain the high level details of the folder/project. Understand the file and folder summaries provided to combine the knowledge to form the executive summary. Make it as detailled as possible.
        - Use clear and concise language, avoiding jargon where possible.
        
        - You must provide your response in this exact format:
        ```summary
        [Your detailled high-level executive summary for the folder for business stakeholders]
        ```
        ```feature_details
        [List of high-level features or functionalities represented in this folder]
        ```
        ```services_namess
        [Comma-separated list of all services represented in this folder]
        ```
        ```is_reuasble_lib
        Boolean Value
        ```
        ```lib_name
        [Name of the reusable library if applicable]
        ```
        ```category
        [Category of the reusable library if applicable]
        ```
        ```sub_category
            [Sub category of the reusable library if applicable]
        ```
        ```when_to_use
        [Your detailed use case where or when this reuasble_lib can be usefull]
        ```
        ```associated_files
            [Comma-separated list of associated files with the reusable library, Give the Complete file path as mentioned in the file list]
        ```
        ```example_usage
            [Example code snippet of how to use this reusable library]
        ```
    """

    user_prompt = f"""
        Generate a summary and services list for the folder: "{folder_name}" (Path: {folder_path})

        FOLDER CONTENTS:
        - Files ({len(file_list)}): {", ".join(file_list) if file_list else "None"}
        - Subfolders ({len(subfolder_list)}): {", ".join(subfolder_list) if subfolder_list else "None"}

        FILE SUMMARIES:
        {os.linesep.join(formatted_file_summaries) if formatted_file_summaries else "No file summaries available"}

        FILE SERVICES:
        {os.linesep.join(formatted_file_services) if formatted_file_services else "No file services available"}

        SUBFOLDER SUMMARIES:
        {os.linesep.join(formatted_subfolder_summaries) if formatted_subfolder_summaries else "No subfolder summaries available"}

        SUBFOLDER SERVICES:
        {os.linesep.join(formatted_subfolder_services) if formatted_subfolder_services else "No subfolder services available"}

        SUBFOLDER FEATURES:
        {os.linesep.join(formatted_subfolder_features) if formatted_subfolder_features else "No subfolder features available"}
        
        Based on these components:
        1. Provide a thorough technical summary explaining the folder's purpose, implementation details, and architectural significance
        2. Compile a comprehensive list of all services represented in this folder based on file and subfolder services information
        
        Follow the exact format specified in the system instructions for your response.
    """

    return system_prompt, user_prompt

def services_generation():
    system_prompt = """
        <Task>
        Create an architectural blueprint of the given repository by identifying and classifying both external services and third-party services with no overlap between categories.
        </Task>

        <Definitions>
        - External services: Company-provided services hosted outside the application (AWS S3, Google Cloud, Stripe, Twilio)
        - Third-party services: Libraries, frameworks, and SDKs that are part of the core application stack (Django, React, MongoDB, Redux)
        </Definitions>

        <Output_Format>
        {
        "external_services": [
            {
            "external_service_name": "string",
            "description": "string",
            "associated_files": ["string"],
            "service_class": "string",
            "used_in_files": ["string"]
            }
        ],
        "thirdparty_services": [
            {
            "thirdparty_service_name": "string",
            "description": "string",
            "associated_files": ["string"],
            "service_class": "string",
            "used_in_files": ["string"]
            }
        ]
        }
        </Output_Format>

        <Instructions>
        1. Conduct a thorough repository analysis to identify all services
        2. Classify each service into exactly ONE category:
        - External services: Cloud platforms, payment processors, authentication providers
        - Third-party services: Frameworks, libraries, SDKs integrated into the codebase
        3. For each service, provide:
        - Name: Exact service name
        - Description: Concise explanation of functionality and purpose
        - Associated files: All files directly importing or using the service
        - Service class: Category (e.g., "cloud storage", "web framework", "database")
        - Used in files: Complete paths of files utilizing the service
        4. Ensure ZERO overlap between categories
        5. Prioritize accuracy over comprehensiveness
        6. Validate that identified services are actively used in the project
        7. Include only services with clear evidence of implementation
        8. Do not create a lot of services which are redundant. Keep it to a maximum of 50 services only.
        </Instructions>

        <Examples>
        Good External Service Entry:
        {
        "external_service_name": "AWS S3",
        "description": "Cloud storage service used for storing user-uploaded files",
        "associated_files": ["src/services/storage.js", "src/config/aws.js"],
        "service_class": "cloud storage",
        "used_in_files": ["src/components/FileUpload.js", "src/pages/UserProfile.js"]
        }

        Good Third-Party Service Entry:
        {
        "thirdparty_service_name": "React",
        "description": "Frontend JavaScript library for building user interfaces",
        "associated_files": ["package.json", "src/index.js"],
        "service_class": "frontend framework",
        "used_in_files": ["src/App.js", "src/components/*.js"]
        }
        </Examples>

        Analyze the repository and provide the complete architectural blueprint in the specified format.
    """

    user_prompt = ""

    return system_prompt, user_prompt

def executive_summary_generation(combined_summary, user_mvf):
    system_prompt = """
    Your Role:
    You are an expert software architect tasked with understanding a codebase and creating an executive summary that clearly articulates the main purpose of this application,
    the core problem that the application is solving, and the prioritized list of the most valuable features, solely based on the provided folder wise summary. Do not hallucinate and create the most valuable features and its description on assumption. This needs to be based on facts.

    Task:
    1. Analyze provided folder wise summary and the services used and the user defined features (if provided).
    2. Understand component interactions and functions.
    3. Prioritize the User Defined Features (if provided) in the summary.
    4. Identify and prioritize the most valuable features based on their importance and relevance to the overall project, as evidenced in the code.
    5. Create a comprehensive executive summary.

    Steps:
    1. Review folder wise summary.
    2. Analyze folder wise summary:
    - Identify key components and their roles
    - Note data operations, design patterns, and architectural decisions
    3. Create summary:
    - Describe the specific problem the codebase solves, based on folder wise summary
    - Explain component interactions
    - Outline data workflow
    4. Identify and prioritize main features:
    - Determine which feature(s) address the core problem of the application, based on code implementation
    - Rank features based on their importance and relevance to solving the main problem, as evidenced in the code
    - The feature should be major components of the codebase and not minor functions like "Modular Architecture" or "Code Reusability", these are not features but design principles.

    Focus Areas:
    - Precised feature prioritization and importance
    - High-level functionality
    - Clear, concise technical language
    - Objective description
    - Capture entire workflow

    Guidelines:
    - Only use the folder wise summary provided
    - Use precise technical terms
    - Include user-defined features if provided and evidenced in the code
    - Prioritize features based on their importance to the core problem, as shown in the folder wise summary

    Feature Identification and Prioritization:
    - Carefully analyze the folder wise summary to identify features actually present in the folder wise summary
    - Do not assume or infer features that are not explicitly mentioned in the folder wise summary
    - Identify the top feature that solves the majority of the problem based on code evidence
    - Rank subsequent features in descending order of importance, ensuring they are present in the folder wise summary
    - Ensure the feature list reflects the codebase's focus and structure
    - Only include features that have substantial implementation in the codebase that is evident from folder wise summary

    Output Format - Adhering to this format is crucial
    ```json
    {
    "data": "generated_summary in string format adhering to the Expected Output Format for Generated Summary",
    "confidence_score": 90,
    "traceback": {
    "Feature 1 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 1 Title' is included, as the 'phrase' is an evidence that this feature is part of the codebase.",
    "Feature 2 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 2 Title' is included, as the 'phrase' is an evidence that this feature is part of the codebase.",
    ...
    }
    }
    ```

    Requirements:
    - Replace \n with \\n in JSON
    - Limit upto 5 main features (max 2 sub-features each) or 7500 tokens
    - If due to any reason such as codebase being small, you are unable to provide 5 features, then provide as many high-level features as possible between the range of 1 to 5.
    - Don't assume features or include minor features due to inability to provide 5 features, lesser number of features is acceptable.
    - Use specified JSON format only
    - Start with "```json" and end with "```"
    - Ensure the top feature in the prioritized list addresses the core problem and is present in the folder wise summary
    - Rank features in descending order of importance to the main problem, based on actual code implementation
    - Do NOT include features that are NOT evidenced in the provided folder wise summary
    - Evaluate the folder wise summary objectively, considering all conclusions on the actual code provided
    - Do NOT make any assumptions about organizational goals or intentions beyond what is explicitly shown in the code
    - Focus solely on the technical aspects and implemented functionality, avoiding speculation about business objectives or future plans
    - Both the keys data, confidence score, and traceback should be present in the output JSON
    - The generated summary should be in string format only and be contained inside the "data" key
    - The "traceback" key should contain a dictionary with feature names as keys and justifications for including these features based on exact phrases from the input
    - Do not include any feature that could potentially be part of the folder wise summary without explicit evidence
    - Every feature mentioned must be driven by clear evidence from the provided input
    """
    user_prompt = """
    Expected Output Format for Generated Summary:

  **Overview**
  <empty line>
  <A brief introduction to the codebase and its main purpose; in paragraph format only, not in points.
  This paragraph should provide a concise yet comprehensive overview of the codebase, its primary functionality, solution provided by the project and its intended use case.
  Aim for 3-5 sentences that capture the essence of the project.>
  <empty line>
  **Highlighted Features**
  <empty line>
  <
  List and briefly explain the key features that are significant components of the codebase and would serve as selling points.
  These features should be presented as follows:
  1. Use numbered points for each feature.
  2. Provide a brief explanation for each feature in 1-2 sentences, highlighting its importance and benefit to the end user.
  3. Focus on features that are central to the codebase's functionality and most important to the end user.
  4. Dont include generic features like "Modular Architecture" or "Code Reusability", these are not features but design principles.
  5. Do not include sub-points under any feature.
  6. Prioritize User Defined Features (if provided) at the beginning of the list.
  7. If User Defined Features are given, list them first before including any features identified through your analysis.
  8. Aim to provide upto of 1 to 5 key features, after each feature add an empty line for formatting purposes.
  9. Ensure that the features listed represent the core functionality and unique selling points based on the folder wise summary.
  10. Use clear, concise language that emphasizes the value proposition of each feature.
  11. Also under each feature, mention which file/folder was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
  12. Do not add features into Highlighted Features if they dont have value for buisness stakeholder about the application. Also do not repeat adding similar feature in this section.

  Output Structure:
  1. ***<Feature 1 Title>***: <Description of the feature in one to two sentences.\n
  2. ***<Feature 2 Title>***: <Description of the feature in one to two sentences.>\n
  >
  <empty line>
  **Key Benefits**
  <empty line>
  <Summarize the key benefits of the codebase in one to two sentences.
  This summary should encapsulate the overall value proposition of the codebase and its potential impact on users or the organization.>
  <empty line>
  <Highlight the most significant key benefits the codebase has to offer in bulleted points. The format should be:
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  Aim for 3-5 bullet points that capture the most compelling advantages of using this codebase, after each point add an empty line for formatting purposes.
  Each benefit should be distinct and provide a clear value proposition.>

  <Final Output Format>
  Output Format - Adhering to this format is crucial, the output should be in parsable JSON format:
  ```json
  {{
    "data": "<generated_summary in string format adhering to the Expected Output Format for Generated Summary>",
    "confidence_score": 90,
    "traceback": {{
      "Feature 1 Title": "Since it mentions about <exact phrase from the folder wise summary>, the 'Feature 1 Title' is included, as the "phrase" is an evidence that this feature is part of the folder wise summary.",
      "Feature 2 Title": "Since it mentions about <exact phrase from the folder wise summary>, the 'Feature 2 Title' is included, as the "phrase" is an evidence that this feature is part of the folder wise summary.",
      ...
    }}
  }}
  ```
  </Final Output Format>
  Note: If the traceback includes phrases that are not present in the folder wise summary then you would be penalized 10000 points.
  The output should be having data, confidence score, and traceback keys, and the entire content inside "```json" and "```" should be parsable by json.
  The "data" key should contain the generated summary and it should be in string format only, allowing the parsing of the entire json.
  If there are any inverted commas inside the generated summary, then escape them with a backslash.
  Do not change or skip the headings of each section in the generated json. The generated summary must have "Overview", "Highlighted Features", "Key Benefits" as section titles. Follow the above provided guidelines."""
    user_prompt += f"""Use the below folder wise summary to generate the summary in the above format: {combined_summary}""" + "User Defined Features : " + str(user_mvf)
    return system_prompt, user_prompt

def db_executive_summary_generation(combined_summary, user_mvf): 
    system_prompt = """
    Role:
    You are an expert Database Architect tasked with understanding the contents of all tables and schema of the database. 
    You shall Articulate a proper executive summary that clearly captures all the main & high-level features of this database.
    The core use-case that this database is intended for, and the prioritized list of the most valuable features, solely based on the provided Table-Level summaries. 
    Do not hallucinate. Do NOT create the most valuable features and its description on pure assumptions. This needs to be based on facts, with proper backing.

    Task:
    1. Analyze provided Table wise summaries.
    2. Understand component interactions and functions.
    3. Prioritize the User Defined Features (if provided) in the summary.
    4. Identify and prioritize the most valuable features based on their importance to the core use-case the Database is solving.
    5. Create a comprehensive executive summary.

    Steps:
    1. Review Table wise summary.
    2. Analyze Table wise summary:
      - Identify all tables. 
      - Take into consideration the foreign keys, primary keys, is-a, has-a, and many-to-many relationships.
      - Deeply understand the intended-use-case of each table.
      - Note data operations, design patterns, and architectural decisions
    3. Create summary:
      - Describe the specific problem the Database is solving, based on Table wise summary
      - Explain high-level interactions and dependencies
      - Outline data workflow
    4. Identify and prioritize main features:
      - Determine which feature(s) address the core problem of the Database, based on SQL implementation and Table wise summary
      - Rank features based on their importance and relevance to solving the main problem, as evidenced in the Database
      - The feature should be major components of the Database and not minor functions like Many-to-Many Relationships, or "Foreign Keys". 
        These are implementation concepts. Not core features.

    Focus Areas:
    - Precised feature prioritization and importance
    - High-level functionality of this Database
    - Clear, concise technical language with Database-specific Language
    - Objective description
    - Capture entire data workflow

    Guidelines:
    - Only use the Table wise summary provided
    - Use precise Database-relevant technical terms
    - Include user-defined features if provided and evidenced in the Table wise summary
    - Prioritize features based on their importance to the core problem, as shown in the Table wise summary

    Feature Identification and Prioritization:
    - Carefully analyze the Table wise summary to identify features actually present in the Table wise summary
    - Do not assume or infer features that are not explicitly mentioned in the Table wise summary
    - Identify the top feature that solves the majority of the problem based on Database and SQL evidence
    - Rank subsequent features in descending order of importance, ensuring they are present in the Table wise summary
    - Ensure the feature list reflects the Database's focus and structure
    - Only include features that have substantial implementation in the Database that is evident from Table wise summary

    Output Format - Adhering to this format is crucial
    ```json
    {
    "data": "generated_summary in string format adhering to the Expected Output Format for Generated Summary",
    "confidence_score": 90,
    "traceback": {
    "Feature 1 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 1 Title' is included, as the 'phrase' is an evidence that this feature is part of the Database.",
    "Feature 2 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 2 Title' is included, as the 'phrase' is an evidence that this feature is part of the Database.",
    ...
    }
    }
    ```

    Requirements:
    - Replace \n with \\n in JSON
    - Limit upto 5 main features (max 2 sub-features each) or 7500 tokens
    - If due to any reason such as Database being small, you are unable to provide 5 features, then provide as many high-level features as possible between the range of 1 to 5.
    - Don't assume features or include minor features due to inability to provide 5 features, lesser number of features is acceptable.
    - Use specified JSON format only
    - Start with "```json" and end with "```"
    - Ensure the top feature in the prioritized list addresses the core problem and is present in the Table wise summary
    - Rank features in descending order of importance to the main problem, based on actual Database and SQL implementation
    - Do NOT include features that are NOT evidenced in the provided Table wise summary
    - Evaluate the Table wise summary objectively, considering all conclusions on the actual Database and SQL provided
    - Do NOT make any assumptions about organizational goals or intentions beyond what is explicitly shown in the Database and SQL
    - Focus solely on the technical aspects and implemented functionality, avoiding speculation about business objectives or future plans
    - Both the keys data, confidence score, and traceback should be present in the output JSON
    - The generated summary should be in string format only and be contained inside the "data" key
    - The "traceback" key should contain a dictionary with feature names as keys and justifications for including these features based on exact phrases from the input
    - Do not include any feature that could potentially be part of the Table wise summary without explicit evidence
    - Every feature mentioned must be driven by clear evidence from the provided input.
    - Strictly use an assertive and objective tone in your response. 
    - Do not be unsure about anything.
    - Do not include the "Folder Name" in your response. Ignore "dbanalysis" folder. Provide Executive Summary of the Database-ONLY.
    """

    user_prompt = """
  Expected Output Format for Generated Summary:

  **Overview**
  <empty line>
  <A brief introduction to the Database and its main purpose; in paragraph format only, not in points.
  This paragraph should provide a concise yet comprehensive overview of the Database, its primary functionality, and its intended use case.
  Aim for 3-5 sentences that capture the essence of the Database.>
  <empty line>
  **Highlighted Features**
  <empty line>
  <
  List and briefly explain the key features that are significant components of the Database and would serve as selling points.
  These features should be presented as follows:
  1. Use numbered points for each feature.
  2. Provide a brief explanation for each feature in 1-2 sentences, highlighting its importance and benefit to the END USER.
  3. Focus on features that are central to the Database's functionality and most important to the END USER.
  4. Dont include generic features like  Many-to-Many Relationships, or "Foreign Keys", these are not features but Design Principles.
  5. Do not include sub-points under any feature.
  6. Prioritize User Defined Features (if provided) at the beginning of the list.
  7. If User Defined Features are given, list them first before including any features identified through your analysis.
  8. Aim to provide upto of 1 to 5 key features, after each feature add an empty line for formatting purposes.
  9. Ensure that the features listed represent the core functionality and unique selling points based on the Table wise summary.
  10. Use clear, concise language that emphasizes the value proposition of each feature.
  11. Also under each feature, mention which file/Table was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
  12. Do not add features into Highlighted Features if they dont have value for buisness stakeholder about the application. Also do not repeat adding similar feature in this section.

  Output Structure:
  1. ***<Feature 1 Title>***: <Description of the feature in one to two sentences.\n
  2. ***<Feature 2 Title>***: <Description of the feature in one to two sentences.>\n
  >
  <empty line>
  **Key Benefits**
  <empty line>
  <Summarize the key benefits of the Database in one to two sentences.
  This summary should encapsulate the overall value proposition of the Database and its potential impact on users or the organization.>
  <empty line>
  <Highlight the most significant key benefits the Database has to offer in bulleted points. The format should be:
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  Aim for 3-5 bullet points that capture the most compelling advantages of using this Database, after each point add an empty line for formatting purposes.
  Each benefit should be distinct and provide a clear value proposition.>

  <Final Output Format>
  Output Format - Adhering to this format is crucial, the output should be in parsable JSON format:
  ```json
  {{
    "data": "<generated_summary in string format adhering to the Expected Output Format for Generated Summary>",
    "confidence_score": 90,
    "traceback": {{
      "Feature 1 Title": "Since it mentions about <exact phrase from the Table wise summary>, the 'Feature 1 Title' is included, as the "phrase" is an evidence that this feature is part of the Table wise summary.",
      "Feature 2 Title": "Since it mentions about <exact phrase from the Table wise summary>, the 'Feature 2 Title' is included, as the "phrase" is an evidence that this feature is part of the Table wise summary.",
      ...
    }}
  }}
  ```
  </Final Output Format>
  Note: If the traceback includes phrases that are not present in the Table wise summary then you would be penalized 10000 points.
  The output should be having data, confidence score, and traceback keys, and the entire content inside "```json" and "```" should be parsable by json.
  The "data" key should contain the generated summary and it should be in string format only, allowing the parsing of the entire json.
  If there are any inverted commas inside the generated summary, then escape them with a backslash.
  Do not change or skip the headings of each section in the generated json. The generated summary must have "Overview", "Highlighted Features", "Key Benefits" as section titles. Follow the above provided guidelines.
    """

    user_prompt += f"""Use the below Table wise summary to generate the summary in the above format: {combined_summary}""" + "User Defined Features : " + str(user_mvf)

    return system_prompt, user_prompt


def architecture_diagram_generation(services_data, icons_metadata):
    user_prompt = f"""
    <Input>
    $services_data = {services_data}
    $icons_metadata
    </Input>

    <Role>
    You are an expert at understanding large projects based on their executive summary and the services being used in them. Create a JSON structure for a ReactFlow diagram based on the given service class JSON.
    </Role>

    <Output Structure>
    1. Create a JSON object with a "nodes" and "edges" array.
    2. Create nodes for each external and third-party service.
    3. "nodes": An array containing all node objects.
      - "id": A unique string identifier for the node.
      - "data":   
        - "label": The name of the node.
        - "description": Description of the service.
        - "associated_files": Associated file and used in files in the service node, defaulting to "No File Available" if not present.
        - "group": The logical group name (e.g., 'Backend', 'Frontend', 'Database',etc..).
        - "subgroup": The specific subgroup within the group (e.g., Frameworks, NoSQL Databases, State Management, etc.).
        - "service": The appropriate filename of the icon based on the $icons_metadata.
      - "position" : The x and y coordinates of the node.
      - "type" : "customNode" This should be fixed.
    4. "edges" : An array having id, source, target, label, and type should be customEdge always.
    4. Ensure all services and files from the input JSON are included.
    5. The output should be in the form of a dictionary containing a "nodes" and "edges" array.
    6. Present only the code inside delimiters "```reactflow [reactflow CODE]```" without any additional explanation.
    """

    system_prompt:str = """
    <Task>
      You are tasked with creating a JSON structure for a ReactFlow diagram based on the given executive summary and the service_class_json. The executive summary contains an overview of the entire project. This JSON includes information about external services and third-party services, along with their associated files. Your output should represent this information as a network of nodes and edges.
    </Task>
    
    <Icons Context>
      $icons_metadata = """ + str(icons_metadata) + """
    </Icons Context>

    <Instructions>
      You are a solution expert, specializing in problem and solution flows. You will be given the solution overview for a project, and your task is to create an interconnected single component of graph which is detailed, and intuitive and self explanatory for:

      Follow these guidelines:
      1. Create nodes for each unique service (both external and third-party).
      2. Do not create any group nodes.
      4. In the data key for each service node, include two additional fields called group and subgroup. The group field should contain the logical group name (e.g., Frontend, Backend, Databases, etc..), and the subgroup field should provide more specific categorization (e.g., Frameworks, NoSQL Databases, etc..). For example, for a service node representing React, the group would be Frontend and the subgroup would be Frameworks.
      5. For each node, check which icon will be the most suitable from the $icons_metadata in the <Icons Context>
      6. Ensure all information from the input is represented in the output.
      7. The position coordinates must be proper for all the nodes.
    </Instructions>

    <Rules>
      **Ensure all nodes in the generated graph are interconnected such that every node has at least one edge, forming a single connected component without any isolated or disjoint sections. (High Priority Requirement)**
      Important Rules to be followed:
      1. Give detailed technical architecture flow and the JSON object following the below output format.
      2. Make sure that the flow and order of new solution approach is explained well in the graph with appropriate edges. Use as many edges you want to describe the data and user flow properly.
      3. The whole user and data flow should be clear.
      4. Do not add unnecessary nodes and edges. Do not create duplicate nodes that perform same task.
      5. Make the Node descriptions detailed, breaking tasks into multiple sub-tasks if needed.
      6. Ensure your edges show the actual flow, and not just connections of what's related. The connections are meant to show the logical flow, and not the relatedness/similarity.
      7. The group name is meant to classify clusters of nodes within each graph. For instance, if we have multiple nodes in features, they would all have "feature" as group. In Architecture Flow, the "Group" should show the layer each node is in, for instance "Backend Layer", "Database Layer" etc.
      9. for a hierarchy of nodes A -> B -> C; ensure that there is not a connection between A -> C.
    </Rules>
    
    <output_format>
    The output should be in between the delimeters ```reactflow and ```. Only provide the json output. Don't give unnecesary explanation.
    ```reactflow
    {
      "nodes": [
        { 
          "id": "unique_node_identifier_string",
          "data" : {
            "label": "name_of_the_service",
            "description": "description of the service",
            "associated_files": ["file_path_1", "file_path_2", "file_path_3", etc.],  // (default: ["No File Available"] if not present)
            "group": "name_of_group",  // Add the logical group name (e.g., "Frontend", "Backend", etc..)
            "subgroup": "name_of_subgroup",  // Add a more specific subgroup name (e.g., "Frameworks", "NoSQL Databases", etc..)
            "service": "filename" //taken from the $icons_metadata,
          }
          "position":{ "x": "Xcoordinate", "y": "Ycoordinate" },
          "type" : "customNode" //this is hardcoded and will be constant
        }
      ],
      "edges": [
        {
          "id": "unique_egde_identifier_string",
          "source": "label A",
          "target": "label B",
          "label": "Showcase what comes from the source node, to the target node. Be concise and specific with labels, such as 'Ingested Data', 'Converted Text', 'User Query' etc. Use at max 5 words",
          "type" : "customEdge" //this is hardcoded and will be constant
        }
      ]
    }```
    </output_format>
    """
    return system_prompt, user_prompt
  

def erd_generation(services_data, icons_metadata):
  tables_metadata = []
  for entry in services_data:
      table_name = entry["table_name"]
      ddl = entry["ddl"]
      columns, primary_keys, foreign_keys = parse_ddl(ddl)
      tables_metadata.append({
          "table_name": table_name,
          "columns": columns,
          "primary_keys": primary_keys,
          "foreign_keys": foreign_keys
      })

  dot = generate_combined_graph(tables_metadata)

  system_prompt:str = """
    You are tasked with creating a JSON structure for a ReactFlow diagram based on the given database ER diagram and schema JSON. This JSON includes information about database columns and their relationships.Your output should represent this information as a network of nodes and edges.
    </Task>
    
    <Icons Context>
      $icons_metadata = """ + str(icons_metadata) + """
    </Icons Context>

    <Instructions>
      You are a solution expert, specializing in problem and solution flows. You will be given the database schema information of a database, and your task is to create an interconnected single component of graph which is detailed, and intuitive and self explanatory for:

      Follow these guidelines:
      1. Create nodes for each unique service (both external and third-party).
      2. Do not create any group nodes.
      4. In the data key for each service node, include two additional fields called group and subgroup. The group field should contain the logical group name (e.g.,Databases, etc..), and the subgroup field should provide more specific categorization (e.g., 'Transactional Tables', 'Reference Tables' etc..). For example, for a service node representing daily transactions, the group would be Database and the subgroup would be Transactional Tables.
      5. For each node, check which icon will be the most suitable from the $icons_metadata in the <Icons Context>
      6. Ensure all information from the input is represented in the output.
      7. The position coordinates must be proper for all the nodes.
    </Instructions>

    <Rules>
      Important Rules to be followed:
      1. Give detailed technical architecture flow and the JSON object following the below output format.
      2. Make sure that the flow and order of new solution approach is explained well in the graph with appropriate edges. Use as many edges you want to describe the data and user flow properly.
      3. The whole user and data flow should be clear.
      4. Do not add unnecessary nodes and edges. Do not create duplicate nodes that perform same task.
      5. Make the Node descriptions detailed, breaking tasks into multiple sub-tasks if needed.
      6. Ensure your edges show the actual flow, and not just connections of what's related. The connections are meant to show the logical flow, and not the relatedness/similarity.
      7. The group name is meant to classify clusters of nodes within each graph. For instance, if we have multiple nodes in features, they would all have "feature" as group. In Architecture Flow, the "Group" should show the layer each node is in, for instance "Database Layer" etc.
      9. for a hierarchy of nodes A -> B -> C; ensure that there is not a connection between A -> C.
    </Rules>
    
    <output_format>
    The output should be in between the delimeters ```reactflow and ```. Only provide the json output. Don't give unnecesary explanation.
    ```reactflow
    {
      "nodes": [
        { 
          "id": "unique_node_identifier_string",
          "data" : {
            "label": "name_of_the_table",
            "description": "description of the table",
  	    "columns": ["order_id [PK]", "product_sku [PK]", "quantity", "unit_price"]
            "group": "name_of_group",  // Add the logical group name (e.g., "Database", etc..)
            "subgroup": "name_of_subgroup",  // Add a more specific subgroup name (e.g., 'Transactional Tables', 'Reference Tables', etc..)
            "service": "filename" //taken from the $icons_metadata,
          }
          "position":{ "x": "Xcoordinate", "y": "Ycoordinate" },
          "type" : "customNode" //this is hardcoded and will be constant
        }
      ],
      "edges": [
        {
          "id": "unique_egde_identifier_string",
          "source": "label A",
          "target": "label B",
          "label": "Showcase what comes from the source node, to the target node. Be concise and specific with labels, such as 'Ingested Data', 'Converted Text', 'User Query' etc. Use at max 5 words",
          "type" : "customEdge" //this is hardcoded and will be constant
        }
      ]
    }```
    </output_format>
    """
    
  user_prompt:str = f"""
    <Input>
    $database_tables = {dot}
    $icons_metadata
    </Input>

    <Role>
    You are an expert at understanding database architecture based on ER diagrams and relational structures. Create a JSON structure for a ReactFlow diagram based on the given database schema.
    </Role>
    <Output Structure>
      1. Create a JSON object with a "nodes" and "edges" array.
      2. Create nodes for each table in the schema.
      3. "nodes": An array containing all node objects.
      - "id": A unique string identifier for the node.
      - "data":  
        - "label": The name of the table.
        - "description": A brief summary of the table's role or content.
        - "columns": List of column names (mark primary keys with [PK], foreign keys with [FK]).
        - "group": The logical group name (e.g., 'Database').
        - "subgroup": The specific subgroup within the group (e.g., 'Transactional Tables', 'Reference Tables').
        - "service": The appropriate filename of the icon based on the $icons_metadata.
      - "position" : The x and y coordinates of the node.
      - "type" : "customNode" This should be fixed.
      4. "edges" : An array having id, source, target, label, and type should be customEdge always.
      5. The label of the edge should describe the relationship, like "order_id â†’ order_id". 
      6. The output should be in the form of a dictionary containing a "nodes" and "edges" array.
      7. Present only the code inside delimiters "```reactflow [reactflow CODE]```" without any additional explanation.
    """
    
  return system_prompt, user_prompt
    

def feature_summary_generation(formatted_data, user_mvf, executive_summary):
    # if input_type is None:
    #     formatted_data = file_summary_list
    # elif input_type == "batch_summary":
    #     formatted_data = format_batchwise_summary_metadata_for_services(file_summary_list)
    # else:
    #     formatted_data = format_file_summaries(file_summary_list)

    user_prompt = """
    Role: You are an AI code analyst specializing in creating concise, feature-level summaries of codebases.

    Objective: Provide a comprehensive yet concise feature-level summary of a given codebase, highlighting key components, functionality, and the project's overall workflow.

    Input: You will receive information about a codebase, which may include an executive summary or other project details.

    Steps:
    1. Analyze the provided codebase information.
    2. Identify the main features (maximum 5) of the project from the executive summary (if provided in same order)
    3. Create a summary following the specified format, including:
        a. An overview of the project
        b. A list of key features with brief descriptions
        c. A closure statement
    4. Self-evaluate the generated summary and assign a confidence score.
    5. Format the output as specified in the instructions.

    Output Format:
    ```json
    {
        "data": "generated_summary in string format adhering to the Detailed Instructions for Output Format",
        "confidence_score": 90
    }
    ```

    Detailed Instructions for Output Format:

    **Overview**
    <empty line>
    < 
        Summarize all features in 2-3 sentences, introducing the project and its purpose.
        Provide a 2-3 sentence summary of key benefits, highlighting core architecture and value proposition.
    >
    <empty line>
    **Key Features**
    <empty line>
    <   
        List a maximum of 5 main features.
        For each feature, provide up to 2 sub-points describing its functionality.
        Ensure clear explanation of how features interact and contribute to the project's goals.
        1. ***<Key Feature Title>*** : 
        * <Sub point 1 description>
        * <Sub point 2 description>
        <empty line>
    >
    <empty line>
    < 
        Summarize the overall impact and value proposition of the project in one sentence as a conclusion statement.
    >
    <empty line>
    
    -> Self-Evaluation:
        - Score the summary out of 100 based on clarity, precision, detail, knowledge, accuracy, technical correctness, and understanding of the data.

    -> Formatting Requirements:
        - Replace all newline characters (\n) with \\n in the JSON output.
        - Ensure the complete JSON is less than 7500 tokens.
        - Start the output with "```json" and end with "```".
        - If an executive summary is provided, use only the highlighted features from it.

    Example Output Structure:
    ```json
    {
        "data": "**Overview**\\n\\n[Project overview]\\n\\n[Benefits summary]\\n\\n**Key Features**\\n\\n1. *Feature 1*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n2. *Feature 2*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n[...continue for up to 5 features...]\\n\\n[Closure statement]",
        "confidence_score": 90
    }
    ```

    Remember: Adhere strictly to the output format and instructions to maintain consistency and accuracy in your summary.
    """

    user_prompt += "User Defined Features : " + str(user_mvf)

    system_prompt = f"""
        <role>
        You are an assistant to a Senior Software Engineer. You are very capable in reading and understanding huge codebases.
        There is no edge-case, no mistake, no functionality no matter how small goes unnoticed by you.
        You will be given a large codebase and be asked queries regarding it.
        </role>

        <Task>
        You will be given relevant files from a production codebase. The Senior Engineer will consult you to clear his doubts and ask for critical code-level and functionality level analysis of the same.
        <Important>
        1. You will be clear. Feel free to be descriptive but Avoid Jargon
        2. You shall perform critical analysis on the code before responding.
        3. Note that the codebase will be quite complex and have dependencies everywhere, be mindful of them all.
        4. Enclose code in (triple backticks)``` code ```
        </Important>
        </Task>

        Files from Codebase goes here :
        <Repo Structure>
        {formatted_data}
        </Repo Structure>
    """

    start_index = executive_summary.find("Highlighted Features")
    end_index = executive_summary.find("Key Benefits")

    if start_index != -1 and end_index != -1:
        executive_summary = executive_summary[start_index:end_index].strip()

    user_prompt += "Executive Summary : " + str(executive_summary)

    return system_prompt, user_prompt

def feature_summary_generation_db(formatted_data, user_mvf, executive_summary):
    # if input_type is None:
    #     formatted_data = file_summary_list
    # elif input_type == "batch_summary":
    #     formatted_data = format_batchwise_summary_metadata_for_services(file_summary_list)
    # else:
    #     formatted_data = format_file_summaries(file_summary_list)

    user_prompt = """
    Role: You are an AI Database Analyst specializing in creating concise, feature-level summaries of complex database schemas and architectures.

    Objective: Provide a comprehensive yet concise feature-level summary of a given database schema information, highlighting key components, entities, relationships, and the overall data architecture workflow.

    Input: You will receive information about a database design, which may include an executive summary or other schema-level details.

    Steps:
    1. Analyze the provided database schema information.
    2. Identify the main features (maximum 5) of the database from the executive summary (if provided in same order)
    3. Create a summary following the specified format, including:
        a. An overview of the database
        b. A list of key features with brief descriptions
        c. A closure statement
    4. Self-evaluate the generated summary and assign a confidence score.
    5. Format the output as specified in the instructions.

    Output Format:
    ```json
    {
        "data": "generated_summary in string format adhering to the Detailed Instructions for Output Format",
        "confidence_score": 90
    }
    ```

    Detailed Instructions for Output Format:

    **Overview**
    <empty line>
    < 
        Summarize all features in 2-3 sentences, introducing the database and its purpose.
        Provide a 2-3 sentence summary of key benefits, highlighting schema structure, normalization or denormalization logic, and value proposition in handling data.
    >
    <empty line>
    **Key Features**
    <empty line>
    <   
        List a maximum of 5 main features.
        For each feature, provide up to 2 sub-points describing its data handling, relationships, or optimization logic.
        Ensure clear explanation of how features contribute to performance, consistency, and data integrity.
        1. ***<Key Feature Title>*** : 
        * <Sub point 1 description>
        * <Sub point 2 description>
        <empty line>
    >
    <empty line>
    < 
        Summarize the overall impact and value proposition of the database in one sentence as a conclusion statement.
    >
    <empty line>
    
    -> Self-Evaluation:
        - Score the summary out of 100 based on clarity, precision, detail, knowledge, accuracy, technical correctness, and understanding of the schema information.

    -> Formatting Requirements:
        - Replace all newline characters (\n) with \\n in the JSON output.
        - Ensure the complete JSON is less than 7500 tokens.
        - Start the output with "```json" and end with "```".
        - If an executive summary is provided, use only the highlighted features from it.

    Example Output Structure:
    ```json
    {
        "data": "**Overview**\\n\\n[Database overview]\\n\\n[Benefits summary]\\n\\n**Key Features**\\n\\n1. *Feature 1*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n2. *Feature 2*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n[...continue for up to 5 features...]\\n\\n[Closure statement]",
        "confidence_score": 90
    }
    ```

    Remember: Adhere strictly to the output format and instructions to maintain consistency and accuracy in your summary.
    """

    user_prompt += "User Defined Features : " + str(user_mvf)

    system_prompt = f"""
        <role>
        You are an assistant to a Senior Data Architect. You are very capable in reading, analyzing, and understanding complex database schemas and data models.
        No entity, constraint, relationship, or optimization logic goes unnoticed by you.
        You will be given a comprehensive database structure or schema information and will be asked to analyze, explain, and summarize it at a structural and functional level.
        </role>

        <Task>
        You will be given relevant database schema files or DDL definitions. The Senior Data Architect will consult you to clear doubts and ask for critical schema-level and data model-level analysis.
        <Important>
        1. You will be clear. Feel free to be descriptive but Avoid Jargon
        2. Perform a critical and deep analysis of the schema and the information given before responding.
        3. The schema will often involve multiple tables, foreign keys, views, procedures, and indexing strategies â€” be mindful of their dependencies and relationships.
        4. Enclose code or schema in (triple backticks)``` code ```
        </Important>
        </Task>

        Files from Database schema goes here :
        <Database Structure>
        {formatted_data}
        </Database Structure>
    """

    start_index = executive_summary.find("Highlighted Features")
    end_index = executive_summary.find("Key Benefits")

    if start_index != -1 and end_index != -1:
        executive_summary = executive_summary[start_index:end_index].strip()

    user_prompt += "Executive Summary : " + str(executive_summary)

    return system_prompt, user_prompt


#FEATURE HIERARCHY:
generate_features_system_prompt = """
  <Role>
    You are a Software Architect with expertise in analyzing large summaries from code files of an application. 
    You can comprehend summaries from code files that are complex, production-grade and are written in various programming languages to generate most important features, their description and the subfeatures with their description belonging to the most important features along with the other relevant information requested below.
    
    You will follow 2 Events before responding : 
    1. Generation of Feature Hierarchy as given in "Output_Format".
    2. Critical Evaluation of Every Confidence Score.  
  </Role> 

    <Task 1>
    You are provided with multiple relative file paths and file-wise code summaries from a application codebase.
    1. Analyze the file summaries carefully, leveraging your expertise to deduce the frameworks, functionality, and features.
    2. Perform a critical assessment of the code's functionality and interdependencies before responding.
    3. The codebase is complex and likely contains dependencies across various modules. Be mindful of these.
    4. Analyse every file summary and assign the features and sub-features based on the information provided.
    5. Respond strictly in the structured JSON format provided below.
    6. In each sub-feature's 'file_path' array:
        - Set 'critical: true' ONLY for files that are CORE & NON-REPLACEABLE to the sub-feature's main functionality.
        - Set 'critical: false' for ALL supporting, secondary, or replaceable files  
        - Each sub-feature should have both true and false entries.
        - If unsure, default to false (be EXTREMELY selective with 'true')
        - Make sure each sub-feature atleast have one file as true.

    Explanation of the Output terms:
    Feature - Features are most valuable and high level features extracted from the list of summaries that are provided to you. 
    Feature description - Description of the features explaining the high level value and impact that it creates for the project. Define the Feature. The description should be crisp, precise, well formatted and must be between 2-3 lines.
    Subfeature - Subfeatures are micro most valuable features that are extracted from the list of summaries and belong to the Most related and similar Features.
    Subfeature description - Description of the subfeatures explaining the specific value, technical and non-technical functionalites that it provided to the project. Define the subfeature and also explain how its related to the feature. The description should be crisp, precise, well formatted and must be between 2-3 lines.
    
    Points to Remember:
    1. Do not extract any feature or subfeature where there are no reference/citations from the application summaries.
    2. The description must be precise, valuable, well-formatted and must be between 2-3 lines.
    3. The Feature titles should be precise, specific, self explanaible, independent and not have similar feature titles. The Feature titles should not be highly generalized.
    4. The SubFeatures titles should be precise, self explanaible and not have similar subfeature titles. The SubFeature titles should not be highly generalized.
    5. SubFeatures should not be very low level that it explains code functions, code process like 'Json handling', 'Reading csv', readME etc.
    6. If similar subfeatures are present, then group them under one common Feature itself. Do not create multuple Features for similar subfeatures.
    6. If Unit testing related summaries are found, then create that as another Feature named 'Unit Testing' and assign the specific testing subfeatures under this feature.
    </Task 1>

  <Task 2>
  You shall now Assign and Justify Confidence Scores for each feature.

  <Critical Evaluation of Confidence Scores> 

  <Evaluation MODE>
  - You will now Forget everything that was done beforehand and act as an unbiased judge.
  - $Project-Summaries-&-Paths (INPUT).
  </Evaluation MODE>
  <Important>
  Critically analyze every "Feature" and "SubFeature" based on the following metrics. 
  You shall generate a confidence score between 0-100 for each of the following :
  1. Is the "Feature" & "SubFeature" name accurate to its functionality ? (Accuracy)
  2. Does the "Feature" & "SubFeature" include files with an unrelated function ? (Feature Dilution Rate)
  3. Important : Does this "Feature" & "SubFeature" make sense given the Overall Purpose of the Application ? (Consistency)
  4. Are all the files in "Feature" & "SubFeature" included ? (Completeness)

  <Strict>
  1. You will now generate a list of 4 confidence scores between 0-100 for above criteria under "confidence_score" key.
  2. Based on above criteria, you shall provide a VERY BRIEF logical explanation (10-20 words) for Confidence Score under "confidence_score_justification" key.
  3. Make sure to mention the entire filepath without omitting the prefix.
  4. Make sure all the filepaths are present.
  <Important> STRICTLY Don't Comment on Missing Files. Don't Overestimate. Don't Underestimate.</Important> 
  </Strict>

  </Important>

  </Critical Evaluation of Confidence Scores> 
  </Step 2>


      <Output_Format>
    Return a response in JSON format. Do not include any extra information or explanations. Strictly DON'T deviate from mentioned KEYS.
    Example:
```json
[
  {
    "name": "User Authentication and Management",
    "feature_description": "Comprehensive user account system with secure login, registration, profile management, and role-based access control.",
    "feature_description_confidence_score": [95, 70, 100, 70],
    "sub_features": [
      {
        "name": "User Registration",
        "description": "Allows new users to create accounts by providing necessary information such as username, email, and password. Implements email verification, password strength checks, and duplicate account prevention. Stores user data securely in the database with password hashing.",
        "file_path": [
          {
            "module_name": "RegistrationController",
            "path": "Controllers/Account/RegistrationController.cs",
            "critical": true
          },
          {
            "module_name": "RegisterView",
            "path": "Views/Account/Register.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [75, 80, 85, 65],
        "sub_feature_confidence_score_justification": "No feature dilution, might have missed some file."
      },
      {
        "name": "User Login",
        "description": "Authenticates users using their credentials, creates and manages user sessions, and implements security measures such as login attempt limiting and two-factor authentication (2FA). Provides password reset functionality for forgotten passwords.",
        "file_path": [
          {
            "module_name": "LoginController",
            "path": "Controllers/Account/LoginController.cs",
            "critical": true
          },
          {
            "module_name": "LoginView",
            "path": "Views/Account/Login.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [80, 100, 80, 75],
        "sub_feature_confidence_score_justification": "High chance of missing files."
      }
    ],
    "feature_confidence_score_justification": "No feature dilution, duplication or missing files. Accurate Naming."
  },
  {
    "name": "Product Catalog Management",
    "feature_description": "Comprehensive system for managing product listings, categories, and inventory across the e-commerce platform.",
    "feature_description_confidence_score": [95, 65, 70, 80],
    "sub_features": [
      {
        "name": "Product CRUD Operations",
        "description": "Enables administrators to create, read, update, and delete product listings. Includes functionality for managing product details such as name, description, price, images, and inventory levels. Implements validation to ensure data integrity and consistency across the product catalog.",
        "file_path": [
          {
            "module_name": "ProductController",
            "path": "Controllers/ProductController.cs",
            "critical": true
          },
          {
            "module_name": "ProductView",
            "path": "Views/Product/Index.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [90, 85, 100, 70],
        "sub_feature_confidence_score_justification": "High confidence with no duplication or dilution."
      },
      {
        "name": "Category Management",
        "description": "Allows for the creation and management of product categories and subcategories. Implements a hierarchical structure for organizing products, enabling efficient navigation and filtering of the product catalog for both administrators and customers.",
        "file_path": [
          {
            "module_name": "CategoryController",
            "path": "Controllers/CategoryController.cs",
            "critical": true
          },
          {
            "module_name": "CategoryView",
            "path": "Views/Category/Index.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [85, 75, 90, 95],
        "sub_feature_confidence_score_justification": "High confidence without any duplication or dilution."
      }
    ],
    "feature_confidence_score_justification": "All files refer to single overall functionality. Might have missed some files."
  }
]
```
  </Output_Format>

"""

generate_features_user_message = """
<Strictly Remember>
1. As input you will be given a batch of `file_path` and `file_summary` from a production codebase. Keep it in mind that it could be a file from a very large repository with lot of inter-dependencies.
2. Understand all the file description first, then try to determine the feature, sub-features and their description. For **each file** it should have a feature or sub-features whenever the conditions are met.
3. The response should contain all the fields given in the example output format. The response should be strictly in json format.
4. The description of features/subfeatures must be in the length of 2-3 lines. The response should be structured and well-formatted.
5. Don't generate any additional explanation or description. Provide the structured response in json only.
</Strictly Remember>
  
<Input file wise summary>
{file_summary}
</Input file wise summary>
<Response>
"""

merge_features_in_hierarchy_user_prompt = """You are a software feature analyzer. Given a list of related features that have been clustered together, create a merged feature that encompasses all the functionality.

Features to merge:
{feature_list}

Generate a JSON response that includes:
1. A name for the merged feature representing accurate feature name. Do not mention its merged or unified or anything as such. The feature name should accurately represent a major funcationality of a repository.
2. A detailed description that covers all functionality
3. A confidence score (0-100) for the merge
4. A justification for the confidence score

Respond with a JSON object in the following format:
```json
{{
    "name": "Merged feature name",
    "description": "Comprehensive description",
    "confidence_score": 85,
    "confidence_justification": "Reason for the confidence score"
}}
```
Give only JSON and nothing else. Do not include any explanations or additional text outside the JSON block. Make sure to start with ```json and end with ``` only.
"""

mapping_names_for_merged_features_user_prompt = """  <Role>
    You are a smart AI cassistant with strong expertise in Software Engineering. You can understand complex, production-grade codebases written in various programming languages and summarize them effectively.
  </Role>
  <Task>
  You will be given a brief description of  features of a large codebase and your task is to generate a relevant feature name, brief description, and priority level.
  <Important>
   1. The feature name should be brief, relevant and should represent the entire description provided.
   2. Generate a relevant description which is basically a overall summary of the description provided.
   3. Assign a priority level (high, medium, low) based on the significance, importance and complexity of the feature to the overall system. 
  </important>
  </Task>
  <Example output>
  ```json
    {
        "name": <feature_name>, //string
        "feature_description": <feature_description>, //string
        "priority": <priority> //string (high, medium, or low)
    }
    ```
  </Example output>
  <Strictly Remember>
1. The feature name should be relevant and at the same time interpretable, easy to understand.
2. The feature description should represnt the entire description given for summarisation, it should be simple and easy to understant.
3. The priority should be one of: high, medium, or low.
4. The response should be strictly in json format specified above.
5. Strictly make sure Feature Description is not more than 200 words.
  </Strictly Remember>

<code summary>
The code summary is given below:
"""


reducing_sub_features_user_prompt = """
    You are a software feature consolidation expert. Your task is to merge similar sub-features into one comprehensive sub-feature.

    Here are the sub-features that need to be merged:
    {sub_features_list}

    For each sub-feature, we have:
    - Name: The sub-feature name
    - Description: The sub-feature description (if available)
    - Confidence Score: The confidence score (if available)

    Your output should be a JSON object containing:
    1. A unified sub-feature name that encompasses all the input sub-features
    2. A comprehensive description that covers all aspects of the input sub-features
    3. A confidence score (use the highest available from input sub-features)
    4. A justification for the confidence score

    Return the output in JSON format starting with ```json and ending with ```.

    Example output format:
    ```json
    {{
        "name": "Unified Sub-Feature Name",
        "description": "Comprehensive description covering all aspects",
        "sub_feature_confidence_score": 95,
        "sub_feature_confidence_score_justification": "Merged from similar sub-features with high semantic similarity"
    }}
    ```
    """


post_processing_feature_name_description_system_prompt="""
  <Role>
    You are a smart AI assistant with strong expertise in Software Engineering. You can understand complex, production-grade codebases written in various programming languages and summarize them effectively.
  </Role>
  <Task>
  You will be given a brief description of modules or features of a large codebase and your task is to generate a relevant feature name and brief description.
  <Important>
   1. The feature name should be brief, relevant and should represent the entire description provided.
   2. Generate a relevant description which is basically a overall summary of the description provided.
   3. Also generate a confidence score in a scale of 0 - 100.
  </important>
  </Task>
  <Example output>
  ```json
    {
        "name": <feature_name>,
        "feature_description_confidence_score": <score 0 - 100>,
        "feature_description": <feature_description>
    }```
  </Example output>"""

post_processing_feature_name_description_user_prompt = """<Strictly Remember>
1. The feature name should be relevant and at the same time interpretable, easy to understant.
2. The confidence score should represent the ability to summarise the description.
3. The feature description should represnt the entire description given for summarisation, it should be simple and easy to understant.
4. The response should be strictly in json format specified above.
</Strictly Remember>
<code summary>
The code summary is given below: \n
{feature_description}
</code_summary>
<response>
Your response in json goes here:
"""

merge_similar_features_system_prompt = """You are a solution architect. Your task is to carefully review each feature and its description, and combine them into a single high-level feature.

The final high-level features should represent what an end user would perceive, e.g., Messenger, Google Chat, Messaging, Reels, etc.

Based on the generated features provided, identify which features can be merged into a single high-level feature. 
Strictly output them in the following format:
{{ 
  <High-Level Feature Name 1>: [<Merged Feature 1>, <Merged Feature 2>, <Merged Feature 3>, ...],
  <High-Level Feature Name 2>: [<Merged Feature 1>, <Merged Feature 2>, <Merged Feature 3>, ...],
  ...
}}

INPUT:
Feature names and descriptions are provided in the format: 
[1. Feature name: <feature name> 
Feature description: <feature description>, 
2. ...]

{feature_texts}

MVFS:
{total_MVFs}

Points to remember:
1. While merging features and naming high-level features, always prefer names from the user-defined MVFs provided. All relevant features can be grouped under these high-level features.
2. If certain features do not fit under the user-defined MVFs, choose a better name than the existing one for the new high-level feature if necessary.
3. The names of the features being merged must remain exactly as provided in the INPUT section; do not modify them. Do not consider Feature description in Feature Names.
4. Follow the output structure strictly: high-level feature names as dictionary keys and merged features as values in list format.
5. If a feature is already a high-level feature, you do not need to forcibly merge it. If a feature seems to be function-level/low-level  features, merge them into a High-level feature.
6. Merge similar features into a single high-level feature based on their names and descriptions, when applicable. Each final high-level feature should be independent of the others.
7. Do not assign the same feature to multiple high-level features.
8. If user-defined MVFs are empty, skip point 1 and begin with point 2.
9. Do **not** include any Feature descriptions in the final output."""


merging_description_user_prompt = """You are a Solution Architect. Your task is to summarize the multiple feature descriptions provided into a brief, coherent summary of **no more than two sentences**.

  The summary must:
  - Accurately capture all key components from the provided descriptions.
  - Align clearly with the given high-level feature name.
  - Serve as the final description of the high-level feature.

  Only the final summarized description should be included in the output â€” no additional commentary or formatting.

  INPUT:
  Multiple descriptions: {merging_feature_description}

  High-Level Feature Name: {high_level_feature}
  """


micro_sub_feature_prompt = """You are an expert system analyst specializing in decomposing SubFeatures into granular, logically independent components. You support **two levels** of splitting:

1. **Horizontal splitting**: Split a subfeature into multiple *same-level subfeatures* when it encompasses multiple independently meaningful functionalities. The subfeatures created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.
2. **Vertical splitting**: Further break each of those subfeatures into *microsubfeatures* (if applicable), ensuring each micro-sub-features/micro-user-story describes a single goal or operation. The micro-sub-features/micro-user-story created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.

---

### ðŸ”§ TASK OVERVIEW

Given a Macro-Feature, Subfeature, its description, associated module files and its summary:

- Decide if the subfeature should be split horizontally into multiple same-level subfeatures.
- For each resulting subfeature (or original if not split), analyze whether it can be split vertically into **microsubfeatures** (fine-grained user stories).
- Provide the confidence scores for the subfeature that is split, whether horizontally or vertically.
- Provide the files that are related to the sub_features too, not just the micro_sub_features.
- Each leaf user-story must have files assigned to them, else you should not create/split these subfeatures.
- Provide description of generated subfeature/sub-user-stories in 2-4 lines but only valid information. Do not assume or hallucinate to generate description.
Apply this recursively: if horizontal splitting occurs, then attempt vertical splitting for each. But remember, not to create any duplicates in the process. 

---

### SPLITTING DECISIONS

#### Horizontal Splitting (Same-level Subfeatures):
Split if:
- The subfeature covers multiple high-level functionalities
- Each function could be planned, developed, and deployed independently
- Each component has a clear boundary and responsibility

#### Vertical Splitting (Microsubfeatures):
Split further if:
- A subfeature contains multiple independent operations or logical stages
- These operations can be implemented, tested, or tracked separately
- Each micro-subfeature represents one atomic, non-overlapping functionality

---

### DO NOT SPLIT IF:
- sub-user-stories are tightly coupled in the Subfeature and cannot function independently.
- Do not split subfeatures into sub-user-stories that are hardly single line of code and cannot be considered as a proper functionality, but just a config/parameter.
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across actions are too complex to isolate.
- There are no files that can be mapped to the generated user-story.
- Do not split if the user-story is barely a functionality. The split user-stories must have independent functionality that contributes to the subfeature and feature and if not, do not split.
- Don not split ReadMe & .md files into sub-user-stories.
- Do not split horizontall for granullar subfeatures as they are not user stories but mid level features.
---

### FILE MAPPING RULES:
- For each subfeature or microsubfeature, cite only directly relevant files.
- Use only the provided input data to match files â€” no guessing.
- Avoid duplication unless a file is clearly shared between components.

Each `file_path` entry must include:
```json
{
  "module_name": "<Name>",
  "path": "<Path>",
  "critical": <true/false>,
  "git_url": "<Git URL>"
}

OUTPUT FORMAT
If the subfeature should NOT be split:
Return: "None"

If the subfeature should be split, return a list of Parent User Stories with subfeatures inside.
If a subfeature itself can be further split into microsubfeatures, nest them under micro_sub_features like so:

[
  {
    "name": "Parent User Story Title 1",
    "description": "Full description of the original or updated user story and its purpose.",
    "file_path": [...],
    "sub_feature_confidence_score":"confidence score of the subfeature with respect to the Feature, as a percentage (e.g., 80)"
    "micro_sub_features": [
      {
        "name": "Sub-User Story Title 1",
        "description": "Standalone description of a single functionality.",
        "file_path": [...],
        "micro_sub_feature_confidence_score":"confidence score of the micro_sub_feature with respect to the sub_feature, as a percentage (e.g., 90)"
        }
          ...
        ]
      },
      ...
    ]
  }
]
Each layer must preserve independence, clarity, and singular focus of each story.

VALIDATION CHECKLIST
- Each title must express one functionality only (no imperative phrasing)
- description must avoid assumptions and describe the real function. It must be as detailled as possible.
- Each story must make sense independently and fit in the broader feature flow
- if there are multiple user-story under the subfeature, it needs to be in sequence of business logic.
- File mappings must be relevant and scoped accurately
- Do no miss/skip any values in the output json. The output structure must be maintained strictly.
- All subfeature and sub-user-story names and descriptions must be strictly in a declarative tone, not imperative.

* Use generic or speculative statements
"""


db_micro_sub_feature_prompt = """
<Role>
You are an expert Database analyst specializing in decomposing SubFeatures into granular, logically independent components. You support **two levels** of splitting:
You shall ALWAYS process features from a Database perspective ONLY. 
There can be more than one Table in the DB context provided to you.
</Role>

1. **Horizontal splitting**: Split a subfeature into multiple *same-level subfeatures* when it encompasses multiple independently meaningful functionalities. The subfeatures created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.
2. **Vertical splitting**: Further break each of those subfeatures into *microsubfeatures* (if applicable), ensuring each micro-sub-features/micro-user-story describes a single goal or operation. The micro-sub-features/micro-user-story created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.

<Strict Constraints> 
- You are dealing with Database Information. 
- No matter what, STRICTLY use Database-Specific Language ALWAYS. 
- Use words like Columns / Fields / Schema / DataTypes / Constraints / Foreign Keys / Primary Keys etc.
- Strictly Do not start descriptions with or start with "this micro-feature" / or "this sub-feature".
- You shall do this regardless of the input context and nature.
Remember : Every "FILE" given to you is information of a table. Therefore in your response, ALWAYS refer to "Table" instead of "File".

</Strict Constraints> 


### ðŸ”§ TASK OVERVIEW

Given a Macro-Feature, Subfeature, its description, associated module files and its summary:

- Decide if the subfeature should be split horizontally into multiple same-level subfeatures.
- For each resulting subfeature (or original if not split), analyze whether it can be split vertically into **microsubfeatures** (fine-grained user stories).
- Provide the confidence scores for the subfeature that is split, whether horizontally or vertically.
- Provide the files that are related to the sub_features too, not just the micro_sub_features.
- Each leaf user-story must have files assigned to them, else you should not create/split these subfeatures.
- Provide description of generated subfeature/sub-user-stories in 2-4 lines but only valid information. Do not assume or hallucinate to generate description.
Apply this recursively: if horizontal splitting occurs, then attempt vertical splitting for each. But remember, not to create any duplicates in the process. 

---

### SPLITTING DECISIONS

#### Horizontal Splitting (Same-level Subfeatures):
Split if:
- The subfeature covers ONE / MORE THAN ONE high-level functionalities
- Each function could be planned and developed independently
- Each component has some clear boundaries and responsibilities

#### Vertical Splitting (Microsubfeatures):
Split further if:
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across actions are too complex to isolate.
- There are no tables that can be mapped to the generated user-story.
- The subfeature is too complex to be planned, developed, and deployed independently
- Each micro-subfeature represents one atomic, non-overlapping functionality
Note: Maintain at least 2 subfeatures unless the database has only one table.
- Prioritize brevity, consistency and no informaiton leakage across subfeatures.
- Ensure crisp segregation.
---

### DO NOT SPLIT IF:
- sub-user-stories are tightly coupled in the Subfeature and cannot function independently.
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across tables in two features are too complex to isolate.
- There are no tables that can be mapped to the generated user-story.
Note: Maintain at least 2 subfeatures and 1 or more microsubfeatures per subfeature, Unless the database has only one table.
Note : Maintain brevity during splitting at the same level. Do NOT overload the a single feature with too many subfeatures.
---


### FILE MAPPING RULES:
- For each subfeature or microsubfeature, cite only directly relevant tables.
- Use only the provided input data to match files â€” no guessing.
- Avoid duplication unless a file is clearly shared between components.

Each `file_path` entry must include:
```json
{
  "module_name": "<Name>",
  "path": "<Path>",
  "critical": <true/false>,
  "git_url": "<Git URL>"
}

OUTPUT FORMAT
If the subfeature should NOT be split:
Return: "None"

If the subfeature should be split, return a list of Parent User Stories with subfeatures inside.
If a subfeature itself can be further split into microsubfeatures, nest them under micro_sub_features like so:

[
  {
    "name": "Parent User Story Title 1",
    "description": "Full description of the original or updated user story and its purpose.",
    "file_path": [...],
    "sub_feature_confidence_score":"confidence score of the subfeature with respect to the Feature, as a percentage (e.g., 80)"
    "micro_sub_features": [
      {
        "name": "Sub-User Story Title 1",
        "description": "Standalone description of a single functionality.",
        "file_path": [...],
        "micro_sub_feature_confidence_score":"confidence score of the micro_sub_feature with respect to the sub_feature, as a percentage (e.g., 90)"
        }
          ...
        ]
      },
      ...
    ]
  }
]
Each layer must preserve independence, clarity, and singular focus of each story.

VALIDATION CHECKLIST
- Each title must express one functionality only (no imperative phrasing)
- description must avoid assumptions and describe the real function. It must be as detailled as possible.
- Each story must make sense independently and fit in the broader feature flow
- if there are multiple user-story under the subfeature, it needs to be in sequence of business logic.
- File mappings must be relevant and scoped accurately
- Do no miss/skip any values in the output json. The output structure must be maintained strictly.
- All subfeature and sub-user-story names and descriptions must be strictly in a declarative tone, not imperative.
- Use Database-specific schema only. Do not include words like "Attributes" / "Code Files" in your response. 
- Strictly Do not start descriptions with or start with "this micro-feature" / or "this sub-feature".
* Use generic or speculative statements

"""import os
from graphviz import Digraph
import re 
import json

def parse_ddl(ddl: str):
    """
    Parse the DDL to extract columns, primary keys, and foreign keys.
    """
    lines = ddl.splitlines()
    column_lines = []

    for line in lines:
        line = line.strip()
        if (
            line.upper().startswith("CREATE")
            or line.upper().startswith("PRIMARY")
            or line.upper().startswith("FOREIGN")
            or line.upper().startswith(")")
            or line == ""
        ):
            continue

        match = re.match(r'(\w+)\s+\w+', line)
        if match:
            column_lines.append(match.group(1))

    pk_match = re.search(r'PRIMARY KEY\s*\((.*?)\)', ddl)
    primary_keys = [key.strip() for key in pk_match.group(1).split(",")] if pk_match else []

    foreign_keys = []
    for match in re.finditer(r'FOREIGN KEY\s*\(([^)]+)\)\s+REFERENCES\s+`?[\w]+\.(\w+)`\(([^)]+)\)', ddl):
        fk_col = match.group(1).strip()
        ref_table = match.group(2).strip()
        ref_col = match.group(3).strip()
        foreign_keys.append((fk_col, ref_table, ref_col))

    return column_lines, primary_keys, foreign_keys


def generate_combined_graph(tables_data):
    """
    Generate a single combined graph from multiple tables.
    """
    dot = Digraph(comment='Combined Table Diagram')
    dot.attr(rankdir='LR')

    # Store individual table nodes
    for table in tables_data:
        table_name = table['table_name']
        columns = table['columns']
        primary_keys = table['primary_keys']
        
        label_lines = []
        for col in columns:
            if col in primary_keys:
                label_lines.append(f"{col} [PK]")
            else:
                label_lines.append(col)
        dot.node(table_name, shape='box', label=f'{table_name}\\n' + "\\n".join(label_lines))

    # Add relationships
    for table in tables_data:
        table_name = table['table_name']
        for fk_col, ref_table, ref_col in table['foreign_keys']:
            dot.edge(table_name, ref_table, label=f'{fk_col} â†’ {ref_col}')

    return dot

def folder_summary_generation_prompts(
        total_allocated_tokens, 
        file_list, folder_name, 
        folder_path,
        subfolder_list,
        formatted_file_summaries,
        formatted_file_services,
        formatted_subfolder_summaries,
        formatted_subfolder_services,
        formatted_subfolder_features
    ):
    
    system_prompt = f"""
        You are an expert code analyst specialized in creating detailed, informative summaries of software project folders. Your task is to thoroughly analyze files and subfolders to provide a comprehensive understanding of the application or project and provide combined summaries along with required details. These summaries must be detailled enough for further summarization.

        Follow these guidelines:
        1. Conduct a deep analysis of the features to identify its core purpose and functionality
        2. Provide detailed explanation of key implementations and technical approaches of the features
        3. Thoroughly examine the summaries based on files and folders to understand relationship between features and combined smaller features into larger high level application level features.
        4. Explain the features within the broader project architecture with specific connections
        5. Describe technical patterns, design decisions, and architectural choices evident in the code
        6. Include specific functions, classes, and methods that define the feature's behavior
        7. Note dependencies, imports, and external connections that shape the folder's functionality
        8. Identify potential architectural strengths and areas for improvement when evident
        9. Identify all services represented in this folder based on file and subfolder services information
        10. Identify and articulate high-level features or functionalities represented by the folder into the feature_details section, when consolidating multiple subfolders or lower-level files. Derive these insights from both file-level and subfolder-level summaries. Also under each feature, mention which file/folder was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
        11. Do not miss any features that could be formed based on these summaries as this information is required to understand the application's buisness logic.
        12. Gather insights from the summaries provided to generate a high level detailled executive summary that could be used by business stakeholders to understand the folder/project.
        13. When analyzing the root folder, both the executive summary and the features must be strictly formed in a high level business logic standpoint of an application.
        
        IMPORTANT: 
        - Your summary should be thorough and detailed({total_allocated_tokens}) while maintaining technical/business precision and depth. Focus on providing insights that would help both stakeholders and developers understand the application better.
        - feature_details must contain high level feature name and feature description(value of the files/folders) strictly in concise bullet points. The feature inforamtion must be in detail to capture the complete high level knowledge for that feature but not the function level details. Feature names cannot be programmatic function names like Dependency management, json handling etc. instead it should be inventory management, order processing etc. 
        - Your services list should be comprehensive and include all services represented in this folder.
        - is_reuasble_lib if a folder is used as reusable lib make it True otherwise False
        - lib_name if is_reusable_lib is True then provide the name of the reusable lib/component If is_reusable_lib False then add Not Applicable
        - category if is_reusable_lib is True then provide category only between 'Frontend' and 'Backend' If is_reusable_lib False then add Not Applicable
        - sub_category if is_reusable_lib is True then provide sub category only between 'UI Component','Custom Hooks', 'http_client', 'Utils', 'Others' In Frontend & 'Middleware', 'Error Handling', 'Auth', 'Utils', 'Others' In Backend If is_reusable_lib False then add Not Applicable
        - when_to_use if is_reusable_lib is True then provide where this reusable lib/component can be used If is_reusable_lib False then add Not Applicable 
        - associated_files if is_reusable_lib is True then provide the list of files associated(give complete path for the assosciated file) with this reusable lib/component If is_reusable_lib False then add Not Applicable
        - summary must not be technical and only explain the high level details of the folder/project. Understand the file and folder summaries provided to combine the knowledge to form the executive summary. Make it as detailled as possible.
        - Use clear and concise language, avoiding jargon where possible.
        
        - You must provide your response in this exact format:
        ```summary
        [Your detailled high-level executive summary for the folder for business stakeholders]
        ```
        ```feature_details
        [List of high-level features or functionalities represented in this folder]
        ```
        ```services_namess
        [Comma-separated list of all services represented in this folder]
        ```
        ```is_reuasble_lib
        Boolean Value
        ```
        ```lib_name
        [Name of the reusable library if applicable]
        ```
        ```category
        [Category of the reusable library if applicable]
        ```
        ```sub_category
            [Sub category of the reusable library if applicable]
        ```
        ```when_to_use
        [Your detailed use case where or when this reuasble_lib can be usefull]
        ```
        ```associated_files
            [Comma-separated list of associated files with the reusable library, Give the Complete file path as mentioned in the file list]
        ```
        ```example_usage
            [Example code snippet of how to use this reusable library]
        ```
    """

    user_prompt = f"""
        Generate a summary and services list for the folder: "{folder_name}" (Path: {folder_path})

        FOLDER CONTENTS:
        - Files ({len(file_list)}): {", ".join(file_list) if file_list else "None"}
        - Subfolders ({len(subfolder_list)}): {", ".join(subfolder_list) if subfolder_list else "None"}

        FILE SUMMARIES:
        {os.linesep.join(formatted_file_summaries) if formatted_file_summaries else "No file summaries available"}

        FILE SERVICES:
        {os.linesep.join(formatted_file_services) if formatted_file_services else "No file services available"}

        SUBFOLDER SUMMARIES:
        {os.linesep.join(formatted_subfolder_summaries) if formatted_subfolder_summaries else "No subfolder summaries available"}

        SUBFOLDER SERVICES:
        {os.linesep.join(formatted_subfolder_services) if formatted_subfolder_services else "No subfolder services available"}

        SUBFOLDER FEATURES:
        {os.linesep.join(formatted_subfolder_features) if formatted_subfolder_features else "No subfolder features available"}
        
        Based on these components:
        1. Provide a thorough technical summary explaining the folder's purpose, implementation details, and architectural significance
        2. Compile a comprehensive list of all services represented in this folder based on file and subfolder services information
        
        Follow the exact format specified in the system instructions for your response.
    """

    return system_prompt, user_prompt

def services_generation():
    system_prompt = """
        <Task>
        Create an architectural blueprint of the given repository by identifying and classifying both external services and third-party services with no overlap between categories.
        </Task>

        <Definitions>
        - External services: Company-provided services hosted outside the application (AWS S3, Google Cloud, Stripe, Twilio)
        - Third-party services: Libraries, frameworks, and SDKs that are part of the core application stack (Django, React, MongoDB, Redux)
        </Definitions>

        <Output_Format>
        {
        "external_services": [
            {
            "external_service_name": "string",
            "description": "string",
            "associated_files": ["string"],
            "service_class": "string",
            "used_in_files": ["string"]
            }
        ],
        "thirdparty_services": [
            {
            "thirdparty_service_name": "string",
            "description": "string",
            "associated_files": ["string"],
            "service_class": "string",
            "used_in_files": ["string"]
            }
        ]
        }
        </Output_Format>

        <Instructions>
        1. Conduct a thorough repository analysis to identify all services
        2. Classify each service into exactly ONE category:
        - External services: Cloud platforms, payment processors, authentication providers
        - Third-party services: Frameworks, libraries, SDKs integrated into the codebase
        3. For each service, provide:
        - Name: Exact service name
        - Description: Concise explanation of functionality and purpose
        - Associated files: All files directly importing or using the service
        - Service class: Category (e.g., "cloud storage", "web framework", "database")
        - Used in files: Complete paths of files utilizing the service
        4. Ensure ZERO overlap between categories
        5. Prioritize accuracy over comprehensiveness
        6. Validate that identified services are actively used in the project
        7. Include only services with clear evidence of implementation
        8. Do not create a lot of services which are redundant. Keep it to a maximum of 50 services only.
        </Instructions>

        <Examples>
        Good External Service Entry:
        {
        "external_service_name": "AWS S3",
        "description": "Cloud storage service used for storing user-uploaded files",
        "associated_files": ["src/services/storage.js", "src/config/aws.js"],
        "service_class": "cloud storage",
        "used_in_files": ["src/components/FileUpload.js", "src/pages/UserProfile.js"]
        }

        Good Third-Party Service Entry:
        {
        "thirdparty_service_name": "React",
        "description": "Frontend JavaScript library for building user interfaces",
        "associated_files": ["package.json", "src/index.js"],
        "service_class": "frontend framework",
        "used_in_files": ["src/App.js", "src/components/*.js"]
        }
        </Examples>

        Analyze the repository and provide the complete architectural blueprint in the specified format.
    """

    user_prompt = ""

    return system_prompt, user_prompt

def executive_summary_generation(combined_summary, user_mvf):
    system_prompt = """
    Your Role:
    You are an expert software architect tasked with understanding a codebase and creating an executive summary that clearly articulates the main purpose of this application,
    the core problem that the application is solving, and the prioritized list of the most valuable features, solely based on the provided folder wise summary. Do not hallucinate and create the most valuable features and its description on assumption. This needs to be based on facts.

    Task:
    1. Analyze provided folder wise summary and the services used and the user defined features (if provided).
    2. Understand component interactions and functions.
    3. Prioritize the User Defined Features (if provided) in the summary.
    4. Identify and prioritize the most valuable features based on their importance and relevance to the overall project, as evidenced in the code.
    5. Create a comprehensive executive summary.

    Steps:
    1. Review folder wise summary.
    2. Analyze folder wise summary:
    - Identify key components and their roles
    - Note data operations, design patterns, and architectural decisions
    3. Create summary:
    - Describe the specific problem the codebase solves, based on folder wise summary
    - Explain component interactions
    - Outline data workflow
    4. Identify and prioritize main features:
    - Determine which feature(s) address the core problem of the application, based on code implementation
    - Rank features based on their importance and relevance to solving the main problem, as evidenced in the code
    - The feature should be major components of the codebase and not minor functions like "Modular Architecture" or "Code Reusability", these are not features but design principles.

    Focus Areas:
    - Precised feature prioritization and importance
    - High-level functionality
    - Clear, concise technical language
    - Objective description
    - Capture entire workflow

    Guidelines:
    - Only use the folder wise summary provided
    - Use precise technical terms
    - Include user-defined features if provided and evidenced in the code
    - Prioritize features based on their importance to the core problem, as shown in the folder wise summary

    Feature Identification and Prioritization:
    - Carefully analyze the folder wise summary to identify features actually present in the folder wise summary
    - Do not assume or infer features that are not explicitly mentioned in the folder wise summary
    - Identify the top feature that solves the majority of the problem based on code evidence
    - Rank subsequent features in descending order of importance, ensuring they are present in the folder wise summary
    - Ensure the feature list reflects the codebase's focus and structure
    - Only include features that have substantial implementation in the codebase that is evident from folder wise summary

    Output Format - Adhering to this format is crucial
    ```json
    {
    "data": "generated_summary in string format adhering to the Expected Output Format for Generated Summary",
    "confidence_score": 90,
    "traceback": {
    "Feature 1 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 1 Title' is included, as the 'phrase' is an evidence that this feature is part of the codebase.",
    "Feature 2 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 2 Title' is included, as the 'phrase' is an evidence that this feature is part of the codebase.",
    ...
    }
    }
    ```

    Requirements:
    - Replace \n with \\n in JSON
    - Limit upto 5 main features (max 2 sub-features each) or 7500 tokens
    - If due to any reason such as codebase being small, you are unable to provide 5 features, then provide as many high-level features as possible between the range of 1 to 5.
    - Don't assume features or include minor features due to inability to provide 5 features, lesser number of features is acceptable.
    - Use specified JSON format only
    - Start with "```json" and end with "```"
    - Ensure the top feature in the prioritized list addresses the core problem and is present in the folder wise summary
    - Rank features in descending order of importance to the main problem, based on actual code implementation
    - Do NOT include features that are NOT evidenced in the provided folder wise summary
    - Evaluate the folder wise summary objectively, considering all conclusions on the actual code provided
    - Do NOT make any assumptions about organizational goals or intentions beyond what is explicitly shown in the code
    - Focus solely on the technical aspects and implemented functionality, avoiding speculation about business objectives or future plans
    - Both the keys data, confidence score, and traceback should be present in the output JSON
    - The generated summary should be in string format only and be contained inside the "data" key
    - The "traceback" key should contain a dictionary with feature names as keys and justifications for including these features based on exact phrases from the input
    - Do not include any feature that could potentially be part of the folder wise summary without explicit evidence
    - Every feature mentioned must be driven by clear evidence from the provided input
    """
    user_prompt = """
    Expected Output Format for Generated Summary:

  **Overview**
  <empty line>
  <A brief introduction to the codebase and its main purpose; in paragraph format only, not in points.
  This paragraph should provide a concise yet comprehensive overview of the codebase, its primary functionality, solution provided by the project and its intended use case.
  Aim for 3-5 sentences that capture the essence of the project.>
  <empty line>
  **Highlighted Features**
  <empty line>
  <
  List and briefly explain the key features that are significant components of the codebase and would serve as selling points.
  These features should be presented as follows:
  1. Use numbered points for each feature.
  2. Provide a brief explanation for each feature in 1-2 sentences, highlighting its importance and benefit to the end user.
  3. Focus on features that are central to the codebase's functionality and most important to the end user.
  4. Dont include generic features like "Modular Architecture" or "Code Reusability", these are not features but design principles.
  5. Do not include sub-points under any feature.
  6. Prioritize User Defined Features (if provided) at the beginning of the list.
  7. If User Defined Features are given, list them first before including any features identified through your analysis.
  8. Aim to provide upto of 1 to 5 key features, after each feature add an empty line for formatting purposes.
  9. Ensure that the features listed represent the core functionality and unique selling points based on the folder wise summary.
  10. Use clear, concise language that emphasizes the value proposition of each feature.
  11. Also under each feature, mention which file/folder was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
  12. Do not add features into Highlighted Features if they dont have value for buisness stakeholder about the application. Also do not repeat adding similar feature in this section.

  Output Structure:
  1. ***<Feature 1 Title>***: <Description of the feature in one to two sentences.\n
  2. ***<Feature 2 Title>***: <Description of the feature in one to two sentences.>\n
  >
  <empty line>
  **Key Benefits**
  <empty line>
  <Summarize the key benefits of the codebase in one to two sentences.
  This summary should encapsulate the overall value proposition of the codebase and its potential impact on users or the organization.>
  <empty line>
  <Highlight the most significant key benefits the codebase has to offer in bulleted points. The format should be:
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  Aim for 3-5 bullet points that capture the most compelling advantages of using this codebase, after each point add an empty line for formatting purposes.
  Each benefit should be distinct and provide a clear value proposition.>

  <Final Output Format>
  Output Format - Adhering to this format is crucial, the output should be in parsable JSON format:
  ```json
  {{
    "data": "<generated_summary in string format adhering to the Expected Output Format for Generated Summary>",
    "confidence_score": 90,
    "traceback": {{
      "Feature 1 Title": "Since it mentions about <exact phrase from the folder wise summary>, the 'Feature 1 Title' is included, as the "phrase" is an evidence that this feature is part of the folder wise summary.",
      "Feature 2 Title": "Since it mentions about <exact phrase from the folder wise summary>, the 'Feature 2 Title' is included, as the "phrase" is an evidence that this feature is part of the folder wise summary.",
      ...
    }}
  }}
  ```
  </Final Output Format>
  Note: If the traceback includes phrases that are not present in the folder wise summary then you would be penalized 10000 points.
  The output should be having data, confidence score, and traceback keys, and the entire content inside "```json" and "```" should be parsable by json.
  The "data" key should contain the generated summary and it should be in string format only, allowing the parsing of the entire json.
  If there are any inverted commas inside the generated summary, then escape them with a backslash.
  Do not change or skip the headings of each section in the generated json. The generated summary must have "Overview", "Highlighted Features", "Key Benefits" as section titles. Follow the above provided guidelines."""
    user_prompt += f"""Use the below folder wise summary to generate the summary in the above format: {combined_summary}""" + "User Defined Features : " + str(user_mvf)
    return system_prompt, user_prompt

def db_executive_summary_generation(combined_summary, user_mvf): 
    system_prompt = """
    Role:
    You are an expert Database Architect tasked with understanding the contents of all tables and schema of the database. 
    You shall Articulate a proper executive summary that clearly captures all the main & high-level features of this database.
    The core use-case that this database is intended for, and the prioritized list of the most valuable features, solely based on the provided Table-Level summaries. 
    Do not hallucinate. Do NOT create the most valuable features and its description on pure assumptions. This needs to be based on facts, with proper backing.

    Task:
    1. Analyze provided Table wise summaries.
    2. Understand component interactions and functions.
    3. Prioritize the User Defined Features (if provided) in the summary.
    4. Identify and prioritize the most valuable features based on their importance to the core use-case the Database is solving.
    5. Create a comprehensive executive summary.

    Steps:
    1. Review Table wise summary.
    2. Analyze Table wise summary:
      - Identify all tables. 
      - Take into consideration the foreign keys, primary keys, is-a, has-a, and many-to-many relationships.
      - Deeply understand the intended-use-case of each table.
      - Note data operations, design patterns, and architectural decisions
    3. Create summary:
      - Describe the specific problem the Database is solving, based on Table wise summary
      - Explain high-level interactions and dependencies
      - Outline data workflow
    4. Identify and prioritize main features:
      - Determine which feature(s) address the core problem of the Database, based on SQL implementation and Table wise summary
      - Rank features based on their importance and relevance to solving the main problem, as evidenced in the Database
      - The feature should be major components of the Database and not minor functions like Many-to-Many Relationships, or "Foreign Keys". 
        These are implementation concepts. Not core features.

    Focus Areas:
    - Precised feature prioritization and importance
    - High-level functionality of this Database
    - Clear, concise technical language with Database-specific Language
    - Objective description
    - Capture entire data workflow

    Guidelines:
    - Only use the Table wise summary provided
    - Use precise Database-relevant technical terms
    - Include user-defined features if provided and evidenced in the Table wise summary
    - Prioritize features based on their importance to the core problem, as shown in the Table wise summary

    Feature Identification and Prioritization:
    - Carefully analyze the Table wise summary to identify features actually present in the Table wise summary
    - Do not assume or infer features that are not explicitly mentioned in the Table wise summary
    - Identify the top feature that solves the majority of the problem based on Database and SQL evidence
    - Rank subsequent features in descending order of importance, ensuring they are present in the Table wise summary
    - Ensure the feature list reflects the Database's focus and structure
    - Only include features that have substantial implementation in the Database that is evident from Table wise summary

    Output Format - Adhering to this format is crucial
    ```json
    {
    "data": "generated_summary in string format adhering to the Expected Output Format for Generated Summary",
    "confidence_score": 90,
    "traceback": {
    "Feature 1 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 1 Title' is included, as the 'phrase' is an evidence that this feature is part of the Database.",
    "Feature 2 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 2 Title' is included, as the 'phrase' is an evidence that this feature is part of the Database.",
    ...
    }
    }
    ```

    Requirements:
    - Replace \n with \\n in JSON
    - Limit upto 5 main features (max 2 sub-features each) or 7500 tokens
    - If due to any reason such as Database being small, you are unable to provide 5 features, then provide as many high-level features as possible between the range of 1 to 5.
    - Don't assume features or include minor features due to inability to provide 5 features, lesser number of features is acceptable.
    - Use specified JSON format only
    - Start with "```json" and end with "```"
    - Ensure the top feature in the prioritized list addresses the core problem and is present in the Table wise summary
    - Rank features in descending order of importance to the main problem, based on actual Database and SQL implementation
    - Do NOT include features that are NOT evidenced in the provided Table wise summary
    - Evaluate the Table wise summary objectively, considering all conclusions on the actual Database and SQL provided
    - Do NOT make any assumptions about organizational goals or intentions beyond what is explicitly shown in the Database and SQL
    - Focus solely on the technical aspects and implemented functionality, avoiding speculation about business objectives or future plans
    - Both the keys data, confidence score, and traceback should be present in the output JSON
    - The generated summary should be in string format only and be contained inside the "data" key
    - The "traceback" key should contain a dictionary with feature names as keys and justifications for including these features based on exact phrases from the input
    - Do not include any feature that could potentially be part of the Table wise summary without explicit evidence
    - Every feature mentioned must be driven by clear evidence from the provided input.
    - Strictly use an assertive and objective tone in your response. 
    - Do not be unsure about anything.
    - Do not include the "Folder Name" in your response. Ignore "dbanalysis" folder. Provide Executive Summary of the Database-ONLY.
    """

    user_prompt = """
  Expected Output Format for Generated Summary:

  **Overview**
  <empty line>
  <A brief introduction to the Database and its main purpose; in paragraph format only, not in points.
  This paragraph should provide a concise yet comprehensive overview of the Database, its primary functionality, and its intended use case.
  Aim for 3-5 sentences that capture the essence of the Database.>
  <empty line>
  **Highlighted Features**
  <empty line>
  <
  List and briefly explain the key features that are significant components of the Database and would serve as selling points.
  These features should be presented as follows:
  1. Use numbered points for each feature.
  2. Provide a brief explanation for each feature in 1-2 sentences, highlighting its importance and benefit to the END USER.
  3. Focus on features that are central to the Database's functionality and most important to the END USER.
  4. Dont include generic features like  Many-to-Many Relationships, or "Foreign Keys", these are not features but Design Principles.
  5. Do not include sub-points under any feature.
  6. Prioritize User Defined Features (if provided) at the beginning of the list.
  7. If User Defined Features are given, list them first before including any features identified through your analysis.
  8. Aim to provide upto of 1 to 5 key features, after each feature add an empty line for formatting purposes.
  9. Ensure that the features listed represent the core functionality and unique selling points based on the Table wise summary.
  10. Use clear, concise language that emphasizes the value proposition of each feature.
  11. Also under each feature, mention which file/Table was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
  12. Do not add features into Highlighted Features if they dont have value for buisness stakeholder about the application. Also do not repeat adding similar feature in this section.

  Output Structure:
  1. ***<Feature 1 Title>***: <Description of the feature in one to two sentences.\n
  2. ***<Feature 2 Title>***: <Description of the feature in one to two sentences.>\n
  >
  <empty line>
  **Key Benefits**
  <empty line>
  <Summarize the key benefits of the Database in one to two sentences.
  This summary should encapsulate the overall value proposition of the Database and its potential impact on users or the organization.>
  <empty line>
  <Highlight the most significant key benefits the Database has to offer in bulleted points. The format should be:
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  Aim for 3-5 bullet points that capture the most compelling advantages of using this Database, after each point add an empty line for formatting purposes.
  Each benefit should be distinct and provide a clear value proposition.>

  <Final Output Format>
  Output Format - Adhering to this format is crucial, the output should be in parsable JSON format:
  ```json
  {{
    "data": "<generated_summary in string format adhering to the Expected Output Format for Generated Summary>",
    "confidence_score": 90,
    "traceback": {{
      "Feature 1 Title": "Since it mentions about <exact phrase from the Table wise summary>, the 'Feature 1 Title' is included, as the "phrase" is an evidence that this feature is part of the Table wise summary.",
      "Feature 2 Title": "Since it mentions about <exact phrase from the Table wise summary>, the 'Feature 2 Title' is included, as the "phrase" is an evidence that this feature is part of the Table wise summary.",
      ...
    }}
  }}
  ```
  </Final Output Format>
  Note: If the traceback includes phrases that are not present in the Table wise summary then you would be penalized 10000 points.
  The output should be having data, confidence score, and traceback keys, and the entire content inside "```json" and "```" should be parsable by json.
  The "data" key should contain the generated summary and it should be in string format only, allowing the parsing of the entire json.
  If there are any inverted commas inside the generated summary, then escape them with a backslash.
  Do not change or skip the headings of each section in the generated json. The generated summary must have "Overview", "Highlighted Features", "Key Benefits" as section titles. Follow the above provided guidelines.
    """

    user_prompt += f"""Use the below Table wise summary to generate the summary in the above format: {combined_summary}""" + "User Defined Features : " + str(user_mvf)

    return system_prompt, user_prompt


def architecture_diagram_generation(services_data, icons_metadata):
    user_prompt = f"""
    <Input>
    $services_data = {services_data}
    $icons_metadata
    </Input>

    <Role>
    You are an expert at understanding large projects based on their executive summary and the services being used in them. Create a JSON structure for a ReactFlow diagram based on the given service class JSON.
    </Role>

    <Output Structure>
    1. Create a JSON object with a "nodes" and "edges" array.
    2. Create nodes for each external and third-party service.
    3. "nodes": An array containing all node objects.
      - "id": A unique string identifier for the node.
      - "data":   
        - "label": The name of the node.
        - "description": Description of the service.
        - "associated_files": Associated file and used in files in the service node, defaulting to "No File Available" if not present.
        - "group": The logical group name (e.g., 'Backend', 'Frontend', 'Database',etc..).
        - "subgroup": The specific subgroup within the group (e.g., Frameworks, NoSQL Databases, State Management, etc.).
        - "service": The appropriate filename of the icon based on the $icons_metadata.
      - "position" : The x and y coordinates of the node.
      - "type" : "customNode" This should be fixed.
    4. "edges" : An array having id, source, target, label, and type should be customEdge always.
    4. Ensure all services and files from the input JSON are included.
    5. The output should be in the form of a dictionary containing a "nodes" and "edges" array.
    6. Present only the code inside delimiters "```reactflow [reactflow CODE]```" without any additional explanation.
    """

    system_prompt:str = """
    <Task>
      You are tasked with creating a JSON structure for a ReactFlow diagram based on the given executive summary and the service_class_json. The executive summary contains an overview of the entire project. This JSON includes information about external services and third-party services, along with their associated files. Your output should represent this information as a network of nodes and edges.
    </Task>
    
    <Icons Context>
      $icons_metadata = """ + str(icons_metadata) + """
    </Icons Context>

    <Instructions>
      You are a solution expert, specializing in problem and solution flows. You will be given the solution overview for a project, and your task is to create an interconnected single component of graph which is detailed, and intuitive and self explanatory for:

      Follow these guidelines:
      1. Create nodes for each unique service (both external and third-party).
      2. Do not create any group nodes.
      4. In the data key for each service node, include two additional fields called group and subgroup. The group field should contain the logical group name (e.g., Frontend, Backend, Databases, etc..), and the subgroup field should provide more specific categorization (e.g., Frameworks, NoSQL Databases, etc..). For example, for a service node representing React, the group would be Frontend and the subgroup would be Frameworks.
      5. For each node, check which icon will be the most suitable from the $icons_metadata in the <Icons Context>
      6. Ensure all information from the input is represented in the output.
      7. The position coordinates must be proper for all the nodes.
    </Instructions>

    <Rules>
      **Ensure all nodes in the generated graph are interconnected such that every node has at least one edge, forming a single connected component without any isolated or disjoint sections. (High Priority Requirement)**
      Important Rules to be followed:
      1. Give detailed technical architecture flow and the JSON object following the below output format.
      2. Make sure that the flow and order of new solution approach is explained well in the graph with appropriate edges. Use as many edges you want to describe the data and user flow properly.
      3. The whole user and data flow should be clear.
      4. Do not add unnecessary nodes and edges. Do not create duplicate nodes that perform same task.
      5. Make the Node descriptions detailed, breaking tasks into multiple sub-tasks if needed.
      6. Ensure your edges show the actual flow, and not just connections of what's related. The connections are meant to show the logical flow, and not the relatedness/similarity.
      7. The group name is meant to classify clusters of nodes within each graph. For instance, if we have multiple nodes in features, they would all have "feature" as group. In Architecture Flow, the "Group" should show the layer each node is in, for instance "Backend Layer", "Database Layer" etc.
      9. for a hierarchy of nodes A -> B -> C; ensure that there is not a connection between A -> C.
    </Rules>
    
    <output_format>
    The output should be in between the delimeters ```reactflow and ```. Only provide the json output. Don't give unnecesary explanation.
    ```reactflow
    {
      "nodes": [
        { 
          "id": "unique_node_identifier_string",
          "data" : {
            "label": "name_of_the_service",
            "description": "description of the service",
            "associated_files": ["file_path_1", "file_path_2", "file_path_3", etc.],  // (default: ["No File Available"] if not present)
            "group": "name_of_group",  // Add the logical group name (e.g., "Frontend", "Backend", etc..)
            "subgroup": "name_of_subgroup",  // Add a more specific subgroup name (e.g., "Frameworks", "NoSQL Databases", etc..)
            "service": "filename" //taken from the $icons_metadata,
          }
          "position":{ "x": "Xcoordinate", "y": "Ycoordinate" },
          "type" : "customNode" //this is hardcoded and will be constant
        }
      ],
      "edges": [
        {
          "id": "unique_egde_identifier_string",
          "source": "label A",
          "target": "label B",
          "label": "Showcase what comes from the source node, to the target node. Be concise and specific with labels, such as 'Ingested Data', 'Converted Text', 'User Query' etc. Use at max 5 words",
          "type" : "customEdge" //this is hardcoded and will be constant
        }
      ]
    }```
    </output_format>
    """
    return system_prompt, user_prompt
  

def erd_generation(services_data, icons_metadata):
  tables_metadata = []
  for entry in services_data:
      table_name = entry["table_name"]
      ddl = entry["ddl"]
      columns, primary_keys, foreign_keys = parse_ddl(ddl)
      tables_metadata.append({
          "table_name": table_name,
          "columns": columns,
          "primary_keys": primary_keys,
          "foreign_keys": foreign_keys
      })

  dot = generate_combined_graph(tables_metadata)

  system_prompt:str = """
    You are tasked with creating a JSON structure for a ReactFlow diagram based on the given database ER diagram and schema JSON. This JSON includes information about database columns and their relationships.Your output should represent this information as a network of nodes and edges.
    </Task>
    
    <Icons Context>
      $icons_metadata = """ + str(icons_metadata) + """
    </Icons Context>

    <Instructions>
      You are a solution expert, specializing in problem and solution flows. You will be given the database schema information of a database, and your task is to create an interconnected single component of graph which is detailed, and intuitive and self explanatory for:

      Follow these guidelines:
      1. Create nodes for each unique service (both external and third-party).
      2. Do not create any group nodes.
      4. In the data key for each service node, include two additional fields called group and subgroup. The group field should contain the logical group name (e.g.,Databases, etc..), and the subgroup field should provide more specific categorization (e.g., 'Transactional Tables', 'Reference Tables' etc..). For example, for a service node representing daily transactions, the group would be Database and the subgroup would be Transactional Tables.
      5. For each node, check which icon will be the most suitable from the $icons_metadata in the <Icons Context>
      6. Ensure all information from the input is represented in the output.
      7. The position coordinates must be proper for all the nodes.
    </Instructions>

    <Rules>
      Important Rules to be followed:
      1. Give detailed technical architecture flow and the JSON object following the below output format.
      2. Make sure that the flow and order of new solution approach is explained well in the graph with appropriate edges. Use as many edges you want to describe the data and user flow properly.
      3. The whole user and data flow should be clear.
      4. Do not add unnecessary nodes and edges. Do not create duplicate nodes that perform same task.
      5. Make the Node descriptions detailed, breaking tasks into multiple sub-tasks if needed.
      6. Ensure your edges show the actual flow, and not just connections of what's related. The connections are meant to show the logical flow, and not the relatedness/similarity.
      7. The group name is meant to classify clusters of nodes within each graph. For instance, if we have multiple nodes in features, they would all have "feature" as group. In Architecture Flow, the "Group" should show the layer each node is in, for instance "Database Layer" etc.
      9. for a hierarchy of nodes A -> B -> C; ensure that there is not a connection between A -> C.
    </Rules>
    
    <output_format>
    The output should be in between the delimeters ```reactflow and ```. Only provide the json output. Don't give unnecesary explanation.
    ```reactflow
    {
      "nodes": [
        { 
          "id": "unique_node_identifier_string",
          "data" : {
            "label": "name_of_the_table",
            "description": "description of the table",
  	    "columns": ["order_id [PK]", "product_sku [PK]", "quantity", "unit_price"]
            "group": "name_of_group",  // Add the logical group name (e.g., "Database", etc..)
            "subgroup": "name_of_subgroup",  // Add a more specific subgroup name (e.g., 'Transactional Tables', 'Reference Tables', etc..)
            "service": "filename" //taken from the $icons_metadata,
          }
          "position":{ "x": "Xcoordinate", "y": "Ycoordinate" },
          "type" : "customNode" //this is hardcoded and will be constant
        }
      ],
      "edges": [
        {
          "id": "unique_egde_identifier_string",
          "source": "label A",
          "target": "label B",
          "label": "Showcase what comes from the source node, to the target node. Be concise and specific with labels, such as 'Ingested Data', 'Converted Text', 'User Query' etc. Use at max 5 words",
          "type" : "customEdge" //this is hardcoded and will be constant
        }
      ]
    }```
    </output_format>
    """
    
  user_prompt:str = f"""
    <Input>
    $database_tables = {dot}
    $icons_metadata
    </Input>

    <Role>
    You are an expert at understanding database architecture based on ER diagrams and relational structures. Create a JSON structure for a ReactFlow diagram based on the given database schema.
    </Role>
    <Output Structure>
      1. Create a JSON object with a "nodes" and "edges" array.
      2. Create nodes for each table in the schema.
      3. "nodes": An array containing all node objects.
      - "id": A unique string identifier for the node.
      - "data":  
        - "label": The name of the table.
        - "description": A brief summary of the table's role or content.
        - "columns": List of column names (mark primary keys with [PK], foreign keys with [FK]).
        - "group": The logical group name (e.g., 'Database').
        - "subgroup": The specific subgroup within the group (e.g., 'Transactional Tables', 'Reference Tables').
        - "service": The appropriate filename of the icon based on the $icons_metadata.
      - "position" : The x and y coordinates of the node.
      - "type" : "customNode" This should be fixed.
      4. "edges" : An array having id, source, target, label, and type should be customEdge always.
      5. The label of the edge should describe the relationship, like "order_id â†’ order_id". 
      6. The output should be in the form of a dictionary containing a "nodes" and "edges" array.
      7. Present only the code inside delimiters "```reactflow [reactflow CODE]```" without any additional explanation.
    """
    
  return system_prompt, user_prompt
    

def feature_summary_generation(formatted_data, user_mvf, executive_summary):
    # if input_type is None:
    #     formatted_data = file_summary_list
    # elif input_type == "batch_summary":
    #     formatted_data = format_batchwise_summary_metadata_for_services(file_summary_list)
    # else:
    #     formatted_data = format_file_summaries(file_summary_list)

    user_prompt = """
    Role: You are an AI code analyst specializing in creating concise, feature-level summaries of codebases.

    Objective: Provide a comprehensive yet concise feature-level summary of a given codebase, highlighting key components, functionality, and the project's overall workflow.

    Input: You will receive information about a codebase, which may include an executive summary or other project details.

    Steps:
    1. Analyze the provided codebase information.
    2. Identify the main features (maximum 5) of the project from the executive summary (if provided in same order)
    3. Create a summary following the specified format, including:
        a. An overview of the project
        b. A list of key features with brief descriptions
        c. A closure statement
    4. Self-evaluate the generated summary and assign a confidence score.
    5. Format the output as specified in the instructions.

    Output Format:
    ```json
    {
        "data": "generated_summary in string format adhering to the Detailed Instructions for Output Format",
        "confidence_score": 90
    }
    ```

    Detailed Instructions for Output Format:

    **Overview**
    <empty line>
    < 
        Summarize all features in 2-3 sentences, introducing the project and its purpose.
        Provide a 2-3 sentence summary of key benefits, highlighting core architecture and value proposition.
    >
    <empty line>
    **Key Features**
    <empty line>
    <   
        List a maximum of 5 main features.
        For each feature, provide up to 2 sub-points describing its functionality.
        Ensure clear explanation of how features interact and contribute to the project's goals.
        1. ***<Key Feature Title>*** : 
        * <Sub point 1 description>
        * <Sub point 2 description>
        <empty line>
    >
    <empty line>
    < 
        Summarize the overall impact and value proposition of the project in one sentence as a conclusion statement.
    >
    <empty line>
    
    -> Self-Evaluation:
        - Score the summary out of 100 based on clarity, precision, detail, knowledge, accuracy, technical correctness, and understanding of the data.

    -> Formatting Requirements:
        - Replace all newline characters (\n) with \\n in the JSON output.
        - Ensure the complete JSON is less than 7500 tokens.
        - Start the output with "```json" and end with "```".
        - If an executive summary is provided, use only the highlighted features from it.

    Example Output Structure:
    ```json
    {
        "data": "**Overview**\\n\\n[Project overview]\\n\\n[Benefits summary]\\n\\n**Key Features**\\n\\n1. *Feature 1*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n2. *Feature 2*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n[...continue for up to 5 features...]\\n\\n[Closure statement]",
        "confidence_score": 90
    }
    ```

    Remember: Adhere strictly to the output format and instructions to maintain consistency and accuracy in your summary.
    """

    user_prompt += "User Defined Features : " + str(user_mvf)

    system_prompt = f"""
        <role>
        You are an assistant to a Senior Software Engineer. You are very capable in reading and understanding huge codebases.
        There is no edge-case, no mistake, no functionality no matter how small goes unnoticed by you.
        You will be given a large codebase and be asked queries regarding it.
        </role>

        <Task>
        You will be given relevant files from a production codebase. The Senior Engineer will consult you to clear his doubts and ask for critical code-level and functionality level analysis of the same.
        <Important>
        1. You will be clear. Feel free to be descriptive but Avoid Jargon
        2. You shall perform critical analysis on the code before responding.
        3. Note that the codebase will be quite complex and have dependencies everywhere, be mindful of them all.
        4. Enclose code in (triple backticks)``` code ```
        </Important>
        </Task>

        Files from Codebase goes here :
        <Repo Structure>
        {formatted_data}
        </Repo Structure>
    """

    start_index = executive_summary.find("Highlighted Features")
    end_index = executive_summary.find("Key Benefits")

    if start_index != -1 and end_index != -1:
        executive_summary = executive_summary[start_index:end_index].strip()

    user_prompt += "Executive Summary : " + str(executive_summary)

    return system_prompt, user_prompt

def feature_summary_generation_db(formatted_data, user_mvf, executive_summary):
    # if input_type is None:
    #     formatted_data = file_summary_list
    # elif input_type == "batch_summary":
    #     formatted_data = format_batchwise_summary_metadata_for_services(file_summary_list)
    # else:
    #     formatted_data = format_file_summaries(file_summary_list)

    user_prompt = """
    Role: You are an AI Database Analyst specializing in creating concise, feature-level summaries of complex database schemas and architectures.

    Objective: Provide a comprehensive yet concise feature-level summary of a given database schema information, highlighting key components, entities, relationships, and the overall data architecture workflow.

    Input: You will receive information about a database design, which may include an executive summary or other schema-level details.

    Steps:
    1. Analyze the provided database schema information.
    2. Identify the main features (maximum 5) of the database from the executive summary (if provided in same order)
    3. Create a summary following the specified format, including:
        a. An overview of the database
        b. A list of key features with brief descriptions
        c. A closure statement
    4. Self-evaluate the generated summary and assign a confidence score.
    5. Format the output as specified in the instructions.

    Output Format:
    ```json
    {
        "data": "generated_summary in string format adhering to the Detailed Instructions for Output Format",
        "confidence_score": 90
    }
    ```

    Detailed Instructions for Output Format:

    **Overview**
    <empty line>
    < 
        Summarize all features in 2-3 sentences, introducing the database and its purpose.
        Provide a 2-3 sentence summary of key benefits, highlighting schema structure, normalization or denormalization logic, and value proposition in handling data.
    >
    <empty line>
    **Key Features**
    <empty line>
    <   
        List a maximum of 5 main features.
        For each feature, provide up to 2 sub-points describing its data handling, relationships, or optimization logic.
        Ensure clear explanation of how features contribute to performance, consistency, and data integrity.
        1. ***<Key Feature Title>*** : 
        * <Sub point 1 description>
        * <Sub point 2 description>
        <empty line>
    >
    <empty line>
    < 
        Summarize the overall impact and value proposition of the database in one sentence as a conclusion statement.
    >
    <empty line>
    
    -> Self-Evaluation:
        - Score the summary out of 100 based on clarity, precision, detail, knowledge, accuracy, technical correctness, and understanding of the schema information.

    -> Formatting Requirements:
        - Replace all newline characters (\n) with \\n in the JSON output.
        - Ensure the complete JSON is less than 7500 tokens.
        - Start the output with "```json" and end with "```".
        - If an executive summary is provided, use only the highlighted features from it.

    Example Output Structure:
    ```json
    {
        "data": "**Overview**\\n\\n[Database overview]\\n\\n[Benefits summary]\\n\\n**Key Features**\\n\\n1. *Feature 1*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n2. *Feature 2*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n[...continue for up to 5 features...]\\n\\n[Closure statement]",
        "confidence_score": 90
    }
    ```

    Remember: Adhere strictly to the output format and instructions to maintain consistency and accuracy in your summary.
    """

    user_prompt += "User Defined Features : " + str(user_mvf)

    system_prompt = f"""
        <role>
        You are an assistant to a Senior Data Architect. You are very capable in reading, analyzing, and understanding complex database schemas and data models.
        No entity, constraint, relationship, or optimization logic goes unnoticed by you.
        You will be given a comprehensive database structure or schema information and will be asked to analyze, explain, and summarize it at a structural and functional level.
        </role>

        <Task>
        You will be given relevant database schema files or DDL definitions. The Senior Data Architect will consult you to clear doubts and ask for critical schema-level and data model-level analysis.
        <Important>
        1. You will be clear. Feel free to be descriptive but Avoid Jargon
        2. Perform a critical and deep analysis of the schema and the information given before responding.
        3. The schema will often involve multiple tables, foreign keys, views, procedures, and indexing strategies â€” be mindful of their dependencies and relationships.
        4. Enclose code or schema in (triple backticks)``` code ```
        </Important>
        </Task>

        Files from Database schema goes here :
        <Database Structure>
        {formatted_data}
        </Database Structure>
    """

    start_index = executive_summary.find("Highlighted Features")
    end_index = executive_summary.find("Key Benefits")

    if start_index != -1 and end_index != -1:
        executive_summary = executive_summary[start_index:end_index].strip()

    user_prompt += "Executive Summary : " + str(executive_summary)

    return system_prompt, user_prompt


#FEATURE HIERARCHY:
generate_features_system_prompt = """
  <Role>
    You are a Software Architect with expertise in analyzing large summaries from code files of an application. 
    You can comprehend summaries from code files that are complex, production-grade and are written in various programming languages to generate most important features, their description and the subfeatures with their description belonging to the most important features along with the other relevant information requested below.
    
    You will follow 2 Events before responding : 
    1. Generation of Feature Hierarchy as given in "Output_Format".
    2. Critical Evaluation of Every Confidence Score.  
  </Role> 

    <Task 1>
    You are provided with multiple relative file paths and file-wise code summaries from a application codebase.
    1. Analyze the file summaries carefully, leveraging your expertise to deduce the frameworks, functionality, and features.
    2. Perform a critical assessment of the code's functionality and interdependencies before responding.
    3. The codebase is complex and likely contains dependencies across various modules. Be mindful of these.
    4. Analyse every file summary and assign the features and sub-features based on the information provided.
    5. Respond strictly in the structured JSON format provided below.
    6. In each sub-feature's 'file_path' array:
        - Set 'critical: true' ONLY for files that are CORE & NON-REPLACEABLE to the sub-feature's main functionality.
        - Set 'critical: false' for ALL supporting, secondary, or replaceable files  
        - Each sub-feature should have both true and false entries.
        - If unsure, default to false (be EXTREMELY selective with 'true')
        - Make sure each sub-feature atleast have one file as true.

    Explanation of the Output terms:
    Feature - Features are most valuable and high level features extracted from the list of summaries that are provided to you. 
    Feature description - Description of the features explaining the high level value and impact that it creates for the project. Define the Feature. The description should be crisp, precise, well formatted and must be between 2-3 lines.
    Subfeature - Subfeatures are micro most valuable features that are extracted from the list of summaries and belong to the Most related and similar Features.
    Subfeature description - Description of the subfeatures explaining the specific value, technical and non-technical functionalites that it provided to the project. Define the subfeature and also explain how its related to the feature. The description should be crisp, precise, well formatted and must be between 2-3 lines.
    
    Points to Remember:
    1. Do not extract any feature or subfeature where there are no reference/citations from the application summaries.
    2. The description must be precise, valuable, well-formatted and must be between 2-3 lines.
    3. The Feature titles should be precise, specific, self explanaible, independent and not have similar feature titles. The Feature titles should not be highly generalized.
    4. The SubFeatures titles should be precise, self explanaible and not have similar subfeature titles. The SubFeature titles should not be highly generalized.
    5. SubFeatures should not be very low level that it explains code functions, code process like 'Json handling', 'Reading csv', readME etc.
    6. If similar subfeatures are present, then group them under one common Feature itself. Do not create multuple Features for similar subfeatures.
    6. If Unit testing related summaries are found, then create that as another Feature named 'Unit Testing' and assign the specific testing subfeatures under this feature.
    </Task 1>

  <Task 2>
  You shall now Assign and Justify Confidence Scores for each feature.

  <Critical Evaluation of Confidence Scores> 

  <Evaluation MODE>
  - You will now Forget everything that was done beforehand and act as an unbiased judge.
  - $Project-Summaries-&-Paths (INPUT).
  </Evaluation MODE>
  <Important>
  Critically analyze every "Feature" and "SubFeature" based on the following metrics. 
  You shall generate a confidence score between 0-100 for each of the following :
  1. Is the "Feature" & "SubFeature" name accurate to its functionality ? (Accuracy)
  2. Does the "Feature" & "SubFeature" include files with an unrelated function ? (Feature Dilution Rate)
  3. Important : Does this "Feature" & "SubFeature" make sense given the Overall Purpose of the Application ? (Consistency)
  4. Are all the files in "Feature" & "SubFeature" included ? (Completeness)

  <Strict>
  1. You will now generate a list of 4 confidence scores between 0-100 for above criteria under "confidence_score" key.
  2. Based on above criteria, you shall provide a VERY BRIEF logical explanation (10-20 words) for Confidence Score under "confidence_score_justification" key.
  3. Make sure to mention the entire filepath without omitting the prefix.
  4. Make sure all the filepaths are present.
  <Important> STRICTLY Don't Comment on Missing Files. Don't Overestimate. Don't Underestimate.</Important> 
  </Strict>

  </Important>

  </Critical Evaluation of Confidence Scores> 
  </Step 2>


      <Output_Format>
    Return a response in JSON format. Do not include any extra information or explanations. Strictly DON'T deviate from mentioned KEYS.
    Example:
```json
[
  {
    "name": "User Authentication and Management",
    "feature_description": "Comprehensive user account system with secure login, registration, profile management, and role-based access control.",
    "feature_description_confidence_score": [95, 70, 100, 70],
    "sub_features": [
      {
        "name": "User Registration",
        "description": "Allows new users to create accounts by providing necessary information such as username, email, and password. Implements email verification, password strength checks, and duplicate account prevention. Stores user data securely in the database with password hashing.",
        "file_path": [
          {
            "module_name": "RegistrationController",
            "path": "Controllers/Account/RegistrationController.cs",
            "critical": true
          },
          {
            "module_name": "RegisterView",
            "path": "Views/Account/Register.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [75, 80, 85, 65],
        "sub_feature_confidence_score_justification": "No feature dilution, might have missed some file."
      },
      {
        "name": "User Login",
        "description": "Authenticates users using their credentials, creates and manages user sessions, and implements security measures such as login attempt limiting and two-factor authentication (2FA). Provides password reset functionality for forgotten passwords.",
        "file_path": [
          {
            "module_name": "LoginController",
            "path": "Controllers/Account/LoginController.cs",
            "critical": true
          },
          {
            "module_name": "LoginView",
            "path": "Views/Account/Login.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [80, 100, 80, 75],
        "sub_feature_confidence_score_justification": "High chance of missing files."
      }
    ],
    "feature_confidence_score_justification": "No feature dilution, duplication or missing files. Accurate Naming."
  },
  {
    "name": "Product Catalog Management",
    "feature_description": "Comprehensive system for managing product listings, categories, and inventory across the e-commerce platform.",
    "feature_description_confidence_score": [95, 65, 70, 80],
    "sub_features": [
      {
        "name": "Product CRUD Operations",
        "description": "Enables administrators to create, read, update, and delete product listings. Includes functionality for managing product details such as name, description, price, images, and inventory levels. Implements validation to ensure data integrity and consistency across the product catalog.",
        "file_path": [
          {
            "module_name": "ProductController",
            "path": "Controllers/ProductController.cs",
            "critical": true
          },
          {
            "module_name": "ProductView",
            "path": "Views/Product/Index.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [90, 85, 100, 70],
        "sub_feature_confidence_score_justification": "High confidence with no duplication or dilution."
      },
      {
        "name": "Category Management",
        "description": "Allows for the creation and management of product categories and subcategories. Implements a hierarchical structure for organizing products, enabling efficient navigation and filtering of the product catalog for both administrators and customers.",
        "file_path": [
          {
            "module_name": "CategoryController",
            "path": "Controllers/CategoryController.cs",
            "critical": true
          },
          {
            "module_name": "CategoryView",
            "path": "Views/Category/Index.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [85, 75, 90, 95],
        "sub_feature_confidence_score_justification": "High confidence without any duplication or dilution."
      }
    ],
    "feature_confidence_score_justification": "All files refer to single overall functionality. Might have missed some files."
  }
]
```
  </Output_Format>

"""

generate_features_user_message = """
<Strictly Remember>
1. As input you will be given a batch of `file_path` and `file_summary` from a production codebase. Keep it in mind that it could be a file from a very large repository with lot of inter-dependencies.
2. Understand all the file description first, then try to determine the feature, sub-features and their description. For **each file** it should have a feature or sub-features whenever the conditions are met.
3. The response should contain all the fields given in the example output format. The response should be strictly in json format.
4. The description of features/subfeatures must be in the length of 2-3 lines. The response should be structured and well-formatted.
5. Don't generate any additional explanation or description. Provide the structured response in json only.
</Strictly Remember>
  
<Input file wise summary>
{file_summary}
</Input file wise summary>
<Response>
"""

merge_features_in_hierarchy_user_prompt = """You are a software feature analyzer. Given a list of related features that have been clustered together, create a merged feature that encompasses all the functionality.

Features to merge:
{feature_list}

Generate a JSON response that includes:
1. A name for the merged feature representing accurate feature name. Do not mention its merged or unified or anything as such. The feature name should accurately represent a major funcationality of a repository.
2. A detailed description that covers all functionality
3. A confidence score (0-100) for the merge
4. A justification for the confidence score

Respond with a JSON object in the following format:
```json
{{
    "name": "Merged feature name",
    "description": "Comprehensive description",
    "confidence_score": 85,
    "confidence_justification": "Reason for the confidence score"
}}
```
Give only JSON and nothing else. Do not include any explanations or additional text outside the JSON block. Make sure to start with ```json and end with ``` only.
"""

mapping_names_for_merged_features_user_prompt = """  <Role>
    You are a smart AI cassistant with strong expertise in Software Engineering. You can understand complex, production-grade codebases written in various programming languages and summarize them effectively.
  </Role>
  <Task>
  You will be given a brief description of  features of a large codebase and your task is to generate a relevant feature name, brief description, and priority level.
  <Important>
   1. The feature name should be brief, relevant and should represent the entire description provided.
   2. Generate a relevant description which is basically a overall summary of the description provided.
   3. Assign a priority level (high, medium, low) based on the significance, importance and complexity of the feature to the overall system. 
  </important>
  </Task>
  <Example output>
  ```json
    {
        "name": <feature_name>, //string
        "feature_description": <feature_description>, //string
        "priority": <priority> //string (high, medium, or low)
    }
    ```
  </Example output>
  <Strictly Remember>
1. The feature name should be relevant and at the same time interpretable, easy to understand.
2. The feature description should represnt the entire description given for summarisation, it should be simple and easy to understant.
3. The priority should be one of: high, medium, or low.
4. The response should be strictly in json format specified above.
5. Strictly make sure Feature Description is not more than 200 words.
  </Strictly Remember>

<code summary>
The code summary is given below:
"""


reducing_sub_features_user_prompt = """
    You are a software feature consolidation expert. Your task is to merge similar sub-features into one comprehensive sub-feature.

    Here are the sub-features that need to be merged:
    {sub_features_list}

    For each sub-feature, we have:
    - Name: The sub-feature name
    - Description: The sub-feature description (if available)
    - Confidence Score: The confidence score (if available)

    Your output should be a JSON object containing:
    1. A unified sub-feature name that encompasses all the input sub-features
    2. A comprehensive description that covers all aspects of the input sub-features
    3. A confidence score (use the highest available from input sub-features)
    4. A justification for the confidence score

    Return the output in JSON format starting with ```json and ending with ```.

    Example output format:
    ```json
    {{
        "name": "Unified Sub-Feature Name",
        "description": "Comprehensive description covering all aspects",
        "sub_feature_confidence_score": 95,
        "sub_feature_confidence_score_justification": "Merged from similar sub-features with high semantic similarity"
    }}
    ```
    """


post_processing_feature_name_description_system_prompt="""
  <Role>
    You are a smart AI assistant with strong expertise in Software Engineering. You can understand complex, production-grade codebases written in various programming languages and summarize them effectively.
  </Role>
  <Task>
  You will be given a brief description of modules or features of a large codebase and your task is to generate a relevant feature name and brief description.
  <Important>
   1. The feature name should be brief, relevant and should represent the entire description provided.
   2. Generate a relevant description which is basically a overall summary of the description provided.
   3. Also generate a confidence score in a scale of 0 - 100.
  </important>
  </Task>
  <Example output>
  ```json
    {
        "name": <feature_name>,
        "feature_description_confidence_score": <score 0 - 100>,
        "feature_description": <feature_description>
    }```
  </Example output>"""

post_processing_feature_name_description_user_prompt = """<Strictly Remember>
1. The feature name should be relevant and at the same time interpretable, easy to understant.
2. The confidence score should represent the ability to summarise the description.
3. The feature description should represnt the entire description given for summarisation, it should be simple and easy to understant.
4. The response should be strictly in json format specified above.
</Strictly Remember>
<code summary>
The code summary is given below: \n
{feature_description}
</code_summary>
<response>
Your response in json goes here:
"""

merge_similar_features_system_prompt = """You are a solution architect. Your task is to carefully review each feature and its description, and combine them into a single high-level feature.

The final high-level features should represent what an end user would perceive, e.g., Messenger, Google Chat, Messaging, Reels, etc.

Based on the generated features provided, identify which features can be merged into a single high-level feature. 
Strictly output them in the following format:
{{ 
  <High-Level Feature Name 1>: [<Merged Feature 1>, <Merged Feature 2>, <Merged Feature 3>, ...],
  <High-Level Feature Name 2>: [<Merged Feature 1>, <Merged Feature 2>, <Merged Feature 3>, ...],
  ...
}}

INPUT:
Feature names and descriptions are provided in the format: 
[1. Feature name: <feature name> 
Feature description: <feature description>, 
2. ...]

{feature_texts}

MVFS:
{total_MVFs}

Points to remember:
1. While merging features and naming high-level features, always prefer names from the user-defined MVFs provided. All relevant features can be grouped under these high-level features.
2. If certain features do not fit under the user-defined MVFs, choose a better name than the existing one for the new high-level feature if necessary.
3. The names of the features being merged must remain exactly as provided in the INPUT section; do not modify them. Do not consider Feature description in Feature Names.
4. Follow the output structure strictly: high-level feature names as dictionary keys and merged features as values in list format.
5. If a feature is already a high-level feature, you do not need to forcibly merge it. If a feature seems to be function-level/low-level  features, merge them into a High-level feature.
6. Merge similar features into a single high-level feature based on their names and descriptions, when applicable. Each final high-level feature should be independent of the others.
7. Do not assign the same feature to multiple high-level features.
8. If user-defined MVFs are empty, skip point 1 and begin with point 2.
9. Do **not** include any Feature descriptions in the final output."""


merging_description_user_prompt = """You are a Solution Architect. Your task is to summarize the multiple feature descriptions provided into a brief, coherent summary of **no more than two sentences**.

  The summary must:
  - Accurately capture all key components from the provided descriptions.
  - Align clearly with the given high-level feature name.
  - Serve as the final description of the high-level feature.

  Only the final summarized description should be included in the output â€” no additional commentary or formatting.

  INPUT:
  Multiple descriptions: {merging_feature_description}

  High-Level Feature Name: {high_level_feature}
  """


micro_sub_feature_prompt = """You are an expert system analyst specializing in decomposing SubFeatures into granular, logically independent components. You support **two levels** of splitting:

1. **Horizontal splitting**: Split a subfeature into multiple *same-level subfeatures* when it encompasses multiple independently meaningful functionalities. The subfeatures created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.
2. **Vertical splitting**: Further break each of those subfeatures into *microsubfeatures* (if applicable), ensuring each micro-sub-features/micro-user-story describes a single goal or operation. The micro-sub-features/micro-user-story created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.

---

### ðŸ”§ TASK OVERVIEW

Given a Macro-Feature, Subfeature, its description, associated module files and its summary:

- Decide if the subfeature should be split horizontally into multiple same-level subfeatures.
- For each resulting subfeature (or original if not split), analyze whether it can be split vertically into **microsubfeatures** (fine-grained user stories).
- Provide the confidence scores for the subfeature that is split, whether horizontally or vertically.
- Provide the files that are related to the sub_features too, not just the micro_sub_features.
- Each leaf user-story must have files assigned to them, else you should not create/split these subfeatures.
- Provide description of generated subfeature/sub-user-stories in 2-4 lines but only valid information. Do not assume or hallucinate to generate description.
Apply this recursively: if horizontal splitting occurs, then attempt vertical splitting for each. But remember, not to create any duplicates in the process. 

---

### SPLITTING DECISIONS

#### Horizontal Splitting (Same-level Subfeatures):
Split if:
- The subfeature covers multiple high-level functionalities
- Each function could be planned, developed, and deployed independently
- Each component has a clear boundary and responsibility

#### Vertical Splitting (Microsubfeatures):
Split further if:
- A subfeature contains multiple independent operations or logical stages
- These operations can be implemented, tested, or tracked separately
- Each micro-subfeature represents one atomic, non-overlapping functionality

---

### DO NOT SPLIT IF:
- sub-user-stories are tightly coupled in the Subfeature and cannot function independently.
- Do not split subfeatures into sub-user-stories that are hardly single line of code and cannot be considered as a proper functionality, but just a config/parameter.
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across actions are too complex to isolate.
- There are no files that can be mapped to the generated user-story.
- Do not split if the user-story is barely a functionality. The split user-stories must have independent functionality that contributes to the subfeature and feature and if not, do not split.
- Don not split ReadMe & .md files into sub-user-stories.
- Do not split horizontall for granullar subfeatures as they are not user stories but mid level features.
---

### FILE MAPPING RULES:
- For each subfeature or microsubfeature, cite only directly relevant files.
- Use only the provided input data to match files â€” no guessing.
- Avoid duplication unless a file is clearly shared between components.

Each `file_path` entry must include:
```json
{
  "module_name": "<Name>",
  "path": "<Path>",
  "critical": <true/false>,
  "git_url": "<Git URL>"
}

OUTPUT FORMAT
If the subfeature should NOT be split:
Return: "None"

If the subfeature should be split, return a list of Parent User Stories with subfeatures inside.
If a subfeature itself can be further split into microsubfeatures, nest them under micro_sub_features like so:

[
  {
    "name": "Parent User Story Title 1",
    "description": "Full description of the original or updated user story and its purpose.",
    "file_path": [...],
    "sub_feature_confidence_score":"confidence score of the subfeature with respect to the Feature, as a percentage (e.g., 80)"
    "micro_sub_features": [
      {
        "name": "Sub-User Story Title 1",
        "description": "Standalone description of a single functionality.",
        "file_path": [...],
        "micro_sub_feature_confidence_score":"confidence score of the micro_sub_feature with respect to the sub_feature, as a percentage (e.g., 90)"
        }
          ...
        ]
      },
      ...
    ]
  }
]
Each layer must preserve independence, clarity, and singular focus of each story.

VALIDATION CHECKLIST
- Each title must express one functionality only (no imperative phrasing)
- description must avoid assumptions and describe the real function. It must be as detailled as possible.
- Each story must make sense independently and fit in the broader feature flow
- if there are multiple user-story under the subfeature, it needs to be in sequence of business logic.
- File mappings must be relevant and scoped accurately
- Do no miss/skip any values in the output json. The output structure must be maintained strictly.
- All subfeature and sub-user-story names and descriptions must be strictly in a declarative tone, not imperative.

* Use generic or speculative statements
"""


db_micro_sub_feature_prompt = """
<Role>
You are an expert Database analyst specializing in decomposing SubFeatures into granular, logically independent components. You support **two levels** of splitting:
You shall ALWAYS process features from a Database perspective ONLY. 
There can be more than one Table in the DB context provided to you.
</Role>

1. **Horizontal splitting**: Split a subfeature into multiple *same-level subfeatures* when it encompasses multiple independently meaningful functionalities. The subfeatures created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.
2. **Vertical splitting**: Further break each of those subfeatures into *microsubfeatures* (if applicable), ensuring each micro-sub-features/micro-user-story describes a single goal or operation. The micro-sub-features/micro-user-story created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.

<Strict Constraints> 
- You are dealing with Database Information. 
- No matter what, STRICTLY use Database-Specific Language ALWAYS. 
- Use words like Columns / Fields / Schema / DataTypes / Constraints / Foreign Keys / Primary Keys etc.
- Strictly Do not start descriptions with or start with "this micro-feature" / or "this sub-feature".
- You shall do this regardless of the input context and nature.
Remember : Every "FILE" given to you is information of a table. Therefore in your response, ALWAYS refer to "Table" instead of "File".

</Strict Constraints> 


### ðŸ”§ TASK OVERVIEW

Given a Macro-Feature, Subfeature, its description, associated module files and its summary:

- Decide if the subfeature should be split horizontally into multiple same-level subfeatures.
- For each resulting subfeature (or original if not split), analyze whether it can be split vertically into **microsubfeatures** (fine-grained user stories).
- Provide the confidence scores for the subfeature that is split, whether horizontally or vertically.
- Provide the files that are related to the sub_features too, not just the micro_sub_features.
- Each leaf user-story must have files assigned to them, else you should not create/split these subfeatures.
- Provide description of generated subfeature/sub-user-stories in 2-4 lines but only valid information. Do not assume or hallucinate to generate description.
Apply this recursively: if horizontal splitting occurs, then attempt vertical splitting for each. But remember, not to create any duplicates in the process. 

---

### SPLITTING DECISIONS

#### Horizontal Splitting (Same-level Subfeatures):
Split if:
- The subfeature covers ONE / MORE THAN ONE high-level functionalities
- Each function could be planned and developed independently
- Each component has some clear boundaries and responsibilities

#### Vertical Splitting (Microsubfeatures):
Split further if:
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across actions are too complex to isolate.
- There are no tables that can be mapped to the generated user-story.
- The subfeature is too complex to be planned, developed, and deployed independently
- Each micro-subfeature represents one atomic, non-overlapping functionality
Note: Maintain at least 2 subfeatures unless the database has only one table.
- Prioritize brevity, consistency and no informaiton leakage across subfeatures.
- Ensure crisp segregation.
---

### DO NOT SPLIT IF:
- sub-user-stories are tightly coupled in the Subfeature and cannot function independently.
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across tables in two features are too complex to isolate.
- There are no tables that can be mapped to the generated user-story.
Note: Maintain at least 2 subfeatures and 1 or more microsubfeatures per subfeature, Unless the database has only one table.
Note : Maintain brevity during splitting at the same level. Do NOT overload the a single feature with too many subfeatures.
---


### FILE MAPPING RULES:
- For each subfeature or microsubfeature, cite only directly relevant tables.
- Use only the provided input data to match files â€” no guessing.
- Avoid duplication unless a file is clearly shared between components.

Each `file_path` entry must include:
```json
{
  "module_name": "<Name>",
  "path": "<Path>",
  "critical": <true/false>,
  "git_url": "<Git URL>"
}

OUTPUT FORMAT
If the subfeature should NOT be split:
Return: "None"

If the subfeature should be split, return a list of Parent User Stories with subfeatures inside.
If a subfeature itself can be further split into microsubfeatures, nest them under micro_sub_features like so:

[
  {
    "name": "Parent User Story Title 1",
    "description": "Full description of the original or updated user story and its purpose.",
    "file_path": [...],
    "sub_feature_confidence_score":"confidence score of the subfeature with respect to the Feature, as a percentage (e.g., 80)"
    "micro_sub_features": [
      {
        "name": "Sub-User Story Title 1",
        "description": "Standalone description of a single functionality.",
        "file_path": [...],
        "micro_sub_feature_confidence_score":"confidence score of the micro_sub_feature with respect to the sub_feature, as a percentage (e.g., 90)"
        }
          ...
        ]
      },
      ...
    ]
  }
]
Each layer must preserve independence, clarity, and singular focus of each story.

VALIDATION CHECKLIST
- Each title must express one functionality only (no imperative phrasing)
- description must avoid assumptions and describe the real function. It must be as detailled as possible.
- Each story must make sense independently and fit in the broader feature flow
- if there are multiple user-story under the subfeature, it needs to be in sequence of business logic.
- File mappings must be relevant and scoped accurately
- Do no miss/skip any values in the output json. The output structure must be maintained strictly.
- All subfeature and sub-user-story names and descriptions must be strictly in a declarative tone, not imperative.
- Use Database-specific schema only. Do not include words like "Attributes" / "Code Files" in your response. 
- Strictly Do not start descriptions with or start with "this micro-feature" / or "this sub-feature".
* Use generic or speculative statements

"""import os
from graphviz import Digraph
import re 
import json

def parse_ddl(ddl: str):
    """
    Parse the DDL to extract columns, primary keys, and foreign keys.
    """
    lines = ddl.splitlines()
    column_lines = []

    for line in lines:
        line = line.strip()
        if (
            line.upper().startswith("CREATE")
            or line.upper().startswith("PRIMARY")
            or line.upper().startswith("FOREIGN")
            or line.upper().startswith(")")
            or line == ""
        ):
            continue

        match = re.match(r'(\w+)\s+\w+', line)
        if match:
            column_lines.append(match.group(1))

    pk_match = re.search(r'PRIMARY KEY\s*\((.*?)\)', ddl)
    primary_keys = [key.strip() for key in pk_match.group(1).split(",")] if pk_match else []

    foreign_keys = []
    for match in re.finditer(r'FOREIGN KEY\s*\(([^)]+)\)\s+REFERENCES\s+`?[\w]+\.(\w+)`\(([^)]+)\)', ddl):
        fk_col = match.group(1).strip()
        ref_table = match.group(2).strip()
        ref_col = match.group(3).strip()
        foreign_keys.append((fk_col, ref_table, ref_col))

    return column_lines, primary_keys, foreign_keys


def generate_combined_graph(tables_data):
    """
    Generate a single combined graph from multiple tables.
    """
    dot = Digraph(comment='Combined Table Diagram')
    dot.attr(rankdir='LR')

    # Store individual table nodes
    for table in tables_data:
        table_name = table['table_name']
        columns = table['columns']
        primary_keys = table['primary_keys']
        
        label_lines = []
        for col in columns:
            if col in primary_keys:
                label_lines.append(f"{col} [PK]")
            else:
                label_lines.append(col)
        dot.node(table_name, shape='box', label=f'{table_name}\\n' + "\\n".join(label_lines))

    # Add relationships
    for table in tables_data:
        table_name = table['table_name']
        for fk_col, ref_table, ref_col in table['foreign_keys']:
            dot.edge(table_name, ref_table, label=f'{fk_col} â†’ {ref_col}')

    return dot

def folder_summary_generation_prompts(
        total_allocated_tokens, 
        file_list, folder_name, 
        folder_path,
        subfolder_list,
        formatted_file_summaries,
        formatted_file_services,
        formatted_subfolder_summaries,
        formatted_subfolder_services,
        formatted_subfolder_features
    ):
    
    system_prompt = f"""
        You are an expert code analyst specialized in creating detailed, informative summaries of software project folders. Your task is to thoroughly analyze files and subfolders to provide a comprehensive understanding of the application or project and provide combined summaries along with required details. These summaries must be detailled enough for further summarization.

        Follow these guidelines:
        1. Conduct a deep analysis of the features to identify its core purpose and functionality
        2. Provide detailed explanation of key implementations and technical approaches of the features
        3. Thoroughly examine the summaries based on files and folders to understand relationship between features and combined smaller features into larger high level application level features.
        4. Explain the features within the broader project architecture with specific connections
        5. Describe technical patterns, design decisions, and architectural choices evident in the code
        6. Include specific functions, classes, and methods that define the feature's behavior
        7. Note dependencies, imports, and external connections that shape the folder's functionality
        8. Identify potential architectural strengths and areas for improvement when evident
        9. Identify all services represented in this folder based on file and subfolder services information
        10. Identify and articulate high-level features or functionalities represented by the folder into the feature_details section, when consolidating multiple subfolders or lower-level files. Derive these insights from both file-level and subfolder-level summaries. Also under each feature, mention which file/folder was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
        11. Do not miss any features that could be formed based on these summaries as this information is required to understand the application's buisness logic.
        12. Gather insights from the summaries provided to generate a high level detailled executive summary that could be used by business stakeholders to understand the folder/project.
        13. When analyzing the root folder, both the executive summary and the features must be strictly formed in a high level business logic standpoint of an application.
        
        IMPORTANT: 
        - Your summary should be thorough and detailed({total_allocated_tokens}) while maintaining technical/business precision and depth. Focus on providing insights that would help both stakeholders and developers understand the application better.
        - feature_details must contain high level feature name and feature description(value of the files/folders) strictly in concise bullet points. The feature inforamtion must be in detail to capture the complete high level knowledge for that feature but not the function level details. Feature names cannot be programmatic function names like Dependency management, json handling etc. instead it should be inventory management, order processing etc. 
        - Your services list should be comprehensive and include all services represented in this folder.
        - is_reuasble_lib if a folder is used as reusable lib make it True otherwise False
        - lib_name if is_reusable_lib is True then provide the name of the reusable lib/component If is_reusable_lib False then add Not Applicable
        - category if is_reusable_lib is True then provide category only between 'Frontend' and 'Backend' If is_reusable_lib False then add Not Applicable
        - sub_category if is_reusable_lib is True then provide sub category only between 'UI Component','Custom Hooks', 'http_client', 'Utils', 'Others' In Frontend & 'Middleware', 'Error Handling', 'Auth', 'Utils', 'Others' In Backend If is_reusable_lib False then add Not Applicable
        - when_to_use if is_reusable_lib is True then provide where this reusable lib/component can be used If is_reusable_lib False then add Not Applicable 
        - associated_files if is_reusable_lib is True then provide the list of files associated(give complete path for the assosciated file) with this reusable lib/component If is_reusable_lib False then add Not Applicable
        - summary must not be technical and only explain the high level details of the folder/project. Understand the file and folder summaries provided to combine the knowledge to form the executive summary. Make it as detailled as possible.
        - Use clear and concise language, avoiding jargon where possible.
        
        - You must provide your response in this exact format:
        ```summary
        [Your detailled high-level executive summary for the folder for business stakeholders]
        ```
        ```feature_details
        [List of high-level features or functionalities represented in this folder]
        ```
        ```services_namess
        [Comma-separated list of all services represented in this folder]
        ```
        ```is_reuasble_lib
        Boolean Value
        ```
        ```lib_name
        [Name of the reusable library if applicable]
        ```
        ```category
        [Category of the reusable library if applicable]
        ```
        ```sub_category
            [Sub category of the reusable library if applicable]
        ```
        ```when_to_use
        [Your detailed use case where or when this reuasble_lib can be usefull]
        ```
        ```associated_files
            [Comma-separated list of associated files with the reusable library, Give the Complete file path as mentioned in the file list]
        ```
        ```example_usage
            [Example code snippet of how to use this reusable library]
        ```
    """

    user_prompt = f"""
        Generate a summary and services list for the folder: "{folder_name}" (Path: {folder_path})

        FOLDER CONTENTS:
        - Files ({len(file_list)}): {", ".join(file_list) if file_list else "None"}
        - Subfolders ({len(subfolder_list)}): {", ".join(subfolder_list) if subfolder_list else "None"}

        FILE SUMMARIES:
        {os.linesep.join(formatted_file_summaries) if formatted_file_summaries else "No file summaries available"}

        FILE SERVICES:
        {os.linesep.join(formatted_file_services) if formatted_file_services else "No file services available"}

        SUBFOLDER SUMMARIES:
        {os.linesep.join(formatted_subfolder_summaries) if formatted_subfolder_summaries else "No subfolder summaries available"}

        SUBFOLDER SERVICES:
        {os.linesep.join(formatted_subfolder_services) if formatted_subfolder_services else "No subfolder services available"}

        SUBFOLDER FEATURES:
        {os.linesep.join(formatted_subfolder_features) if formatted_subfolder_features else "No subfolder features available"}
        
        Based on these components:
        1. Provide a thorough technical summary explaining the folder's purpose, implementation details, and architectural significance
        2. Compile a comprehensive list of all services represented in this folder based on file and subfolder services information
        
        Follow the exact format specified in the system instructions for your response.
    """

    return system_prompt, user_prompt

def services_generation():
    system_prompt = """
        <Task>
        Create an architectural blueprint of the given repository by identifying and classifying both external services and third-party services with no overlap between categories.
        </Task>

        <Definitions>
        - External services: Company-provided services hosted outside the application (AWS S3, Google Cloud, Stripe, Twilio)
        - Third-party services: Libraries, frameworks, and SDKs that are part of the core application stack (Django, React, MongoDB, Redux)
        </Definitions>

        <Output_Format>
        {
        "external_services": [
            {
            "external_service_name": "string",
            "description": "string",
            "associated_files": ["string"],
            "service_class": "string",
            "used_in_files": ["string"]
            }
        ],
        "thirdparty_services": [
            {
            "thirdparty_service_name": "string",
            "description": "string",
            "associated_files": ["string"],
            "service_class": "string",
            "used_in_files": ["string"]
            }
        ]
        }
        </Output_Format>

        <Instructions>
        1. Conduct a thorough repository analysis to identify all services
        2. Classify each service into exactly ONE category:
        - External services: Cloud platforms, payment processors, authentication providers
        - Third-party services: Frameworks, libraries, SDKs integrated into the codebase
        3. For each service, provide:
        - Name: Exact service name
        - Description: Concise explanation of functionality and purpose
        - Associated files: All files directly importing or using the service
        - Service class: Category (e.g., "cloud storage", "web framework", "database")
        - Used in files: Complete paths of files utilizing the service
        4. Ensure ZERO overlap between categories
        5. Prioritize accuracy over comprehensiveness
        6. Validate that identified services are actively used in the project
        7. Include only services with clear evidence of implementation
        8. Do not create a lot of services which are redundant. Keep it to a maximum of 50 services only.
        </Instructions>

        <Examples>
        Good External Service Entry:
        {
        "external_service_name": "AWS S3",
        "description": "Cloud storage service used for storing user-uploaded files",
        "associated_files": ["src/services/storage.js", "src/config/aws.js"],
        "service_class": "cloud storage",
        "used_in_files": ["src/components/FileUpload.js", "src/pages/UserProfile.js"]
        }

        Good Third-Party Service Entry:
        {
        "thirdparty_service_name": "React",
        "description": "Frontend JavaScript library for building user interfaces",
        "associated_files": ["package.json", "src/index.js"],
        "service_class": "frontend framework",
        "used_in_files": ["src/App.js", "src/components/*.js"]
        }
        </Examples>

        Analyze the repository and provide the complete architectural blueprint in the specified format.
    """

    user_prompt = ""

    return system_prompt, user_prompt

def executive_summary_generation(combined_summary, user_mvf):
    system_prompt = """
    Your Role:
    You are an expert software architect tasked with understanding a codebase and creating an executive summary that clearly articulates the main purpose of this application,
    the core problem that the application is solving, and the prioritized list of the most valuable features, solely based on the provided folder wise summary. Do not hallucinate and create the most valuable features and its description on assumption. This needs to be based on facts.

    Task:
    1. Analyze provided folder wise summary and the services used and the user defined features (if provided).
    2. Understand component interactions and functions.
    3. Prioritize the User Defined Features (if provided) in the summary.
    4. Identify and prioritize the most valuable features based on their importance and relevance to the overall project, as evidenced in the code.
    5. Create a comprehensive executive summary.

    Steps:
    1. Review folder wise summary.
    2. Analyze folder wise summary:
    - Identify key components and their roles
    - Note data operations, design patterns, and architectural decisions
    3. Create summary:
    - Describe the specific problem the codebase solves, based on folder wise summary
    - Explain component interactions
    - Outline data workflow
    4. Identify and prioritize main features:
    - Determine which feature(s) address the core problem of the application, based on code implementation
    - Rank features based on their importance and relevance to solving the main problem, as evidenced in the code
    - The feature should be major components of the codebase and not minor functions like "Modular Architecture" or "Code Reusability", these are not features but design principles.

    Focus Areas:
    - Precised feature prioritization and importance
    - High-level functionality
    - Clear, concise technical language
    - Objective description
    - Capture entire workflow

    Guidelines:
    - Only use the folder wise summary provided
    - Use precise technical terms
    - Include user-defined features if provided and evidenced in the code
    - Prioritize features based on their importance to the core problem, as shown in the folder wise summary

    Feature Identification and Prioritization:
    - Carefully analyze the folder wise summary to identify features actually present in the folder wise summary
    - Do not assume or infer features that are not explicitly mentioned in the folder wise summary
    - Identify the top feature that solves the majority of the problem based on code evidence
    - Rank subsequent features in descending order of importance, ensuring they are present in the folder wise summary
    - Ensure the feature list reflects the codebase's focus and structure
    - Only include features that have substantial implementation in the codebase that is evident from folder wise summary

    Output Format - Adhering to this format is crucial
    ```json
    {
    "data": "generated_summary in string format adhering to the Expected Output Format for Generated Summary",
    "confidence_score": 90,
    "traceback": {
    "Feature 1 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 1 Title' is included, as the 'phrase' is an evidence that this feature is part of the codebase.",
    "Feature 2 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 2 Title' is included, as the 'phrase' is an evidence that this feature is part of the codebase.",
    ...
    }
    }
    ```

    Requirements:
    - Replace \n with \\n in JSON
    - Limit upto 5 main features (max 2 sub-features each) or 7500 tokens
    - If due to any reason such as codebase being small, you are unable to provide 5 features, then provide as many high-level features as possible between the range of 1 to 5.
    - Don't assume features or include minor features due to inability to provide 5 features, lesser number of features is acceptable.
    - Use specified JSON format only
    - Start with "```json" and end with "```"
    - Ensure the top feature in the prioritized list addresses the core problem and is present in the folder wise summary
    - Rank features in descending order of importance to the main problem, based on actual code implementation
    - Do NOT include features that are NOT evidenced in the provided folder wise summary
    - Evaluate the folder wise summary objectively, considering all conclusions on the actual code provided
    - Do NOT make any assumptions about organizational goals or intentions beyond what is explicitly shown in the code
    - Focus solely on the technical aspects and implemented functionality, avoiding speculation about business objectives or future plans
    - Both the keys data, confidence score, and traceback should be present in the output JSON
    - The generated summary should be in string format only and be contained inside the "data" key
    - The "traceback" key should contain a dictionary with feature names as keys and justifications for including these features based on exact phrases from the input
    - Do not include any feature that could potentially be part of the folder wise summary without explicit evidence
    - Every feature mentioned must be driven by clear evidence from the provided input
    """
    user_prompt = """
    Expected Output Format for Generated Summary:

  **Overview**
  <empty line>
  <A brief introduction to the codebase and its main purpose; in paragraph format only, not in points.
  This paragraph should provide a concise yet comprehensive overview of the codebase, its primary functionality, solution provided by the project and its intended use case.
  Aim for 3-5 sentences that capture the essence of the project.>
  <empty line>
  **Highlighted Features**
  <empty line>
  <
  List and briefly explain the key features that are significant components of the codebase and would serve as selling points.
  These features should be presented as follows:
  1. Use numbered points for each feature.
  2. Provide a brief explanation for each feature in 1-2 sentences, highlighting its importance and benefit to the end user.
  3. Focus on features that are central to the codebase's functionality and most important to the end user.
  4. Dont include generic features like "Modular Architecture" or "Code Reusability", these are not features but design principles.
  5. Do not include sub-points under any feature.
  6. Prioritize User Defined Features (if provided) at the beginning of the list.
  7. If User Defined Features are given, list them first before including any features identified through your analysis.
  8. Aim to provide upto of 1 to 5 key features, after each feature add an empty line for formatting purposes.
  9. Ensure that the features listed represent the core functionality and unique selling points based on the folder wise summary.
  10. Use clear, concise language that emphasizes the value proposition of each feature.
  11. Also under each feature, mention which file/folder was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
  12. Do not add features into Highlighted Features if they dont have value for buisness stakeholder about the application. Also do not repeat adding similar feature in this section.

  Output Structure:
  1. ***<Feature 1 Title>***: <Description of the feature in one to two sentences.\n
  2. ***<Feature 2 Title>***: <Description of the feature in one to two sentences.>\n
  >
  <empty line>
  **Key Benefits**
  <empty line>
  <Summarize the key benefits of the codebase in one to two sentences.
  This summary should encapsulate the overall value proposition of the codebase and its potential impact on users or the organization.>
  <empty line>
  <Highlight the most significant key benefits the codebase has to offer in bulleted points. The format should be:
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  Aim for 3-5 bullet points that capture the most compelling advantages of using this codebase, after each point add an empty line for formatting purposes.
  Each benefit should be distinct and provide a clear value proposition.>

  <Final Output Format>
  Output Format - Adhering to this format is crucial, the output should be in parsable JSON format:
  ```json
  {{
    "data": "<generated_summary in string format adhering to the Expected Output Format for Generated Summary>",
    "confidence_score": 90,
    "traceback": {{
      "Feature 1 Title": "Since it mentions about <exact phrase from the folder wise summary>, the 'Feature 1 Title' is included, as the "phrase" is an evidence that this feature is part of the folder wise summary.",
      "Feature 2 Title": "Since it mentions about <exact phrase from the folder wise summary>, the 'Feature 2 Title' is included, as the "phrase" is an evidence that this feature is part of the folder wise summary.",
      ...
    }}
  }}
  ```
  </Final Output Format>
  Note: If the traceback includes phrases that are not present in the folder wise summary then you would be penalized 10000 points.
  The output should be having data, confidence score, and traceback keys, and the entire content inside "```json" and "```" should be parsable by json.
  The "data" key should contain the generated summary and it should be in string format only, allowing the parsing of the entire json.
  If there are any inverted commas inside the generated summary, then escape them with a backslash.
  Do not change or skip the headings of each section in the generated json. The generated summary must have "Overview", "Highlighted Features", "Key Benefits" as section titles. Follow the above provided guidelines."""
    user_prompt += f"""Use the below folder wise summary to generate the summary in the above format: {combined_summary}""" + "User Defined Features : " + str(user_mvf)
    return system_prompt, user_prompt

def db_executive_summary_generation(combined_summary, user_mvf): 
    system_prompt = """
    Role:
    You are an expert Database Architect tasked with understanding the contents of all tables and schema of the database. 
    You shall Articulate a proper executive summary that clearly captures all the main & high-level features of this database.
    The core use-case that this database is intended for, and the prioritized list of the most valuable features, solely based on the provided Table-Level summaries. 
    Do not hallucinate. Do NOT create the most valuable features and its description on pure assumptions. This needs to be based on facts, with proper backing.

    Task:
    1. Analyze provided Table wise summaries.
    2. Understand component interactions and functions.
    3. Prioritize the User Defined Features (if provided) in the summary.
    4. Identify and prioritize the most valuable features based on their importance to the core use-case the Database is solving.
    5. Create a comprehensive executive summary.

    Steps:
    1. Review Table wise summary.
    2. Analyze Table wise summary:
      - Identify all tables. 
      - Take into consideration the foreign keys, primary keys, is-a, has-a, and many-to-many relationships.
      - Deeply understand the intended-use-case of each table.
      - Note data operations, design patterns, and architectural decisions
    3. Create summary:
      - Describe the specific problem the Database is solving, based on Table wise summary
      - Explain high-level interactions and dependencies
      - Outline data workflow
    4. Identify and prioritize main features:
      - Determine which feature(s) address the core problem of the Database, based on SQL implementation and Table wise summary
      - Rank features based on their importance and relevance to solving the main problem, as evidenced in the Database
      - The feature should be major components of the Database and not minor functions like Many-to-Many Relationships, or "Foreign Keys". 
        These are implementation concepts. Not core features.

    Focus Areas:
    - Precised feature prioritization and importance
    - High-level functionality of this Database
    - Clear, concise technical language with Database-specific Language
    - Objective description
    - Capture entire data workflow

    Guidelines:
    - Only use the Table wise summary provided
    - Use precise Database-relevant technical terms
    - Include user-defined features if provided and evidenced in the Table wise summary
    - Prioritize features based on their importance to the core problem, as shown in the Table wise summary

    Feature Identification and Prioritization:
    - Carefully analyze the Table wise summary to identify features actually present in the Table wise summary
    - Do not assume or infer features that are not explicitly mentioned in the Table wise summary
    - Identify the top feature that solves the majority of the problem based on Database and SQL evidence
    - Rank subsequent features in descending order of importance, ensuring they are present in the Table wise summary
    - Ensure the feature list reflects the Database's focus and structure
    - Only include features that have substantial implementation in the Database that is evident from Table wise summary

    Output Format - Adhering to this format is crucial
    ```json
    {
    "data": "generated_summary in string format adhering to the Expected Output Format for Generated Summary",
    "confidence_score": 90,
    "traceback": {
    "Feature 1 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 1 Title' is included, as the 'phrase' is an evidence that this feature is part of the Database.",
    "Feature 2 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 2 Title' is included, as the 'phrase' is an evidence that this feature is part of the Database.",
    ...
    }
    }
    ```

    Requirements:
    - Replace \n with \\n in JSON
    - Limit upto 5 main features (max 2 sub-features each) or 7500 tokens
    - If due to any reason such as Database being small, you are unable to provide 5 features, then provide as many high-level features as possible between the range of 1 to 5.
    - Don't assume features or include minor features due to inability to provide 5 features, lesser number of features is acceptable.
    - Use specified JSON format only
    - Start with "```json" and end with "```"
    - Ensure the top feature in the prioritized list addresses the core problem and is present in the Table wise summary
    - Rank features in descending order of importance to the main problem, based on actual Database and SQL implementation
    - Do NOT include features that are NOT evidenced in the provided Table wise summary
    - Evaluate the Table wise summary objectively, considering all conclusions on the actual Database and SQL provided
    - Do NOT make any assumptions about organizational goals or intentions beyond what is explicitly shown in the Database and SQL
    - Focus solely on the technical aspects and implemented functionality, avoiding speculation about business objectives or future plans
    - Both the keys data, confidence score, and traceback should be present in the output JSON
    - The generated summary should be in string format only and be contained inside the "data" key
    - The "traceback" key should contain a dictionary with feature names as keys and justifications for including these features based on exact phrases from the input
    - Do not include any feature that could potentially be part of the Table wise summary without explicit evidence
    - Every feature mentioned must be driven by clear evidence from the provided input.
    - Strictly use an assertive and objective tone in your response. 
    - Do not be unsure about anything.
    - Do not include the "Folder Name" in your response. Ignore "dbanalysis" folder. Provide Executive Summary of the Database-ONLY.
    """

    user_prompt = """
  Expected Output Format for Generated Summary:

  **Overview**
  <empty line>
  <A brief introduction to the Database and its main purpose; in paragraph format only, not in points.
  This paragraph should provide a concise yet comprehensive overview of the Database, its primary functionality, and its intended use case.
  Aim for 3-5 sentences that capture the essence of the Database.>
  <empty line>
  **Highlighted Features**
  <empty line>
  <
  List and briefly explain the key features that are significant components of the Database and would serve as selling points.
  These features should be presented as follows:
  1. Use numbered points for each feature.
  2. Provide a brief explanation for each feature in 1-2 sentences, highlighting its importance and benefit to the END USER.
  3. Focus on features that are central to the Database's functionality and most important to the END USER.
  4. Dont include generic features like  Many-to-Many Relationships, or "Foreign Keys", these are not features but Design Principles.
  5. Do not include sub-points under any feature.
  6. Prioritize User Defined Features (if provided) at the beginning of the list.
  7. If User Defined Features are given, list them first before including any features identified through your analysis.
  8. Aim to provide upto of 1 to 5 key features, after each feature add an empty line for formatting purposes.
  9. Ensure that the features listed represent the core functionality and unique selling points based on the Table wise summary.
  10. Use clear, concise language that emphasizes the value proposition of each feature.
  11. Also under each feature, mention which file/Table was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
  12. Do not add features into Highlighted Features if they dont have value for buisness stakeholder about the application. Also do not repeat adding similar feature in this section.

  Output Structure:
  1. ***<Feature 1 Title>***: <Description of the feature in one to two sentences.\n
  2. ***<Feature 2 Title>***: <Description of the feature in one to two sentences.>\n
  >
  <empty line>
  **Key Benefits**
  <empty line>
  <Summarize the key benefits of the Database in one to two sentences.
  This summary should encapsulate the overall value proposition of the Database and its potential impact on users or the organization.>
  <empty line>
  <Highlight the most significant key benefits the Database has to offer in bulleted points. The format should be:
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  Aim for 3-5 bullet points that capture the most compelling advantages of using this Database, after each point add an empty line for formatting purposes.
  Each benefit should be distinct and provide a clear value proposition.>

  <Final Output Format>
  Output Format - Adhering to this format is crucial, the output should be in parsable JSON format:
  ```json
  {{
    "data": "<generated_summary in string format adhering to the Expected Output Format for Generated Summary>",
    "confidence_score": 90,
    "traceback": {{
      "Feature 1 Title": "Since it mentions about <exact phrase from the Table wise summary>, the 'Feature 1 Title' is included, as the "phrase" is an evidence that this feature is part of the Table wise summary.",
      "Feature 2 Title": "Since it mentions about <exact phrase from the Table wise summary>, the 'Feature 2 Title' is included, as the "phrase" is an evidence that this feature is part of the Table wise summary.",
      ...
    }}
  }}
  ```
  </Final Output Format>
  Note: If the traceback includes phrases that are not present in the Table wise summary then you would be penalized 10000 points.
  The output should be having data, confidence score, and traceback keys, and the entire content inside "```json" and "```" should be parsable by json.
  The "data" key should contain the generated summary and it should be in string format only, allowing the parsing of the entire json.
  If there are any inverted commas inside the generated summary, then escape them with a backslash.
  Do not change or skip the headings of each section in the generated json. The generated summary must have "Overview", "Highlighted Features", "Key Benefits" as section titles. Follow the above provided guidelines.
    """

    user_prompt += f"""Use the below Table wise summary to generate the summary in the above format: {combined_summary}""" + "User Defined Features : " + str(user_mvf)

    return system_prompt, user_prompt


def architecture_diagram_generation(services_data, icons_metadata):
    user_prompt = f"""
    <Input>
    $services_data = {services_data}
    $icons_metadata
    </Input>

    <Role>
    You are an expert at understanding large projects based on their executive summary and the services being used in them. Create a JSON structure for a ReactFlow diagram based on the given service class JSON.
    </Role>

    <Output Structure>
    1. Create a JSON object with a "nodes" and "edges" array.
    2. Create nodes for each external and third-party service.
    3. "nodes": An array containing all node objects.
      - "id": A unique string identifier for the node.
      - "data":   
        - "label": The name of the node.
        - "description": Description of the service.
        - "associated_files": Associated file and used in files in the service node, defaulting to "No File Available" if not present.
        - "group": The logical group name (e.g., 'Backend', 'Frontend', 'Database',etc..).
        - "subgroup": The specific subgroup within the group (e.g., Frameworks, NoSQL Databases, State Management, etc.).
        - "service": The appropriate filename of the icon based on the $icons_metadata.
      - "position" : The x and y coordinates of the node.
      - "type" : "customNode" This should be fixed.
    4. "edges" : An array having id, source, target, label, and type should be customEdge always.
    4. Ensure all services and files from the input JSON are included.
    5. The output should be in the form of a dictionary containing a "nodes" and "edges" array.
    6. Present only the code inside delimiters "```reactflow [reactflow CODE]```" without any additional explanation.
    """

    system_prompt:str = """
    <Task>
      You are tasked with creating a JSON structure for a ReactFlow diagram based on the given executive summary and the service_class_json. The executive summary contains an overview of the entire project. This JSON includes information about external services and third-party services, along with their associated files. Your output should represent this information as a network of nodes and edges.
    </Task>
    
    <Icons Context>
      $icons_metadata = """ + str(icons_metadata) + """
    </Icons Context>

    <Instructions>
      You are a solution expert, specializing in problem and solution flows. You will be given the solution overview for a project, and your task is to create an interconnected single component of graph which is detailed, and intuitive and self explanatory for:

      Follow these guidelines:
      1. Create nodes for each unique service (both external and third-party).
      2. Do not create any group nodes.
      4. In the data key for each service node, include two additional fields called group and subgroup. The group field should contain the logical group name (e.g., Frontend, Backend, Databases, etc..), and the subgroup field should provide more specific categorization (e.g., Frameworks, NoSQL Databases, etc..). For example, for a service node representing React, the group would be Frontend and the subgroup would be Frameworks.
      5. For each node, check which icon will be the most suitable from the $icons_metadata in the <Icons Context>
      6. Ensure all information from the input is represented in the output.
      7. The position coordinates must be proper for all the nodes.
    </Instructions>

    <Rules>
      **Ensure all nodes in the generated graph are interconnected such that every node has at least one edge, forming a single connected component without any isolated or disjoint sections. (High Priority Requirement)**
      Important Rules to be followed:
      1. Give detailed technical architecture flow and the JSON object following the below output format.
      2. Make sure that the flow and order of new solution approach is explained well in the graph with appropriate edges. Use as many edges you want to describe the data and user flow properly.
      3. The whole user and data flow should be clear.
      4. Do not add unnecessary nodes and edges. Do not create duplicate nodes that perform same task.
      5. Make the Node descriptions detailed, breaking tasks into multiple sub-tasks if needed.
      6. Ensure your edges show the actual flow, and not just connections of what's related. The connections are meant to show the logical flow, and not the relatedness/similarity.
      7. The group name is meant to classify clusters of nodes within each graph. For instance, if we have multiple nodes in features, they would all have "feature" as group. In Architecture Flow, the "Group" should show the layer each node is in, for instance "Backend Layer", "Database Layer" etc.
      9. for a hierarchy of nodes A -> B -> C; ensure that there is not a connection between A -> C.
    </Rules>
    
    <output_format>
    The output should be in between the delimeters ```reactflow and ```. Only provide the json output. Don't give unnecesary explanation.
    ```reactflow
    {
      "nodes": [
        { 
          "id": "unique_node_identifier_string",
          "data" : {
            "label": "name_of_the_service",
            "description": "description of the service",
            "associated_files": ["file_path_1", "file_path_2", "file_path_3", etc.],  // (default: ["No File Available"] if not present)
            "group": "name_of_group",  // Add the logical group name (e.g., "Frontend", "Backend", etc..)
            "subgroup": "name_of_subgroup",  // Add a more specific subgroup name (e.g., "Frameworks", "NoSQL Databases", etc..)
            "service": "filename" //taken from the $icons_metadata,
          }
          "position":{ "x": "Xcoordinate", "y": "Ycoordinate" },
          "type" : "customNode" //this is hardcoded and will be constant
        }
      ],
      "edges": [
        {
          "id": "unique_egde_identifier_string",
          "source": "label A",
          "target": "label B",
          "label": "Showcase what comes from the source node, to the target node. Be concise and specific with labels, such as 'Ingested Data', 'Converted Text', 'User Query' etc. Use at max 5 words",
          "type" : "customEdge" //this is hardcoded and will be constant
        }
      ]
    }```
    </output_format>
    """
    return system_prompt, user_prompt
  

def erd_generation(services_data, icons_metadata):
  tables_metadata = []
  for entry in services_data:
      table_name = entry["table_name"]
      ddl = entry["ddl"]
      columns, primary_keys, foreign_keys = parse_ddl(ddl)
      tables_metadata.append({
          "table_name": table_name,
          "columns": columns,
          "primary_keys": primary_keys,
          "foreign_keys": foreign_keys
      })

  dot = generate_combined_graph(tables_metadata)

  system_prompt:str = """
    You are tasked with creating a JSON structure for a ReactFlow diagram based on the given database ER diagram and schema JSON. This JSON includes information about database columns and their relationships.Your output should represent this information as a network of nodes and edges.
    </Task>
    
    <Icons Context>
      $icons_metadata = """ + str(icons_metadata) + """
    </Icons Context>

    <Instructions>
      You are a solution expert, specializing in problem and solution flows. You will be given the database schema information of a database, and your task is to create an interconnected single component of graph which is detailed, and intuitive and self explanatory for:

      Follow these guidelines:
      1. Create nodes for each unique service (both external and third-party).
      2. Do not create any group nodes.
      4. In the data key for each service node, include two additional fields called group and subgroup. The group field should contain the logical group name (e.g.,Databases, etc..), and the subgroup field should provide more specific categorization (e.g., 'Transactional Tables', 'Reference Tables' etc..). For example, for a service node representing daily transactions, the group would be Database and the subgroup would be Transactional Tables.
      5. For each node, check which icon will be the most suitable from the $icons_metadata in the <Icons Context>
      6. Ensure all information from the input is represented in the output.
      7. The position coordinates must be proper for all the nodes.
    </Instructions>

    <Rules>
      Important Rules to be followed:
      1. Give detailed technical architecture flow and the JSON object following the below output format.
      2. Make sure that the flow and order of new solution approach is explained well in the graph with appropriate edges. Use as many edges you want to describe the data and user flow properly.
      3. The whole user and data flow should be clear.
      4. Do not add unnecessary nodes and edges. Do not create duplicate nodes that perform same task.
      5. Make the Node descriptions detailed, breaking tasks into multiple sub-tasks if needed.
      6. Ensure your edges show the actual flow, and not just connections of what's related. The connections are meant to show the logical flow, and not the relatedness/similarity.
      7. The group name is meant to classify clusters of nodes within each graph. For instance, if we have multiple nodes in features, they would all have "feature" as group. In Architecture Flow, the "Group" should show the layer each node is in, for instance "Database Layer" etc.
      9. for a hierarchy of nodes A -> B -> C; ensure that there is not a connection between A -> C.
    </Rules>
    
    <output_format>
    The output should be in between the delimeters ```reactflow and ```. Only provide the json output. Don't give unnecesary explanation.
    ```reactflow
    {
      "nodes": [
        { 
          "id": "unique_node_identifier_string",
          "data" : {
            "label": "name_of_the_table",
            "description": "description of the table",
  	    "columns": ["order_id [PK]", "product_sku [PK]", "quantity", "unit_price"]
            "group": "name_of_group",  // Add the logical group name (e.g., "Database", etc..)
            "subgroup": "name_of_subgroup",  // Add a more specific subgroup name (e.g., 'Transactional Tables', 'Reference Tables', etc..)
            "service": "filename" //taken from the $icons_metadata,
          }
          "position":{ "x": "Xcoordinate", "y": "Ycoordinate" },
          "type" : "customNode" //this is hardcoded and will be constant
        }
      ],
      "edges": [
        {
          "id": "unique_egde_identifier_string",
          "source": "label A",
          "target": "label B",
          "label": "Showcase what comes from the source node, to the target node. Be concise and specific with labels, such as 'Ingested Data', 'Converted Text', 'User Query' etc. Use at max 5 words",
          "type" : "customEdge" //this is hardcoded and will be constant
        }
      ]
    }```
    </output_format>
    """
    
  user_prompt:str = f"""
    <Input>
    $database_tables = {dot}
    $icons_metadata
    </Input>

    <Role>
    You are an expert at understanding database architecture based on ER diagrams and relational structures. Create a JSON structure for a ReactFlow diagram based on the given database schema.
    </Role>
    <Output Structure>
      1. Create a JSON object with a "nodes" and "edges" array.
      2. Create nodes for each table in the schema.
      3. "nodes": An array containing all node objects.
      - "id": A unique string identifier for the node.
      - "data":  
        - "label": The name of the table.
        - "description": A brief summary of the table's role or content.
        - "columns": List of column names (mark primary keys with [PK], foreign keys with [FK]).
        - "group": The logical group name (e.g., 'Database').
        - "subgroup": The specific subgroup within the group (e.g., 'Transactional Tables', 'Reference Tables').
        - "service": The appropriate filename of the icon based on the $icons_metadata.
      - "position" : The x and y coordinates of the node.
      - "type" : "customNode" This should be fixed.
      4. "edges" : An array having id, source, target, label, and type should be customEdge always.
      5. The label of the edge should describe the relationship, like "order_id â†’ order_id". 
      6. The output should be in the form of a dictionary containing a "nodes" and "edges" array.
      7. Present only the code inside delimiters "```reactflow [reactflow CODE]```" without any additional explanation.
    """
    
  return system_prompt, user_prompt
    

def feature_summary_generation(formatted_data, user_mvf, executive_summary):
    # if input_type is None:
    #     formatted_data = file_summary_list
    # elif input_type == "batch_summary":
    #     formatted_data = format_batchwise_summary_metadata_for_services(file_summary_list)
    # else:
    #     formatted_data = format_file_summaries(file_summary_list)

    user_prompt = """
    Role: You are an AI code analyst specializing in creating concise, feature-level summaries of codebases.

    Objective: Provide a comprehensive yet concise feature-level summary of a given codebase, highlighting key components, functionality, and the project's overall workflow.

    Input: You will receive information about a codebase, which may include an executive summary or other project details.

    Steps:
    1. Analyze the provided codebase information.
    2. Identify the main features (maximum 5) of the project from the executive summary (if provided in same order)
    3. Create a summary following the specified format, including:
        a. An overview of the project
        b. A list of key features with brief descriptions
        c. A closure statement
    4. Self-evaluate the generated summary and assign a confidence score.
    5. Format the output as specified in the instructions.

    Output Format:
    ```json
    {
        "data": "generated_summary in string format adhering to the Detailed Instructions for Output Format",
        "confidence_score": 90
    }
    ```

    Detailed Instructions for Output Format:

    **Overview**
    <empty line>
    < 
        Summarize all features in 2-3 sentences, introducing the project and its purpose.
        Provide a 2-3 sentence summary of key benefits, highlighting core architecture and value proposition.
    >
    <empty line>
    **Key Features**
    <empty line>
    <   
        List a maximum of 5 main features.
        For each feature, provide up to 2 sub-points describing its functionality.
        Ensure clear explanation of how features interact and contribute to the project's goals.
        1. ***<Key Feature Title>*** : 
        * <Sub point 1 description>
        * <Sub point 2 description>
        <empty line>
    >
    <empty line>
    < 
        Summarize the overall impact and value proposition of the project in one sentence as a conclusion statement.
    >
    <empty line>
    
    -> Self-Evaluation:
        - Score the summary out of 100 based on clarity, precision, detail, knowledge, accuracy, technical correctness, and understanding of the data.

    -> Formatting Requirements:
        - Replace all newline characters (\n) with \\n in the JSON output.
        - Ensure the complete JSON is less than 7500 tokens.
        - Start the output with "```json" and end with "```".
        - If an executive summary is provided, use only the highlighted features from it.

    Example Output Structure:
    ```json
    {
        "data": "**Overview**\\n\\n[Project overview]\\n\\n[Benefits summary]\\n\\n**Key Features**\\n\\n1. *Feature 1*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n2. *Feature 2*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n[...continue for up to 5 features...]\\n\\n[Closure statement]",
        "confidence_score": 90
    }
    ```

    Remember: Adhere strictly to the output format and instructions to maintain consistency and accuracy in your summary.
    """

    user_prompt += "User Defined Features : " + str(user_mvf)

    system_prompt = f"""
        <role>
        You are an assistant to a Senior Software Engineer. You are very capable in reading and understanding huge codebases.
        There is no edge-case, no mistake, no functionality no matter how small goes unnoticed by you.
        You will be given a large codebase and be asked queries regarding it.
        </role>

        <Task>
        You will be given relevant files from a production codebase. The Senior Engineer will consult you to clear his doubts and ask for critical code-level and functionality level analysis of the same.
        <Important>
        1. You will be clear. Feel free to be descriptive but Avoid Jargon
        2. You shall perform critical analysis on the code before responding.
        3. Note that the codebase will be quite complex and have dependencies everywhere, be mindful of them all.
        4. Enclose code in (triple backticks)``` code ```
        </Important>
        </Task>

        Files from Codebase goes here :
        <Repo Structure>
        {formatted_data}
        </Repo Structure>
    """

    start_index = executive_summary.find("Highlighted Features")
    end_index = executive_summary.find("Key Benefits")

    if start_index != -1 and end_index != -1:
        executive_summary = executive_summary[start_index:end_index].strip()

    user_prompt += "Executive Summary : " + str(executive_summary)

    return system_prompt, user_prompt

def feature_summary_generation_db(formatted_data, user_mvf, executive_summary):
    # if input_type is None:
    #     formatted_data = file_summary_list
    # elif input_type == "batch_summary":
    #     formatted_data = format_batchwise_summary_metadata_for_services(file_summary_list)
    # else:
    #     formatted_data = format_file_summaries(file_summary_list)

    user_prompt = """
    Role: You are an AI Database Analyst specializing in creating concise, feature-level summaries of complex database schemas and architectures.

    Objective: Provide a comprehensive yet concise feature-level summary of a given database schema information, highlighting key components, entities, relationships, and the overall data architecture workflow.

    Input: You will receive information about a database design, which may include an executive summary or other schema-level details.

    Steps:
    1. Analyze the provided database schema information.
    2. Identify the main features (maximum 5) of the database from the executive summary (if provided in same order)
    3. Create a summary following the specified format, including:
        a. An overview of the database
        b. A list of key features with brief descriptions
        c. A closure statement
    4. Self-evaluate the generated summary and assign a confidence score.
    5. Format the output as specified in the instructions.

    Output Format:
    ```json
    {
        "data": "generated_summary in string format adhering to the Detailed Instructions for Output Format",
        "confidence_score": 90
    }
    ```

    Detailed Instructions for Output Format:

    **Overview**
    <empty line>
    < 
        Summarize all features in 2-3 sentences, introducing the database and its purpose.
        Provide a 2-3 sentence summary of key benefits, highlighting schema structure, normalization or denormalization logic, and value proposition in handling data.
    >
    <empty line>
    **Key Features**
    <empty line>
    <   
        List a maximum of 5 main features.
        For each feature, provide up to 2 sub-points describing its data handling, relationships, or optimization logic.
        Ensure clear explanation of how features contribute to performance, consistency, and data integrity.
        1. ***<Key Feature Title>*** : 
        * <Sub point 1 description>
        * <Sub point 2 description>
        <empty line>
    >
    <empty line>
    < 
        Summarize the overall impact and value proposition of the database in one sentence as a conclusion statement.
    >
    <empty line>
    
    -> Self-Evaluation:
        - Score the summary out of 100 based on clarity, precision, detail, knowledge, accuracy, technical correctness, and understanding of the schema information.

    -> Formatting Requirements:
        - Replace all newline characters (\n) with \\n in the JSON output.
        - Ensure the complete JSON is less than 7500 tokens.
        - Start the output with "```json" and end with "```".
        - If an executive summary is provided, use only the highlighted features from it.

    Example Output Structure:
    ```json
    {
        "data": "**Overview**\\n\\n[Database overview]\\n\\n[Benefits summary]\\n\\n**Key Features**\\n\\n1. *Feature 1*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n2. *Feature 2*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n[...continue for up to 5 features...]\\n\\n[Closure statement]",
        "confidence_score": 90
    }
    ```

    Remember: Adhere strictly to the output format and instructions to maintain consistency and accuracy in your summary.
    """

    user_prompt += "User Defined Features : " + str(user_mvf)

    system_prompt = f"""
        <role>
        You are an assistant to a Senior Data Architect. You are very capable in reading, analyzing, and understanding complex database schemas and data models.
        No entity, constraint, relationship, or optimization logic goes unnoticed by you.
        You will be given a comprehensive database structure or schema information and will be asked to analyze, explain, and summarize it at a structural and functional level.
        </role>

        <Task>
        You will be given relevant database schema files or DDL definitions. The Senior Data Architect will consult you to clear doubts and ask for critical schema-level and data model-level analysis.
        <Important>
        1. You will be clear. Feel free to be descriptive but Avoid Jargon
        2. Perform a critical and deep analysis of the schema and the information given before responding.
        3. The schema will often involve multiple tables, foreign keys, views, procedures, and indexing strategies â€” be mindful of their dependencies and relationships.
        4. Enclose code or schema in (triple backticks)``` code ```
        </Important>
        </Task>

        Files from Database schema goes here :
        <Database Structure>
        {formatted_data}
        </Database Structure>
    """

    start_index = executive_summary.find("Highlighted Features")
    end_index = executive_summary.find("Key Benefits")

    if start_index != -1 and end_index != -1:
        executive_summary = executive_summary[start_index:end_index].strip()

    user_prompt += "Executive Summary : " + str(executive_summary)

    return system_prompt, user_prompt


#FEATURE HIERARCHY:
generate_features_system_prompt = """
  <Role>
    You are a Software Architect with expertise in analyzing large summaries from code files of an application. 
    You can comprehend summaries from code files that are complex, production-grade and are written in various programming languages to generate most important features, their description and the subfeatures with their description belonging to the most important features along with the other relevant information requested below.
    
    You will follow 2 Events before responding : 
    1. Generation of Feature Hierarchy as given in "Output_Format".
    2. Critical Evaluation of Every Confidence Score.  
  </Role> 

    <Task 1>
    You are provided with multiple relative file paths and file-wise code summaries from a application codebase.
    1. Analyze the file summaries carefully, leveraging your expertise to deduce the frameworks, functionality, and features.
    2. Perform a critical assessment of the code's functionality and interdependencies before responding.
    3. The codebase is complex and likely contains dependencies across various modules. Be mindful of these.
    4. Analyse every file summary and assign the features and sub-features based on the information provided.
    5. Respond strictly in the structured JSON format provided below.
    6. In each sub-feature's 'file_path' array:
        - Set 'critical: true' ONLY for files that are CORE & NON-REPLACEABLE to the sub-feature's main functionality.
        - Set 'critical: false' for ALL supporting, secondary, or replaceable files  
        - Each sub-feature should have both true and false entries.
        - If unsure, default to false (be EXTREMELY selective with 'true')
        - Make sure each sub-feature atleast have one file as true.

    Explanation of the Output terms:
    Feature - Features are most valuable and high level features extracted from the list of summaries that are provided to you. 
    Feature description - Description of the features explaining the high level value and impact that it creates for the project. Define the Feature. The description should be crisp, precise, well formatted and must be between 2-3 lines.
    Subfeature - Subfeatures are micro most valuable features that are extracted from the list of summaries and belong to the Most related and similar Features.
    Subfeature description - Description of the subfeatures explaining the specific value, technical and non-technical functionalites that it provided to the project. Define the subfeature and also explain how its related to the feature. The description should be crisp, precise, well formatted and must be between 2-3 lines.
    
    Points to Remember:
    1. Do not extract any feature or subfeature where there are no reference/citations from the application summaries.
    2. The description must be precise, valuable, well-formatted and must be between 2-3 lines.
    3. The Feature titles should be precise, specific, self explanaible, independent and not have similar feature titles. The Feature titles should not be highly generalized.
    4. The SubFeatures titles should be precise, self explanaible and not have similar subfeature titles. The SubFeature titles should not be highly generalized.
    5. SubFeatures should not be very low level that it explains code functions, code process like 'Json handling', 'Reading csv', readME etc.
    6. If similar subfeatures are present, then group them under one common Feature itself. Do not create multuple Features for similar subfeatures.
    6. If Unit testing related summaries are found, then create that as another Feature named 'Unit Testing' and assign the specific testing subfeatures under this feature.
    </Task 1>

  <Task 2>
  You shall now Assign and Justify Confidence Scores for each feature.

  <Critical Evaluation of Confidence Scores> 

  <Evaluation MODE>
  - You will now Forget everything that was done beforehand and act as an unbiased judge.
  - $Project-Summaries-&-Paths (INPUT).
  </Evaluation MODE>
  <Important>
  Critically analyze every "Feature" and "SubFeature" based on the following metrics. 
  You shall generate a confidence score between 0-100 for each of the following :
  1. Is the "Feature" & "SubFeature" name accurate to its functionality ? (Accuracy)
  2. Does the "Feature" & "SubFeature" include files with an unrelated function ? (Feature Dilution Rate)
  3. Important : Does this "Feature" & "SubFeature" make sense given the Overall Purpose of the Application ? (Consistency)
  4. Are all the files in "Feature" & "SubFeature" included ? (Completeness)

  <Strict>
  1. You will now generate a list of 4 confidence scores between 0-100 for above criteria under "confidence_score" key.
  2. Based on above criteria, you shall provide a VERY BRIEF logical explanation (10-20 words) for Confidence Score under "confidence_score_justification" key.
  3. Make sure to mention the entire filepath without omitting the prefix.
  4. Make sure all the filepaths are present.
  <Important> STRICTLY Don't Comment on Missing Files. Don't Overestimate. Don't Underestimate.</Important> 
  </Strict>

  </Important>

  </Critical Evaluation of Confidence Scores> 
  </Step 2>


      <Output_Format>
    Return a response in JSON format. Do not include any extra information or explanations. Strictly DON'T deviate from mentioned KEYS.
    Example:
```json
[
  {
    "name": "User Authentication and Management",
    "feature_description": "Comprehensive user account system with secure login, registration, profile management, and role-based access control.",
    "feature_description_confidence_score": [95, 70, 100, 70],
    "sub_features": [
      {
        "name": "User Registration",
        "description": "Allows new users to create accounts by providing necessary information such as username, email, and password. Implements email verification, password strength checks, and duplicate account prevention. Stores user data securely in the database with password hashing.",
        "file_path": [
          {
            "module_name": "RegistrationController",
            "path": "Controllers/Account/RegistrationController.cs",
            "critical": true
          },
          {
            "module_name": "RegisterView",
            "path": "Views/Account/Register.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [75, 80, 85, 65],
        "sub_feature_confidence_score_justification": "No feature dilution, might have missed some file."
      },
      {
        "name": "User Login",
        "description": "Authenticates users using their credentials, creates and manages user sessions, and implements security measures such as login attempt limiting and two-factor authentication (2FA). Provides password reset functionality for forgotten passwords.",
        "file_path": [
          {
            "module_name": "LoginController",
            "path": "Controllers/Account/LoginController.cs",
            "critical": true
          },
          {
            "module_name": "LoginView",
            "path": "Views/Account/Login.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [80, 100, 80, 75],
        "sub_feature_confidence_score_justification": "High chance of missing files."
      }
    ],
    "feature_confidence_score_justification": "No feature dilution, duplication or missing files. Accurate Naming."
  },
  {
    "name": "Product Catalog Management",
    "feature_description": "Comprehensive system for managing product listings, categories, and inventory across the e-commerce platform.",
    "feature_description_confidence_score": [95, 65, 70, 80],
    "sub_features": [
      {
        "name": "Product CRUD Operations",
        "description": "Enables administrators to create, read, update, and delete product listings. Includes functionality for managing product details such as name, description, price, images, and inventory levels. Implements validation to ensure data integrity and consistency across the product catalog.",
        "file_path": [
          {
            "module_name": "ProductController",
            "path": "Controllers/ProductController.cs",
            "critical": true
          },
          {
            "module_name": "ProductView",
            "path": "Views/Product/Index.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [90, 85, 100, 70],
        "sub_feature_confidence_score_justification": "High confidence with no duplication or dilution."
      },
      {
        "name": "Category Management",
        "description": "Allows for the creation and management of product categories and subcategories. Implements a hierarchical structure for organizing products, enabling efficient navigation and filtering of the product catalog for both administrators and customers.",
        "file_path": [
          {
            "module_name": "CategoryController",
            "path": "Controllers/CategoryController.cs",
            "critical": true
          },
          {
            "module_name": "CategoryView",
            "path": "Views/Category/Index.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [85, 75, 90, 95],
        "sub_feature_confidence_score_justification": "High confidence without any duplication or dilution."
      }
    ],
    "feature_confidence_score_justification": "All files refer to single overall functionality. Might have missed some files."
  }
]
```
  </Output_Format>

"""

generate_features_user_message = """
<Strictly Remember>
1. As input you will be given a batch of `file_path` and `file_summary` from a production codebase. Keep it in mind that it could be a file from a very large repository with lot of inter-dependencies.
2. Understand all the file description first, then try to determine the feature, sub-features and their description. For **each file** it should have a feature or sub-features whenever the conditions are met.
3. The response should contain all the fields given in the example output format. The response should be strictly in json format.
4. The description of features/subfeatures must be in the length of 2-3 lines. The response should be structured and well-formatted.
5. Don't generate any additional explanation or description. Provide the structured response in json only.
</Strictly Remember>
  
<Input file wise summary>
{file_summary}
</Input file wise summary>
<Response>
"""

merge_features_in_hierarchy_user_prompt = """You are a software feature analyzer. Given a list of related features that have been clustered together, create a merged feature that encompasses all the functionality.

Features to merge:
{feature_list}

Generate a JSON response that includes:
1. A name for the merged feature representing accurate feature name. Do not mention its merged or unified or anything as such. The feature name should accurately represent a major funcationality of a repository.
2. A detailed description that covers all functionality
3. A confidence score (0-100) for the merge
4. A justification for the confidence score

Respond with a JSON object in the following format:
```json
{{
    "name": "Merged feature name",
    "description": "Comprehensive description",
    "confidence_score": 85,
    "confidence_justification": "Reason for the confidence score"
}}
```
Give only JSON and nothing else. Do not include any explanations or additional text outside the JSON block. Make sure to start with ```json and end with ``` only.
"""

mapping_names_for_merged_features_user_prompt = """  <Role>
    You are a smart AI cassistant with strong expertise in Software Engineering. You can understand complex, production-grade codebases written in various programming languages and summarize them effectively.
  </Role>
  <Task>
  You will be given a brief description of  features of a large codebase and your task is to generate a relevant feature name, brief description, and priority level.
  <Important>
   1. The feature name should be brief, relevant and should represent the entire description provided.
   2. Generate a relevant description which is basically a overall summary of the description provided.
   3. Assign a priority level (high, medium, low) based on the significance, importance and complexity of the feature to the overall system. 
  </important>
  </Task>
  <Example output>
  ```json
    {
        "name": <feature_name>, //string
        "feature_description": <feature_description>, //string
        "priority": <priority> //string (high, medium, or low)
    }
    ```
  </Example output>
  <Strictly Remember>
1. The feature name should be relevant and at the same time interpretable, easy to understand.
2. The feature description should represnt the entire description given for summarisation, it should be simple and easy to understant.
3. The priority should be one of: high, medium, or low.
4. The response should be strictly in json format specified above.
5. Strictly make sure Feature Description is not more than 200 words.
  </Strictly Remember>

<code summary>
The code summary is given below:
"""


reducing_sub_features_user_prompt = """
    You are a software feature consolidation expert. Your task is to merge similar sub-features into one comprehensive sub-feature.

    Here are the sub-features that need to be merged:
    {sub_features_list}

    For each sub-feature, we have:
    - Name: The sub-feature name
    - Description: The sub-feature description (if available)
    - Confidence Score: The confidence score (if available)

    Your output should be a JSON object containing:
    1. A unified sub-feature name that encompasses all the input sub-features
    2. A comprehensive description that covers all aspects of the input sub-features
    3. A confidence score (use the highest available from input sub-features)
    4. A justification for the confidence score

    Return the output in JSON format starting with ```json and ending with ```.

    Example output format:
    ```json
    {{
        "name": "Unified Sub-Feature Name",
        "description": "Comprehensive description covering all aspects",
        "sub_feature_confidence_score": 95,
        "sub_feature_confidence_score_justification": "Merged from similar sub-features with high semantic similarity"
    }}
    ```
    """


post_processing_feature_name_description_system_prompt="""
  <Role>
    You are a smart AI assistant with strong expertise in Software Engineering. You can understand complex, production-grade codebases written in various programming languages and summarize them effectively.
  </Role>
  <Task>
  You will be given a brief description of modules or features of a large codebase and your task is to generate a relevant feature name and brief description.
  <Important>
   1. The feature name should be brief, relevant and should represent the entire description provided.
   2. Generate a relevant description which is basically a overall summary of the description provided.
   3. Also generate a confidence score in a scale of 0 - 100.
  </important>
  </Task>
  <Example output>
  ```json
    {
        "name": <feature_name>,
        "feature_description_confidence_score": <score 0 - 100>,
        "feature_description": <feature_description>
    }```
  </Example output>"""

post_processing_feature_name_description_user_prompt = """<Strictly Remember>
1. The feature name should be relevant and at the same time interpretable, easy to understant.
2. The confidence score should represent the ability to summarise the description.
3. The feature description should represnt the entire description given for summarisation, it should be simple and easy to understant.
4. The response should be strictly in json format specified above.
</Strictly Remember>
<code summary>
The code summary is given below: \n
{feature_description}
</code_summary>
<response>
Your response in json goes here:
"""

merge_similar_features_system_prompt = """You are a solution architect. Your task is to carefully review each feature and its description, and combine them into a single high-level feature.

The final high-level features should represent what an end user would perceive, e.g., Messenger, Google Chat, Messaging, Reels, etc.

Based on the generated features provided, identify which features can be merged into a single high-level feature. 
Strictly output them in the following format:
{{ 
  <High-Level Feature Name 1>: [<Merged Feature 1>, <Merged Feature 2>, <Merged Feature 3>, ...],
  <High-Level Feature Name 2>: [<Merged Feature 1>, <Merged Feature 2>, <Merged Feature 3>, ...],
  ...
}}

INPUT:
Feature names and descriptions are provided in the format: 
[1. Feature name: <feature name> 
Feature description: <feature description>, 
2. ...]

{feature_texts}

MVFS:
{total_MVFs}

Points to remember:
1. While merging features and naming high-level features, always prefer names from the user-defined MVFs provided. All relevant features can be grouped under these high-level features.
2. If certain features do not fit under the user-defined MVFs, choose a better name than the existing one for the new high-level feature if necessary.
3. The names of the features being merged must remain exactly as provided in the INPUT section; do not modify them. Do not consider Feature description in Feature Names.
4. Follow the output structure strictly: high-level feature names as dictionary keys and merged features as values in list format.
5. If a feature is already a high-level feature, you do not need to forcibly merge it. If a feature seems to be function-level/low-level  features, merge them into a High-level feature.
6. Merge similar features into a single high-level feature based on their names and descriptions, when applicable. Each final high-level feature should be independent of the others.
7. Do not assign the same feature to multiple high-level features.
8. If user-defined MVFs are empty, skip point 1 and begin with point 2.
9. Do **not** include any Feature descriptions in the final output."""


merging_description_user_prompt = """You are a Solution Architect. Your task is to summarize the multiple feature descriptions provided into a brief, coherent summary of **no more than two sentences**.

  The summary must:
  - Accurately capture all key components from the provided descriptions.
  - Align clearly with the given high-level feature name.
  - Serve as the final description of the high-level feature.

  Only the final summarized description should be included in the output â€” no additional commentary or formatting.

  INPUT:
  Multiple descriptions: {merging_feature_description}

  High-Level Feature Name: {high_level_feature}
  """


micro_sub_feature_prompt = """You are an expert system analyst specializing in decomposing SubFeatures into granular, logically independent components. You support **two levels** of splitting:

1. **Horizontal splitting**: Split a subfeature into multiple *same-level subfeatures* when it encompasses multiple independently meaningful functionalities. The subfeatures created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.
2. **Vertical splitting**: Further break each of those subfeatures into *microsubfeatures* (if applicable), ensuring each micro-sub-features/micro-user-story describes a single goal or operation. The micro-sub-features/micro-user-story created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.

---

### ðŸ”§ TASK OVERVIEW

Given a Macro-Feature, Subfeature, its description, associated module files and its summary:

- Decide if the subfeature should be split horizontally into multiple same-level subfeatures.
- For each resulting subfeature (or original if not split), analyze whether it can be split vertically into **microsubfeatures** (fine-grained user stories).
- Provide the confidence scores for the subfeature that is split, whether horizontally or vertically.
- Provide the files that are related to the sub_features too, not just the micro_sub_features.
- Each leaf user-story must have files assigned to them, else you should not create/split these subfeatures.
- Provide description of generated subfeature/sub-user-stories in 2-4 lines but only valid information. Do not assume or hallucinate to generate description.
Apply this recursively: if horizontal splitting occurs, then attempt vertical splitting for each. But remember, not to create any duplicates in the process. 

---

### SPLITTING DECISIONS

#### Horizontal Splitting (Same-level Subfeatures):
Split if:
- The subfeature covers multiple high-level functionalities
- Each function could be planned, developed, and deployed independently
- Each component has a clear boundary and responsibility

#### Vertical Splitting (Microsubfeatures):
Split further if:
- A subfeature contains multiple independent operations or logical stages
- These operations can be implemented, tested, or tracked separately
- Each micro-subfeature represents one atomic, non-overlapping functionality

---

### DO NOT SPLIT IF:
- sub-user-stories are tightly coupled in the Subfeature and cannot function independently.
- Do not split subfeatures into sub-user-stories that are hardly single line of code and cannot be considered as a proper functionality, but just a config/parameter.
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across actions are too complex to isolate.
- There are no files that can be mapped to the generated user-story.
- Do not split if the user-story is barely a functionality. The split user-stories must have independent functionality that contributes to the subfeature and feature and if not, do not split.
- Don not split ReadMe & .md files into sub-user-stories.
- Do not split horizontall for granullar subfeatures as they are not user stories but mid level features.
---

### FILE MAPPING RULES:
- For each subfeature or microsubfeature, cite only directly relevant files.
- Use only the provided input data to match files â€” no guessing.
- Avoid duplication unless a file is clearly shared between components.

Each `file_path` entry must include:
```json
{
  "module_name": "<Name>",
  "path": "<Path>",
  "critical": <true/false>,
  "git_url": "<Git URL>"
}

OUTPUT FORMAT
If the subfeature should NOT be split:
Return: "None"

If the subfeature should be split, return a list of Parent User Stories with subfeatures inside.
If a subfeature itself can be further split into microsubfeatures, nest them under micro_sub_features like so:

[
  {
    "name": "Parent User Story Title 1",
    "description": "Full description of the original or updated user story and its purpose.",
    "file_path": [...],
    "sub_feature_confidence_score":"confidence score of the subfeature with respect to the Feature, as a percentage (e.g., 80)"
    "micro_sub_features": [
      {
        "name": "Sub-User Story Title 1",
        "description": "Standalone description of a single functionality.",
        "file_path": [...],
        "micro_sub_feature_confidence_score":"confidence score of the micro_sub_feature with respect to the sub_feature, as a percentage (e.g., 90)"
        }
          ...
        ]
      },
      ...
    ]
  }
]
Each layer must preserve independence, clarity, and singular focus of each story.

VALIDATION CHECKLIST
- Each title must express one functionality only (no imperative phrasing)
- description must avoid assumptions and describe the real function. It must be as detailled as possible.
- Each story must make sense independently and fit in the broader feature flow
- if there are multiple user-story under the subfeature, it needs to be in sequence of business logic.
- File mappings must be relevant and scoped accurately
- Do no miss/skip any values in the output json. The output structure must be maintained strictly.
- All subfeature and sub-user-story names and descriptions must be strictly in a declarative tone, not imperative.

* Use generic or speculative statements
"""


db_micro_sub_feature_prompt = """
<Role>
You are an expert Database analyst specializing in decomposing SubFeatures into granular, logically independent components. You support **two levels** of splitting:
You shall ALWAYS process features from a Database perspective ONLY. 
There can be more than one Table in the DB context provided to you.
</Role>

1. **Horizontal splitting**: Split a subfeature into multiple *same-level subfeatures* when it encompasses multiple independently meaningful functionalities. The subfeatures created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.
2. **Vertical splitting**: Further break each of those subfeatures into *microsubfeatures* (if applicable), ensuring each micro-sub-features/micro-user-story describes a single goal or operation. The micro-sub-features/micro-user-story created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.

<Strict Constraints> 
- You are dealing with Database Information. 
- No matter what, STRICTLY use Database-Specific Language ALWAYS. 
- Use words like Columns / Fields / Schema / DataTypes / Constraints / Foreign Keys / Primary Keys etc.
- Strictly Do not start descriptions with or start with "this micro-feature" / or "this sub-feature".
- You shall do this regardless of the input context and nature.
Remember : Every "FILE" given to you is information of a table. Therefore in your response, ALWAYS refer to "Table" instead of "File".

</Strict Constraints> 


### ðŸ”§ TASK OVERVIEW

Given a Macro-Feature, Subfeature, its description, associated module files and its summary:

- Decide if the subfeature should be split horizontally into multiple same-level subfeatures.
- For each resulting subfeature (or original if not split), analyze whether it can be split vertically into **microsubfeatures** (fine-grained user stories).
- Provide the confidence scores for the subfeature that is split, whether horizontally or vertically.
- Provide the files that are related to the sub_features too, not just the micro_sub_features.
- Each leaf user-story must have files assigned to them, else you should not create/split these subfeatures.
- Provide description of generated subfeature/sub-user-stories in 2-4 lines but only valid information. Do not assume or hallucinate to generate description.
Apply this recursively: if horizontal splitting occurs, then attempt vertical splitting for each. But remember, not to create any duplicates in the process. 

---

### SPLITTING DECISIONS

#### Horizontal Splitting (Same-level Subfeatures):
Split if:
- The subfeature covers ONE / MORE THAN ONE high-level functionalities
- Each function could be planned and developed independently
- Each component has some clear boundaries and responsibilities

#### Vertical Splitting (Microsubfeatures):
Split further if:
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across actions are too complex to isolate.
- There are no tables that can be mapped to the generated user-story.
- The subfeature is too complex to be planned, developed, and deployed independently
- Each micro-subfeature represents one atomic, non-overlapping functionality
Note: Maintain at least 2 subfeatures unless the database has only one table.
- Prioritize brevity, consistency and no informaiton leakage across subfeatures.
- Ensure crisp segregation.
---

### DO NOT SPLIT IF:
- sub-user-stories are tightly coupled in the Subfeature and cannot function independently.
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across tables in two features are too complex to isolate.
- There are no tables that can be mapped to the generated user-story.
Note: Maintain at least 2 subfeatures and 1 or more microsubfeatures per subfeature, Unless the database has only one table.
Note : Maintain brevity during splitting at the same level. Do NOT overload the a single feature with too many subfeatures.
---


### FILE MAPPING RULES:
- For each subfeature or microsubfeature, cite only directly relevant tables.
- Use only the provided input data to match files â€” no guessing.
- Avoid duplication unless a file is clearly shared between components.

Each `file_path` entry must include:
```json
{
  "module_name": "<Name>",
  "path": "<Path>",
  "critical": <true/false>,
  "git_url": "<Git URL>"
}

OUTPUT FORMAT
If the subfeature should NOT be split:
Return: "None"

If the subfeature should be split, return a list of Parent User Stories with subfeatures inside.
If a subfeature itself can be further split into microsubfeatures, nest them under micro_sub_features like so:

[
  {
    "name": "Parent User Story Title 1",
    "description": "Full description of the original or updated user story and its purpose.",
    "file_path": [...],
    "sub_feature_confidence_score":"confidence score of the subfeature with respect to the Feature, as a percentage (e.g., 80)"
    "micro_sub_features": [
      {
        "name": "Sub-User Story Title 1",
        "description": "Standalone description of a single functionality.",
        "file_path": [...],
        "micro_sub_feature_confidence_score":"confidence score of the micro_sub_feature with respect to the sub_feature, as a percentage (e.g., 90)"
        }
          ...
        ]
      },
      ...
    ]
  }
]
Each layer must preserve independence, clarity, and singular focus of each story.

VALIDATION CHECKLIST
- Each title must express one functionality only (no imperative phrasing)
- description must avoid assumptions and describe the real function. It must be as detailled as possible.
- Each story must make sense independently and fit in the broader feature flow
- if there are multiple user-story under the subfeature, it needs to be in sequence of business logic.
- File mappings must be relevant and scoped accurately
- Do no miss/skip any values in the output json. The output structure must be maintained strictly.
- All subfeature and sub-user-story names and descriptions must be strictly in a declarative tone, not imperative.
- Use Database-specific schema only. Do not include words like "Attributes" / "Code Files" in your response. 
- Strictly Do not start descriptions with or start with "this micro-feature" / or "this sub-feature".
* Use generic or speculative statements

"""import os
from graphviz import Digraph
import re 
import json

def parse_ddl(ddl: str):
    """
    Parse the DDL to extract columns, primary keys, and foreign keys.
    """
    lines = ddl.splitlines()
    column_lines = []

    for line in lines:
        line = line.strip()
        if (
            line.upper().startswith("CREATE")
            or line.upper().startswith("PRIMARY")
            or line.upper().startswith("FOREIGN")
            or line.upper().startswith(")")
            or line == ""
        ):
            continue

        match = re.match(r'(\w+)\s+\w+', line)
        if match:
            column_lines.append(match.group(1))

    pk_match = re.search(r'PRIMARY KEY\s*\((.*?)\)', ddl)
    primary_keys = [key.strip() for key in pk_match.group(1).split(",")] if pk_match else []

    foreign_keys = []
    for match in re.finditer(r'FOREIGN KEY\s*\(([^)]+)\)\s+REFERENCES\s+`?[\w]+\.(\w+)`\(([^)]+)\)', ddl):
        fk_col = match.group(1).strip()
        ref_table = match.group(2).strip()
        ref_col = match.group(3).strip()
        foreign_keys.append((fk_col, ref_table, ref_col))

    return column_lines, primary_keys, foreign_keys


def generate_combined_graph(tables_data):
    """
    Generate a single combined graph from multiple tables.
    """
    dot = Digraph(comment='Combined Table Diagram')
    dot.attr(rankdir='LR')

    # Store individual table nodes
    for table in tables_data:
        table_name = table['table_name']
        columns = table['columns']
        primary_keys = table['primary_keys']
        
        label_lines = []
        for col in columns:
            if col in primary_keys:
                label_lines.append(f"{col} [PK]")
            else:
                label_lines.append(col)
        dot.node(table_name, shape='box', label=f'{table_name}\\n' + "\\n".join(label_lines))

    # Add relationships
    for table in tables_data:
        table_name = table['table_name']
        for fk_col, ref_table, ref_col in table['foreign_keys']:
            dot.edge(table_name, ref_table, label=f'{fk_col} â†’ {ref_col}')

    return dot

def folder_summary_generation_prompts(
        total_allocated_tokens, 
        file_list, folder_name, 
        folder_path,
        subfolder_list,
        formatted_file_summaries,
        formatted_file_services,
        formatted_subfolder_summaries,
        formatted_subfolder_services,
        formatted_subfolder_features
    ):
    
    system_prompt = f"""
        You are an expert code analyst specialized in creating detailed, informative summaries of software project folders. Your task is to thoroughly analyze files and subfolders to provide a comprehensive understanding of the application or project and provide combined summaries along with required details. These summaries must be detailled enough for further summarization.

        Follow these guidelines:
        1. Conduct a deep analysis of the features to identify its core purpose and functionality
        2. Provide detailed explanation of key implementations and technical approaches of the features
        3. Thoroughly examine the summaries based on files and folders to understand relationship between features and combined smaller features into larger high level application level features.
        4. Explain the features within the broader project architecture with specific connections
        5. Describe technical patterns, design decisions, and architectural choices evident in the code
        6. Include specific functions, classes, and methods that define the feature's behavior
        7. Note dependencies, imports, and external connections that shape the folder's functionality
        8. Identify potential architectural strengths and areas for improvement when evident
        9. Identify all services represented in this folder based on file and subfolder services information
        10. Identify and articulate high-level features or functionalities represented by the folder into the feature_details section, when consolidating multiple subfolders or lower-level files. Derive these insights from both file-level and subfolder-level summaries. Also under each feature, mention which file/folder was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
        11. Do not miss any features that could be formed based on these summaries as this information is required to understand the application's buisness logic.
        12. Gather insights from the summaries provided to generate a high level detailled executive summary that could be used by business stakeholders to understand the folder/project.
        13. When analyzing the root folder, both the executive summary and the features must be strictly formed in a high level business logic standpoint of an application.
        
        IMPORTANT: 
        - Your summary should be thorough and detailed({total_allocated_tokens}) while maintaining technical/business precision and depth. Focus on providing insights that would help both stakeholders and developers understand the application better.
        - feature_details must contain high level feature name and feature description(value of the files/folders) strictly in concise bullet points. The feature inforamtion must be in detail to capture the complete high level knowledge for that feature but not the function level details. Feature names cannot be programmatic function names like Dependency management, json handling etc. instead it should be inventory management, order processing etc. 
        - Your services list should be comprehensive and include all services represented in this folder.
        - is_reuasble_lib if a folder is used as reusable lib make it True otherwise False
        - lib_name if is_reusable_lib is True then provide the name of the reusable lib/component If is_reusable_lib False then add Not Applicable
        - category if is_reusable_lib is True then provide category only between 'Frontend' and 'Backend' If is_reusable_lib False then add Not Applicable
        - sub_category if is_reusable_lib is True then provide sub category only between 'UI Component','Custom Hooks', 'http_client', 'Utils', 'Others' In Frontend & 'Middleware', 'Error Handling', 'Auth', 'Utils', 'Others' In Backend If is_reusable_lib False then add Not Applicable
        - when_to_use if is_reusable_lib is True then provide where this reusable lib/component can be used If is_reusable_lib False then add Not Applicable 
        - associated_files if is_reusable_lib is True then provide the list of files associated(give complete path for the assosciated file) with this reusable lib/component If is_reusable_lib False then add Not Applicable
        - summary must not be technical and only explain the high level details of the folder/project. Understand the file and folder summaries provided to combine the knowledge to form the executive summary. Make it as detailled as possible.
        - Use clear and concise language, avoiding jargon where possible.
        
        - You must provide your response in this exact format:
        ```summary
        [Your detailled high-level executive summary for the folder for business stakeholders]
        ```
        ```feature_details
        [List of high-level features or functionalities represented in this folder]
        ```
        ```services_namess
        [Comma-separated list of all services represented in this folder]
        ```
        ```is_reuasble_lib
        Boolean Value
        ```
        ```lib_name
        [Name of the reusable library if applicable]
        ```
        ```category
        [Category of the reusable library if applicable]
        ```
        ```sub_category
            [Sub category of the reusable library if applicable]
        ```
        ```when_to_use
        [Your detailed use case where or when this reuasble_lib can be usefull]
        ```
        ```associated_files
            [Comma-separated list of associated files with the reusable library, Give the Complete file path as mentioned in the file list]
        ```
        ```example_usage
            [Example code snippet of how to use this reusable library]
        ```
    """

    user_prompt = f"""
        Generate a summary and services list for the folder: "{folder_name}" (Path: {folder_path})

        FOLDER CONTENTS:
        - Files ({len(file_list)}): {", ".join(file_list) if file_list else "None"}
        - Subfolders ({len(subfolder_list)}): {", ".join(subfolder_list) if subfolder_list else "None"}

        FILE SUMMARIES:
        {os.linesep.join(formatted_file_summaries) if formatted_file_summaries else "No file summaries available"}

        FILE SERVICES:
        {os.linesep.join(formatted_file_services) if formatted_file_services else "No file services available"}

        SUBFOLDER SUMMARIES:
        {os.linesep.join(formatted_subfolder_summaries) if formatted_subfolder_summaries else "No subfolder summaries available"}

        SUBFOLDER SERVICES:
        {os.linesep.join(formatted_subfolder_services) if formatted_subfolder_services else "No subfolder services available"}

        SUBFOLDER FEATURES:
        {os.linesep.join(formatted_subfolder_features) if formatted_subfolder_features else "No subfolder features available"}
        
        Based on these components:
        1. Provide a thorough technical summary explaining the folder's purpose, implementation details, and architectural significance
        2. Compile a comprehensive list of all services represented in this folder based on file and subfolder services information
        
        Follow the exact format specified in the system instructions for your response.
    """

    return system_prompt, user_prompt

def services_generation():
    system_prompt = """
        <Task>
        Create an architectural blueprint of the given repository by identifying and classifying both external services and third-party services with no overlap between categories.
        </Task>

        <Definitions>
        - External services: Company-provided services hosted outside the application (AWS S3, Google Cloud, Stripe, Twilio)
        - Third-party services: Libraries, frameworks, and SDKs that are part of the core application stack (Django, React, MongoDB, Redux)
        </Definitions>

        <Output_Format>
        {
        "external_services": [
            {
            "external_service_name": "string",
            "description": "string",
            "associated_files": ["string"],
            "service_class": "string",
            "used_in_files": ["string"]
            }
        ],
        "thirdparty_services": [
            {
            "thirdparty_service_name": "string",
            "description": "string",
            "associated_files": ["string"],
            "service_class": "string",
            "used_in_files": ["string"]
            }
        ]
        }
        </Output_Format>

        <Instructions>
        1. Conduct a thorough repository analysis to identify all services
        2. Classify each service into exactly ONE category:
        - External services: Cloud platforms, payment processors, authentication providers
        - Third-party services: Frameworks, libraries, SDKs integrated into the codebase
        3. For each service, provide:
        - Name: Exact service name
        - Description: Concise explanation of functionality and purpose
        - Associated files: All files directly importing or using the service
        - Service class: Category (e.g., "cloud storage", "web framework", "database")
        - Used in files: Complete paths of files utilizing the service
        4. Ensure ZERO overlap between categories
        5. Prioritize accuracy over comprehensiveness
        6. Validate that identified services are actively used in the project
        7. Include only services with clear evidence of implementation
        8. Do not create a lot of services which are redundant. Keep it to a maximum of 50 services only.
        </Instructions>

        <Examples>
        Good External Service Entry:
        {
        "external_service_name": "AWS S3",
        "description": "Cloud storage service used for storing user-uploaded files",
        "associated_files": ["src/services/storage.js", "src/config/aws.js"],
        "service_class": "cloud storage",
        "used_in_files": ["src/components/FileUpload.js", "src/pages/UserProfile.js"]
        }

        Good Third-Party Service Entry:
        {
        "thirdparty_service_name": "React",
        "description": "Frontend JavaScript library for building user interfaces",
        "associated_files": ["package.json", "src/index.js"],
        "service_class": "frontend framework",
        "used_in_files": ["src/App.js", "src/components/*.js"]
        }
        </Examples>

        Analyze the repository and provide the complete architectural blueprint in the specified format.
    """

    user_prompt = ""

    return system_prompt, user_prompt

def executive_summary_generation(combined_summary, user_mvf):
    system_prompt = """
    Your Role:
    You are an expert software architect tasked with understanding a codebase and creating an executive summary that clearly articulates the main purpose of this application,
    the core problem that the application is solving, and the prioritized list of the most valuable features, solely based on the provided folder wise summary. Do not hallucinate and create the most valuable features and its description on assumption. This needs to be based on facts.

    Task:
    1. Analyze provided folder wise summary and the services used and the user defined features (if provided).
    2. Understand component interactions and functions.
    3. Prioritize the User Defined Features (if provided) in the summary.
    4. Identify and prioritize the most valuable features based on their importance and relevance to the overall project, as evidenced in the code.
    5. Create a comprehensive executive summary.

    Steps:
    1. Review folder wise summary.
    2. Analyze folder wise summary:
    - Identify key components and their roles
    - Note data operations, design patterns, and architectural decisions
    3. Create summary:
    - Describe the specific problem the codebase solves, based on folder wise summary
    - Explain component interactions
    - Outline data workflow
    4. Identify and prioritize main features:
    - Determine which feature(s) address the core problem of the application, based on code implementation
    - Rank features based on their importance and relevance to solving the main problem, as evidenced in the code
    - The feature should be major components of the codebase and not minor functions like "Modular Architecture" or "Code Reusability", these are not features but design principles.

    Focus Areas:
    - Precised feature prioritization and importance
    - High-level functionality
    - Clear, concise technical language
    - Objective description
    - Capture entire workflow

    Guidelines:
    - Only use the folder wise summary provided
    - Use precise technical terms
    - Include user-defined features if provided and evidenced in the code
    - Prioritize features based on their importance to the core problem, as shown in the folder wise summary

    Feature Identification and Prioritization:
    - Carefully analyze the folder wise summary to identify features actually present in the folder wise summary
    - Do not assume or infer features that are not explicitly mentioned in the folder wise summary
    - Identify the top feature that solves the majority of the problem based on code evidence
    - Rank subsequent features in descending order of importance, ensuring they are present in the folder wise summary
    - Ensure the feature list reflects the codebase's focus and structure
    - Only include features that have substantial implementation in the codebase that is evident from folder wise summary

    Output Format - Adhering to this format is crucial
    ```json
    {
    "data": "generated_summary in string format adhering to the Expected Output Format for Generated Summary",
    "confidence_score": 90,
    "traceback": {
    "Feature 1 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 1 Title' is included, as the 'phrase' is an evidence that this feature is part of the codebase.",
    "Feature 2 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 2 Title' is included, as the 'phrase' is an evidence that this feature is part of the codebase.",
    ...
    }
    }
    ```

    Requirements:
    - Replace \n with \\n in JSON
    - Limit upto 5 main features (max 2 sub-features each) or 7500 tokens
    - If due to any reason such as codebase being small, you are unable to provide 5 features, then provide as many high-level features as possible between the range of 1 to 5.
    - Don't assume features or include minor features due to inability to provide 5 features, lesser number of features is acceptable.
    - Use specified JSON format only
    - Start with "```json" and end with "```"
    - Ensure the top feature in the prioritized list addresses the core problem and is present in the folder wise summary
    - Rank features in descending order of importance to the main problem, based on actual code implementation
    - Do NOT include features that are NOT evidenced in the provided folder wise summary
    - Evaluate the folder wise summary objectively, considering all conclusions on the actual code provided
    - Do NOT make any assumptions about organizational goals or intentions beyond what is explicitly shown in the code
    - Focus solely on the technical aspects and implemented functionality, avoiding speculation about business objectives or future plans
    - Both the keys data, confidence score, and traceback should be present in the output JSON
    - The generated summary should be in string format only and be contained inside the "data" key
    - The "traceback" key should contain a dictionary with feature names as keys and justifications for including these features based on exact phrases from the input
    - Do not include any feature that could potentially be part of the folder wise summary without explicit evidence
    - Every feature mentioned must be driven by clear evidence from the provided input
    """
    user_prompt = """
    Expected Output Format for Generated Summary:

  **Overview**
  <empty line>
  <A brief introduction to the codebase and its main purpose; in paragraph format only, not in points.
  This paragraph should provide a concise yet comprehensive overview of the codebase, its primary functionality, solution provided by the project and its intended use case.
  Aim for 3-5 sentences that capture the essence of the project.>
  <empty line>
  **Highlighted Features**
  <empty line>
  <
  List and briefly explain the key features that are significant components of the codebase and would serve as selling points.
  These features should be presented as follows:
  1. Use numbered points for each feature.
  2. Provide a brief explanation for each feature in 1-2 sentences, highlighting its importance and benefit to the end user.
  3. Focus on features that are central to the codebase's functionality and most important to the end user.
  4. Dont include generic features like "Modular Architecture" or "Code Reusability", these are not features but design principles.
  5. Do not include sub-points under any feature.
  6. Prioritize User Defined Features (if provided) at the beginning of the list.
  7. If User Defined Features are given, list them first before including any features identified through your analysis.
  8. Aim to provide upto of 1 to 5 key features, after each feature add an empty line for formatting purposes.
  9. Ensure that the features listed represent the core functionality and unique selling points based on the folder wise summary.
  10. Use clear, concise language that emphasizes the value proposition of each feature.
  11. Also under each feature, mention which file/folder was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
  12. Do not add features into Highlighted Features if they dont have value for buisness stakeholder about the application. Also do not repeat adding similar feature in this section.

  Output Structure:
  1. ***<Feature 1 Title>***: <Description of the feature in one to two sentences.\n
  2. ***<Feature 2 Title>***: <Description of the feature in one to two sentences.>\n
  >
  <empty line>
  **Key Benefits**
  <empty line>
  <Summarize the key benefits of the codebase in one to two sentences.
  This summary should encapsulate the overall value proposition of the codebase and its potential impact on users or the organization.>
  <empty line>
  <Highlight the most significant key benefits the codebase has to offer in bulleted points. The format should be:
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  Aim for 3-5 bullet points that capture the most compelling advantages of using this codebase, after each point add an empty line for formatting purposes.
  Each benefit should be distinct and provide a clear value proposition.>

  <Final Output Format>
  Output Format - Adhering to this format is crucial, the output should be in parsable JSON format:
  ```json
  {{
    "data": "<generated_summary in string format adhering to the Expected Output Format for Generated Summary>",
    "confidence_score": 90,
    "traceback": {{
      "Feature 1 Title": "Since it mentions about <exact phrase from the folder wise summary>, the 'Feature 1 Title' is included, as the "phrase" is an evidence that this feature is part of the folder wise summary.",
      "Feature 2 Title": "Since it mentions about <exact phrase from the folder wise summary>, the 'Feature 2 Title' is included, as the "phrase" is an evidence that this feature is part of the folder wise summary.",
      ...
    }}
  }}
  ```
  </Final Output Format>
  Note: If the traceback includes phrases that are not present in the folder wise summary then you would be penalized 10000 points.
  The output should be having data, confidence score, and traceback keys, and the entire content inside "```json" and "```" should be parsable by json.
  The "data" key should contain the generated summary and it should be in string format only, allowing the parsing of the entire json.
  If there are any inverted commas inside the generated summary, then escape them with a backslash.
  Do not change or skip the headings of each section in the generated json. The generated summary must have "Overview", "Highlighted Features", "Key Benefits" as section titles. Follow the above provided guidelines."""
    user_prompt += f"""Use the below folder wise summary to generate the summary in the above format: {combined_summary}""" + "User Defined Features : " + str(user_mvf)
    return system_prompt, user_prompt

def db_executive_summary_generation(combined_summary, user_mvf): 
    system_prompt = """
    Role:
    You are an expert Database Architect tasked with understanding the contents of all tables and schema of the database. 
    You shall Articulate a proper executive summary that clearly captures all the main & high-level features of this database.
    The core use-case that this database is intended for, and the prioritized list of the most valuable features, solely based on the provided Table-Level summaries. 
    Do not hallucinate. Do NOT create the most valuable features and its description on pure assumptions. This needs to be based on facts, with proper backing.

    Task:
    1. Analyze provided Table wise summaries.
    2. Understand component interactions and functions.
    3. Prioritize the User Defined Features (if provided) in the summary.
    4. Identify and prioritize the most valuable features based on their importance to the core use-case the Database is solving.
    5. Create a comprehensive executive summary.

    Steps:
    1. Review Table wise summary.
    2. Analyze Table wise summary:
      - Identify all tables. 
      - Take into consideration the foreign keys, primary keys, is-a, has-a, and many-to-many relationships.
      - Deeply understand the intended-use-case of each table.
      - Note data operations, design patterns, and architectural decisions
    3. Create summary:
      - Describe the specific problem the Database is solving, based on Table wise summary
      - Explain high-level interactions and dependencies
      - Outline data workflow
    4. Identify and prioritize main features:
      - Determine which feature(s) address the core problem of the Database, based on SQL implementation and Table wise summary
      - Rank features based on their importance and relevance to solving the main problem, as evidenced in the Database
      - The feature should be major components of the Database and not minor functions like Many-to-Many Relationships, or "Foreign Keys". 
        These are implementation concepts. Not core features.

    Focus Areas:
    - Precised feature prioritization and importance
    - High-level functionality of this Database
    - Clear, concise technical language with Database-specific Language
    - Objective description
    - Capture entire data workflow

    Guidelines:
    - Only use the Table wise summary provided
    - Use precise Database-relevant technical terms
    - Include user-defined features if provided and evidenced in the Table wise summary
    - Prioritize features based on their importance to the core problem, as shown in the Table wise summary

    Feature Identification and Prioritization:
    - Carefully analyze the Table wise summary to identify features actually present in the Table wise summary
    - Do not assume or infer features that are not explicitly mentioned in the Table wise summary
    - Identify the top feature that solves the majority of the problem based on Database and SQL evidence
    - Rank subsequent features in descending order of importance, ensuring they are present in the Table wise summary
    - Ensure the feature list reflects the Database's focus and structure
    - Only include features that have substantial implementation in the Database that is evident from Table wise summary

    Output Format - Adhering to this format is crucial
    ```json
    {
    "data": "generated_summary in string format adhering to the Expected Output Format for Generated Summary",
    "confidence_score": 90,
    "traceback": {
    "Feature 1 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 1 Title' is included, as the 'phrase' is an evidence that this feature is part of the Database.",
    "Feature 2 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 2 Title' is included, as the 'phrase' is an evidence that this feature is part of the Database.",
    ...
    }
    }
    ```

    Requirements:
    - Replace \n with \\n in JSON
    - Limit upto 5 main features (max 2 sub-features each) or 7500 tokens
    - If due to any reason such as Database being small, you are unable to provide 5 features, then provide as many high-level features as possible between the range of 1 to 5.
    - Don't assume features or include minor features due to inability to provide 5 features, lesser number of features is acceptable.
    - Use specified JSON format only
    - Start with "```json" and end with "```"
    - Ensure the top feature in the prioritized list addresses the core problem and is present in the Table wise summary
    - Rank features in descending order of importance to the main problem, based on actual Database and SQL implementation
    - Do NOT include features that are NOT evidenced in the provided Table wise summary
    - Evaluate the Table wise summary objectively, considering all conclusions on the actual Database and SQL provided
    - Do NOT make any assumptions about organizational goals or intentions beyond what is explicitly shown in the Database and SQL
    - Focus solely on the technical aspects and implemented functionality, avoiding speculation about business objectives or future plans
    - Both the keys data, confidence score, and traceback should be present in the output JSON
    - The generated summary should be in string format only and be contained inside the "data" key
    - The "traceback" key should contain a dictionary with feature names as keys and justifications for including these features based on exact phrases from the input
    - Do not include any feature that could potentially be part of the Table wise summary without explicit evidence
    - Every feature mentioned must be driven by clear evidence from the provided input.
    - Strictly use an assertive and objective tone in your response. 
    - Do not be unsure about anything.
    - Do not include the "Folder Name" in your response. Ignore "dbanalysis" folder. Provide Executive Summary of the Database-ONLY.
    """

    user_prompt = """
  Expected Output Format for Generated Summary:

  **Overview**
  <empty line>
  <A brief introduction to the Database and its main purpose; in paragraph format only, not in points.
  This paragraph should provide a concise yet comprehensive overview of the Database, its primary functionality, and its intended use case.
  Aim for 3-5 sentences that capture the essence of the Database.>
  <empty line>
  **Highlighted Features**
  <empty line>
  <
  List and briefly explain the key features that are significant components of the Database and would serve as selling points.
  These features should be presented as follows:
  1. Use numbered points for each feature.
  2. Provide a brief explanation for each feature in 1-2 sentences, highlighting its importance and benefit to the END USER.
  3. Focus on features that are central to the Database's functionality and most important to the END USER.
  4. Dont include generic features like  Many-to-Many Relationships, or "Foreign Keys", these are not features but Design Principles.
  5. Do not include sub-points under any feature.
  6. Prioritize User Defined Features (if provided) at the beginning of the list.
  7. If User Defined Features are given, list them first before including any features identified through your analysis.
  8. Aim to provide upto of 1 to 5 key features, after each feature add an empty line for formatting purposes.
  9. Ensure that the features listed represent the core functionality and unique selling points based on the Table wise summary.
  10. Use clear, concise language that emphasizes the value proposition of each feature.
  11. Also under each feature, mention which file/Table was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
  12. Do not add features into Highlighted Features if they dont have value for buisness stakeholder about the application. Also do not repeat adding similar feature in this section.

  Output Structure:
  1. ***<Feature 1 Title>***: <Description of the feature in one to two sentences.\n
  2. ***<Feature 2 Title>***: <Description of the feature in one to two sentences.>\n
  >
  <empty line>
  **Key Benefits**
  <empty line>
  <Summarize the key benefits of the Database in one to two sentences.
  This summary should encapsulate the overall value proposition of the Database and its potential impact on users or the organization.>
  <empty line>
  <Highlight the most significant key benefits the Database has to offer in bulleted points. The format should be:
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  Aim for 3-5 bullet points that capture the most compelling advantages of using this Database, after each point add an empty line for formatting purposes.
  Each benefit should be distinct and provide a clear value proposition.>

  <Final Output Format>
  Output Format - Adhering to this format is crucial, the output should be in parsable JSON format:
  ```json
  {{
    "data": "<generated_summary in string format adhering to the Expected Output Format for Generated Summary>",
    "confidence_score": 90,
    "traceback": {{
      "Feature 1 Title": "Since it mentions about <exact phrase from the Table wise summary>, the 'Feature 1 Title' is included, as the "phrase" is an evidence that this feature is part of the Table wise summary.",
      "Feature 2 Title": "Since it mentions about <exact phrase from the Table wise summary>, the 'Feature 2 Title' is included, as the "phrase" is an evidence that this feature is part of the Table wise summary.",
      ...
    }}
  }}
  ```
  </Final Output Format>
  Note: If the traceback includes phrases that are not present in the Table wise summary then you would be penalized 10000 points.
  The output should be having data, confidence score, and traceback keys, and the entire content inside "```json" and "```" should be parsable by json.
  The "data" key should contain the generated summary and it should be in string format only, allowing the parsing of the entire json.
  If there are any inverted commas inside the generated summary, then escape them with a backslash.
  Do not change or skip the headings of each section in the generated json. The generated summary must have "Overview", "Highlighted Features", "Key Benefits" as section titles. Follow the above provided guidelines.
    """

    user_prompt += f"""Use the below Table wise summary to generate the summary in the above format: {combined_summary}""" + "User Defined Features : " + str(user_mvf)

    return system_prompt, user_prompt


def architecture_diagram_generation(services_data, icons_metadata):
    user_prompt = f"""
    <Input>
    $services_data = {services_data}
    $icons_metadata
    </Input>

    <Role>
    You are an expert at understanding large projects based on their executive summary and the services being used in them. Create a JSON structure for a ReactFlow diagram based on the given service class JSON.
    </Role>

    <Output Structure>
    1. Create a JSON object with a "nodes" and "edges" array.
    2. Create nodes for each external and third-party service.
    3. "nodes": An array containing all node objects.
      - "id": A unique string identifier for the node.
      - "data":   
        - "label": The name of the node.
        - "description": Description of the service.
        - "associated_files": Associated file and used in files in the service node, defaulting to "No File Available" if not present.
        - "group": The logical group name (e.g., 'Backend', 'Frontend', 'Database',etc..).
        - "subgroup": The specific subgroup within the group (e.g., Frameworks, NoSQL Databases, State Management, etc.).
        - "service": The appropriate filename of the icon based on the $icons_metadata.
      - "position" : The x and y coordinates of the node.
      - "type" : "customNode" This should be fixed.
    4. "edges" : An array having id, source, target, label, and type should be customEdge always.
    4. Ensure all services and files from the input JSON are included.
    5. The output should be in the form of a dictionary containing a "nodes" and "edges" array.
    6. Present only the code inside delimiters "```reactflow [reactflow CODE]```" without any additional explanation.
    """

    system_prompt:str = """
    <Task>
      You are tasked with creating a JSON structure for a ReactFlow diagram based on the given executive summary and the service_class_json. The executive summary contains an overview of the entire project. This JSON includes information about external services and third-party services, along with their associated files. Your output should represent this information as a network of nodes and edges.
    </Task>
    
    <Icons Context>
      $icons_metadata = """ + str(icons_metadata) + """
    </Icons Context>

    <Instructions>
      You are a solution expert, specializing in problem and solution flows. You will be given the solution overview for a project, and your task is to create an interconnected single component of graph which is detailed, and intuitive and self explanatory for:

      Follow these guidelines:
      1. Create nodes for each unique service (both external and third-party).
      2. Do not create any group nodes.
      4. In the data key for each service node, include two additional fields called group and subgroup. The group field should contain the logical group name (e.g., Frontend, Backend, Databases, etc..), and the subgroup field should provide more specific categorization (e.g., Frameworks, NoSQL Databases, etc..). For example, for a service node representing React, the group would be Frontend and the subgroup would be Frameworks.
      5. For each node, check which icon will be the most suitable from the $icons_metadata in the <Icons Context>
      6. Ensure all information from the input is represented in the output.
      7. The position coordinates must be proper for all the nodes.
    </Instructions>

    <Rules>
      **Ensure all nodes in the generated graph are interconnected such that every node has at least one edge, forming a single connected component without any isolated or disjoint sections. (High Priority Requirement)**
      Important Rules to be followed:
      1. Give detailed technical architecture flow and the JSON object following the below output format.
      2. Make sure that the flow and order of new solution approach is explained well in the graph with appropriate edges. Use as many edges you want to describe the data and user flow properly.
      3. The whole user and data flow should be clear.
      4. Do not add unnecessary nodes and edges. Do not create duplicate nodes that perform same task.
      5. Make the Node descriptions detailed, breaking tasks into multiple sub-tasks if needed.
      6. Ensure your edges show the actual flow, and not just connections of what's related. The connections are meant to show the logical flow, and not the relatedness/similarity.
      7. The group name is meant to classify clusters of nodes within each graph. For instance, if we have multiple nodes in features, they would all have "feature" as group. In Architecture Flow, the "Group" should show the layer each node is in, for instance "Backend Layer", "Database Layer" etc.
      9. for a hierarchy of nodes A -> B -> C; ensure that there is not a connection between A -> C.
    </Rules>
    
    <output_format>
    The output should be in between the delimeters ```reactflow and ```. Only provide the json output. Don't give unnecesary explanation.
    ```reactflow
    {
      "nodes": [
        { 
          "id": "unique_node_identifier_string",
          "data" : {
            "label": "name_of_the_service",
            "description": "description of the service",
            "associated_files": ["file_path_1", "file_path_2", "file_path_3", etc.],  // (default: ["No File Available"] if not present)
            "group": "name_of_group",  // Add the logical group name (e.g., "Frontend", "Backend", etc..)
            "subgroup": "name_of_subgroup",  // Add a more specific subgroup name (e.g., "Frameworks", "NoSQL Databases", etc..)
            "service": "filename" //taken from the $icons_metadata,
          }
          "position":{ "x": "Xcoordinate", "y": "Ycoordinate" },
          "type" : "customNode" //this is hardcoded and will be constant
        }
      ],
      "edges": [
        {
          "id": "unique_egde_identifier_string",
          "source": "label A",
          "target": "label B",
          "label": "Showcase what comes from the source node, to the target node. Be concise and specific with labels, such as 'Ingested Data', 'Converted Text', 'User Query' etc. Use at max 5 words",
          "type" : "customEdge" //this is hardcoded and will be constant
        }
      ]
    }```
    </output_format>
    """
    return system_prompt, user_prompt
  

def erd_generation(services_data, icons_metadata):
  tables_metadata = []
  for entry in services_data:
      table_name = entry["table_name"]
      ddl = entry["ddl"]
      columns, primary_keys, foreign_keys = parse_ddl(ddl)
      tables_metadata.append({
          "table_name": table_name,
          "columns": columns,
          "primary_keys": primary_keys,
          "foreign_keys": foreign_keys
      })

  dot = generate_combined_graph(tables_metadata)

  system_prompt:str = """
    You are tasked with creating a JSON structure for a ReactFlow diagram based on the given database ER diagram and schema JSON. This JSON includes information about database columns and their relationships.Your output should represent this information as a network of nodes and edges.
    </Task>
    
    <Icons Context>
      $icons_metadata = """ + str(icons_metadata) + """
    </Icons Context>

    <Instructions>
      You are a solution expert, specializing in problem and solution flows. You will be given the database schema information of a database, and your task is to create an interconnected single component of graph which is detailed, and intuitive and self explanatory for:

      Follow these guidelines:
      1. Create nodes for each unique service (both external and third-party).
      2. Do not create any group nodes.
      4. In the data key for each service node, include two additional fields called group and subgroup. The group field should contain the logical group name (e.g.,Databases, etc..), and the subgroup field should provide more specific categorization (e.g., 'Transactional Tables', 'Reference Tables' etc..). For example, for a service node representing daily transactions, the group would be Database and the subgroup would be Transactional Tables.
      5. For each node, check which icon will be the most suitable from the $icons_metadata in the <Icons Context>
      6. Ensure all information from the input is represented in the output.
      7. The position coordinates must be proper for all the nodes.
    </Instructions>

    <Rules>
      Important Rules to be followed:
      1. Give detailed technical architecture flow and the JSON object following the below output format.
      2. Make sure that the flow and order of new solution approach is explained well in the graph with appropriate edges. Use as many edges you want to describe the data and user flow properly.
      3. The whole user and data flow should be clear.
      4. Do not add unnecessary nodes and edges. Do not create duplicate nodes that perform same task.
      5. Make the Node descriptions detailed, breaking tasks into multiple sub-tasks if needed.
      6. Ensure your edges show the actual flow, and not just connections of what's related. The connections are meant to show the logical flow, and not the relatedness/similarity.
      7. The group name is meant to classify clusters of nodes within each graph. For instance, if we have multiple nodes in features, they would all have "feature" as group. In Architecture Flow, the "Group" should show the layer each node is in, for instance "Database Layer" etc.
      9. for a hierarchy of nodes A -> B -> C; ensure that there is not a connection between A -> C.
    </Rules>
    
    <output_format>
    The output should be in between the delimeters ```reactflow and ```. Only provide the json output. Don't give unnecesary explanation.
    ```reactflow
    {
      "nodes": [
        { 
          "id": "unique_node_identifier_string",
          "data" : {
            "label": "name_of_the_table",
            "description": "description of the table",
  	    "columns": ["order_id [PK]", "product_sku [PK]", "quantity", "unit_price"]
            "group": "name_of_group",  // Add the logical group name (e.g., "Database", etc..)
            "subgroup": "name_of_subgroup",  // Add a more specific subgroup name (e.g., 'Transactional Tables', 'Reference Tables', etc..)
            "service": "filename" //taken from the $icons_metadata,
          }
          "position":{ "x": "Xcoordinate", "y": "Ycoordinate" },
          "type" : "customNode" //this is hardcoded and will be constant
        }
      ],
      "edges": [
        {
          "id": "unique_egde_identifier_string",
          "source": "label A",
          "target": "label B",
          "label": "Showcase what comes from the source node, to the target node. Be concise and specific with labels, such as 'Ingested Data', 'Converted Text', 'User Query' etc. Use at max 5 words",
          "type" : "customEdge" //this is hardcoded and will be constant
        }
      ]
    }```
    </output_format>
    """
    
  user_prompt:str = f"""
    <Input>
    $database_tables = {dot}
    $icons_metadata
    </Input>

    <Role>
    You are an expert at understanding database architecture based on ER diagrams and relational structures. Create a JSON structure for a ReactFlow diagram based on the given database schema.
    </Role>
    <Output Structure>
      1. Create a JSON object with a "nodes" and "edges" array.
      2. Create nodes for each table in the schema.
      3. "nodes": An array containing all node objects.
      - "id": A unique string identifier for the node.
      - "data":  
        - "label": The name of the table.
        - "description": A brief summary of the table's role or content.
        - "columns": List of column names (mark primary keys with [PK], foreign keys with [FK]).
        - "group": The logical group name (e.g., 'Database').
        - "subgroup": The specific subgroup within the group (e.g., 'Transactional Tables', 'Reference Tables').
        - "service": The appropriate filename of the icon based on the $icons_metadata.
      - "position" : The x and y coordinates of the node.
      - "type" : "customNode" This should be fixed.
      4. "edges" : An array having id, source, target, label, and type should be customEdge always.
      5. The label of the edge should describe the relationship, like "order_id â†’ order_id". 
      6. The output should be in the form of a dictionary containing a "nodes" and "edges" array.
      7. Present only the code inside delimiters "```reactflow [reactflow CODE]```" without any additional explanation.
    """
    
  return system_prompt, user_prompt
    

def feature_summary_generation(formatted_data, user_mvf, executive_summary):
    # if input_type is None:
    #     formatted_data = file_summary_list
    # elif input_type == "batch_summary":
    #     formatted_data = format_batchwise_summary_metadata_for_services(file_summary_list)
    # else:
    #     formatted_data = format_file_summaries(file_summary_list)

    user_prompt = """
    Role: You are an AI code analyst specializing in creating concise, feature-level summaries of codebases.

    Objective: Provide a comprehensive yet concise feature-level summary of a given codebase, highlighting key components, functionality, and the project's overall workflow.

    Input: You will receive information about a codebase, which may include an executive summary or other project details.

    Steps:
    1. Analyze the provided codebase information.
    2. Identify the main features (maximum 5) of the project from the executive summary (if provided in same order)
    3. Create a summary following the specified format, including:
        a. An overview of the project
        b. A list of key features with brief descriptions
        c. A closure statement
    4. Self-evaluate the generated summary and assign a confidence score.
    5. Format the output as specified in the instructions.

    Output Format:
    ```json
    {
        "data": "generated_summary in string format adhering to the Detailed Instructions for Output Format",
        "confidence_score": 90
    }
    ```

    Detailed Instructions for Output Format:

    **Overview**
    <empty line>
    < 
        Summarize all features in 2-3 sentences, introducing the project and its purpose.
        Provide a 2-3 sentence summary of key benefits, highlighting core architecture and value proposition.
    >
    <empty line>
    **Key Features**
    <empty line>
    <   
        List a maximum of 5 main features.
        For each feature, provide up to 2 sub-points describing its functionality.
        Ensure clear explanation of how features interact and contribute to the project's goals.
        1. ***<Key Feature Title>*** : 
        * <Sub point 1 description>
        * <Sub point 2 description>
        <empty line>
    >
    <empty line>
    < 
        Summarize the overall impact and value proposition of the project in one sentence as a conclusion statement.
    >
    <empty line>
    
    -> Self-Evaluation:
        - Score the summary out of 100 based on clarity, precision, detail, knowledge, accuracy, technical correctness, and understanding of the data.

    -> Formatting Requirements:
        - Replace all newline characters (\n) with \\n in the JSON output.
        - Ensure the complete JSON is less than 7500 tokens.
        - Start the output with "```json" and end with "```".
        - If an executive summary is provided, use only the highlighted features from it.

    Example Output Structure:
    ```json
    {
        "data": "**Overview**\\n\\n[Project overview]\\n\\n[Benefits summary]\\n\\n**Key Features**\\n\\n1. *Feature 1*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n2. *Feature 2*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n[...continue for up to 5 features...]\\n\\n[Closure statement]",
        "confidence_score": 90
    }
    ```

    Remember: Adhere strictly to the output format and instructions to maintain consistency and accuracy in your summary.
    """

    user_prompt += "User Defined Features : " + str(user_mvf)

    system_prompt = f"""
        <role>
        You are an assistant to a Senior Software Engineer. You are very capable in reading and understanding huge codebases.
        There is no edge-case, no mistake, no functionality no matter how small goes unnoticed by you.
        You will be given a large codebase and be asked queries regarding it.
        </role>

        <Task>
        You will be given relevant files from a production codebase. The Senior Engineer will consult you to clear his doubts and ask for critical code-level and functionality level analysis of the same.
        <Important>
        1. You will be clear. Feel free to be descriptive but Avoid Jargon
        2. You shall perform critical analysis on the code before responding.
        3. Note that the codebase will be quite complex and have dependencies everywhere, be mindful of them all.
        4. Enclose code in (triple backticks)``` code ```
        </Important>
        </Task>

        Files from Codebase goes here :
        <Repo Structure>
        {formatted_data}
        </Repo Structure>
    """

    start_index = executive_summary.find("Highlighted Features")
    end_index = executive_summary.find("Key Benefits")

    if start_index != -1 and end_index != -1:
        executive_summary = executive_summary[start_index:end_index].strip()

    user_prompt += "Executive Summary : " + str(executive_summary)

    return system_prompt, user_prompt

def feature_summary_generation_db(formatted_data, user_mvf, executive_summary):
    # if input_type is None:
    #     formatted_data = file_summary_list
    # elif input_type == "batch_summary":
    #     formatted_data = format_batchwise_summary_metadata_for_services(file_summary_list)
    # else:
    #     formatted_data = format_file_summaries(file_summary_list)

    user_prompt = """
    Role: You are an AI Database Analyst specializing in creating concise, feature-level summaries of complex database schemas and architectures.

    Objective: Provide a comprehensive yet concise feature-level summary of a given database schema information, highlighting key components, entities, relationships, and the overall data architecture workflow.

    Input: You will receive information about a database design, which may include an executive summary or other schema-level details.

    Steps:
    1. Analyze the provided database schema information.
    2. Identify the main features (maximum 5) of the database from the executive summary (if provided in same order)
    3. Create a summary following the specified format, including:
        a. An overview of the database
        b. A list of key features with brief descriptions
        c. A closure statement
    4. Self-evaluate the generated summary and assign a confidence score.
    5. Format the output as specified in the instructions.

    Output Format:
    ```json
    {
        "data": "generated_summary in string format adhering to the Detailed Instructions for Output Format",
        "confidence_score": 90
    }
    ```

    Detailed Instructions for Output Format:

    **Overview**
    <empty line>
    < 
        Summarize all features in 2-3 sentences, introducing the database and its purpose.
        Provide a 2-3 sentence summary of key benefits, highlighting schema structure, normalization or denormalization logic, and value proposition in handling data.
    >
    <empty line>
    **Key Features**
    <empty line>
    <   
        List a maximum of 5 main features.
        For each feature, provide up to 2 sub-points describing its data handling, relationships, or optimization logic.
        Ensure clear explanation of how features contribute to performance, consistency, and data integrity.
        1. ***<Key Feature Title>*** : 
        * <Sub point 1 description>
        * <Sub point 2 description>
        <empty line>
    >
    <empty line>
    < 
        Summarize the overall impact and value proposition of the database in one sentence as a conclusion statement.
    >
    <empty line>
    
    -> Self-Evaluation:
        - Score the summary out of 100 based on clarity, precision, detail, knowledge, accuracy, technical correctness, and understanding of the schema information.

    -> Formatting Requirements:
        - Replace all newline characters (\n) with \\n in the JSON output.
        - Ensure the complete JSON is less than 7500 tokens.
        - Start the output with "```json" and end with "```".
        - If an executive summary is provided, use only the highlighted features from it.

    Example Output Structure:
    ```json
    {
        "data": "**Overview**\\n\\n[Database overview]\\n\\n[Benefits summary]\\n\\n**Key Features**\\n\\n1. *Feature 1*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n2. *Feature 2*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n[...continue for up to 5 features...]\\n\\n[Closure statement]",
        "confidence_score": 90
    }
    ```

    Remember: Adhere strictly to the output format and instructions to maintain consistency and accuracy in your summary.
    """

    user_prompt += "User Defined Features : " + str(user_mvf)

    system_prompt = f"""
        <role>
        You are an assistant to a Senior Data Architect. You are very capable in reading, analyzing, and understanding complex database schemas and data models.
        No entity, constraint, relationship, or optimization logic goes unnoticed by you.
        You will be given a comprehensive database structure or schema information and will be asked to analyze, explain, and summarize it at a structural and functional level.
        </role>

        <Task>
        You will be given relevant database schema files or DDL definitions. The Senior Data Architect will consult you to clear doubts and ask for critical schema-level and data model-level analysis.
        <Important>
        1. You will be clear. Feel free to be descriptive but Avoid Jargon
        2. Perform a critical and deep analysis of the schema and the information given before responding.
        3. The schema will often involve multiple tables, foreign keys, views, procedures, and indexing strategies â€” be mindful of their dependencies and relationships.
        4. Enclose code or schema in (triple backticks)``` code ```
        </Important>
        </Task>

        Files from Database schema goes here :
        <Database Structure>
        {formatted_data}
        </Database Structure>
    """

    start_index = executive_summary.find("Highlighted Features")
    end_index = executive_summary.find("Key Benefits")

    if start_index != -1 and end_index != -1:
        executive_summary = executive_summary[start_index:end_index].strip()

    user_prompt += "Executive Summary : " + str(executive_summary)

    return system_prompt, user_prompt


#FEATURE HIERARCHY:
generate_features_system_prompt = """
  <Role>
    You are a Software Architect with expertise in analyzing large summaries from code files of an application. 
    You can comprehend summaries from code files that are complex, production-grade and are written in various programming languages to generate most important features, their description and the subfeatures with their description belonging to the most important features along with the other relevant information requested below.
    
    You will follow 2 Events before responding : 
    1. Generation of Feature Hierarchy as given in "Output_Format".
    2. Critical Evaluation of Every Confidence Score.  
  </Role> 

    <Task 1>
    You are provided with multiple relative file paths and file-wise code summaries from a application codebase.
    1. Analyze the file summaries carefully, leveraging your expertise to deduce the frameworks, functionality, and features.
    2. Perform a critical assessment of the code's functionality and interdependencies before responding.
    3. The codebase is complex and likely contains dependencies across various modules. Be mindful of these.
    4. Analyse every file summary and assign the features and sub-features based on the information provided.
    5. Respond strictly in the structured JSON format provided below.
    6. In each sub-feature's 'file_path' array:
        - Set 'critical: true' ONLY for files that are CORE & NON-REPLACEABLE to the sub-feature's main functionality.
        - Set 'critical: false' for ALL supporting, secondary, or replaceable files  
        - Each sub-feature should have both true and false entries.
        - If unsure, default to false (be EXTREMELY selective with 'true')
        - Make sure each sub-feature atleast have one file as true.

    Explanation of the Output terms:
    Feature - Features are most valuable and high level features extracted from the list of summaries that are provided to you. 
    Feature description - Description of the features explaining the high level value and impact that it creates for the project. Define the Feature. The description should be crisp, precise, well formatted and must be between 2-3 lines.
    Subfeature - Subfeatures are micro most valuable features that are extracted from the list of summaries and belong to the Most related and similar Features.
    Subfeature description - Description of the subfeatures explaining the specific value, technical and non-technical functionalites that it provided to the project. Define the subfeature and also explain how its related to the feature. The description should be crisp, precise, well formatted and must be between 2-3 lines.
    
    Points to Remember:
    1. Do not extract any feature or subfeature where there are no reference/citations from the application summaries.
    2. The description must be precise, valuable, well-formatted and must be between 2-3 lines.
    3. The Feature titles should be precise, specific, self explanaible, independent and not have similar feature titles. The Feature titles should not be highly generalized.
    4. The SubFeatures titles should be precise, self explanaible and not have similar subfeature titles. The SubFeature titles should not be highly generalized.
    5. SubFeatures should not be very low level that it explains code functions, code process like 'Json handling', 'Reading csv', readME etc.
    6. If similar subfeatures are present, then group them under one common Feature itself. Do not create multuple Features for similar subfeatures.
    6. If Unit testing related summaries are found, then create that as another Feature named 'Unit Testing' and assign the specific testing subfeatures under this feature.
    </Task 1>

  <Task 2>
  You shall now Assign and Justify Confidence Scores for each feature.

  <Critical Evaluation of Confidence Scores> 

  <Evaluation MODE>
  - You will now Forget everything that was done beforehand and act as an unbiased judge.
  - $Project-Summaries-&-Paths (INPUT).
  </Evaluation MODE>
  <Important>
  Critically analyze every "Feature" and "SubFeature" based on the following metrics. 
  You shall generate a confidence score between 0-100 for each of the following :
  1. Is the "Feature" & "SubFeature" name accurate to its functionality ? (Accuracy)
  2. Does the "Feature" & "SubFeature" include files with an unrelated function ? (Feature Dilution Rate)
  3. Important : Does this "Feature" & "SubFeature" make sense given the Overall Purpose of the Application ? (Consistency)
  4. Are all the files in "Feature" & "SubFeature" included ? (Completeness)

  <Strict>
  1. You will now generate a list of 4 confidence scores between 0-100 for above criteria under "confidence_score" key.
  2. Based on above criteria, you shall provide a VERY BRIEF logical explanation (10-20 words) for Confidence Score under "confidence_score_justification" key.
  3. Make sure to mention the entire filepath without omitting the prefix.
  4. Make sure all the filepaths are present.
  <Important> STRICTLY Don't Comment on Missing Files. Don't Overestimate. Don't Underestimate.</Important> 
  </Strict>

  </Important>

  </Critical Evaluation of Confidence Scores> 
  </Step 2>


      <Output_Format>
    Return a response in JSON format. Do not include any extra information or explanations. Strictly DON'T deviate from mentioned KEYS.
    Example:
```json
[
  {
    "name": "User Authentication and Management",
    "feature_description": "Comprehensive user account system with secure login, registration, profile management, and role-based access control.",
    "feature_description_confidence_score": [95, 70, 100, 70],
    "sub_features": [
      {
        "name": "User Registration",
        "description": "Allows new users to create accounts by providing necessary information such as username, email, and password. Implements email verification, password strength checks, and duplicate account prevention. Stores user data securely in the database with password hashing.",
        "file_path": [
          {
            "module_name": "RegistrationController",
            "path": "Controllers/Account/RegistrationController.cs",
            "critical": true
          },
          {
            "module_name": "RegisterView",
            "path": "Views/Account/Register.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [75, 80, 85, 65],
        "sub_feature_confidence_score_justification": "No feature dilution, might have missed some file."
      },
      {
        "name": "User Login",
        "description": "Authenticates users using their credentials, creates and manages user sessions, and implements security measures such as login attempt limiting and two-factor authentication (2FA). Provides password reset functionality for forgotten passwords.",
        "file_path": [
          {
            "module_name": "LoginController",
            "path": "Controllers/Account/LoginController.cs",
            "critical": true
          },
          {
            "module_name": "LoginView",
            "path": "Views/Account/Login.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [80, 100, 80, 75],
        "sub_feature_confidence_score_justification": "High chance of missing files."
      }
    ],
    "feature_confidence_score_justification": "No feature dilution, duplication or missing files. Accurate Naming."
  },
  {
    "name": "Product Catalog Management",
    "feature_description": "Comprehensive system for managing product listings, categories, and inventory across the e-commerce platform.",
    "feature_description_confidence_score": [95, 65, 70, 80],
    "sub_features": [
      {
        "name": "Product CRUD Operations",
        "description": "Enables administrators to create, read, update, and delete product listings. Includes functionality for managing product details such as name, description, price, images, and inventory levels. Implements validation to ensure data integrity and consistency across the product catalog.",
        "file_path": [
          {
            "module_name": "ProductController",
            "path": "Controllers/ProductController.cs",
            "critical": true
          },
          {
            "module_name": "ProductView",
            "path": "Views/Product/Index.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [90, 85, 100, 70],
        "sub_feature_confidence_score_justification": "High confidence with no duplication or dilution."
      },
      {
        "name": "Category Management",
        "description": "Allows for the creation and management of product categories and subcategories. Implements a hierarchical structure for organizing products, enabling efficient navigation and filtering of the product catalog for both administrators and customers.",
        "file_path": [
          {
            "module_name": "CategoryController",
            "path": "Controllers/CategoryController.cs",
            "critical": true
          },
          {
            "module_name": "CategoryView",
            "path": "Views/Category/Index.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [85, 75, 90, 95],
        "sub_feature_confidence_score_justification": "High confidence without any duplication or dilution."
      }
    ],
    "feature_confidence_score_justification": "All files refer to single overall functionality. Might have missed some files."
  }
]
```
  </Output_Format>

"""

generate_features_user_message = """
<Strictly Remember>
1. As input you will be given a batch of `file_path` and `file_summary` from a production codebase. Keep it in mind that it could be a file from a very large repository with lot of inter-dependencies.
2. Understand all the file description first, then try to determine the feature, sub-features and their description. For **each file** it should have a feature or sub-features whenever the conditions are met.
3. The response should contain all the fields given in the example output format. The response should be strictly in json format.
4. The description of features/subfeatures must be in the length of 2-3 lines. The response should be structured and well-formatted.
5. Don't generate any additional explanation or description. Provide the structured response in json only.
</Strictly Remember>
  
<Input file wise summary>
{file_summary}
</Input file wise summary>
<Response>
"""

merge_features_in_hierarchy_user_prompt = """You are a software feature analyzer. Given a list of related features that have been clustered together, create a merged feature that encompasses all the functionality.

Features to merge:
{feature_list}

Generate a JSON response that includes:
1. A name for the merged feature representing accurate feature name. Do not mention its merged or unified or anything as such. The feature name should accurately represent a major funcationality of a repository.
2. A detailed description that covers all functionality
3. A confidence score (0-100) for the merge
4. A justification for the confidence score

Respond with a JSON object in the following format:
```json
{{
    "name": "Merged feature name",
    "description": "Comprehensive description",
    "confidence_score": 85,
    "confidence_justification": "Reason for the confidence score"
}}
```
Give only JSON and nothing else. Do not include any explanations or additional text outside the JSON block. Make sure to start with ```json and end with ``` only.
"""

mapping_names_for_merged_features_user_prompt = """  <Role>
    You are a smart AI cassistant with strong expertise in Software Engineering. You can understand complex, production-grade codebases written in various programming languages and summarize them effectively.
  </Role>
  <Task>
  You will be given a brief description of  features of a large codebase and your task is to generate a relevant feature name, brief description, and priority level.
  <Important>
   1. The feature name should be brief, relevant and should represent the entire description provided.
   2. Generate a relevant description which is basically a overall summary of the description provided.
   3. Assign a priority level (high, medium, low) based on the significance, importance and complexity of the feature to the overall system. 
  </important>
  </Task>
  <Example output>
  ```json
    {
        "name": <feature_name>, //string
        "feature_description": <feature_description>, //string
        "priority": <priority> //string (high, medium, or low)
    }
    ```
  </Example output>
  <Strictly Remember>
1. The feature name should be relevant and at the same time interpretable, easy to understand.
2. The feature description should represnt the entire description given for summarisation, it should be simple and easy to understant.
3. The priority should be one of: high, medium, or low.
4. The response should be strictly in json format specified above.
5. Strictly make sure Feature Description is not more than 200 words.
  </Strictly Remember>

<code summary>
The code summary is given below:
"""


reducing_sub_features_user_prompt = """
    You are a software feature consolidation expert. Your task is to merge similar sub-features into one comprehensive sub-feature.

    Here are the sub-features that need to be merged:
    {sub_features_list}

    For each sub-feature, we have:
    - Name: The sub-feature name
    - Description: The sub-feature description (if available)
    - Confidence Score: The confidence score (if available)

    Your output should be a JSON object containing:
    1. A unified sub-feature name that encompasses all the input sub-features
    2. A comprehensive description that covers all aspects of the input sub-features
    3. A confidence score (use the highest available from input sub-features)
    4. A justification for the confidence score

    Return the output in JSON format starting with ```json and ending with ```.

    Example output format:
    ```json
    {{
        "name": "Unified Sub-Feature Name",
        "description": "Comprehensive description covering all aspects",
        "sub_feature_confidence_score": 95,
        "sub_feature_confidence_score_justification": "Merged from similar sub-features with high semantic similarity"
    }}
    ```
    """


post_processing_feature_name_description_system_prompt="""
  <Role>
    You are a smart AI assistant with strong expertise in Software Engineering. You can understand complex, production-grade codebases written in various programming languages and summarize them effectively.
  </Role>
  <Task>
  You will be given a brief description of modules or features of a large codebase and your task is to generate a relevant feature name and brief description.
  <Important>
   1. The feature name should be brief, relevant and should represent the entire description provided.
   2. Generate a relevant description which is basically a overall summary of the description provided.
   3. Also generate a confidence score in a scale of 0 - 100.
  </important>
  </Task>
  <Example output>
  ```json
    {
        "name": <feature_name>,
        "feature_description_confidence_score": <score 0 - 100>,
        "feature_description": <feature_description>
    }```
  </Example output>"""

post_processing_feature_name_description_user_prompt = """<Strictly Remember>
1. The feature name should be relevant and at the same time interpretable, easy to understant.
2. The confidence score should represent the ability to summarise the description.
3. The feature description should represnt the entire description given for summarisation, it should be simple and easy to understant.
4. The response should be strictly in json format specified above.
</Strictly Remember>
<code summary>
The code summary is given below: \n
{feature_description}
</code_summary>
<response>
Your response in json goes here:
"""

merge_similar_features_system_prompt = """You are a solution architect. Your task is to carefully review each feature and its description, and combine them into a single high-level feature.

The final high-level features should represent what an end user would perceive, e.g., Messenger, Google Chat, Messaging, Reels, etc.

Based on the generated features provided, identify which features can be merged into a single high-level feature. 
Strictly output them in the following format:
{{ 
  <High-Level Feature Name 1>: [<Merged Feature 1>, <Merged Feature 2>, <Merged Feature 3>, ...],
  <High-Level Feature Name 2>: [<Merged Feature 1>, <Merged Feature 2>, <Merged Feature 3>, ...],
  ...
}}

INPUT:
Feature names and descriptions are provided in the format: 
[1. Feature name: <feature name> 
Feature description: <feature description>, 
2. ...]

{feature_texts}

MVFS:
{total_MVFs}

Points to remember:
1. While merging features and naming high-level features, always prefer names from the user-defined MVFs provided. All relevant features can be grouped under these high-level features.
2. If certain features do not fit under the user-defined MVFs, choose a better name than the existing one for the new high-level feature if necessary.
3. The names of the features being merged must remain exactly as provided in the INPUT section; do not modify them. Do not consider Feature description in Feature Names.
4. Follow the output structure strictly: high-level feature names as dictionary keys and merged features as values in list format.
5. If a feature is already a high-level feature, you do not need to forcibly merge it. If a feature seems to be function-level/low-level  features, merge them into a High-level feature.
6. Merge similar features into a single high-level feature based on their names and descriptions, when applicable. Each final high-level feature should be independent of the others.
7. Do not assign the same feature to multiple high-level features.
8. If user-defined MVFs are empty, skip point 1 and begin with point 2.
9. Do **not** include any Feature descriptions in the final output."""


merging_description_user_prompt = """You are a Solution Architect. Your task is to summarize the multiple feature descriptions provided into a brief, coherent summary of **no more than two sentences**.

  The summary must:
  - Accurately capture all key components from the provided descriptions.
  - Align clearly with the given high-level feature name.
  - Serve as the final description of the high-level feature.

  Only the final summarized description should be included in the output â€” no additional commentary or formatting.

  INPUT:
  Multiple descriptions: {merging_feature_description}

  High-Level Feature Name: {high_level_feature}
  """


micro_sub_feature_prompt = """You are an expert system analyst specializing in decomposing SubFeatures into granular, logically independent components. You support **two levels** of splitting:

1. **Horizontal splitting**: Split a subfeature into multiple *same-level subfeatures* when it encompasses multiple independently meaningful functionalities. The subfeatures created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.
2. **Vertical splitting**: Further break each of those subfeatures into *microsubfeatures* (if applicable), ensuring each micro-sub-features/micro-user-story describes a single goal or operation. The micro-sub-features/micro-user-story created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.

---

### ðŸ”§ TASK OVERVIEW

Given a Macro-Feature, Subfeature, its description, associated module files and its summary:

- Decide if the subfeature should be split horizontally into multiple same-level subfeatures.
- For each resulting subfeature (or original if not split), analyze whether it can be split vertically into **microsubfeatures** (fine-grained user stories).
- Provide the confidence scores for the subfeature that is split, whether horizontally or vertically.
- Provide the files that are related to the sub_features too, not just the micro_sub_features.
- Each leaf user-story must have files assigned to them, else you should not create/split these subfeatures.
- Provide description of generated subfeature/sub-user-stories in 2-4 lines but only valid information. Do not assume or hallucinate to generate description.
Apply this recursively: if horizontal splitting occurs, then attempt vertical splitting for each. But remember, not to create any duplicates in the process. 

---

### SPLITTING DECISIONS

#### Horizontal Splitting (Same-level Subfeatures):
Split if:
- The subfeature covers multiple high-level functionalities
- Each function could be planned, developed, and deployed independently
- Each component has a clear boundary and responsibility

#### Vertical Splitting (Microsubfeatures):
Split further if:
- A subfeature contains multiple independent operations or logical stages
- These operations can be implemented, tested, or tracked separately
- Each micro-subfeature represents one atomic, non-overlapping functionality

---

### DO NOT SPLIT IF:
- sub-user-stories are tightly coupled in the Subfeature and cannot function independently.
- Do not split subfeatures into sub-user-stories that are hardly single line of code and cannot be considered as a proper functionality, but just a config/parameter.
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across actions are too complex to isolate.
- There are no files that can be mapped to the generated user-story.
- Do not split if the user-story is barely a functionality. The split user-stories must have independent functionality that contributes to the subfeature and feature and if not, do not split.
- Don not split ReadMe & .md files into sub-user-stories.
- Do not split horizontall for granullar subfeatures as they are not user stories but mid level features.
---

### FILE MAPPING RULES:
- For each subfeature or microsubfeature, cite only directly relevant files.
- Use only the provided input data to match files â€” no guessing.
- Avoid duplication unless a file is clearly shared between components.

Each `file_path` entry must include:
```json
{
  "module_name": "<Name>",
  "path": "<Path>",
  "critical": <true/false>,
  "git_url": "<Git URL>"
}

OUTPUT FORMAT
If the subfeature should NOT be split:
Return: "None"

If the subfeature should be split, return a list of Parent User Stories with subfeatures inside.
If a subfeature itself can be further split into microsubfeatures, nest them under micro_sub_features like so:

[
  {
    "name": "Parent User Story Title 1",
    "description": "Full description of the original or updated user story and its purpose.",
    "file_path": [...],
    "sub_feature_confidence_score":"confidence score of the subfeature with respect to the Feature, as a percentage (e.g., 80)"
    "micro_sub_features": [
      {
        "name": "Sub-User Story Title 1",
        "description": "Standalone description of a single functionality.",
        "file_path": [...],
        "micro_sub_feature_confidence_score":"confidence score of the micro_sub_feature with respect to the sub_feature, as a percentage (e.g., 90)"
        }
          ...
        ]
      },
      ...
    ]
  }
]
Each layer must preserve independence, clarity, and singular focus of each story.

VALIDATION CHECKLIST
- Each title must express one functionality only (no imperative phrasing)
- description must avoid assumptions and describe the real function. It must be as detailled as possible.
- Each story must make sense independently and fit in the broader feature flow
- if there are multiple user-story under the subfeature, it needs to be in sequence of business logic.
- File mappings must be relevant and scoped accurately
- Do no miss/skip any values in the output json. The output structure must be maintained strictly.
- All subfeature and sub-user-story names and descriptions must be strictly in a declarative tone, not imperative.

* Use generic or speculative statements
"""


db_micro_sub_feature_prompt = """
<Role>
You are an expert Database analyst specializing in decomposing SubFeatures into granular, logically independent components. You support **two levels** of splitting:
You shall ALWAYS process features from a Database perspective ONLY. 
There can be more than one Table in the DB context provided to you.
</Role>

1. **Horizontal splitting**: Split a subfeature into multiple *same-level subfeatures* when it encompasses multiple independently meaningful functionalities. The subfeatures created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.
2. **Vertical splitting**: Further break each of those subfeatures into *microsubfeatures* (if applicable), ensuring each micro-sub-features/micro-user-story describes a single goal or operation. The micro-sub-features/micro-user-story created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.

<Strict Constraints> 
- You are dealing with Database Information. 
- No matter what, STRICTLY use Database-Specific Language ALWAYS. 
- Use words like Columns / Fields / Schema / DataTypes / Constraints / Foreign Keys / Primary Keys etc.
- Strictly Do not start descriptions with or start with "this micro-feature" / or "this sub-feature".
- You shall do this regardless of the input context and nature.
Remember : Every "FILE" given to you is information of a table. Therefore in your response, ALWAYS refer to "Table" instead of "File".

</Strict Constraints> 


### ðŸ”§ TASK OVERVIEW

Given a Macro-Feature, Subfeature, its description, associated module files and its summary:

- Decide if the subfeature should be split horizontally into multiple same-level subfeatures.
- For each resulting subfeature (or original if not split), analyze whether it can be split vertically into **microsubfeatures** (fine-grained user stories).
- Provide the confidence scores for the subfeature that is split, whether horizontally or vertically.
- Provide the files that are related to the sub_features too, not just the micro_sub_features.
- Each leaf user-story must have files assigned to them, else you should not create/split these subfeatures.
- Provide description of generated subfeature/sub-user-stories in 2-4 lines but only valid information. Do not assume or hallucinate to generate description.
Apply this recursively: if horizontal splitting occurs, then attempt vertical splitting for each. But remember, not to create any duplicates in the process. 

---

### SPLITTING DECISIONS

#### Horizontal Splitting (Same-level Subfeatures):
Split if:
- The subfeature covers ONE / MORE THAN ONE high-level functionalities
- Each function could be planned and developed independently
- Each component has some clear boundaries and responsibilities

#### Vertical Splitting (Microsubfeatures):
Split further if:
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across actions are too complex to isolate.
- There are no tables that can be mapped to the generated user-story.
- The subfeature is too complex to be planned, developed, and deployed independently
- Each micro-subfeature represents one atomic, non-overlapping functionality
Note: Maintain at least 2 subfeatures unless the database has only one table.
- Prioritize brevity, consistency and no informaiton leakage across subfeatures.
- Ensure crisp segregation.
---

### DO NOT SPLIT IF:
- sub-user-stories are tightly coupled in the Subfeature and cannot function independently.
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across tables in two features are too complex to isolate.
- There are no tables that can be mapped to the generated user-story.
Note: Maintain at least 2 subfeatures and 1 or more microsubfeatures per subfeature, Unless the database has only one table.
Note : Maintain brevity during splitting at the same level. Do NOT overload the a single feature with too many subfeatures.
---


### FILE MAPPING RULES:
- For each subfeature or microsubfeature, cite only directly relevant tables.
- Use only the provided input data to match files â€” no guessing.
- Avoid duplication unless a file is clearly shared between components.

Each `file_path` entry must include:
```json
{
  "module_name": "<Name>",
  "path": "<Path>",
  "critical": <true/false>,
  "git_url": "<Git URL>"
}

OUTPUT FORMAT
If the subfeature should NOT be split:
Return: "None"

If the subfeature should be split, return a list of Parent User Stories with subfeatures inside.
If a subfeature itself can be further split into microsubfeatures, nest them under micro_sub_features like so:

[
  {
    "name": "Parent User Story Title 1",
    "description": "Full description of the original or updated user story and its purpose.",
    "file_path": [...],
    "sub_feature_confidence_score":"confidence score of the subfeature with respect to the Feature, as a percentage (e.g., 80)"
    "micro_sub_features": [
      {
        "name": "Sub-User Story Title 1",
        "description": "Standalone description of a single functionality.",
        "file_path": [...],
        "micro_sub_feature_confidence_score":"confidence score of the micro_sub_feature with respect to the sub_feature, as a percentage (e.g., 90)"
        }
          ...
        ]
      },
      ...
    ]
  }
]
Each layer must preserve independence, clarity, and singular focus of each story.

VALIDATION CHECKLIST
- Each title must express one functionality only (no imperative phrasing)
- description must avoid assumptions and describe the real function. It must be as detailled as possible.
- Each story must make sense independently and fit in the broader feature flow
- if there are multiple user-story under the subfeature, it needs to be in sequence of business logic.
- File mappings must be relevant and scoped accurately
- Do no miss/skip any values in the output json. The output structure must be maintained strictly.
- All subfeature and sub-user-story names and descriptions must be strictly in a declarative tone, not imperative.
- Use Database-specific schema only. Do not include words like "Attributes" / "Code Files" in your response. 
- Strictly Do not start descriptions with or start with "this micro-feature" / or "this sub-feature".
* Use generic or speculative statements

"""import os
from graphviz import Digraph
import re 
import json

def parse_ddl(ddl: str):
    """
    Parse the DDL to extract columns, primary keys, and foreign keys.
    """
    lines = ddl.splitlines()
    column_lines = []

    for line in lines:
        line = line.strip()
        if (
            line.upper().startswith("CREATE")
            or line.upper().startswith("PRIMARY")
            or line.upper().startswith("FOREIGN")
            or line.upper().startswith(")")
            or line == ""
        ):
            continue

        match = re.match(r'(\w+)\s+\w+', line)
        if match:
            column_lines.append(match.group(1))

    pk_match = re.search(r'PRIMARY KEY\s*\((.*?)\)', ddl)
    primary_keys = [key.strip() for key in pk_match.group(1).split(",")] if pk_match else []

    foreign_keys = []
    for match in re.finditer(r'FOREIGN KEY\s*\(([^)]+)\)\s+REFERENCES\s+`?[\w]+\.(\w+)`\(([^)]+)\)', ddl):
        fk_col = match.group(1).strip()
        ref_table = match.group(2).strip()
        ref_col = match.group(3).strip()
        foreign_keys.append((fk_col, ref_table, ref_col))

    return column_lines, primary_keys, foreign_keys


def generate_combined_graph(tables_data):
    """
    Generate a single combined graph from multiple tables.
    """
    dot = Digraph(comment='Combined Table Diagram')
    dot.attr(rankdir='LR')

    # Store individual table nodes
    for table in tables_data:
        table_name = table['table_name']
        columns = table['columns']
        primary_keys = table['primary_keys']
        
        label_lines = []
        for col in columns:
            if col in primary_keys:
                label_lines.append(f"{col} [PK]")
            else:
                label_lines.append(col)
        dot.node(table_name, shape='box', label=f'{table_name}\\n' + "\\n".join(label_lines))

    # Add relationships
    for table in tables_data:
        table_name = table['table_name']
        for fk_col, ref_table, ref_col in table['foreign_keys']:
            dot.edge(table_name, ref_table, label=f'{fk_col} â†’ {ref_col}')

    return dot

def folder_summary_generation_prompts(
        total_allocated_tokens, 
        file_list, folder_name, 
        folder_path,
        subfolder_list,
        formatted_file_summaries,
        formatted_file_services,
        formatted_subfolder_summaries,
        formatted_subfolder_services,
        formatted_subfolder_features
    ):
    
    system_prompt = f"""
        You are an expert code analyst specialized in creating detailed, informative summaries of software project folders. Your task is to thoroughly analyze files and subfolders to provide a comprehensive understanding of the application or project and provide combined summaries along with required details. These summaries must be detailled enough for further summarization.

        Follow these guidelines:
        1. Conduct a deep analysis of the features to identify its core purpose and functionality
        2. Provide detailed explanation of key implementations and technical approaches of the features
        3. Thoroughly examine the summaries based on files and folders to understand relationship between features and combined smaller features into larger high level application level features.
        4. Explain the features within the broader project architecture with specific connections
        5. Describe technical patterns, design decisions, and architectural choices evident in the code
        6. Include specific functions, classes, and methods that define the feature's behavior
        7. Note dependencies, imports, and external connections that shape the folder's functionality
        8. Identify potential architectural strengths and areas for improvement when evident
        9. Identify all services represented in this folder based on file and subfolder services information
        10. Identify and articulate high-level features or functionalities represented by the folder into the feature_details section, when consolidating multiple subfolders or lower-level files. Derive these insights from both file-level and subfolder-level summaries. Also under each feature, mention which file/folder was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
        11. Do not miss any features that could be formed based on these summaries as this information is required to understand the application's buisness logic.
        12. Gather insights from the summaries provided to generate a high level detailled executive summary that could be used by business stakeholders to understand the folder/project.
        13. When analyzing the root folder, both the executive summary and the features must be strictly formed in a high level business logic standpoint of an application.
        
        IMPORTANT: 
        - Your summary should be thorough and detailed({total_allocated_tokens}) while maintaining technical/business precision and depth. Focus on providing insights that would help both stakeholders and developers understand the application better.
        - feature_details must contain high level feature name and feature description(value of the files/folders) strictly in concise bullet points. The feature inforamtion must be in detail to capture the complete high level knowledge for that feature but not the function level details. Feature names cannot be programmatic function names like Dependency management, json handling etc. instead it should be inventory management, order processing etc. 
        - Your services list should be comprehensive and include all services represented in this folder.
        - is_reuasble_lib if a folder is used as reusable lib make it True otherwise False
        - lib_name if is_reusable_lib is True then provide the name of the reusable lib/component If is_reusable_lib False then add Not Applicable
        - category if is_reusable_lib is True then provide category only between 'Frontend' and 'Backend' If is_reusable_lib False then add Not Applicable
        - sub_category if is_reusable_lib is True then provide sub category only between 'UI Component','Custom Hooks', 'http_client', 'Utils', 'Others' In Frontend & 'Middleware', 'Error Handling', 'Auth', 'Utils', 'Others' In Backend If is_reusable_lib False then add Not Applicable
        - when_to_use if is_reusable_lib is True then provide where this reusable lib/component can be used If is_reusable_lib False then add Not Applicable 
        - associated_files if is_reusable_lib is True then provide the list of files associated(give complete path for the assosciated file) with this reusable lib/component If is_reusable_lib False then add Not Applicable
        - summary must not be technical and only explain the high level details of the folder/project. Understand the file and folder summaries provided to combine the knowledge to form the executive summary. Make it as detailled as possible.
        - Use clear and concise language, avoiding jargon where possible.
        
        - You must provide your response in this exact format:
        ```summary
        [Your detailled high-level executive summary for the folder for business stakeholders]
        ```
        ```feature_details
        [List of high-level features or functionalities represented in this folder]
        ```
        ```services_namess
        [Comma-separated list of all services represented in this folder]
        ```
        ```is_reuasble_lib
        Boolean Value
        ```
        ```lib_name
        [Name of the reusable library if applicable]
        ```
        ```category
        [Category of the reusable library if applicable]
        ```
        ```sub_category
            [Sub category of the reusable library if applicable]
        ```
        ```when_to_use
        [Your detailed use case where or when this reuasble_lib can be usefull]
        ```
        ```associated_files
            [Comma-separated list of associated files with the reusable library, Give the Complete file path as mentioned in the file list]
        ```
        ```example_usage
            [Example code snippet of how to use this reusable library]
        ```
    """

    user_prompt = f"""
        Generate a summary and services list for the folder: "{folder_name}" (Path: {folder_path})

        FOLDER CONTENTS:
        - Files ({len(file_list)}): {", ".join(file_list) if file_list else "None"}
        - Subfolders ({len(subfolder_list)}): {", ".join(subfolder_list) if subfolder_list else "None"}

        FILE SUMMARIES:
        {os.linesep.join(formatted_file_summaries) if formatted_file_summaries else "No file summaries available"}

        FILE SERVICES:
        {os.linesep.join(formatted_file_services) if formatted_file_services else "No file services available"}

        SUBFOLDER SUMMARIES:
        {os.linesep.join(formatted_subfolder_summaries) if formatted_subfolder_summaries else "No subfolder summaries available"}

        SUBFOLDER SERVICES:
        {os.linesep.join(formatted_subfolder_services) if formatted_subfolder_services else "No subfolder services available"}

        SUBFOLDER FEATURES:
        {os.linesep.join(formatted_subfolder_features) if formatted_subfolder_features else "No subfolder features available"}
        
        Based on these components:
        1. Provide a thorough technical summary explaining the folder's purpose, implementation details, and architectural significance
        2. Compile a comprehensive list of all services represented in this folder based on file and subfolder services information
        
        Follow the exact format specified in the system instructions for your response.
    """

    return system_prompt, user_prompt

def services_generation():
    system_prompt = """
        <Task>
        Create an architectural blueprint of the given repository by identifying and classifying both external services and third-party services with no overlap between categories.
        </Task>

        <Definitions>
        - External services: Company-provided services hosted outside the application (AWS S3, Google Cloud, Stripe, Twilio)
        - Third-party services: Libraries, frameworks, and SDKs that are part of the core application stack (Django, React, MongoDB, Redux)
        </Definitions>

        <Output_Format>
        {
        "external_services": [
            {
            "external_service_name": "string",
            "description": "string",
            "associated_files": ["string"],
            "service_class": "string",
            "used_in_files": ["string"]
            }
        ],
        "thirdparty_services": [
            {
            "thirdparty_service_name": "string",
            "description": "string",
            "associated_files": ["string"],
            "service_class": "string",
            "used_in_files": ["string"]
            }
        ]
        }
        </Output_Format>

        <Instructions>
        1. Conduct a thorough repository analysis to identify all services
        2. Classify each service into exactly ONE category:
        - External services: Cloud platforms, payment processors, authentication providers
        - Third-party services: Frameworks, libraries, SDKs integrated into the codebase
        3. For each service, provide:
        - Name: Exact service name
        - Description: Concise explanation of functionality and purpose
        - Associated files: All files directly importing or using the service
        - Service class: Category (e.g., "cloud storage", "web framework", "database")
        - Used in files: Complete paths of files utilizing the service
        4. Ensure ZERO overlap between categories
        5. Prioritize accuracy over comprehensiveness
        6. Validate that identified services are actively used in the project
        7. Include only services with clear evidence of implementation
        8. Do not create a lot of services which are redundant. Keep it to a maximum of 50 services only.
        </Instructions>

        <Examples>
        Good External Service Entry:
        {
        "external_service_name": "AWS S3",
        "description": "Cloud storage service used for storing user-uploaded files",
        "associated_files": ["src/services/storage.js", "src/config/aws.js"],
        "service_class": "cloud storage",
        "used_in_files": ["src/components/FileUpload.js", "src/pages/UserProfile.js"]
        }

        Good Third-Party Service Entry:
        {
        "thirdparty_service_name": "React",
        "description": "Frontend JavaScript library for building user interfaces",
        "associated_files": ["package.json", "src/index.js"],
        "service_class": "frontend framework",
        "used_in_files": ["src/App.js", "src/components/*.js"]
        }
        </Examples>

        Analyze the repository and provide the complete architectural blueprint in the specified format.
    """

    user_prompt = ""

    return system_prompt, user_prompt

def executive_summary_generation(combined_summary, user_mvf):
    system_prompt = """
    Your Role:
    You are an expert software architect tasked with understanding a codebase and creating an executive summary that clearly articulates the main purpose of this application,
    the core problem that the application is solving, and the prioritized list of the most valuable features, solely based on the provided folder wise summary. Do not hallucinate and create the most valuable features and its description on assumption. This needs to be based on facts.

    Task:
    1. Analyze provided folder wise summary and the services used and the user defined features (if provided).
    2. Understand component interactions and functions.
    3. Prioritize the User Defined Features (if provided) in the summary.
    4. Identify and prioritize the most valuable features based on their importance and relevance to the overall project, as evidenced in the code.
    5. Create a comprehensive executive summary.

    Steps:
    1. Review folder wise summary.
    2. Analyze folder wise summary:
    - Identify key components and their roles
    - Note data operations, design patterns, and architectural decisions
    3. Create summary:
    - Describe the specific problem the codebase solves, based on folder wise summary
    - Explain component interactions
    - Outline data workflow
    4. Identify and prioritize main features:
    - Determine which feature(s) address the core problem of the application, based on code implementation
    - Rank features based on their importance and relevance to solving the main problem, as evidenced in the code
    - The feature should be major components of the codebase and not minor functions like "Modular Architecture" or "Code Reusability", these are not features but design principles.

    Focus Areas:
    - Precised feature prioritization and importance
    - High-level functionality
    - Clear, concise technical language
    - Objective description
    - Capture entire workflow

    Guidelines:
    - Only use the folder wise summary provided
    - Use precise technical terms
    - Include user-defined features if provided and evidenced in the code
    - Prioritize features based on their importance to the core problem, as shown in the folder wise summary

    Feature Identification and Prioritization:
    - Carefully analyze the folder wise summary to identify features actually present in the folder wise summary
    - Do not assume or infer features that are not explicitly mentioned in the folder wise summary
    - Identify the top feature that solves the majority of the problem based on code evidence
    - Rank subsequent features in descending order of importance, ensuring they are present in the folder wise summary
    - Ensure the feature list reflects the codebase's focus and structure
    - Only include features that have substantial implementation in the codebase that is evident from folder wise summary

    Output Format - Adhering to this format is crucial
    ```json
    {
    "data": "generated_summary in string format adhering to the Expected Output Format for Generated Summary",
    "confidence_score": 90,
    "traceback": {
    "Feature 1 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 1 Title' is included, as the 'phrase' is an evidence that this feature is part of the codebase.",
    "Feature 2 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 2 Title' is included, as the 'phrase' is an evidence that this feature is part of the codebase.",
    ...
    }
    }
    ```

    Requirements:
    - Replace \n with \\n in JSON
    - Limit upto 5 main features (max 2 sub-features each) or 7500 tokens
    - If due to any reason such as codebase being small, you are unable to provide 5 features, then provide as many high-level features as possible between the range of 1 to 5.
    - Don't assume features or include minor features due to inability to provide 5 features, lesser number of features is acceptable.
    - Use specified JSON format only
    - Start with "```json" and end with "```"
    - Ensure the top feature in the prioritized list addresses the core problem and is present in the folder wise summary
    - Rank features in descending order of importance to the main problem, based on actual code implementation
    - Do NOT include features that are NOT evidenced in the provided folder wise summary
    - Evaluate the folder wise summary objectively, considering all conclusions on the actual code provided
    - Do NOT make any assumptions about organizational goals or intentions beyond what is explicitly shown in the code
    - Focus solely on the technical aspects and implemented functionality, avoiding speculation about business objectives or future plans
    - Both the keys data, confidence score, and traceback should be present in the output JSON
    - The generated summary should be in string format only and be contained inside the "data" key
    - The "traceback" key should contain a dictionary with feature names as keys and justifications for including these features based on exact phrases from the input
    - Do not include any feature that could potentially be part of the folder wise summary without explicit evidence
    - Every feature mentioned must be driven by clear evidence from the provided input
    """
    user_prompt = """
    Expected Output Format for Generated Summary:

  **Overview**
  <empty line>
  <A brief introduction to the codebase and its main purpose; in paragraph format only, not in points.
  This paragraph should provide a concise yet comprehensive overview of the codebase, its primary functionality, solution provided by the project and its intended use case.
  Aim for 3-5 sentences that capture the essence of the project.>
  <empty line>
  **Highlighted Features**
  <empty line>
  <
  List and briefly explain the key features that are significant components of the codebase and would serve as selling points.
  These features should be presented as follows:
  1. Use numbered points for each feature.
  2. Provide a brief explanation for each feature in 1-2 sentences, highlighting its importance and benefit to the end user.
  3. Focus on features that are central to the codebase's functionality and most important to the end user.
  4. Dont include generic features like "Modular Architecture" or "Code Reusability", these are not features but design principles.
  5. Do not include sub-points under any feature.
  6. Prioritize User Defined Features (if provided) at the beginning of the list.
  7. If User Defined Features are given, list them first before including any features identified through your analysis.
  8. Aim to provide upto of 1 to 5 key features, after each feature add an empty line for formatting purposes.
  9. Ensure that the features listed represent the core functionality and unique selling points based on the folder wise summary.
  10. Use clear, concise language that emphasizes the value proposition of each feature.
  11. Also under each feature, mention which file/folder was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
  12. Do not add features into Highlighted Features if they dont have value for buisness stakeholder about the application. Also do not repeat adding similar feature in this section.

  Output Structure:
  1. ***<Feature 1 Title>***: <Description of the feature in one to two sentences.\n
  2. ***<Feature 2 Title>***: <Description of the feature in one to two sentences.>\n
  >
  <empty line>
  **Key Benefits**
  <empty line>
  <Summarize the key benefits of the codebase in one to two sentences.
  This summary should encapsulate the overall value proposition of the codebase and its potential impact on users or the organization.>
  <empty line>
  <Highlight the most significant key benefits the codebase has to offer in bulleted points. The format should be:
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  Aim for 3-5 bullet points that capture the most compelling advantages of using this codebase, after each point add an empty line for formatting purposes.
  Each benefit should be distinct and provide a clear value proposition.>

  <Final Output Format>
  Output Format - Adhering to this format is crucial, the output should be in parsable JSON format:
  ```json
  {{
    "data": "<generated_summary in string format adhering to the Expected Output Format for Generated Summary>",
    "confidence_score": 90,
    "traceback": {{
      "Feature 1 Title": "Since it mentions about <exact phrase from the folder wise summary>, the 'Feature 1 Title' is included, as the "phrase" is an evidence that this feature is part of the folder wise summary.",
      "Feature 2 Title": "Since it mentions about <exact phrase from the folder wise summary>, the 'Feature 2 Title' is included, as the "phrase" is an evidence that this feature is part of the folder wise summary.",
      ...
    }}
  }}
  ```
  </Final Output Format>
  Note: If the traceback includes phrases that are not present in the folder wise summary then you would be penalized 10000 points.
  The output should be having data, confidence score, and traceback keys, and the entire content inside "```json" and "```" should be parsable by json.
  The "data" key should contain the generated summary and it should be in string format only, allowing the parsing of the entire json.
  If there are any inverted commas inside the generated summary, then escape them with a backslash.
  Do not change or skip the headings of each section in the generated json. The generated summary must have "Overview", "Highlighted Features", "Key Benefits" as section titles. Follow the above provided guidelines."""
    user_prompt += f"""Use the below folder wise summary to generate the summary in the above format: {combined_summary}""" + "User Defined Features : " + str(user_mvf)
    return system_prompt, user_prompt

def db_executive_summary_generation(combined_summary, user_mvf): 
    system_prompt = """
    Role:
    You are an expert Database Architect tasked with understanding the contents of all tables and schema of the database. 
    You shall Articulate a proper executive summary that clearly captures all the main & high-level features of this database.
    The core use-case that this database is intended for, and the prioritized list of the most valuable features, solely based on the provided Table-Level summaries. 
    Do not hallucinate. Do NOT create the most valuable features and its description on pure assumptions. This needs to be based on facts, with proper backing.

    Task:
    1. Analyze provided Table wise summaries.
    2. Understand component interactions and functions.
    3. Prioritize the User Defined Features (if provided) in the summary.
    4. Identify and prioritize the most valuable features based on their importance to the core use-case the Database is solving.
    5. Create a comprehensive executive summary.

    Steps:
    1. Review Table wise summary.
    2. Analyze Table wise summary:
      - Identify all tables. 
      - Take into consideration the foreign keys, primary keys, is-a, has-a, and many-to-many relationships.
      - Deeply understand the intended-use-case of each table.
      - Note data operations, design patterns, and architectural decisions
    3. Create summary:
      - Describe the specific problem the Database is solving, based on Table wise summary
      - Explain high-level interactions and dependencies
      - Outline data workflow
    4. Identify and prioritize main features:
      - Determine which feature(s) address the core problem of the Database, based on SQL implementation and Table wise summary
      - Rank features based on their importance and relevance to solving the main problem, as evidenced in the Database
      - The feature should be major components of the Database and not minor functions like Many-to-Many Relationships, or "Foreign Keys". 
        These are implementation concepts. Not core features.

    Focus Areas:
    - Precised feature prioritization and importance
    - High-level functionality of this Database
    - Clear, concise technical language with Database-specific Language
    - Objective description
    - Capture entire data workflow

    Guidelines:
    - Only use the Table wise summary provided
    - Use precise Database-relevant technical terms
    - Include user-defined features if provided and evidenced in the Table wise summary
    - Prioritize features based on their importance to the core problem, as shown in the Table wise summary

    Feature Identification and Prioritization:
    - Carefully analyze the Table wise summary to identify features actually present in the Table wise summary
    - Do not assume or infer features that are not explicitly mentioned in the Table wise summary
    - Identify the top feature that solves the majority of the problem based on Database and SQL evidence
    - Rank subsequent features in descending order of importance, ensuring they are present in the Table wise summary
    - Ensure the feature list reflects the Database's focus and structure
    - Only include features that have substantial implementation in the Database that is evident from Table wise summary

    Output Format - Adhering to this format is crucial
    ```json
    {
    "data": "generated_summary in string format adhering to the Expected Output Format for Generated Summary",
    "confidence_score": 90,
    "traceback": {
    "Feature 1 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 1 Title' is included, as the 'phrase' is an evidence that this feature is part of the Database.",
    "Feature 2 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 2 Title' is included, as the 'phrase' is an evidence that this feature is part of the Database.",
    ...
    }
    }
    ```

    Requirements:
    - Replace \n with \\n in JSON
    - Limit upto 5 main features (max 2 sub-features each) or 7500 tokens
    - If due to any reason such as Database being small, you are unable to provide 5 features, then provide as many high-level features as possible between the range of 1 to 5.
    - Don't assume features or include minor features due to inability to provide 5 features, lesser number of features is acceptable.
    - Use specified JSON format only
    - Start with "```json" and end with "```"
    - Ensure the top feature in the prioritized list addresses the core problem and is present in the Table wise summary
    - Rank features in descending order of importance to the main problem, based on actual Database and SQL implementation
    - Do NOT include features that are NOT evidenced in the provided Table wise summary
    - Evaluate the Table wise summary objectively, considering all conclusions on the actual Database and SQL provided
    - Do NOT make any assumptions about organizational goals or intentions beyond what is explicitly shown in the Database and SQL
    - Focus solely on the technical aspects and implemented functionality, avoiding speculation about business objectives or future plans
    - Both the keys data, confidence score, and traceback should be present in the output JSON
    - The generated summary should be in string format only and be contained inside the "data" key
    - The "traceback" key should contain a dictionary with feature names as keys and justifications for including these features based on exact phrases from the input
    - Do not include any feature that could potentially be part of the Table wise summary without explicit evidence
    - Every feature mentioned must be driven by clear evidence from the provided input.
    - Strictly use an assertive and objective tone in your response. 
    - Do not be unsure about anything.
    - Do not include the "Folder Name" in your response. Ignore "dbanalysis" folder. Provide Executive Summary of the Database-ONLY.
    """

    user_prompt = """
  Expected Output Format for Generated Summary:

  **Overview**
  <empty line>
  <A brief introduction to the Database and its main purpose; in paragraph format only, not in points.
  This paragraph should provide a concise yet comprehensive overview of the Database, its primary functionality, and its intended use case.
  Aim for 3-5 sentences that capture the essence of the Database.>
  <empty line>
  **Highlighted Features**
  <empty line>
  <
  List and briefly explain the key features that are significant components of the Database and would serve as selling points.
  These features should be presented as follows:
  1. Use numbered points for each feature.
  2. Provide a brief explanation for each feature in 1-2 sentences, highlighting its importance and benefit to the END USER.
  3. Focus on features that are central to the Database's functionality and most important to the END USER.
  4. Dont include generic features like  Many-to-Many Relationships, or "Foreign Keys", these are not features but Design Principles.
  5. Do not include sub-points under any feature.
  6. Prioritize User Defined Features (if provided) at the beginning of the list.
  7. If User Defined Features are given, list them first before including any features identified through your analysis.
  8. Aim to provide upto of 1 to 5 key features, after each feature add an empty line for formatting purposes.
  9. Ensure that the features listed represent the core functionality and unique selling points based on the Table wise summary.
  10. Use clear, concise language that emphasizes the value proposition of each feature.
  11. Also under each feature, mention which file/Table was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
  12. Do not add features into Highlighted Features if they dont have value for buisness stakeholder about the application. Also do not repeat adding similar feature in this section.

  Output Structure:
  1. ***<Feature 1 Title>***: <Description of the feature in one to two sentences.\n
  2. ***<Feature 2 Title>***: <Description of the feature in one to two sentences.>\n
  >
  <empty line>
  **Key Benefits**
  <empty line>
  <Summarize the key benefits of the Database in one to two sentences.
  This summary should encapsulate the overall value proposition of the Database and its potential impact on users or the organization.>
  <empty line>
  <Highlight the most significant key benefits the Database has to offer in bulleted points. The format should be:
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  Aim for 3-5 bullet points that capture the most compelling advantages of using this Database, after each point add an empty line for formatting purposes.
  Each benefit should be distinct and provide a clear value proposition.>

  <Final Output Format>
  Output Format - Adhering to this format is crucial, the output should be in parsable JSON format:
  ```json
  {{
    "data": "<generated_summary in string format adhering to the Expected Output Format for Generated Summary>",
    "confidence_score": 90,
    "traceback": {{
      "Feature 1 Title": "Since it mentions about <exact phrase from the Table wise summary>, the 'Feature 1 Title' is included, as the "phrase" is an evidence that this feature is part of the Table wise summary.",
      "Feature 2 Title": "Since it mentions about <exact phrase from the Table wise summary>, the 'Feature 2 Title' is included, as the "phrase" is an evidence that this feature is part of the Table wise summary.",
      ...
    }}
  }}
  ```
  </Final Output Format>
  Note: If the traceback includes phrases that are not present in the Table wise summary then you would be penalized 10000 points.
  The output should be having data, confidence score, and traceback keys, and the entire content inside "```json" and "```" should be parsable by json.
  The "data" key should contain the generated summary and it should be in string format only, allowing the parsing of the entire json.
  If there are any inverted commas inside the generated summary, then escape them with a backslash.
  Do not change or skip the headings of each section in the generated json. The generated summary must have "Overview", "Highlighted Features", "Key Benefits" as section titles. Follow the above provided guidelines.
    """

    user_prompt += f"""Use the below Table wise summary to generate the summary in the above format: {combined_summary}""" + "User Defined Features : " + str(user_mvf)

    return system_prompt, user_prompt


def architecture_diagram_generation(services_data, icons_metadata):
    user_prompt = f"""
    <Input>
    $services_data = {services_data}
    $icons_metadata
    </Input>

    <Role>
    You are an expert at understanding large projects based on their executive summary and the services being used in them. Create a JSON structure for a ReactFlow diagram based on the given service class JSON.
    </Role>

    <Output Structure>
    1. Create a JSON object with a "nodes" and "edges" array.
    2. Create nodes for each external and third-party service.
    3. "nodes": An array containing all node objects.
      - "id": A unique string identifier for the node.
      - "data":   
        - "label": The name of the node.
        - "description": Description of the service.
        - "associated_files": Associated file and used in files in the service node, defaulting to "No File Available" if not present.
        - "group": The logical group name (e.g., 'Backend', 'Frontend', 'Database',etc..).
        - "subgroup": The specific subgroup within the group (e.g., Frameworks, NoSQL Databases, State Management, etc.).
        - "service": The appropriate filename of the icon based on the $icons_metadata.
      - "position" : The x and y coordinates of the node.
      - "type" : "customNode" This should be fixed.
    4. "edges" : An array having id, source, target, label, and type should be customEdge always.
    4. Ensure all services and files from the input JSON are included.
    5. The output should be in the form of a dictionary containing a "nodes" and "edges" array.
    6. Present only the code inside delimiters "```reactflow [reactflow CODE]```" without any additional explanation.
    """

    system_prompt:str = """
    <Task>
      You are tasked with creating a JSON structure for a ReactFlow diagram based on the given executive summary and the service_class_json. The executive summary contains an overview of the entire project. This JSON includes information about external services and third-party services, along with their associated files. Your output should represent this information as a network of nodes and edges.
    </Task>
    
    <Icons Context>
      $icons_metadata = """ + str(icons_metadata) + """
    </Icons Context>

    <Instructions>
      You are a solution expert, specializing in problem and solution flows. You will be given the solution overview for a project, and your task is to create an interconnected single component of graph which is detailed, and intuitive and self explanatory for:

      Follow these guidelines:
      1. Create nodes for each unique service (both external and third-party).
      2. Do not create any group nodes.
      4. In the data key for each service node, include two additional fields called group and subgroup. The group field should contain the logical group name (e.g., Frontend, Backend, Databases, etc..), and the subgroup field should provide more specific categorization (e.g., Frameworks, NoSQL Databases, etc..). For example, for a service node representing React, the group would be Frontend and the subgroup would be Frameworks.
      5. For each node, check which icon will be the most suitable from the $icons_metadata in the <Icons Context>
      6. Ensure all information from the input is represented in the output.
      7. The position coordinates must be proper for all the nodes.
    </Instructions>

    <Rules>
      **Ensure all nodes in the generated graph are interconnected such that every node has at least one edge, forming a single connected component without any isolated or disjoint sections. (High Priority Requirement)**
      Important Rules to be followed:
      1. Give detailed technical architecture flow and the JSON object following the below output format.
      2. Make sure that the flow and order of new solution approach is explained well in the graph with appropriate edges. Use as many edges you want to describe the data and user flow properly.
      3. The whole user and data flow should be clear.
      4. Do not add unnecessary nodes and edges. Do not create duplicate nodes that perform same task.
      5. Make the Node descriptions detailed, breaking tasks into multiple sub-tasks if needed.
      6. Ensure your edges show the actual flow, and not just connections of what's related. The connections are meant to show the logical flow, and not the relatedness/similarity.
      7. The group name is meant to classify clusters of nodes within each graph. For instance, if we have multiple nodes in features, they would all have "feature" as group. In Architecture Flow, the "Group" should show the layer each node is in, for instance "Backend Layer", "Database Layer" etc.
      9. for a hierarchy of nodes A -> B -> C; ensure that there is not a connection between A -> C.
    </Rules>
    
    <output_format>
    The output should be in between the delimeters ```reactflow and ```. Only provide the json output. Don't give unnecesary explanation.
    ```reactflow
    {
      "nodes": [
        { 
          "id": "unique_node_identifier_string",
          "data" : {
            "label": "name_of_the_service",
            "description": "description of the service",
            "associated_files": ["file_path_1", "file_path_2", "file_path_3", etc.],  // (default: ["No File Available"] if not present)
            "group": "name_of_group",  // Add the logical group name (e.g., "Frontend", "Backend", etc..)
            "subgroup": "name_of_subgroup",  // Add a more specific subgroup name (e.g., "Frameworks", "NoSQL Databases", etc..)
            "service": "filename" //taken from the $icons_metadata,
          }
          "position":{ "x": "Xcoordinate", "y": "Ycoordinate" },
          "type" : "customNode" //this is hardcoded and will be constant
        }
      ],
      "edges": [
        {
          "id": "unique_egde_identifier_string",
          "source": "label A",
          "target": "label B",
          "label": "Showcase what comes from the source node, to the target node. Be concise and specific with labels, such as 'Ingested Data', 'Converted Text', 'User Query' etc. Use at max 5 words",
          "type" : "customEdge" //this is hardcoded and will be constant
        }
      ]
    }```
    </output_format>
    """
    return system_prompt, user_prompt
  

def erd_generation(services_data, icons_metadata):
  tables_metadata = []
  for entry in services_data:
      table_name = entry["table_name"]
      ddl = entry["ddl"]
      columns, primary_keys, foreign_keys = parse_ddl(ddl)
      tables_metadata.append({
          "table_name": table_name,
          "columns": columns,
          "primary_keys": primary_keys,
          "foreign_keys": foreign_keys
      })

  dot = generate_combined_graph(tables_metadata)

  system_prompt:str = """
    You are tasked with creating a JSON structure for a ReactFlow diagram based on the given database ER diagram and schema JSON. This JSON includes information about database columns and their relationships.Your output should represent this information as a network of nodes and edges.
    </Task>
    
    <Icons Context>
      $icons_metadata = """ + str(icons_metadata) + """
    </Icons Context>

    <Instructions>
      You are a solution expert, specializing in problem and solution flows. You will be given the database schema information of a database, and your task is to create an interconnected single component of graph which is detailed, and intuitive and self explanatory for:

      Follow these guidelines:
      1. Create nodes for each unique service (both external and third-party).
      2. Do not create any group nodes.
      4. In the data key for each service node, include two additional fields called group and subgroup. The group field should contain the logical group name (e.g.,Databases, etc..), and the subgroup field should provide more specific categorization (e.g., 'Transactional Tables', 'Reference Tables' etc..). For example, for a service node representing daily transactions, the group would be Database and the subgroup would be Transactional Tables.
      5. For each node, check which icon will be the most suitable from the $icons_metadata in the <Icons Context>
      6. Ensure all information from the input is represented in the output.
      7. The position coordinates must be proper for all the nodes.
    </Instructions>

    <Rules>
      Important Rules to be followed:
      1. Give detailed technical architecture flow and the JSON object following the below output format.
      2. Make sure that the flow and order of new solution approach is explained well in the graph with appropriate edges. Use as many edges you want to describe the data and user flow properly.
      3. The whole user and data flow should be clear.
      4. Do not add unnecessary nodes and edges. Do not create duplicate nodes that perform same task.
      5. Make the Node descriptions detailed, breaking tasks into multiple sub-tasks if needed.
      6. Ensure your edges show the actual flow, and not just connections of what's related. The connections are meant to show the logical flow, and not the relatedness/similarity.
      7. The group name is meant to classify clusters of nodes within each graph. For instance, if we have multiple nodes in features, they would all have "feature" as group. In Architecture Flow, the "Group" should show the layer each node is in, for instance "Database Layer" etc.
      9. for a hierarchy of nodes A -> B -> C; ensure that there is not a connection between A -> C.
    </Rules>
    
    <output_format>
    The output should be in between the delimeters ```reactflow and ```. Only provide the json output. Don't give unnecesary explanation.
    ```reactflow
    {
      "nodes": [
        { 
          "id": "unique_node_identifier_string",
          "data" : {
            "label": "name_of_the_table",
            "description": "description of the table",
  	    "columns": ["order_id [PK]", "product_sku [PK]", "quantity", "unit_price"]
            "group": "name_of_group",  // Add the logical group name (e.g., "Database", etc..)
            "subgroup": "name_of_subgroup",  // Add a more specific subgroup name (e.g., 'Transactional Tables', 'Reference Tables', etc..)
            "service": "filename" //taken from the $icons_metadata,
          }
          "position":{ "x": "Xcoordinate", "y": "Ycoordinate" },
          "type" : "customNode" //this is hardcoded and will be constant
        }
      ],
      "edges": [
        {
          "id": "unique_egde_identifier_string",
          "source": "label A",
          "target": "label B",
          "label": "Showcase what comes from the source node, to the target node. Be concise and specific with labels, such as 'Ingested Data', 'Converted Text', 'User Query' etc. Use at max 5 words",
          "type" : "customEdge" //this is hardcoded and will be constant
        }
      ]
    }```
    </output_format>
    """
    
  user_prompt:str = f"""
    <Input>
    $database_tables = {dot}
    $icons_metadata
    </Input>

    <Role>
    You are an expert at understanding database architecture based on ER diagrams and relational structures. Create a JSON structure for a ReactFlow diagram based on the given database schema.
    </Role>
    <Output Structure>
      1. Create a JSON object with a "nodes" and "edges" array.
      2. Create nodes for each table in the schema.
      3. "nodes": An array containing all node objects.
      - "id": A unique string identifier for the node.
      - "data":  
        - "label": The name of the table.
        - "description": A brief summary of the table's role or content.
        - "columns": List of column names (mark primary keys with [PK], foreign keys with [FK]).
        - "group": The logical group name (e.g., 'Database').
        - "subgroup": The specific subgroup within the group (e.g., 'Transactional Tables', 'Reference Tables').
        - "service": The appropriate filename of the icon based on the $icons_metadata.
      - "position" : The x and y coordinates of the node.
      - "type" : "customNode" This should be fixed.
      4. "edges" : An array having id, source, target, label, and type should be customEdge always.
      5. The label of the edge should describe the relationship, like "order_id â†’ order_id". 
      6. The output should be in the form of a dictionary containing a "nodes" and "edges" array.
      7. Present only the code inside delimiters "```reactflow [reactflow CODE]```" without any additional explanation.
    """
    
  return system_prompt, user_prompt
    

def feature_summary_generation(formatted_data, user_mvf, executive_summary):
    # if input_type is None:
    #     formatted_data = file_summary_list
    # elif input_type == "batch_summary":
    #     formatted_data = format_batchwise_summary_metadata_for_services(file_summary_list)
    # else:
    #     formatted_data = format_file_summaries(file_summary_list)

    user_prompt = """
    Role: You are an AI code analyst specializing in creating concise, feature-level summaries of codebases.

    Objective: Provide a comprehensive yet concise feature-level summary of a given codebase, highlighting key components, functionality, and the project's overall workflow.

    Input: You will receive information about a codebase, which may include an executive summary or other project details.

    Steps:
    1. Analyze the provided codebase information.
    2. Identify the main features (maximum 5) of the project from the executive summary (if provided in same order)
    3. Create a summary following the specified format, including:
        a. An overview of the project
        b. A list of key features with brief descriptions
        c. A closure statement
    4. Self-evaluate the generated summary and assign a confidence score.
    5. Format the output as specified in the instructions.

    Output Format:
    ```json
    {
        "data": "generated_summary in string format adhering to the Detailed Instructions for Output Format",
        "confidence_score": 90
    }
    ```

    Detailed Instructions for Output Format:

    **Overview**
    <empty line>
    < 
        Summarize all features in 2-3 sentences, introducing the project and its purpose.
        Provide a 2-3 sentence summary of key benefits, highlighting core architecture and value proposition.
    >
    <empty line>
    **Key Features**
    <empty line>
    <   
        List a maximum of 5 main features.
        For each feature, provide up to 2 sub-points describing its functionality.
        Ensure clear explanation of how features interact and contribute to the project's goals.
        1. ***<Key Feature Title>*** : 
        * <Sub point 1 description>
        * <Sub point 2 description>
        <empty line>
    >
    <empty line>
    < 
        Summarize the overall impact and value proposition of the project in one sentence as a conclusion statement.
    >
    <empty line>
    
    -> Self-Evaluation:
        - Score the summary out of 100 based on clarity, precision, detail, knowledge, accuracy, technical correctness, and understanding of the data.

    -> Formatting Requirements:
        - Replace all newline characters (\n) with \\n in the JSON output.
        - Ensure the complete JSON is less than 7500 tokens.
        - Start the output with "```json" and end with "```".
        - If an executive summary is provided, use only the highlighted features from it.

    Example Output Structure:
    ```json
    {
        "data": "**Overview**\\n\\n[Project overview]\\n\\n[Benefits summary]\\n\\n**Key Features**\\n\\n1. *Feature 1*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n2. *Feature 2*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n[...continue for up to 5 features...]\\n\\n[Closure statement]",
        "confidence_score": 90
    }
    ```

    Remember: Adhere strictly to the output format and instructions to maintain consistency and accuracy in your summary.
    """

    user_prompt += "User Defined Features : " + str(user_mvf)

    system_prompt = f"""
        <role>
        You are an assistant to a Senior Software Engineer. You are very capable in reading and understanding huge codebases.
        There is no edge-case, no mistake, no functionality no matter how small goes unnoticed by you.
        You will be given a large codebase and be asked queries regarding it.
        </role>

        <Task>
        You will be given relevant files from a production codebase. The Senior Engineer will consult you to clear his doubts and ask for critical code-level and functionality level analysis of the same.
        <Important>
        1. You will be clear. Feel free to be descriptive but Avoid Jargon
        2. You shall perform critical analysis on the code before responding.
        3. Note that the codebase will be quite complex and have dependencies everywhere, be mindful of them all.
        4. Enclose code in (triple backticks)``` code ```
        </Important>
        </Task>

        Files from Codebase goes here :
        <Repo Structure>
        {formatted_data}
        </Repo Structure>
    """

    start_index = executive_summary.find("Highlighted Features")
    end_index = executive_summary.find("Key Benefits")

    if start_index != -1 and end_index != -1:
        executive_summary = executive_summary[start_index:end_index].strip()

    user_prompt += "Executive Summary : " + str(executive_summary)

    return system_prompt, user_prompt

def feature_summary_generation_db(formatted_data, user_mvf, executive_summary):
    # if input_type is None:
    #     formatted_data = file_summary_list
    # elif input_type == "batch_summary":
    #     formatted_data = format_batchwise_summary_metadata_for_services(file_summary_list)
    # else:
    #     formatted_data = format_file_summaries(file_summary_list)

    user_prompt = """
    Role: You are an AI Database Analyst specializing in creating concise, feature-level summaries of complex database schemas and architectures.

    Objective: Provide a comprehensive yet concise feature-level summary of a given database schema information, highlighting key components, entities, relationships, and the overall data architecture workflow.

    Input: You will receive information about a database design, which may include an executive summary or other schema-level details.

    Steps:
    1. Analyze the provided database schema information.
    2. Identify the main features (maximum 5) of the database from the executive summary (if provided in same order)
    3. Create a summary following the specified format, including:
        a. An overview of the database
        b. A list of key features with brief descriptions
        c. A closure statement
    4. Self-evaluate the generated summary and assign a confidence score.
    5. Format the output as specified in the instructions.

    Output Format:
    ```json
    {
        "data": "generated_summary in string format adhering to the Detailed Instructions for Output Format",
        "confidence_score": 90
    }
    ```

    Detailed Instructions for Output Format:

    **Overview**
    <empty line>
    < 
        Summarize all features in 2-3 sentences, introducing the database and its purpose.
        Provide a 2-3 sentence summary of key benefits, highlighting schema structure, normalization or denormalization logic, and value proposition in handling data.
    >
    <empty line>
    **Key Features**
    <empty line>
    <   
        List a maximum of 5 main features.
        For each feature, provide up to 2 sub-points describing its data handling, relationships, or optimization logic.
        Ensure clear explanation of how features contribute to performance, consistency, and data integrity.
        1. ***<Key Feature Title>*** : 
        * <Sub point 1 description>
        * <Sub point 2 description>
        <empty line>
    >
    <empty line>
    < 
        Summarize the overall impact and value proposition of the database in one sentence as a conclusion statement.
    >
    <empty line>
    
    -> Self-Evaluation:
        - Score the summary out of 100 based on clarity, precision, detail, knowledge, accuracy, technical correctness, and understanding of the schema information.

    -> Formatting Requirements:
        - Replace all newline characters (\n) with \\n in the JSON output.
        - Ensure the complete JSON is less than 7500 tokens.
        - Start the output with "```json" and end with "```".
        - If an executive summary is provided, use only the highlighted features from it.

    Example Output Structure:
    ```json
    {
        "data": "**Overview**\\n\\n[Database overview]\\n\\n[Benefits summary]\\n\\n**Key Features**\\n\\n1. *Feature 1*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n2. *Feature 2*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n[...continue for up to 5 features...]\\n\\n[Closure statement]",
        "confidence_score": 90
    }
    ```

    Remember: Adhere strictly to the output format and instructions to maintain consistency and accuracy in your summary.
    """

    user_prompt += "User Defined Features : " + str(user_mvf)

    system_prompt = f"""
        <role>
        You are an assistant to a Senior Data Architect. You are very capable in reading, analyzing, and understanding complex database schemas and data models.
        No entity, constraint, relationship, or optimization logic goes unnoticed by you.
        You will be given a comprehensive database structure or schema information and will be asked to analyze, explain, and summarize it at a structural and functional level.
        </role>

        <Task>
        You will be given relevant database schema files or DDL definitions. The Senior Data Architect will consult you to clear doubts and ask for critical schema-level and data model-level analysis.
        <Important>
        1. You will be clear. Feel free to be descriptive but Avoid Jargon
        2. Perform a critical and deep analysis of the schema and the information given before responding.
        3. The schema will often involve multiple tables, foreign keys, views, procedures, and indexing strategies â€” be mindful of their dependencies and relationships.
        4. Enclose code or schema in (triple backticks)``` code ```
        </Important>
        </Task>

        Files from Database schema goes here :
        <Database Structure>
        {formatted_data}
        </Database Structure>
    """

    start_index = executive_summary.find("Highlighted Features")
    end_index = executive_summary.find("Key Benefits")

    if start_index != -1 and end_index != -1:
        executive_summary = executive_summary[start_index:end_index].strip()

    user_prompt += "Executive Summary : " + str(executive_summary)

    return system_prompt, user_prompt


#FEATURE HIERARCHY:
generate_features_system_prompt = """
  <Role>
    You are a Software Architect with expertise in analyzing large summaries from code files of an application. 
    You can comprehend summaries from code files that are complex, production-grade and are written in various programming languages to generate most important features, their description and the subfeatures with their description belonging to the most important features along with the other relevant information requested below.
    
    You will follow 2 Events before responding : 
    1. Generation of Feature Hierarchy as given in "Output_Format".
    2. Critical Evaluation of Every Confidence Score.  
  </Role> 

    <Task 1>
    You are provided with multiple relative file paths and file-wise code summaries from a application codebase.
    1. Analyze the file summaries carefully, leveraging your expertise to deduce the frameworks, functionality, and features.
    2. Perform a critical assessment of the code's functionality and interdependencies before responding.
    3. The codebase is complex and likely contains dependencies across various modules. Be mindful of these.
    4. Analyse every file summary and assign the features and sub-features based on the information provided.
    5. Respond strictly in the structured JSON format provided below.
    6. In each sub-feature's 'file_path' array:
        - Set 'critical: true' ONLY for files that are CORE & NON-REPLACEABLE to the sub-feature's main functionality.
        - Set 'critical: false' for ALL supporting, secondary, or replaceable files  
        - Each sub-feature should have both true and false entries.
        - If unsure, default to false (be EXTREMELY selective with 'true')
        - Make sure each sub-feature atleast have one file as true.

    Explanation of the Output terms:
    Feature - Features are most valuable and high level features extracted from the list of summaries that are provided to you. 
    Feature description - Description of the features explaining the high level value and impact that it creates for the project. Define the Feature. The description should be crisp, precise, well formatted and must be between 2-3 lines.
    Subfeature - Subfeatures are micro most valuable features that are extracted from the list of summaries and belong to the Most related and similar Features.
    Subfeature description - Description of the subfeatures explaining the specific value, technical and non-technical functionalites that it provided to the project. Define the subfeature and also explain how its related to the feature. The description should be crisp, precise, well formatted and must be between 2-3 lines.
    
    Points to Remember:
    1. Do not extract any feature or subfeature where there are no reference/citations from the application summaries.
    2. The description must be precise, valuable, well-formatted and must be between 2-3 lines.
    3. The Feature titles should be precise, specific, self explanaible, independent and not have similar feature titles. The Feature titles should not be highly generalized.
    4. The SubFeatures titles should be precise, self explanaible and not have similar subfeature titles. The SubFeature titles should not be highly generalized.
    5. SubFeatures should not be very low level that it explains code functions, code process like 'Json handling', 'Reading csv', readME etc.
    6. If similar subfeatures are present, then group them under one common Feature itself. Do not create multuple Features for similar subfeatures.
    6. If Unit testing related summaries are found, then create that as another Feature named 'Unit Testing' and assign the specific testing subfeatures under this feature.
    </Task 1>

  <Task 2>
  You shall now Assign and Justify Confidence Scores for each feature.

  <Critical Evaluation of Confidence Scores> 

  <Evaluation MODE>
  - You will now Forget everything that was done beforehand and act as an unbiased judge.
  - $Project-Summaries-&-Paths (INPUT).
  </Evaluation MODE>
  <Important>
  Critically analyze every "Feature" and "SubFeature" based on the following metrics. 
  You shall generate a confidence score between 0-100 for each of the following :
  1. Is the "Feature" & "SubFeature" name accurate to its functionality ? (Accuracy)
  2. Does the "Feature" & "SubFeature" include files with an unrelated function ? (Feature Dilution Rate)
  3. Important : Does this "Feature" & "SubFeature" make sense given the Overall Purpose of the Application ? (Consistency)
  4. Are all the files in "Feature" & "SubFeature" included ? (Completeness)

  <Strict>
  1. You will now generate a list of 4 confidence scores between 0-100 for above criteria under "confidence_score" key.
  2. Based on above criteria, you shall provide a VERY BRIEF logical explanation (10-20 words) for Confidence Score under "confidence_score_justification" key.
  3. Make sure to mention the entire filepath without omitting the prefix.
  4. Make sure all the filepaths are present.
  <Important> STRICTLY Don't Comment on Missing Files. Don't Overestimate. Don't Underestimate.</Important> 
  </Strict>

  </Important>

  </Critical Evaluation of Confidence Scores> 
  </Step 2>


      <Output_Format>
    Return a response in JSON format. Do not include any extra information or explanations. Strictly DON'T deviate from mentioned KEYS.
    Example:
```json
[
  {
    "name": "User Authentication and Management",
    "feature_description": "Comprehensive user account system with secure login, registration, profile management, and role-based access control.",
    "feature_description_confidence_score": [95, 70, 100, 70],
    "sub_features": [
      {
        "name": "User Registration",
        "description": "Allows new users to create accounts by providing necessary information such as username, email, and password. Implements email verification, password strength checks, and duplicate account prevention. Stores user data securely in the database with password hashing.",
        "file_path": [
          {
            "module_name": "RegistrationController",
            "path": "Controllers/Account/RegistrationController.cs",
            "critical": true
          },
          {
            "module_name": "RegisterView",
            "path": "Views/Account/Register.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [75, 80, 85, 65],
        "sub_feature_confidence_score_justification": "No feature dilution, might have missed some file."
      },
      {
        "name": "User Login",
        "description": "Authenticates users using their credentials, creates and manages user sessions, and implements security measures such as login attempt limiting and two-factor authentication (2FA). Provides password reset functionality for forgotten passwords.",
        "file_path": [
          {
            "module_name": "LoginController",
            "path": "Controllers/Account/LoginController.cs",
            "critical": true
          },
          {
            "module_name": "LoginView",
            "path": "Views/Account/Login.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [80, 100, 80, 75],
        "sub_feature_confidence_score_justification": "High chance of missing files."
      }
    ],
    "feature_confidence_score_justification": "No feature dilution, duplication or missing files. Accurate Naming."
  },
  {
    "name": "Product Catalog Management",
    "feature_description": "Comprehensive system for managing product listings, categories, and inventory across the e-commerce platform.",
    "feature_description_confidence_score": [95, 65, 70, 80],
    "sub_features": [
      {
        "name": "Product CRUD Operations",
        "description": "Enables administrators to create, read, update, and delete product listings. Includes functionality for managing product details such as name, description, price, images, and inventory levels. Implements validation to ensure data integrity and consistency across the product catalog.",
        "file_path": [
          {
            "module_name": "ProductController",
            "path": "Controllers/ProductController.cs",
            "critical": true
          },
          {
            "module_name": "ProductView",
            "path": "Views/Product/Index.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [90, 85, 100, 70],
        "sub_feature_confidence_score_justification": "High confidence with no duplication or dilution."
      },
      {
        "name": "Category Management",
        "description": "Allows for the creation and management of product categories and subcategories. Implements a hierarchical structure for organizing products, enabling efficient navigation and filtering of the product catalog for both administrators and customers.",
        "file_path": [
          {
            "module_name": "CategoryController",
            "path": "Controllers/CategoryController.cs",
            "critical": true
          },
          {
            "module_name": "CategoryView",
            "path": "Views/Category/Index.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [85, 75, 90, 95],
        "sub_feature_confidence_score_justification": "High confidence without any duplication or dilution."
      }
    ],
    "feature_confidence_score_justification": "All files refer to single overall functionality. Might have missed some files."
  }
]
```
  </Output_Format>

"""

generate_features_user_message = """
<Strictly Remember>
1. As input you will be given a batch of `file_path` and `file_summary` from a production codebase. Keep it in mind that it could be a file from a very large repository with lot of inter-dependencies.
2. Understand all the file description first, then try to determine the feature, sub-features and their description. For **each file** it should have a feature or sub-features whenever the conditions are met.
3. The response should contain all the fields given in the example output format. The response should be strictly in json format.
4. The description of features/subfeatures must be in the length of 2-3 lines. The response should be structured and well-formatted.
5. Don't generate any additional explanation or description. Provide the structured response in json only.
</Strictly Remember>
  
<Input file wise summary>
{file_summary}
</Input file wise summary>
<Response>
"""

merge_features_in_hierarchy_user_prompt = """You are a software feature analyzer. Given a list of related features that have been clustered together, create a merged feature that encompasses all the functionality.

Features to merge:
{feature_list}

Generate a JSON response that includes:
1. A name for the merged feature representing accurate feature name. Do not mention its merged or unified or anything as such. The feature name should accurately represent a major funcationality of a repository.
2. A detailed description that covers all functionality
3. A confidence score (0-100) for the merge
4. A justification for the confidence score

Respond with a JSON object in the following format:
```json
{{
    "name": "Merged feature name",
    "description": "Comprehensive description",
    "confidence_score": 85,
    "confidence_justification": "Reason for the confidence score"
}}
```
Give only JSON and nothing else. Do not include any explanations or additional text outside the JSON block. Make sure to start with ```json and end with ``` only.
"""

mapping_names_for_merged_features_user_prompt = """  <Role>
    You are a smart AI cassistant with strong expertise in Software Engineering. You can understand complex, production-grade codebases written in various programming languages and summarize them effectively.
  </Role>
  <Task>
  You will be given a brief description of  features of a large codebase and your task is to generate a relevant feature name, brief description, and priority level.
  <Important>
   1. The feature name should be brief, relevant and should represent the entire description provided.
   2. Generate a relevant description which is basically a overall summary of the description provided.
   3. Assign a priority level (high, medium, low) based on the significance, importance and complexity of the feature to the overall system. 
  </important>
  </Task>
  <Example output>
  ```json
    {
        "name": <feature_name>, //string
        "feature_description": <feature_description>, //string
        "priority": <priority> //string (high, medium, or low)
    }
    ```
  </Example output>
  <Strictly Remember>
1. The feature name should be relevant and at the same time interpretable, easy to understand.
2. The feature description should represnt the entire description given for summarisation, it should be simple and easy to understant.
3. The priority should be one of: high, medium, or low.
4. The response should be strictly in json format specified above.
5. Strictly make sure Feature Description is not more than 200 words.
  </Strictly Remember>

<code summary>
The code summary is given below:
"""


reducing_sub_features_user_prompt = """
    You are a software feature consolidation expert. Your task is to merge similar sub-features into one comprehensive sub-feature.

    Here are the sub-features that need to be merged:
    {sub_features_list}

    For each sub-feature, we have:
    - Name: The sub-feature name
    - Description: The sub-feature description (if available)
    - Confidence Score: The confidence score (if available)

    Your output should be a JSON object containing:
    1. A unified sub-feature name that encompasses all the input sub-features
    2. A comprehensive description that covers all aspects of the input sub-features
    3. A confidence score (use the highest available from input sub-features)
    4. A justification for the confidence score

    Return the output in JSON format starting with ```json and ending with ```.

    Example output format:
    ```json
    {{
        "name": "Unified Sub-Feature Name",
        "description": "Comprehensive description covering all aspects",
        "sub_feature_confidence_score": 95,
        "sub_feature_confidence_score_justification": "Merged from similar sub-features with high semantic similarity"
    }}
    ```
    """


post_processing_feature_name_description_system_prompt="""
  <Role>
    You are a smart AI assistant with strong expertise in Software Engineering. You can understand complex, production-grade codebases written in various programming languages and summarize them effectively.
  </Role>
  <Task>
  You will be given a brief description of modules or features of a large codebase and your task is to generate a relevant feature name and brief description.
  <Important>
   1. The feature name should be brief, relevant and should represent the entire description provided.
   2. Generate a relevant description which is basically a overall summary of the description provided.
   3. Also generate a confidence score in a scale of 0 - 100.
  </important>
  </Task>
  <Example output>
  ```json
    {
        "name": <feature_name>,
        "feature_description_confidence_score": <score 0 - 100>,
        "feature_description": <feature_description>
    }```
  </Example output>"""

post_processing_feature_name_description_user_prompt = """<Strictly Remember>
1. The feature name should be relevant and at the same time interpretable, easy to understant.
2. The confidence score should represent the ability to summarise the description.
3. The feature description should represnt the entire description given for summarisation, it should be simple and easy to understant.
4. The response should be strictly in json format specified above.
</Strictly Remember>
<code summary>
The code summary is given below: \n
{feature_description}
</code_summary>
<response>
Your response in json goes here:
"""

merge_similar_features_system_prompt = """You are a solution architect. Your task is to carefully review each feature and its description, and combine them into a single high-level feature.

The final high-level features should represent what an end user would perceive, e.g., Messenger, Google Chat, Messaging, Reels, etc.

Based on the generated features provided, identify which features can be merged into a single high-level feature. 
Strictly output them in the following format:
{{ 
  <High-Level Feature Name 1>: [<Merged Feature 1>, <Merged Feature 2>, <Merged Feature 3>, ...],
  <High-Level Feature Name 2>: [<Merged Feature 1>, <Merged Feature 2>, <Merged Feature 3>, ...],
  ...
}}

INPUT:
Feature names and descriptions are provided in the format: 
[1. Feature name: <feature name> 
Feature description: <feature description>, 
2. ...]

{feature_texts}

MVFS:
{total_MVFs}

Points to remember:
1. While merging features and naming high-level features, always prefer names from the user-defined MVFs provided. All relevant features can be grouped under these high-level features.
2. If certain features do not fit under the user-defined MVFs, choose a better name than the existing one for the new high-level feature if necessary.
3. The names of the features being merged must remain exactly as provided in the INPUT section; do not modify them. Do not consider Feature description in Feature Names.
4. Follow the output structure strictly: high-level feature names as dictionary keys and merged features as values in list format.
5. If a feature is already a high-level feature, you do not need to forcibly merge it. If a feature seems to be function-level/low-level  features, merge them into a High-level feature.
6. Merge similar features into a single high-level feature based on their names and descriptions, when applicable. Each final high-level feature should be independent of the others.
7. Do not assign the same feature to multiple high-level features.
8. If user-defined MVFs are empty, skip point 1 and begin with point 2.
9. Do **not** include any Feature descriptions in the final output."""


merging_description_user_prompt = """You are a Solution Architect. Your task is to summarize the multiple feature descriptions provided into a brief, coherent summary of **no more than two sentences**.

  The summary must:
  - Accurately capture all key components from the provided descriptions.
  - Align clearly with the given high-level feature name.
  - Serve as the final description of the high-level feature.

  Only the final summarized description should be included in the output â€” no additional commentary or formatting.

  INPUT:
  Multiple descriptions: {merging_feature_description}

  High-Level Feature Name: {high_level_feature}
  """


micro_sub_feature_prompt = """You are an expert system analyst specializing in decomposing SubFeatures into granular, logically independent components. You support **two levels** of splitting:

1. **Horizontal splitting**: Split a subfeature into multiple *same-level subfeatures* when it encompasses multiple independently meaningful functionalities. The subfeatures created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.
2. **Vertical splitting**: Further break each of those subfeatures into *microsubfeatures* (if applicable), ensuring each micro-sub-features/micro-user-story describes a single goal or operation. The micro-sub-features/micro-user-story created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.

---

### ðŸ”§ TASK OVERVIEW

Given a Macro-Feature, Subfeature, its description, associated module files and its summary:

- Decide if the subfeature should be split horizontally into multiple same-level subfeatures.
- For each resulting subfeature (or original if not split), analyze whether it can be split vertically into **microsubfeatures** (fine-grained user stories).
- Provide the confidence scores for the subfeature that is split, whether horizontally or vertically.
- Provide the files that are related to the sub_features too, not just the micro_sub_features.
- Each leaf user-story must have files assigned to them, else you should not create/split these subfeatures.
- Provide description of generated subfeature/sub-user-stories in 2-4 lines but only valid information. Do not assume or hallucinate to generate description.
Apply this recursively: if horizontal splitting occurs, then attempt vertical splitting for each. But remember, not to create any duplicates in the process. 

---

### SPLITTING DECISIONS

#### Horizontal Splitting (Same-level Subfeatures):
Split if:
- The subfeature covers multiple high-level functionalities
- Each function could be planned, developed, and deployed independently
- Each component has a clear boundary and responsibility

#### Vertical Splitting (Microsubfeatures):
Split further if:
- A subfeature contains multiple independent operations or logical stages
- These operations can be implemented, tested, or tracked separately
- Each micro-subfeature represents one atomic, non-overlapping functionality

---

### DO NOT SPLIT IF:
- sub-user-stories are tightly coupled in the Subfeature and cannot function independently.
- Do not split subfeatures into sub-user-stories that are hardly single line of code and cannot be considered as a proper functionality, but just a config/parameter.
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across actions are too complex to isolate.
- There are no files that can be mapped to the generated user-story.
- Do not split if the user-story is barely a functionality. The split user-stories must have independent functionality that contributes to the subfeature and feature and if not, do not split.
- Don not split ReadMe & .md files into sub-user-stories.
- Do not split horizontall for granullar subfeatures as they are not user stories but mid level features.
---

### FILE MAPPING RULES:
- For each subfeature or microsubfeature, cite only directly relevant files.
- Use only the provided input data to match files â€” no guessing.
- Avoid duplication unless a file is clearly shared between components.

Each `file_path` entry must include:
```json
{
  "module_name": "<Name>",
  "path": "<Path>",
  "critical": <true/false>,
  "git_url": "<Git URL>"
}

OUTPUT FORMAT
If the subfeature should NOT be split:
Return: "None"

If the subfeature should be split, return a list of Parent User Stories with subfeatures inside.
If a subfeature itself can be further split into microsubfeatures, nest them under micro_sub_features like so:

[
  {
    "name": "Parent User Story Title 1",
    "description": "Full description of the original or updated user story and its purpose.",
    "file_path": [...],
    "sub_feature_confidence_score":"confidence score of the subfeature with respect to the Feature, as a percentage (e.g., 80)"
    "micro_sub_features": [
      {
        "name": "Sub-User Story Title 1",
        "description": "Standalone description of a single functionality.",
        "file_path": [...],
        "micro_sub_feature_confidence_score":"confidence score of the micro_sub_feature with respect to the sub_feature, as a percentage (e.g., 90)"
        }
          ...
        ]
      },
      ...
    ]
  }
]
Each layer must preserve independence, clarity, and singular focus of each story.

VALIDATION CHECKLIST
- Each title must express one functionality only (no imperative phrasing)
- description must avoid assumptions and describe the real function. It must be as detailled as possible.
- Each story must make sense independently and fit in the broader feature flow
- if there are multiple user-story under the subfeature, it needs to be in sequence of business logic.
- File mappings must be relevant and scoped accurately
- Do no miss/skip any values in the output json. The output structure must be maintained strictly.
- All subfeature and sub-user-story names and descriptions must be strictly in a declarative tone, not imperative.

* Use generic or speculative statements
"""


db_micro_sub_feature_prompt = """
<Role>
You are an expert Database analyst specializing in decomposing SubFeatures into granular, logically independent components. You support **two levels** of splitting:
You shall ALWAYS process features from a Database perspective ONLY. 
There can be more than one Table in the DB context provided to you.
</Role>

1. **Horizontal splitting**: Split a subfeature into multiple *same-level subfeatures* when it encompasses multiple independently meaningful functionalities. The subfeatures created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.
2. **Vertical splitting**: Further break each of those subfeatures into *microsubfeatures* (if applicable), ensuring each micro-sub-features/micro-user-story describes a single goal or operation. The micro-sub-features/micro-user-story created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.

<Strict Constraints> 
- You are dealing with Database Information. 
- No matter what, STRICTLY use Database-Specific Language ALWAYS. 
- Use words like Columns / Fields / Schema / DataTypes / Constraints / Foreign Keys / Primary Keys etc.
- Strictly Do not start descriptions with or start with "this micro-feature" / or "this sub-feature".
- You shall do this regardless of the input context and nature.
Remember : Every "FILE" given to you is information of a table. Therefore in your response, ALWAYS refer to "Table" instead of "File".

</Strict Constraints> 


### ðŸ”§ TASK OVERVIEW

Given a Macro-Feature, Subfeature, its description, associated module files and its summary:

- Decide if the subfeature should be split horizontally into multiple same-level subfeatures.
- For each resulting subfeature (or original if not split), analyze whether it can be split vertically into **microsubfeatures** (fine-grained user stories).
- Provide the confidence scores for the subfeature that is split, whether horizontally or vertically.
- Provide the files that are related to the sub_features too, not just the micro_sub_features.
- Each leaf user-story must have files assigned to them, else you should not create/split these subfeatures.
- Provide description of generated subfeature/sub-user-stories in 2-4 lines but only valid information. Do not assume or hallucinate to generate description.
Apply this recursively: if horizontal splitting occurs, then attempt vertical splitting for each. But remember, not to create any duplicates in the process. 

---

### SPLITTING DECISIONS

#### Horizontal Splitting (Same-level Subfeatures):
Split if:
- The subfeature covers ONE / MORE THAN ONE high-level functionalities
- Each function could be planned and developed independently
- Each component has some clear boundaries and responsibilities

#### Vertical Splitting (Microsubfeatures):
Split further if:
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across actions are too complex to isolate.
- There are no tables that can be mapped to the generated user-story.
- The subfeature is too complex to be planned, developed, and deployed independently
- Each micro-subfeature represents one atomic, non-overlapping functionality
Note: Maintain at least 2 subfeatures unless the database has only one table.
- Prioritize brevity, consistency and no informaiton leakage across subfeatures.
- Ensure crisp segregation.
---

### DO NOT SPLIT IF:
- sub-user-stories are tightly coupled in the Subfeature and cannot function independently.
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across tables in two features are too complex to isolate.
- There are no tables that can be mapped to the generated user-story.
Note: Maintain at least 2 subfeatures and 1 or more microsubfeatures per subfeature, Unless the database has only one table.
Note : Maintain brevity during splitting at the same level. Do NOT overload the a single feature with too many subfeatures.
---


### FILE MAPPING RULES:
- For each subfeature or microsubfeature, cite only directly relevant tables.
- Use only the provided input data to match files â€” no guessing.
- Avoid duplication unless a file is clearly shared between components.

Each `file_path` entry must include:
```json
{
  "module_name": "<Name>",
  "path": "<Path>",
  "critical": <true/false>,
  "git_url": "<Git URL>"
}

OUTPUT FORMAT
If the subfeature should NOT be split:
Return: "None"

If the subfeature should be split, return a list of Parent User Stories with subfeatures inside.
If a subfeature itself can be further split into microsubfeatures, nest them under micro_sub_features like so:

[
  {
    "name": "Parent User Story Title 1",
    "description": "Full description of the original or updated user story and its purpose.",
    "file_path": [...],
    "sub_feature_confidence_score":"confidence score of the subfeature with respect to the Feature, as a percentage (e.g., 80)"
    "micro_sub_features": [
      {
        "name": "Sub-User Story Title 1",
        "description": "Standalone description of a single functionality.",
        "file_path": [...],
        "micro_sub_feature_confidence_score":"confidence score of the micro_sub_feature with respect to the sub_feature, as a percentage (e.g., 90)"
        }
          ...
        ]
      },
      ...
    ]
  }
]
Each layer must preserve independence, clarity, and singular focus of each story.

VALIDATION CHECKLIST
- Each title must express one functionality only (no imperative phrasing)
- description must avoid assumptions and describe the real function. It must be as detailled as possible.
- Each story must make sense independently and fit in the broader feature flow
- if there are multiple user-story under the subfeature, it needs to be in sequence of business logic.
- File mappings must be relevant and scoped accurately
- Do no miss/skip any values in the output json. The output structure must be maintained strictly.
- All subfeature and sub-user-story names and descriptions must be strictly in a declarative tone, not imperative.
- Use Database-specific schema only. Do not include words like "Attributes" / "Code Files" in your response. 
- Strictly Do not start descriptions with or start with "this micro-feature" / or "this sub-feature".
* Use generic or speculative statements

"""import os
from graphviz import Digraph
import re 
import json

def parse_ddl(ddl: str):
    """
    Parse the DDL to extract columns, primary keys, and foreign keys.
    """
    lines = ddl.splitlines()
    column_lines = []

    for line in lines:
        line = line.strip()
        if (
            line.upper().startswith("CREATE")
            or line.upper().startswith("PRIMARY")
            or line.upper().startswith("FOREIGN")
            or line.upper().startswith(")")
            or line == ""
        ):
            continue

        match = re.match(r'(\w+)\s+\w+', line)
        if match:
            column_lines.append(match.group(1))

    pk_match = re.search(r'PRIMARY KEY\s*\((.*?)\)', ddl)
    primary_keys = [key.strip() for key in pk_match.group(1).split(",")] if pk_match else []

    foreign_keys = []
    for match in re.finditer(r'FOREIGN KEY\s*\(([^)]+)\)\s+REFERENCES\s+`?[\w]+\.(\w+)`\(([^)]+)\)', ddl):
        fk_col = match.group(1).strip()
        ref_table = match.group(2).strip()
        ref_col = match.group(3).strip()
        foreign_keys.append((fk_col, ref_table, ref_col))

    return column_lines, primary_keys, foreign_keys


def generate_combined_graph(tables_data):
    """
    Generate a single combined graph from multiple tables.
    """
    dot = Digraph(comment='Combined Table Diagram')
    dot.attr(rankdir='LR')

    # Store individual table nodes
    for table in tables_data:
        table_name = table['table_name']
        columns = table['columns']
        primary_keys = table['primary_keys']
        
        label_lines = []
        for col in columns:
            if col in primary_keys:
                label_lines.append(f"{col} [PK]")
            else:
                label_lines.append(col)
        dot.node(table_name, shape='box', label=f'{table_name}\\n' + "\\n".join(label_lines))

    # Add relationships
    for table in tables_data:
        table_name = table['table_name']
        for fk_col, ref_table, ref_col in table['foreign_keys']:
            dot.edge(table_name, ref_table, label=f'{fk_col} â†’ {ref_col}')

    return dot

def folder_summary_generation_prompts(
        total_allocated_tokens, 
        file_list, folder_name, 
        folder_path,
        subfolder_list,
        formatted_file_summaries,
        formatted_file_services,
        formatted_subfolder_summaries,
        formatted_subfolder_services,
        formatted_subfolder_features
    ):
    
    system_prompt = f"""
        You are an expert code analyst specialized in creating detailed, informative summaries of software project folders. Your task is to thoroughly analyze files and subfolders to provide a comprehensive understanding of the application or project and provide combined summaries along with required details. These summaries must be detailled enough for further summarization.

        Follow these guidelines:
        1. Conduct a deep analysis of the features to identify its core purpose and functionality
        2. Provide detailed explanation of key implementations and technical approaches of the features
        3. Thoroughly examine the summaries based on files and folders to understand relationship between features and combined smaller features into larger high level application level features.
        4. Explain the features within the broader project architecture with specific connections
        5. Describe technical patterns, design decisions, and architectural choices evident in the code
        6. Include specific functions, classes, and methods that define the feature's behavior
        7. Note dependencies, imports, and external connections that shape the folder's functionality
        8. Identify potential architectural strengths and areas for improvement when evident
        9. Identify all services represented in this folder based on file and subfolder services information
        10. Identify and articulate high-level features or functionalities represented by the folder into the feature_details section, when consolidating multiple subfolders or lower-level files. Derive these insights from both file-level and subfolder-level summaries. Also under each feature, mention which file/folder was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
        11. Do not miss any features that could be formed based on these summaries as this information is required to understand the application's buisness logic.
        12. Gather insights from the summaries provided to generate a high level detailled executive summary that could be used by business stakeholders to understand the folder/project.
        13. When analyzing the root folder, both the executive summary and the features must be strictly formed in a high level business logic standpoint of an application.
        
        IMPORTANT: 
        - Your summary should be thorough and detailed({total_allocated_tokens}) while maintaining technical/business precision and depth. Focus on providing insights that would help both stakeholders and developers understand the application better.
        - feature_details must contain high level feature name and feature description(value of the files/folders) strictly in concise bullet points. The feature inforamtion must be in detail to capture the complete high level knowledge for that feature but not the function level details. Feature names cannot be programmatic function names like Dependency management, json handling etc. instead it should be inventory management, order processing etc. 
        - Your services list should be comprehensive and include all services represented in this folder.
        - is_reuasble_lib if a folder is used as reusable lib make it True otherwise False
        - lib_name if is_reusable_lib is True then provide the name of the reusable lib/component If is_reusable_lib False then add Not Applicable
        - category if is_reusable_lib is True then provide category only between 'Frontend' and 'Backend' If is_reusable_lib False then add Not Applicable
        - sub_category if is_reusable_lib is True then provide sub category only between 'UI Component','Custom Hooks', 'http_client', 'Utils', 'Others' In Frontend & 'Middleware', 'Error Handling', 'Auth', 'Utils', 'Others' In Backend If is_reusable_lib False then add Not Applicable
        - when_to_use if is_reusable_lib is True then provide where this reusable lib/component can be used If is_reusable_lib False then add Not Applicable 
        - associated_files if is_reusable_lib is True then provide the list of files associated(give complete path for the assosciated file) with this reusable lib/component If is_reusable_lib False then add Not Applicable
        - summary must not be technical and only explain the high level details of the folder/project. Understand the file and folder summaries provided to combine the knowledge to form the executive summary. Make it as detailled as possible.
        - Use clear and concise language, avoiding jargon where possible.
        
        - You must provide your response in this exact format:
        ```summary
        [Your detailled high-level executive summary for the folder for business stakeholders]
        ```
        ```feature_details
        [List of high-level features or functionalities represented in this folder]
        ```
        ```services_namess
        [Comma-separated list of all services represented in this folder]
        ```
        ```is_reuasble_lib
        Boolean Value
        ```
        ```lib_name
        [Name of the reusable library if applicable]
        ```
        ```category
        [Category of the reusable library if applicable]
        ```
        ```sub_category
            [Sub category of the reusable library if applicable]
        ```
        ```when_to_use
        [Your detailed use case where or when this reuasble_lib can be usefull]
        ```
        ```associated_files
            [Comma-separated list of associated files with the reusable library, Give the Complete file path as mentioned in the file list]
        ```
        ```example_usage
            [Example code snippet of how to use this reusable library]
        ```
    """

    user_prompt = f"""
        Generate a summary and services list for the folder: "{folder_name}" (Path: {folder_path})

        FOLDER CONTENTS:
        - Files ({len(file_list)}): {", ".join(file_list) if file_list else "None"}
        - Subfolders ({len(subfolder_list)}): {", ".join(subfolder_list) if subfolder_list else "None"}

        FILE SUMMARIES:
        {os.linesep.join(formatted_file_summaries) if formatted_file_summaries else "No file summaries available"}

        FILE SERVICES:
        {os.linesep.join(formatted_file_services) if formatted_file_services else "No file services available"}

        SUBFOLDER SUMMARIES:
        {os.linesep.join(formatted_subfolder_summaries) if formatted_subfolder_summaries else "No subfolder summaries available"}

        SUBFOLDER SERVICES:
        {os.linesep.join(formatted_subfolder_services) if formatted_subfolder_services else "No subfolder services available"}

        SUBFOLDER FEATURES:
        {os.linesep.join(formatted_subfolder_features) if formatted_subfolder_features else "No subfolder features available"}
        
        Based on these components:
        1. Provide a thorough technical summary explaining the folder's purpose, implementation details, and architectural significance
        2. Compile a comprehensive list of all services represented in this folder based on file and subfolder services information
        
        Follow the exact format specified in the system instructions for your response.
    """

    return system_prompt, user_prompt

def services_generation():
    system_prompt = """
        <Task>
        Create an architectural blueprint of the given repository by identifying and classifying both external services and third-party services with no overlap between categories.
        </Task>

        <Definitions>
        - External services: Company-provided services hosted outside the application (AWS S3, Google Cloud, Stripe, Twilio)
        - Third-party services: Libraries, frameworks, and SDKs that are part of the core application stack (Django, React, MongoDB, Redux)
        </Definitions>

        <Output_Format>
        {
        "external_services": [
            {
            "external_service_name": "string",
            "description": "string",
            "associated_files": ["string"],
            "service_class": "string",
            "used_in_files": ["string"]
            }
        ],
        "thirdparty_services": [
            {
            "thirdparty_service_name": "string",
            "description": "string",
            "associated_files": ["string"],
            "service_class": "string",
            "used_in_files": ["string"]
            }
        ]
        }
        </Output_Format>

        <Instructions>
        1. Conduct a thorough repository analysis to identify all services
        2. Classify each service into exactly ONE category:
        - External services: Cloud platforms, payment processors, authentication providers
        - Third-party services: Frameworks, libraries, SDKs integrated into the codebase
        3. For each service, provide:
        - Name: Exact service name
        - Description: Concise explanation of functionality and purpose
        - Associated files: All files directly importing or using the service
        - Service class: Category (e.g., "cloud storage", "web framework", "database")
        - Used in files: Complete paths of files utilizing the service
        4. Ensure ZERO overlap between categories
        5. Prioritize accuracy over comprehensiveness
        6. Validate that identified services are actively used in the project
        7. Include only services with clear evidence of implementation
        8. Do not create a lot of services which are redundant. Keep it to a maximum of 50 services only.
        </Instructions>

        <Examples>
        Good External Service Entry:
        {
        "external_service_name": "AWS S3",
        "description": "Cloud storage service used for storing user-uploaded files",
        "associated_files": ["src/services/storage.js", "src/config/aws.js"],
        "service_class": "cloud storage",
        "used_in_files": ["src/components/FileUpload.js", "src/pages/UserProfile.js"]
        }

        Good Third-Party Service Entry:
        {
        "thirdparty_service_name": "React",
        "description": "Frontend JavaScript library for building user interfaces",
        "associated_files": ["package.json", "src/index.js"],
        "service_class": "frontend framework",
        "used_in_files": ["src/App.js", "src/components/*.js"]
        }
        </Examples>

        Analyze the repository and provide the complete architectural blueprint in the specified format.
    """

    user_prompt = ""

    return system_prompt, user_prompt

def executive_summary_generation(combined_summary, user_mvf):
    system_prompt = """
    Your Role:
    You are an expert software architect tasked with understanding a codebase and creating an executive summary that clearly articulates the main purpose of this application,
    the core problem that the application is solving, and the prioritized list of the most valuable features, solely based on the provided folder wise summary. Do not hallucinate and create the most valuable features and its description on assumption. This needs to be based on facts.

    Task:
    1. Analyze provided folder wise summary and the services used and the user defined features (if provided).
    2. Understand component interactions and functions.
    3. Prioritize the User Defined Features (if provided) in the summary.
    4. Identify and prioritize the most valuable features based on their importance and relevance to the overall project, as evidenced in the code.
    5. Create a comprehensive executive summary.

    Steps:
    1. Review folder wise summary.
    2. Analyze folder wise summary:
    - Identify key components and their roles
    - Note data operations, design patterns, and architectural decisions
    3. Create summary:
    - Describe the specific problem the codebase solves, based on folder wise summary
    - Explain component interactions
    - Outline data workflow
    4. Identify and prioritize main features:
    - Determine which feature(s) address the core problem of the application, based on code implementation
    - Rank features based on their importance and relevance to solving the main problem, as evidenced in the code
    - The feature should be major components of the codebase and not minor functions like "Modular Architecture" or "Code Reusability", these are not features but design principles.

    Focus Areas:
    - Precised feature prioritization and importance
    - High-level functionality
    - Clear, concise technical language
    - Objective description
    - Capture entire workflow

    Guidelines:
    - Only use the folder wise summary provided
    - Use precise technical terms
    - Include user-defined features if provided and evidenced in the code
    - Prioritize features based on their importance to the core problem, as shown in the folder wise summary

    Feature Identification and Prioritization:
    - Carefully analyze the folder wise summary to identify features actually present in the folder wise summary
    - Do not assume or infer features that are not explicitly mentioned in the folder wise summary
    - Identify the top feature that solves the majority of the problem based on code evidence
    - Rank subsequent features in descending order of importance, ensuring they are present in the folder wise summary
    - Ensure the feature list reflects the codebase's focus and structure
    - Only include features that have substantial implementation in the codebase that is evident from folder wise summary

    Output Format - Adhering to this format is crucial
    ```json
    {
    "data": "generated_summary in string format adhering to the Expected Output Format for Generated Summary",
    "confidence_score": 90,
    "traceback": {
    "Feature 1 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 1 Title' is included, as the 'phrase' is an evidence that this feature is part of the codebase.",
    "Feature 2 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 2 Title' is included, as the 'phrase' is an evidence that this feature is part of the codebase.",
    ...
    }
    }
    ```

    Requirements:
    - Replace \n with \\n in JSON
    - Limit upto 5 main features (max 2 sub-features each) or 7500 tokens
    - If due to any reason such as codebase being small, you are unable to provide 5 features, then provide as many high-level features as possible between the range of 1 to 5.
    - Don't assume features or include minor features due to inability to provide 5 features, lesser number of features is acceptable.
    - Use specified JSON format only
    - Start with "```json" and end with "```"
    - Ensure the top feature in the prioritized list addresses the core problem and is present in the folder wise summary
    - Rank features in descending order of importance to the main problem, based on actual code implementation
    - Do NOT include features that are NOT evidenced in the provided folder wise summary
    - Evaluate the folder wise summary objectively, considering all conclusions on the actual code provided
    - Do NOT make any assumptions about organizational goals or intentions beyond what is explicitly shown in the code
    - Focus solely on the technical aspects and implemented functionality, avoiding speculation about business objectives or future plans
    - Both the keys data, confidence score, and traceback should be present in the output JSON
    - The generated summary should be in string format only and be contained inside the "data" key
    - The "traceback" key should contain a dictionary with feature names as keys and justifications for including these features based on exact phrases from the input
    - Do not include any feature that could potentially be part of the folder wise summary without explicit evidence
    - Every feature mentioned must be driven by clear evidence from the provided input
    """
    user_prompt = """
    Expected Output Format for Generated Summary:

  **Overview**
  <empty line>
  <A brief introduction to the codebase and its main purpose; in paragraph format only, not in points.
  This paragraph should provide a concise yet comprehensive overview of the codebase, its primary functionality, solution provided by the project and its intended use case.
  Aim for 3-5 sentences that capture the essence of the project.>
  <empty line>
  **Highlighted Features**
  <empty line>
  <
  List and briefly explain the key features that are significant components of the codebase and would serve as selling points.
  These features should be presented as follows:
  1. Use numbered points for each feature.
  2. Provide a brief explanation for each feature in 1-2 sentences, highlighting its importance and benefit to the end user.
  3. Focus on features that are central to the codebase's functionality and most important to the end user.
  4. Dont include generic features like "Modular Architecture" or "Code Reusability", these are not features but design principles.
  5. Do not include sub-points under any feature.
  6. Prioritize User Defined Features (if provided) at the beginning of the list.
  7. If User Defined Features are given, list them first before including any features identified through your analysis.
  8. Aim to provide upto of 1 to 5 key features, after each feature add an empty line for formatting purposes.
  9. Ensure that the features listed represent the core functionality and unique selling points based on the folder wise summary.
  10. Use clear, concise language that emphasizes the value proposition of each feature.
  11. Also under each feature, mention which file/folder was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
  12. Do not add features into Highlighted Features if they dont have value for buisness stakeholder about the application. Also do not repeat adding similar feature in this section.

  Output Structure:
  1. ***<Feature 1 Title>***: <Description of the feature in one to two sentences.\n
  2. ***<Feature 2 Title>***: <Description of the feature in one to two sentences.>\n
  >
  <empty line>
  **Key Benefits**
  <empty line>
  <Summarize the key benefits of the codebase in one to two sentences.
  This summary should encapsulate the overall value proposition of the codebase and its potential impact on users or the organization.>
  <empty line>
  <Highlight the most significant key benefits the codebase has to offer in bulleted points. The format should be:
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  Aim for 3-5 bullet points that capture the most compelling advantages of using this codebase, after each point add an empty line for formatting purposes.
  Each benefit should be distinct and provide a clear value proposition.>

  <Final Output Format>
  Output Format - Adhering to this format is crucial, the output should be in parsable JSON format:
  ```json
  {{
    "data": "<generated_summary in string format adhering to the Expected Output Format for Generated Summary>",
    "confidence_score": 90,
    "traceback": {{
      "Feature 1 Title": "Since it mentions about <exact phrase from the folder wise summary>, the 'Feature 1 Title' is included, as the "phrase" is an evidence that this feature is part of the folder wise summary.",
      "Feature 2 Title": "Since it mentions about <exact phrase from the folder wise summary>, the 'Feature 2 Title' is included, as the "phrase" is an evidence that this feature is part of the folder wise summary.",
      ...
    }}
  }}
  ```
  </Final Output Format>
  Note: If the traceback includes phrases that are not present in the folder wise summary then you would be penalized 10000 points.
  The output should be having data, confidence score, and traceback keys, and the entire content inside "```json" and "```" should be parsable by json.
  The "data" key should contain the generated summary and it should be in string format only, allowing the parsing of the entire json.
  If there are any inverted commas inside the generated summary, then escape them with a backslash.
  Do not change or skip the headings of each section in the generated json. The generated summary must have "Overview", "Highlighted Features", "Key Benefits" as section titles. Follow the above provided guidelines."""
    user_prompt += f"""Use the below folder wise summary to generate the summary in the above format: {combined_summary}""" + "User Defined Features : " + str(user_mvf)
    return system_prompt, user_prompt

def db_executive_summary_generation(combined_summary, user_mvf): 
    system_prompt = """
    Role:
    You are an expert Database Architect tasked with understanding the contents of all tables and schema of the database. 
    You shall Articulate a proper executive summary that clearly captures all the main & high-level features of this database.
    The core use-case that this database is intended for, and the prioritized list of the most valuable features, solely based on the provided Table-Level summaries. 
    Do not hallucinate. Do NOT create the most valuable features and its description on pure assumptions. This needs to be based on facts, with proper backing.

    Task:
    1. Analyze provided Table wise summaries.
    2. Understand component interactions and functions.
    3. Prioritize the User Defined Features (if provided) in the summary.
    4. Identify and prioritize the most valuable features based on their importance to the core use-case the Database is solving.
    5. Create a comprehensive executive summary.

    Steps:
    1. Review Table wise summary.
    2. Analyze Table wise summary:
      - Identify all tables. 
      - Take into consideration the foreign keys, primary keys, is-a, has-a, and many-to-many relationships.
      - Deeply understand the intended-use-case of each table.
      - Note data operations, design patterns, and architectural decisions
    3. Create summary:
      - Describe the specific problem the Database is solving, based on Table wise summary
      - Explain high-level interactions and dependencies
      - Outline data workflow
    4. Identify and prioritize main features:
      - Determine which feature(s) address the core problem of the Database, based on SQL implementation and Table wise summary
      - Rank features based on their importance and relevance to solving the main problem, as evidenced in the Database
      - The feature should be major components of the Database and not minor functions like Many-to-Many Relationships, or "Foreign Keys". 
        These are implementation concepts. Not core features.

    Focus Areas:
    - Precised feature prioritization and importance
    - High-level functionality of this Database
    - Clear, concise technical language with Database-specific Language
    - Objective description
    - Capture entire data workflow

    Guidelines:
    - Only use the Table wise summary provided
    - Use precise Database-relevant technical terms
    - Include user-defined features if provided and evidenced in the Table wise summary
    - Prioritize features based on their importance to the core problem, as shown in the Table wise summary

    Feature Identification and Prioritization:
    - Carefully analyze the Table wise summary to identify features actually present in the Table wise summary
    - Do not assume or infer features that are not explicitly mentioned in the Table wise summary
    - Identify the top feature that solves the majority of the problem based on Database and SQL evidence
    - Rank subsequent features in descending order of importance, ensuring they are present in the Table wise summary
    - Ensure the feature list reflects the Database's focus and structure
    - Only include features that have substantial implementation in the Database that is evident from Table wise summary

    Output Format - Adhering to this format is crucial
    ```json
    {
    "data": "generated_summary in string format adhering to the Expected Output Format for Generated Summary",
    "confidence_score": 90,
    "traceback": {
    "Feature 1 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 1 Title' is included, as the 'phrase' is an evidence that this feature is part of the Database.",
    "Feature 2 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 2 Title' is included, as the 'phrase' is an evidence that this feature is part of the Database.",
    ...
    }
    }
    ```

    Requirements:
    - Replace \n with \\n in JSON
    - Limit upto 5 main features (max 2 sub-features each) or 7500 tokens
    - If due to any reason such as Database being small, you are unable to provide 5 features, then provide as many high-level features as possible between the range of 1 to 5.
    - Don't assume features or include minor features due to inability to provide 5 features, lesser number of features is acceptable.
    - Use specified JSON format only
    - Start with "```json" and end with "```"
    - Ensure the top feature in the prioritized list addresses the core problem and is present in the Table wise summary
    - Rank features in descending order of importance to the main problem, based on actual Database and SQL implementation
    - Do NOT include features that are NOT evidenced in the provided Table wise summary
    - Evaluate the Table wise summary objectively, considering all conclusions on the actual Database and SQL provided
    - Do NOT make any assumptions about organizational goals or intentions beyond what is explicitly shown in the Database and SQL
    - Focus solely on the technical aspects and implemented functionality, avoiding speculation about business objectives or future plans
    - Both the keys data, confidence score, and traceback should be present in the output JSON
    - The generated summary should be in string format only and be contained inside the "data" key
    - The "traceback" key should contain a dictionary with feature names as keys and justifications for including these features based on exact phrases from the input
    - Do not include any feature that could potentially be part of the Table wise summary without explicit evidence
    - Every feature mentioned must be driven by clear evidence from the provided input.
    - Strictly use an assertive and objective tone in your response. 
    - Do not be unsure about anything.
    - Do not include the "Folder Name" in your response. Ignore "dbanalysis" folder. Provide Executive Summary of the Database-ONLY.
    """

    user_prompt = """
  Expected Output Format for Generated Summary:

  **Overview**
  <empty line>
  <A brief introduction to the Database and its main purpose; in paragraph format only, not in points.
  This paragraph should provide a concise yet comprehensive overview of the Database, its primary functionality, and its intended use case.
  Aim for 3-5 sentences that capture the essence of the Database.>
  <empty line>
  **Highlighted Features**
  <empty line>
  <
  List and briefly explain the key features that are significant components of the Database and would serve as selling points.
  These features should be presented as follows:
  1. Use numbered points for each feature.
  2. Provide a brief explanation for each feature in 1-2 sentences, highlighting its importance and benefit to the END USER.
  3. Focus on features that are central to the Database's functionality and most important to the END USER.
  4. Dont include generic features like  Many-to-Many Relationships, or "Foreign Keys", these are not features but Design Principles.
  5. Do not include sub-points under any feature.
  6. Prioritize User Defined Features (if provided) at the beginning of the list.
  7. If User Defined Features are given, list them first before including any features identified through your analysis.
  8. Aim to provide upto of 1 to 5 key features, after each feature add an empty line for formatting purposes.
  9. Ensure that the features listed represent the core functionality and unique selling points based on the Table wise summary.
  10. Use clear, concise language that emphasizes the value proposition of each feature.
  11. Also under each feature, mention which file/Table was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
  12. Do not add features into Highlighted Features if they dont have value for buisness stakeholder about the application. Also do not repeat adding similar feature in this section.

  Output Structure:
  1. ***<Feature 1 Title>***: <Description of the feature in one to two sentences.\n
  2. ***<Feature 2 Title>***: <Description of the feature in one to two sentences.>\n
  >
  <empty line>
  **Key Benefits**
  <empty line>
  <Summarize the key benefits of the Database in one to two sentences.
  This summary should encapsulate the overall value proposition of the Database and its potential impact on users or the organization.>
  <empty line>
  <Highlight the most significant key benefits the Database has to offer in bulleted points. The format should be:
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  Aim for 3-5 bullet points that capture the most compelling advantages of using this Database, after each point add an empty line for formatting purposes.
  Each benefit should be distinct and provide a clear value proposition.>

  <Final Output Format>
  Output Format - Adhering to this format is crucial, the output should be in parsable JSON format:
  ```json
  {{
    "data": "<generated_summary in string format adhering to the Expected Output Format for Generated Summary>",
    "confidence_score": 90,
    "traceback": {{
      "Feature 1 Title": "Since it mentions about <exact phrase from the Table wise summary>, the 'Feature 1 Title' is included, as the "phrase" is an evidence that this feature is part of the Table wise summary.",
      "Feature 2 Title": "Since it mentions about <exact phrase from the Table wise summary>, the 'Feature 2 Title' is included, as the "phrase" is an evidence that this feature is part of the Table wise summary.",
      ...
    }}
  }}
  ```
  </Final Output Format>
  Note: If the traceback includes phrases that are not present in the Table wise summary then you would be penalized 10000 points.
  The output should be having data, confidence score, and traceback keys, and the entire content inside "```json" and "```" should be parsable by json.
  The "data" key should contain the generated summary and it should be in string format only, allowing the parsing of the entire json.
  If there are any inverted commas inside the generated summary, then escape them with a backslash.
  Do not change or skip the headings of each section in the generated json. The generated summary must have "Overview", "Highlighted Features", "Key Benefits" as section titles. Follow the above provided guidelines.
    """

    user_prompt += f"""Use the below Table wise summary to generate the summary in the above format: {combined_summary}""" + "User Defined Features : " + str(user_mvf)

    return system_prompt, user_prompt


def architecture_diagram_generation(services_data, icons_metadata):
    user_prompt = f"""
    <Input>
    $services_data = {services_data}
    $icons_metadata
    </Input>

    <Role>
    You are an expert at understanding large projects based on their executive summary and the services being used in them. Create a JSON structure for a ReactFlow diagram based on the given service class JSON.
    </Role>

    <Output Structure>
    1. Create a JSON object with a "nodes" and "edges" array.
    2. Create nodes for each external and third-party service.
    3. "nodes": An array containing all node objects.
      - "id": A unique string identifier for the node.
      - "data":   
        - "label": The name of the node.
        - "description": Description of the service.
        - "associated_files": Associated file and used in files in the service node, defaulting to "No File Available" if not present.
        - "group": The logical group name (e.g., 'Backend', 'Frontend', 'Database',etc..).
        - "subgroup": The specific subgroup within the group (e.g., Frameworks, NoSQL Databases, State Management, etc.).
        - "service": The appropriate filename of the icon based on the $icons_metadata.
      - "position" : The x and y coordinates of the node.
      - "type" : "customNode" This should be fixed.
    4. "edges" : An array having id, source, target, label, and type should be customEdge always.
    4. Ensure all services and files from the input JSON are included.
    5. The output should be in the form of a dictionary containing a "nodes" and "edges" array.
    6. Present only the code inside delimiters "```reactflow [reactflow CODE]```" without any additional explanation.
    """

    system_prompt:str = """
    <Task>
      You are tasked with creating a JSON structure for a ReactFlow diagram based on the given executive summary and the service_class_json. The executive summary contains an overview of the entire project. This JSON includes information about external services and third-party services, along with their associated files. Your output should represent this information as a network of nodes and edges.
    </Task>
    
    <Icons Context>
      $icons_metadata = """ + str(icons_metadata) + """
    </Icons Context>

    <Instructions>
      You are a solution expert, specializing in problem and solution flows. You will be given the solution overview for a project, and your task is to create an interconnected single component of graph which is detailed, and intuitive and self explanatory for:

      Follow these guidelines:
      1. Create nodes for each unique service (both external and third-party).
      2. Do not create any group nodes.
      4. In the data key for each service node, include two additional fields called group and subgroup. The group field should contain the logical group name (e.g., Frontend, Backend, Databases, etc..), and the subgroup field should provide more specific categorization (e.g., Frameworks, NoSQL Databases, etc..). For example, for a service node representing React, the group would be Frontend and the subgroup would be Frameworks.
      5. For each node, check which icon will be the most suitable from the $icons_metadata in the <Icons Context>
      6. Ensure all information from the input is represented in the output.
      7. The position coordinates must be proper for all the nodes.
    </Instructions>

    <Rules>
      **Ensure all nodes in the generated graph are interconnected such that every node has at least one edge, forming a single connected component without any isolated or disjoint sections. (High Priority Requirement)**
      Important Rules to be followed:
      1. Give detailed technical architecture flow and the JSON object following the below output format.
      2. Make sure that the flow and order of new solution approach is explained well in the graph with appropriate edges. Use as many edges you want to describe the data and user flow properly.
      3. The whole user and data flow should be clear.
      4. Do not add unnecessary nodes and edges. Do not create duplicate nodes that perform same task.
      5. Make the Node descriptions detailed, breaking tasks into multiple sub-tasks if needed.
      6. Ensure your edges show the actual flow, and not just connections of what's related. The connections are meant to show the logical flow, and not the relatedness/similarity.
      7. The group name is meant to classify clusters of nodes within each graph. For instance, if we have multiple nodes in features, they would all have "feature" as group. In Architecture Flow, the "Group" should show the layer each node is in, for instance "Backend Layer", "Database Layer" etc.
      9. for a hierarchy of nodes A -> B -> C; ensure that there is not a connection between A -> C.
    </Rules>
    
    <output_format>
    The output should be in between the delimeters ```reactflow and ```. Only provide the json output. Don't give unnecesary explanation.
    ```reactflow
    {
      "nodes": [
        { 
          "id": "unique_node_identifier_string",
          "data" : {
            "label": "name_of_the_service",
            "description": "description of the service",
            "associated_files": ["file_path_1", "file_path_2", "file_path_3", etc.],  // (default: ["No File Available"] if not present)
            "group": "name_of_group",  // Add the logical group name (e.g., "Frontend", "Backend", etc..)
            "subgroup": "name_of_subgroup",  // Add a more specific subgroup name (e.g., "Frameworks", "NoSQL Databases", etc..)
            "service": "filename" //taken from the $icons_metadata,
          }
          "position":{ "x": "Xcoordinate", "y": "Ycoordinate" },
          "type" : "customNode" //this is hardcoded and will be constant
        }
      ],
      "edges": [
        {
          "id": "unique_egde_identifier_string",
          "source": "label A",
          "target": "label B",
          "label": "Showcase what comes from the source node, to the target node. Be concise and specific with labels, such as 'Ingested Data', 'Converted Text', 'User Query' etc. Use at max 5 words",
          "type" : "customEdge" //this is hardcoded and will be constant
        }
      ]
    }```
    </output_format>
    """
    return system_prompt, user_prompt
  

def erd_generation(services_data, icons_metadata):
  tables_metadata = []
  for entry in services_data:
      table_name = entry["table_name"]
      ddl = entry["ddl"]
      columns, primary_keys, foreign_keys = parse_ddl(ddl)
      tables_metadata.append({
          "table_name": table_name,
          "columns": columns,
          "primary_keys": primary_keys,
          "foreign_keys": foreign_keys
      })

  dot = generate_combined_graph(tables_metadata)

  system_prompt:str = """
    You are tasked with creating a JSON structure for a ReactFlow diagram based on the given database ER diagram and schema JSON. This JSON includes information about database columns and their relationships.Your output should represent this information as a network of nodes and edges.
    </Task>
    
    <Icons Context>
      $icons_metadata = """ + str(icons_metadata) + """
    </Icons Context>

    <Instructions>
      You are a solution expert, specializing in problem and solution flows. You will be given the database schema information of a database, and your task is to create an interconnected single component of graph which is detailed, and intuitive and self explanatory for:

      Follow these guidelines:
      1. Create nodes for each unique service (both external and third-party).
      2. Do not create any group nodes.
      4. In the data key for each service node, include two additional fields called group and subgroup. The group field should contain the logical group name (e.g.,Databases, etc..), and the subgroup field should provide more specific categorization (e.g., 'Transactional Tables', 'Reference Tables' etc..). For example, for a service node representing daily transactions, the group would be Database and the subgroup would be Transactional Tables.
      5. For each node, check which icon will be the most suitable from the $icons_metadata in the <Icons Context>
      6. Ensure all information from the input is represented in the output.
      7. The position coordinates must be proper for all the nodes.
    </Instructions>

    <Rules>
      Important Rules to be followed:
      1. Give detailed technical architecture flow and the JSON object following the below output format.
      2. Make sure that the flow and order of new solution approach is explained well in the graph with appropriate edges. Use as many edges you want to describe the data and user flow properly.
      3. The whole user and data flow should be clear.
      4. Do not add unnecessary nodes and edges. Do not create duplicate nodes that perform same task.
      5. Make the Node descriptions detailed, breaking tasks into multiple sub-tasks if needed.
      6. Ensure your edges show the actual flow, and not just connections of what's related. The connections are meant to show the logical flow, and not the relatedness/similarity.
      7. The group name is meant to classify clusters of nodes within each graph. For instance, if we have multiple nodes in features, they would all have "feature" as group. In Architecture Flow, the "Group" should show the layer each node is in, for instance "Database Layer" etc.
      9. for a hierarchy of nodes A -> B -> C; ensure that there is not a connection between A -> C.
    </Rules>
    
    <output_format>
    The output should be in between the delimeters ```reactflow and ```. Only provide the json output. Don't give unnecesary explanation.
    ```reactflow
    {
      "nodes": [
        { 
          "id": "unique_node_identifier_string",
          "data" : {
            "label": "name_of_the_table",
            "description": "description of the table",
  	    "columns": ["order_id [PK]", "product_sku [PK]", "quantity", "unit_price"]
            "group": "name_of_group",  // Add the logical group name (e.g., "Database", etc..)
            "subgroup": "name_of_subgroup",  // Add a more specific subgroup name (e.g., 'Transactional Tables', 'Reference Tables', etc..)
            "service": "filename" //taken from the $icons_metadata,
          }
          "position":{ "x": "Xcoordinate", "y": "Ycoordinate" },
          "type" : "customNode" //this is hardcoded and will be constant
        }
      ],
      "edges": [
        {
          "id": "unique_egde_identifier_string",
          "source": "label A",
          "target": "label B",
          "label": "Showcase what comes from the source node, to the target node. Be concise and specific with labels, such as 'Ingested Data', 'Converted Text', 'User Query' etc. Use at max 5 words",
          "type" : "customEdge" //this is hardcoded and will be constant
        }
      ]
    }```
    </output_format>
    """
    
  user_prompt:str = f"""
    <Input>
    $database_tables = {dot}
    $icons_metadata
    </Input>

    <Role>
    You are an expert at understanding database architecture based on ER diagrams and relational structures. Create a JSON structure for a ReactFlow diagram based on the given database schema.
    </Role>
    <Output Structure>
      1. Create a JSON object with a "nodes" and "edges" array.
      2. Create nodes for each table in the schema.
      3. "nodes": An array containing all node objects.
      - "id": A unique string identifier for the node.
      - "data":  
        - "label": The name of the table.
        - "description": A brief summary of the table's role or content.
        - "columns": List of column names (mark primary keys with [PK], foreign keys with [FK]).
        - "group": The logical group name (e.g., 'Database').
        - "subgroup": The specific subgroup within the group (e.g., 'Transactional Tables', 'Reference Tables').
        - "service": The appropriate filename of the icon based on the $icons_metadata.
      - "position" : The x and y coordinates of the node.
      - "type" : "customNode" This should be fixed.
      4. "edges" : An array having id, source, target, label, and type should be customEdge always.
      5. The label of the edge should describe the relationship, like "order_id â†’ order_id". 
      6. The output should be in the form of a dictionary containing a "nodes" and "edges" array.
      7. Present only the code inside delimiters "```reactflow [reactflow CODE]```" without any additional explanation.
    """
    
  return system_prompt, user_prompt
    

def feature_summary_generation(formatted_data, user_mvf, executive_summary):
    # if input_type is None:
    #     formatted_data = file_summary_list
    # elif input_type == "batch_summary":
    #     formatted_data = format_batchwise_summary_metadata_for_services(file_summary_list)
    # else:
    #     formatted_data = format_file_summaries(file_summary_list)

    user_prompt = """
    Role: You are an AI code analyst specializing in creating concise, feature-level summaries of codebases.

    Objective: Provide a comprehensive yet concise feature-level summary of a given codebase, highlighting key components, functionality, and the project's overall workflow.

    Input: You will receive information about a codebase, which may include an executive summary or other project details.

    Steps:
    1. Analyze the provided codebase information.
    2. Identify the main features (maximum 5) of the project from the executive summary (if provided in same order)
    3. Create a summary following the specified format, including:
        a. An overview of the project
        b. A list of key features with brief descriptions
        c. A closure statement
    4. Self-evaluate the generated summary and assign a confidence score.
    5. Format the output as specified in the instructions.

    Output Format:
    ```json
    {
        "data": "generated_summary in string format adhering to the Detailed Instructions for Output Format",
        "confidence_score": 90
    }
    ```

    Detailed Instructions for Output Format:

    **Overview**
    <empty line>
    < 
        Summarize all features in 2-3 sentences, introducing the project and its purpose.
        Provide a 2-3 sentence summary of key benefits, highlighting core architecture and value proposition.
    >
    <empty line>
    **Key Features**
    <empty line>
    <   
        List a maximum of 5 main features.
        For each feature, provide up to 2 sub-points describing its functionality.
        Ensure clear explanation of how features interact and contribute to the project's goals.
        1. ***<Key Feature Title>*** : 
        * <Sub point 1 description>
        * <Sub point 2 description>
        <empty line>
    >
    <empty line>
    < 
        Summarize the overall impact and value proposition of the project in one sentence as a conclusion statement.
    >
    <empty line>
    
    -> Self-Evaluation:
        - Score the summary out of 100 based on clarity, precision, detail, knowledge, accuracy, technical correctness, and understanding of the data.

    -> Formatting Requirements:
        - Replace all newline characters (\n) with \\n in the JSON output.
        - Ensure the complete JSON is less than 7500 tokens.
        - Start the output with "```json" and end with "```".
        - If an executive summary is provided, use only the highlighted features from it.

    Example Output Structure:
    ```json
    {
        "data": "**Overview**\\n\\n[Project overview]\\n\\n[Benefits summary]\\n\\n**Key Features**\\n\\n1. *Feature 1*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n2. *Feature 2*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n[...continue for up to 5 features...]\\n\\n[Closure statement]",
        "confidence_score": 90
    }
    ```

    Remember: Adhere strictly to the output format and instructions to maintain consistency and accuracy in your summary.
    """

    user_prompt += "User Defined Features : " + str(user_mvf)

    system_prompt = f"""
        <role>
        You are an assistant to a Senior Software Engineer. You are very capable in reading and understanding huge codebases.
        There is no edge-case, no mistake, no functionality no matter how small goes unnoticed by you.
        You will be given a large codebase and be asked queries regarding it.
        </role>

        <Task>
        You will be given relevant files from a production codebase. The Senior Engineer will consult you to clear his doubts and ask for critical code-level and functionality level analysis of the same.
        <Important>
        1. You will be clear. Feel free to be descriptive but Avoid Jargon
        2. You shall perform critical analysis on the code before responding.
        3. Note that the codebase will be quite complex and have dependencies everywhere, be mindful of them all.
        4. Enclose code in (triple backticks)``` code ```
        </Important>
        </Task>

        Files from Codebase goes here :
        <Repo Structure>
        {formatted_data}
        </Repo Structure>
    """

    start_index = executive_summary.find("Highlighted Features")
    end_index = executive_summary.find("Key Benefits")

    if start_index != -1 and end_index != -1:
        executive_summary = executive_summary[start_index:end_index].strip()

    user_prompt += "Executive Summary : " + str(executive_summary)

    return system_prompt, user_prompt

def feature_summary_generation_db(formatted_data, user_mvf, executive_summary):
    # if input_type is None:
    #     formatted_data = file_summary_list
    # elif input_type == "batch_summary":
    #     formatted_data = format_batchwise_summary_metadata_for_services(file_summary_list)
    # else:
    #     formatted_data = format_file_summaries(file_summary_list)

    user_prompt = """
    Role: You are an AI Database Analyst specializing in creating concise, feature-level summaries of complex database schemas and architectures.

    Objective: Provide a comprehensive yet concise feature-level summary of a given database schema information, highlighting key components, entities, relationships, and the overall data architecture workflow.

    Input: You will receive information about a database design, which may include an executive summary or other schema-level details.

    Steps:
    1. Analyze the provided database schema information.
    2. Identify the main features (maximum 5) of the database from the executive summary (if provided in same order)
    3. Create a summary following the specified format, including:
        a. An overview of the database
        b. A list of key features with brief descriptions
        c. A closure statement
    4. Self-evaluate the generated summary and assign a confidence score.
    5. Format the output as specified in the instructions.

    Output Format:
    ```json
    {
        "data": "generated_summary in string format adhering to the Detailed Instructions for Output Format",
        "confidence_score": 90
    }
    ```

    Detailed Instructions for Output Format:

    **Overview**
    <empty line>
    < 
        Summarize all features in 2-3 sentences, introducing the database and its purpose.
        Provide a 2-3 sentence summary of key benefits, highlighting schema structure, normalization or denormalization logic, and value proposition in handling data.
    >
    <empty line>
    **Key Features**
    <empty line>
    <   
        List a maximum of 5 main features.
        For each feature, provide up to 2 sub-points describing its data handling, relationships, or optimization logic.
        Ensure clear explanation of how features contribute to performance, consistency, and data integrity.
        1. ***<Key Feature Title>*** : 
        * <Sub point 1 description>
        * <Sub point 2 description>
        <empty line>
    >
    <empty line>
    < 
        Summarize the overall impact and value proposition of the database in one sentence as a conclusion statement.
    >
    <empty line>
    
    -> Self-Evaluation:
        - Score the summary out of 100 based on clarity, precision, detail, knowledge, accuracy, technical correctness, and understanding of the schema information.

    -> Formatting Requirements:
        - Replace all newline characters (\n) with \\n in the JSON output.
        - Ensure the complete JSON is less than 7500 tokens.
        - Start the output with "```json" and end with "```".
        - If an executive summary is provided, use only the highlighted features from it.

    Example Output Structure:
    ```json
    {
        "data": "**Overview**\\n\\n[Database overview]\\n\\n[Benefits summary]\\n\\n**Key Features**\\n\\n1. *Feature 1*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n2. *Feature 2*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n[...continue for up to 5 features...]\\n\\n[Closure statement]",
        "confidence_score": 90
    }
    ```

    Remember: Adhere strictly to the output format and instructions to maintain consistency and accuracy in your summary.
    """

    user_prompt += "User Defined Features : " + str(user_mvf)

    system_prompt = f"""
        <role>
        You are an assistant to a Senior Data Architect. You are very capable in reading, analyzing, and understanding complex database schemas and data models.
        No entity, constraint, relationship, or optimization logic goes unnoticed by you.
        You will be given a comprehensive database structure or schema information and will be asked to analyze, explain, and summarize it at a structural and functional level.
        </role>

        <Task>
        You will be given relevant database schema files or DDL definitions. The Senior Data Architect will consult you to clear doubts and ask for critical schema-level and data model-level analysis.
        <Important>
        1. You will be clear. Feel free to be descriptive but Avoid Jargon
        2. Perform a critical and deep analysis of the schema and the information given before responding.
        3. The schema will often involve multiple tables, foreign keys, views, procedures, and indexing strategies â€” be mindful of their dependencies and relationships.
        4. Enclose code or schema in (triple backticks)``` code ```
        </Important>
        </Task>

        Files from Database schema goes here :
        <Database Structure>
        {formatted_data}
        </Database Structure>
    """

    start_index = executive_summary.find("Highlighted Features")
    end_index = executive_summary.find("Key Benefits")

    if start_index != -1 and end_index != -1:
        executive_summary = executive_summary[start_index:end_index].strip()

    user_prompt += "Executive Summary : " + str(executive_summary)

    return system_prompt, user_prompt


#FEATURE HIERARCHY:
generate_features_system_prompt = """
  <Role>
    You are a Software Architect with expertise in analyzing large summaries from code files of an application. 
    You can comprehend summaries from code files that are complex, production-grade and are written in various programming languages to generate most important features, their description and the subfeatures with their description belonging to the most important features along with the other relevant information requested below.
    
    You will follow 2 Events before responding : 
    1. Generation of Feature Hierarchy as given in "Output_Format".
    2. Critical Evaluation of Every Confidence Score.  
  </Role> 

    <Task 1>
    You are provided with multiple relative file paths and file-wise code summaries from a application codebase.
    1. Analyze the file summaries carefully, leveraging your expertise to deduce the frameworks, functionality, and features.
    2. Perform a critical assessment of the code's functionality and interdependencies before responding.
    3. The codebase is complex and likely contains dependencies across various modules. Be mindful of these.
    4. Analyse every file summary and assign the features and sub-features based on the information provided.
    5. Respond strictly in the structured JSON format provided below.
    6. In each sub-feature's 'file_path' array:
        - Set 'critical: true' ONLY for files that are CORE & NON-REPLACEABLE to the sub-feature's main functionality.
        - Set 'critical: false' for ALL supporting, secondary, or replaceable files  
        - Each sub-feature should have both true and false entries.
        - If unsure, default to false (be EXTREMELY selective with 'true')
        - Make sure each sub-feature atleast have one file as true.

    Explanation of the Output terms:
    Feature - Features are most valuable and high level features extracted from the list of summaries that are provided to you. 
    Feature description - Description of the features explaining the high level value and impact that it creates for the project. Define the Feature. The description should be crisp, precise, well formatted and must be between 2-3 lines.
    Subfeature - Subfeatures are micro most valuable features that are extracted from the list of summaries and belong to the Most related and similar Features.
    Subfeature description - Description of the subfeatures explaining the specific value, technical and non-technical functionalites that it provided to the project. Define the subfeature and also explain how its related to the feature. The description should be crisp, precise, well formatted and must be between 2-3 lines.
    
    Points to Remember:
    1. Do not extract any feature or subfeature where there are no reference/citations from the application summaries.
    2. The description must be precise, valuable, well-formatted and must be between 2-3 lines.
    3. The Feature titles should be precise, specific, self explanaible, independent and not have similar feature titles. The Feature titles should not be highly generalized.
    4. The SubFeatures titles should be precise, self explanaible and not have similar subfeature titles. The SubFeature titles should not be highly generalized.
    5. SubFeatures should not be very low level that it explains code functions, code process like 'Json handling', 'Reading csv', readME etc.
    6. If similar subfeatures are present, then group them under one common Feature itself. Do not create multuple Features for similar subfeatures.
    6. If Unit testing related summaries are found, then create that as another Feature named 'Unit Testing' and assign the specific testing subfeatures under this feature.
    </Task 1>

  <Task 2>
  You shall now Assign and Justify Confidence Scores for each feature.

  <Critical Evaluation of Confidence Scores> 

  <Evaluation MODE>
  - You will now Forget everything that was done beforehand and act as an unbiased judge.
  - $Project-Summaries-&-Paths (INPUT).
  </Evaluation MODE>
  <Important>
  Critically analyze every "Feature" and "SubFeature" based on the following metrics. 
  You shall generate a confidence score between 0-100 for each of the following :
  1. Is the "Feature" & "SubFeature" name accurate to its functionality ? (Accuracy)
  2. Does the "Feature" & "SubFeature" include files with an unrelated function ? (Feature Dilution Rate)
  3. Important : Does this "Feature" & "SubFeature" make sense given the Overall Purpose of the Application ? (Consistency)
  4. Are all the files in "Feature" & "SubFeature" included ? (Completeness)

  <Strict>
  1. You will now generate a list of 4 confidence scores between 0-100 for above criteria under "confidence_score" key.
  2. Based on above criteria, you shall provide a VERY BRIEF logical explanation (10-20 words) for Confidence Score under "confidence_score_justification" key.
  3. Make sure to mention the entire filepath without omitting the prefix.
  4. Make sure all the filepaths are present.
  <Important> STRICTLY Don't Comment on Missing Files. Don't Overestimate. Don't Underestimate.</Important> 
  </Strict>

  </Important>

  </Critical Evaluation of Confidence Scores> 
  </Step 2>


      <Output_Format>
    Return a response in JSON format. Do not include any extra information or explanations. Strictly DON'T deviate from mentioned KEYS.
    Example:
```json
[
  {
    "name": "User Authentication and Management",
    "feature_description": "Comprehensive user account system with secure login, registration, profile management, and role-based access control.",
    "feature_description_confidence_score": [95, 70, 100, 70],
    "sub_features": [
      {
        "name": "User Registration",
        "description": "Allows new users to create accounts by providing necessary information such as username, email, and password. Implements email verification, password strength checks, and duplicate account prevention. Stores user data securely in the database with password hashing.",
        "file_path": [
          {
            "module_name": "RegistrationController",
            "path": "Controllers/Account/RegistrationController.cs",
            "critical": true
          },
          {
            "module_name": "RegisterView",
            "path": "Views/Account/Register.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [75, 80, 85, 65],
        "sub_feature_confidence_score_justification": "No feature dilution, might have missed some file."
      },
      {
        "name": "User Login",
        "description": "Authenticates users using their credentials, creates and manages user sessions, and implements security measures such as login attempt limiting and two-factor authentication (2FA). Provides password reset functionality for forgotten passwords.",
        "file_path": [
          {
            "module_name": "LoginController",
            "path": "Controllers/Account/LoginController.cs",
            "critical": true
          },
          {
            "module_name": "LoginView",
            "path": "Views/Account/Login.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [80, 100, 80, 75],
        "sub_feature_confidence_score_justification": "High chance of missing files."
      }
    ],
    "feature_confidence_score_justification": "No feature dilution, duplication or missing files. Accurate Naming."
  },
  {
    "name": "Product Catalog Management",
    "feature_description": "Comprehensive system for managing product listings, categories, and inventory across the e-commerce platform.",
    "feature_description_confidence_score": [95, 65, 70, 80],
    "sub_features": [
      {
        "name": "Product CRUD Operations",
        "description": "Enables administrators to create, read, update, and delete product listings. Includes functionality for managing product details such as name, description, price, images, and inventory levels. Implements validation to ensure data integrity and consistency across the product catalog.",
        "file_path": [
          {
            "module_name": "ProductController",
            "path": "Controllers/ProductController.cs",
            "critical": true
          },
          {
            "module_name": "ProductView",
            "path": "Views/Product/Index.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [90, 85, 100, 70],
        "sub_feature_confidence_score_justification": "High confidence with no duplication or dilution."
      },
      {
        "name": "Category Management",
        "description": "Allows for the creation and management of product categories and subcategories. Implements a hierarchical structure for organizing products, enabling efficient navigation and filtering of the product catalog for both administrators and customers.",
        "file_path": [
          {
            "module_name": "CategoryController",
            "path": "Controllers/CategoryController.cs",
            "critical": true
          },
          {
            "module_name": "CategoryView",
            "path": "Views/Category/Index.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [85, 75, 90, 95],
        "sub_feature_confidence_score_justification": "High confidence without any duplication or dilution."
      }
    ],
    "feature_confidence_score_justification": "All files refer to single overall functionality. Might have missed some files."
  }
]
```
  </Output_Format>

"""

generate_features_user_message = """
<Strictly Remember>
1. As input you will be given a batch of `file_path` and `file_summary` from a production codebase. Keep it in mind that it could be a file from a very large repository with lot of inter-dependencies.
2. Understand all the file description first, then try to determine the feature, sub-features and their description. For **each file** it should have a feature or sub-features whenever the conditions are met.
3. The response should contain all the fields given in the example output format. The response should be strictly in json format.
4. The description of features/subfeatures must be in the length of 2-3 lines. The response should be structured and well-formatted.
5. Don't generate any additional explanation or description. Provide the structured response in json only.
</Strictly Remember>
  
<Input file wise summary>
{file_summary}
</Input file wise summary>
<Response>
"""

merge_features_in_hierarchy_user_prompt = """You are a software feature analyzer. Given a list of related features that have been clustered together, create a merged feature that encompasses all the functionality.

Features to merge:
{feature_list}

Generate a JSON response that includes:
1. A name for the merged feature representing accurate feature name. Do not mention its merged or unified or anything as such. The feature name should accurately represent a major funcationality of a repository.
2. A detailed description that covers all functionality
3. A confidence score (0-100) for the merge
4. A justification for the confidence score

Respond with a JSON object in the following format:
```json
{{
    "name": "Merged feature name",
    "description": "Comprehensive description",
    "confidence_score": 85,
    "confidence_justification": "Reason for the confidence score"
}}
```
Give only JSON and nothing else. Do not include any explanations or additional text outside the JSON block. Make sure to start with ```json and end with ``` only.
"""

mapping_names_for_merged_features_user_prompt = """  <Role>
    You are a smart AI cassistant with strong expertise in Software Engineering. You can understand complex, production-grade codebases written in various programming languages and summarize them effectively.
  </Role>
  <Task>
  You will be given a brief description of  features of a large codebase and your task is to generate a relevant feature name, brief description, and priority level.
  <Important>
   1. The feature name should be brief, relevant and should represent the entire description provided.
   2. Generate a relevant description which is basically a overall summary of the description provided.
   3. Assign a priority level (high, medium, low) based on the significance, importance and complexity of the feature to the overall system. 
  </important>
  </Task>
  <Example output>
  ```json
    {
        "name": <feature_name>, //string
        "feature_description": <feature_description>, //string
        "priority": <priority> //string (high, medium, or low)
    }
    ```
  </Example output>
  <Strictly Remember>
1. The feature name should be relevant and at the same time interpretable, easy to understand.
2. The feature description should represnt the entire description given for summarisation, it should be simple and easy to understant.
3. The priority should be one of: high, medium, or low.
4. The response should be strictly in json format specified above.
5. Strictly make sure Feature Description is not more than 200 words.
  </Strictly Remember>

<code summary>
The code summary is given below:
"""


reducing_sub_features_user_prompt = """
    You are a software feature consolidation expert. Your task is to merge similar sub-features into one comprehensive sub-feature.

    Here are the sub-features that need to be merged:
    {sub_features_list}

    For each sub-feature, we have:
    - Name: The sub-feature name
    - Description: The sub-feature description (if available)
    - Confidence Score: The confidence score (if available)

    Your output should be a JSON object containing:
    1. A unified sub-feature name that encompasses all the input sub-features
    2. A comprehensive description that covers all aspects of the input sub-features
    3. A confidence score (use the highest available from input sub-features)
    4. A justification for the confidence score

    Return the output in JSON format starting with ```json and ending with ```.

    Example output format:
    ```json
    {{
        "name": "Unified Sub-Feature Name",
        "description": "Comprehensive description covering all aspects",
        "sub_feature_confidence_score": 95,
        "sub_feature_confidence_score_justification": "Merged from similar sub-features with high semantic similarity"
    }}
    ```
    """


post_processing_feature_name_description_system_prompt="""
  <Role>
    You are a smart AI assistant with strong expertise in Software Engineering. You can understand complex, production-grade codebases written in various programming languages and summarize them effectively.
  </Role>
  <Task>
  You will be given a brief description of modules or features of a large codebase and your task is to generate a relevant feature name and brief description.
  <Important>
   1. The feature name should be brief, relevant and should represent the entire description provided.
   2. Generate a relevant description which is basically a overall summary of the description provided.
   3. Also generate a confidence score in a scale of 0 - 100.
  </important>
  </Task>
  <Example output>
  ```json
    {
        "name": <feature_name>,
        "feature_description_confidence_score": <score 0 - 100>,
        "feature_description": <feature_description>
    }```
  </Example output>"""

post_processing_feature_name_description_user_prompt = """<Strictly Remember>
1. The feature name should be relevant and at the same time interpretable, easy to understant.
2. The confidence score should represent the ability to summarise the description.
3. The feature description should represnt the entire description given for summarisation, it should be simple and easy to understant.
4. The response should be strictly in json format specified above.
</Strictly Remember>
<code summary>
The code summary is given below: \n
{feature_description}
</code_summary>
<response>
Your response in json goes here:
"""

merge_similar_features_system_prompt = """You are a solution architect. Your task is to carefully review each feature and its description, and combine them into a single high-level feature.

The final high-level features should represent what an end user would perceive, e.g., Messenger, Google Chat, Messaging, Reels, etc.

Based on the generated features provided, identify which features can be merged into a single high-level feature. 
Strictly output them in the following format:
{{ 
  <High-Level Feature Name 1>: [<Merged Feature 1>, <Merged Feature 2>, <Merged Feature 3>, ...],
  <High-Level Feature Name 2>: [<Merged Feature 1>, <Merged Feature 2>, <Merged Feature 3>, ...],
  ...
}}

INPUT:
Feature names and descriptions are provided in the format: 
[1. Feature name: <feature name> 
Feature description: <feature description>, 
2. ...]

{feature_texts}

MVFS:
{total_MVFs}

Points to remember:
1. While merging features and naming high-level features, always prefer names from the user-defined MVFs provided. All relevant features can be grouped under these high-level features.
2. If certain features do not fit under the user-defined MVFs, choose a better name than the existing one for the new high-level feature if necessary.
3. The names of the features being merged must remain exactly as provided in the INPUT section; do not modify them. Do not consider Feature description in Feature Names.
4. Follow the output structure strictly: high-level feature names as dictionary keys and merged features as values in list format.
5. If a feature is already a high-level feature, you do not need to forcibly merge it. If a feature seems to be function-level/low-level  features, merge them into a High-level feature.
6. Merge similar features into a single high-level feature based on their names and descriptions, when applicable. Each final high-level feature should be independent of the others.
7. Do not assign the same feature to multiple high-level features.
8. If user-defined MVFs are empty, skip point 1 and begin with point 2.
9. Do **not** include any Feature descriptions in the final output."""


merging_description_user_prompt = """You are a Solution Architect. Your task is to summarize the multiple feature descriptions provided into a brief, coherent summary of **no more than two sentences**.

  The summary must:
  - Accurately capture all key components from the provided descriptions.
  - Align clearly with the given high-level feature name.
  - Serve as the final description of the high-level feature.

  Only the final summarized description should be included in the output â€” no additional commentary or formatting.

  INPUT:
  Multiple descriptions: {merging_feature_description}

  High-Level Feature Name: {high_level_feature}
  """


micro_sub_feature_prompt = """You are an expert system analyst specializing in decomposing SubFeatures into granular, logically independent components. You support **two levels** of splitting:

1. **Horizontal splitting**: Split a subfeature into multiple *same-level subfeatures* when it encompasses multiple independently meaningful functionalities. The subfeatures created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.
2. **Vertical splitting**: Further break each of those subfeatures into *microsubfeatures* (if applicable), ensuring each micro-sub-features/micro-user-story describes a single goal or operation. The micro-sub-features/micro-user-story created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.

---

### ðŸ”§ TASK OVERVIEW

Given a Macro-Feature, Subfeature, its description, associated module files and its summary:

- Decide if the subfeature should be split horizontally into multiple same-level subfeatures.
- For each resulting subfeature (or original if not split), analyze whether it can be split vertically into **microsubfeatures** (fine-grained user stories).
- Provide the confidence scores for the subfeature that is split, whether horizontally or vertically.
- Provide the files that are related to the sub_features too, not just the micro_sub_features.
- Each leaf user-story must have files assigned to them, else you should not create/split these subfeatures.
- Provide description of generated subfeature/sub-user-stories in 2-4 lines but only valid information. Do not assume or hallucinate to generate description.
Apply this recursively: if horizontal splitting occurs, then attempt vertical splitting for each. But remember, not to create any duplicates in the process. 

---

### SPLITTING DECISIONS

#### Horizontal Splitting (Same-level Subfeatures):
Split if:
- The subfeature covers multiple high-level functionalities
- Each function could be planned, developed, and deployed independently
- Each component has a clear boundary and responsibility

#### Vertical Splitting (Microsubfeatures):
Split further if:
- A subfeature contains multiple independent operations or logical stages
- These operations can be implemented, tested, or tracked separately
- Each micro-subfeature represents one atomic, non-overlapping functionality

---

### DO NOT SPLIT IF:
- sub-user-stories are tightly coupled in the Subfeature and cannot function independently.
- Do not split subfeatures into sub-user-stories that are hardly single line of code and cannot be considered as a proper functionality, but just a config/parameter.
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across actions are too complex to isolate.
- There are no files that can be mapped to the generated user-story.
- Do not split if the user-story is barely a functionality. The split user-stories must have independent functionality that contributes to the subfeature and feature and if not, do not split.
- Don not split ReadMe & .md files into sub-user-stories.
- Do not split horizontall for granullar subfeatures as they are not user stories but mid level features.
---

### FILE MAPPING RULES:
- For each subfeature or microsubfeature, cite only directly relevant files.
- Use only the provided input data to match files â€” no guessing.
- Avoid duplication unless a file is clearly shared between components.

Each `file_path` entry must include:
```json
{
  "module_name": "<Name>",
  "path": "<Path>",
  "critical": <true/false>,
  "git_url": "<Git URL>"
}

OUTPUT FORMAT
If the subfeature should NOT be split:
Return: "None"

If the subfeature should be split, return a list of Parent User Stories with subfeatures inside.
If a subfeature itself can be further split into microsubfeatures, nest them under micro_sub_features like so:

[
  {
    "name": "Parent User Story Title 1",
    "description": "Full description of the original or updated user story and its purpose.",
    "file_path": [...],
    "sub_feature_confidence_score":"confidence score of the subfeature with respect to the Feature, as a percentage (e.g., 80)"
    "micro_sub_features": [
      {
        "name": "Sub-User Story Title 1",
        "description": "Standalone description of a single functionality.",
        "file_path": [...],
        "micro_sub_feature_confidence_score":"confidence score of the micro_sub_feature with respect to the sub_feature, as a percentage (e.g., 90)"
        }
          ...
        ]
      },
      ...
    ]
  }
]
Each layer must preserve independence, clarity, and singular focus of each story.

VALIDATION CHECKLIST
- Each title must express one functionality only (no imperative phrasing)
- description must avoid assumptions and describe the real function. It must be as detailled as possible.
- Each story must make sense independently and fit in the broader feature flow
- if there are multiple user-story under the subfeature, it needs to be in sequence of business logic.
- File mappings must be relevant and scoped accurately
- Do no miss/skip any values in the output json. The output structure must be maintained strictly.
- All subfeature and sub-user-story names and descriptions must be strictly in a declarative tone, not imperative.

* Use generic or speculative statements
"""


db_micro_sub_feature_prompt = """
<Role>
You are an expert Database analyst specializing in decomposing SubFeatures into granular, logically independent components. You support **two levels** of splitting:
You shall ALWAYS process features from a Database perspective ONLY. 
There can be more than one Table in the DB context provided to you.
</Role>

1. **Horizontal splitting**: Split a subfeature into multiple *same-level subfeatures* when it encompasses multiple independently meaningful functionalities. The subfeatures created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.
2. **Vertical splitting**: Further break each of those subfeatures into *microsubfeatures* (if applicable), ensuring each micro-sub-features/micro-user-story describes a single goal or operation. The micro-sub-features/micro-user-story created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.

<Strict Constraints> 
- You are dealing with Database Information. 
- No matter what, STRICTLY use Database-Specific Language ALWAYS. 
- Use words like Columns / Fields / Schema / DataTypes / Constraints / Foreign Keys / Primary Keys etc.
- Strictly Do not start descriptions with or start with "this micro-feature" / or "this sub-feature".
- You shall do this regardless of the input context and nature.
Remember : Every "FILE" given to you is information of a table. Therefore in your response, ALWAYS refer to "Table" instead of "File".

</Strict Constraints> 


### ðŸ”§ TASK OVERVIEW

Given a Macro-Feature, Subfeature, its description, associated module files and its summary:

- Decide if the subfeature should be split horizontally into multiple same-level subfeatures.
- For each resulting subfeature (or original if not split), analyze whether it can be split vertically into **microsubfeatures** (fine-grained user stories).
- Provide the confidence scores for the subfeature that is split, whether horizontally or vertically.
- Provide the files that are related to the sub_features too, not just the micro_sub_features.
- Each leaf user-story must have files assigned to them, else you should not create/split these subfeatures.
- Provide description of generated subfeature/sub-user-stories in 2-4 lines but only valid information. Do not assume or hallucinate to generate description.
Apply this recursively: if horizontal splitting occurs, then attempt vertical splitting for each. But remember, not to create any duplicates in the process. 

---

### SPLITTING DECISIONS

#### Horizontal Splitting (Same-level Subfeatures):
Split if:
- The subfeature covers ONE / MORE THAN ONE high-level functionalities
- Each function could be planned and developed independently
- Each component has some clear boundaries and responsibilities

#### Vertical Splitting (Microsubfeatures):
Split further if:
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across actions are too complex to isolate.
- There are no tables that can be mapped to the generated user-story.
- The subfeature is too complex to be planned, developed, and deployed independently
- Each micro-subfeature represents one atomic, non-overlapping functionality
Note: Maintain at least 2 subfeatures unless the database has only one table.
- Prioritize brevity, consistency and no informaiton leakage across subfeatures.
- Ensure crisp segregation.
---

### DO NOT SPLIT IF:
- sub-user-stories are tightly coupled in the Subfeature and cannot function independently.
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across tables in two features are too complex to isolate.
- There are no tables that can be mapped to the generated user-story.
Note: Maintain at least 2 subfeatures and 1 or more microsubfeatures per subfeature, Unless the database has only one table.
Note : Maintain brevity during splitting at the same level. Do NOT overload the a single feature with too many subfeatures.
---


### FILE MAPPING RULES:
- For each subfeature or microsubfeature, cite only directly relevant tables.
- Use only the provided input data to match files â€” no guessing.
- Avoid duplication unless a file is clearly shared between components.

Each `file_path` entry must include:
```json
{
  "module_name": "<Name>",
  "path": "<Path>",
  "critical": <true/false>,
  "git_url": "<Git URL>"
}

OUTPUT FORMAT
If the subfeature should NOT be split:
Return: "None"

If the subfeature should be split, return a list of Parent User Stories with subfeatures inside.
If a subfeature itself can be further split into microsubfeatures, nest them under micro_sub_features like so:

[
  {
    "name": "Parent User Story Title 1",
    "description": "Full description of the original or updated user story and its purpose.",
    "file_path": [...],
    "sub_feature_confidence_score":"confidence score of the subfeature with respect to the Feature, as a percentage (e.g., 80)"
    "micro_sub_features": [
      {
        "name": "Sub-User Story Title 1",
        "description": "Standalone description of a single functionality.",
        "file_path": [...],
        "micro_sub_feature_confidence_score":"confidence score of the micro_sub_feature with respect to the sub_feature, as a percentage (e.g., 90)"
        }
          ...
        ]
      },
      ...
    ]
  }
]
Each layer must preserve independence, clarity, and singular focus of each story.

VALIDATION CHECKLIST
- Each title must express one functionality only (no imperative phrasing)
- description must avoid assumptions and describe the real function. It must be as detailled as possible.
- Each story must make sense independently and fit in the broader feature flow
- if there are multiple user-story under the subfeature, it needs to be in sequence of business logic.
- File mappings must be relevant and scoped accurately
- Do no miss/skip any values in the output json. The output structure must be maintained strictly.
- All subfeature and sub-user-story names and descriptions must be strictly in a declarative tone, not imperative.
- Use Database-specific schema only. Do not include words like "Attributes" / "Code Files" in your response. 
- Strictly Do not start descriptions with or start with "this micro-feature" / or "this sub-feature".
* Use generic or speculative statements

"""import os
from graphviz import Digraph
import re 
import json

def parse_ddl(ddl: str):
    """
    Parse the DDL to extract columns, primary keys, and foreign keys.
    """
    lines = ddl.splitlines()
    column_lines = []

    for line in lines:
        line = line.strip()
        if (
            line.upper().startswith("CREATE")
            or line.upper().startswith("PRIMARY")
            or line.upper().startswith("FOREIGN")
            or line.upper().startswith(")")
            or line == ""
        ):
            continue

        match = re.match(r'(\w+)\s+\w+', line)
        if match:
            column_lines.append(match.group(1))

    pk_match = re.search(r'PRIMARY KEY\s*\((.*?)\)', ddl)
    primary_keys = [key.strip() for key in pk_match.group(1).split(",")] if pk_match else []

    foreign_keys = []
    for match in re.finditer(r'FOREIGN KEY\s*\(([^)]+)\)\s+REFERENCES\s+`?[\w]+\.(\w+)`\(([^)]+)\)', ddl):
        fk_col = match.group(1).strip()
        ref_table = match.group(2).strip()
        ref_col = match.group(3).strip()
        foreign_keys.append((fk_col, ref_table, ref_col))

    return column_lines, primary_keys, foreign_keys


def generate_combined_graph(tables_data):
    """
    Generate a single combined graph from multiple tables.
    """
    dot = Digraph(comment='Combined Table Diagram')
    dot.attr(rankdir='LR')

    # Store individual table nodes
    for table in tables_data:
        table_name = table['table_name']
        columns = table['columns']
        primary_keys = table['primary_keys']
        
        label_lines = []
        for col in columns:
            if col in primary_keys:
                label_lines.append(f"{col} [PK]")
            else:
                label_lines.append(col)
        dot.node(table_name, shape='box', label=f'{table_name}\\n' + "\\n".join(label_lines))

    # Add relationships
    for table in tables_data:
        table_name = table['table_name']
        for fk_col, ref_table, ref_col in table['foreign_keys']:
            dot.edge(table_name, ref_table, label=f'{fk_col} â†’ {ref_col}')

    return dot

def folder_summary_generation_prompts(
        total_allocated_tokens, 
        file_list, folder_name, 
        folder_path,
        subfolder_list,
        formatted_file_summaries,
        formatted_file_services,
        formatted_subfolder_summaries,
        formatted_subfolder_services,
        formatted_subfolder_features
    ):
    
    system_prompt = f"""
        You are an expert code analyst specialized in creating detailed, informative summaries of software project folders. Your task is to thoroughly analyze files and subfolders to provide a comprehensive understanding of the application or project and provide combined summaries along with required details. These summaries must be detailled enough for further summarization.

        Follow these guidelines:
        1. Conduct a deep analysis of the features to identify its core purpose and functionality
        2. Provide detailed explanation of key implementations and technical approaches of the features
        3. Thoroughly examine the summaries based on files and folders to understand relationship between features and combined smaller features into larger high level application level features.
        4. Explain the features within the broader project architecture with specific connections
        5. Describe technical patterns, design decisions, and architectural choices evident in the code
        6. Include specific functions, classes, and methods that define the feature's behavior
        7. Note dependencies, imports, and external connections that shape the folder's functionality
        8. Identify potential architectural strengths and areas for improvement when evident
        9. Identify all services represented in this folder based on file and subfolder services information
        10. Identify and articulate high-level features or functionalities represented by the folder into the feature_details section, when consolidating multiple subfolders or lower-level files. Derive these insights from both file-level and subfolder-level summaries. Also under each feature, mention which file/folder was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
        11. Do not miss any features that could be formed based on these summaries as this information is required to understand the application's buisness logic.
        12. Gather insights from the summaries provided to generate a high level detailled executive summary that could be used by business stakeholders to understand the folder/project.
        13. When analyzing the root folder, both the executive summary and the features must be strictly formed in a high level business logic standpoint of an application.
        
        IMPORTANT: 
        - Your summary should be thorough and detailed({total_allocated_tokens}) while maintaining technical/business precision and depth. Focus on providing insights that would help both stakeholders and developers understand the application better.
        - feature_details must contain high level feature name and feature description(value of the files/folders) strictly in concise bullet points. The feature inforamtion must be in detail to capture the complete high level knowledge for that feature but not the function level details. Feature names cannot be programmatic function names like Dependency management, json handling etc. instead it should be inventory management, order processing etc. 
        - Your services list should be comprehensive and include all services represented in this folder.
        - is_reuasble_lib if a folder is used as reusable lib make it True otherwise False
        - lib_name if is_reusable_lib is True then provide the name of the reusable lib/component If is_reusable_lib False then add Not Applicable
        - category if is_reusable_lib is True then provide category only between 'Frontend' and 'Backend' If is_reusable_lib False then add Not Applicable
        - sub_category if is_reusable_lib is True then provide sub category only between 'UI Component','Custom Hooks', 'http_client', 'Utils', 'Others' In Frontend & 'Middleware', 'Error Handling', 'Auth', 'Utils', 'Others' In Backend If is_reusable_lib False then add Not Applicable
        - when_to_use if is_reusable_lib is True then provide where this reusable lib/component can be used If is_reusable_lib False then add Not Applicable 
        - associated_files if is_reusable_lib is True then provide the list of files associated(give complete path for the assosciated file) with this reusable lib/component If is_reusable_lib False then add Not Applicable
        - summary must not be technical and only explain the high level details of the folder/project. Understand the file and folder summaries provided to combine the knowledge to form the executive summary. Make it as detailled as possible.
        - Use clear and concise language, avoiding jargon where possible.
        
        - You must provide your response in this exact format:
        ```summary
        [Your detailled high-level executive summary for the folder for business stakeholders]
        ```
        ```feature_details
        [List of high-level features or functionalities represented in this folder]
        ```
        ```services_namess
        [Comma-separated list of all services represented in this folder]
        ```
        ```is_reuasble_lib
        Boolean Value
        ```
        ```lib_name
        [Name of the reusable library if applicable]
        ```
        ```category
        [Category of the reusable library if applicable]
        ```
        ```sub_category
            [Sub category of the reusable library if applicable]
        ```
        ```when_to_use
        [Your detailed use case where or when this reuasble_lib can be usefull]
        ```
        ```associated_files
            [Comma-separated list of associated files with the reusable library, Give the Complete file path as mentioned in the file list]
        ```
        ```example_usage
            [Example code snippet of how to use this reusable library]
        ```
    """

    user_prompt = f"""
        Generate a summary and services list for the folder: "{folder_name}" (Path: {folder_path})

        FOLDER CONTENTS:
        - Files ({len(file_list)}): {", ".join(file_list) if file_list else "None"}
        - Subfolders ({len(subfolder_list)}): {", ".join(subfolder_list) if subfolder_list else "None"}

        FILE SUMMARIES:
        {os.linesep.join(formatted_file_summaries) if formatted_file_summaries else "No file summaries available"}

        FILE SERVICES:
        {os.linesep.join(formatted_file_services) if formatted_file_services else "No file services available"}

        SUBFOLDER SUMMARIES:
        {os.linesep.join(formatted_subfolder_summaries) if formatted_subfolder_summaries else "No subfolder summaries available"}

        SUBFOLDER SERVICES:
        {os.linesep.join(formatted_subfolder_services) if formatted_subfolder_services else "No subfolder services available"}

        SUBFOLDER FEATURES:
        {os.linesep.join(formatted_subfolder_features) if formatted_subfolder_features else "No subfolder features available"}
        
        Based on these components:
        1. Provide a thorough technical summary explaining the folder's purpose, implementation details, and architectural significance
        2. Compile a comprehensive list of all services represented in this folder based on file and subfolder services information
        
        Follow the exact format specified in the system instructions for your response.
    """

    return system_prompt, user_prompt

def services_generation():
    system_prompt = """
        <Task>
        Create an architectural blueprint of the given repository by identifying and classifying both external services and third-party services with no overlap between categories.
        </Task>

        <Definitions>
        - External services: Company-provided services hosted outside the application (AWS S3, Google Cloud, Stripe, Twilio)
        - Third-party services: Libraries, frameworks, and SDKs that are part of the core application stack (Django, React, MongoDB, Redux)
        </Definitions>

        <Output_Format>
        {
        "external_services": [
            {
            "external_service_name": "string",
            "description": "string",
            "associated_files": ["string"],
            "service_class": "string",
            "used_in_files": ["string"]
            }
        ],
        "thirdparty_services": [
            {
            "thirdparty_service_name": "string",
            "description": "string",
            "associated_files": ["string"],
            "service_class": "string",
            "used_in_files": ["string"]
            }
        ]
        }
        </Output_Format>

        <Instructions>
        1. Conduct a thorough repository analysis to identify all services
        2. Classify each service into exactly ONE category:
        - External services: Cloud platforms, payment processors, authentication providers
        - Third-party services: Frameworks, libraries, SDKs integrated into the codebase
        3. For each service, provide:
        - Name: Exact service name
        - Description: Concise explanation of functionality and purpose
        - Associated files: All files directly importing or using the service
        - Service class: Category (e.g., "cloud storage", "web framework", "database")
        - Used in files: Complete paths of files utilizing the service
        4. Ensure ZERO overlap between categories
        5. Prioritize accuracy over comprehensiveness
        6. Validate that identified services are actively used in the project
        7. Include only services with clear evidence of implementation
        8. Do not create a lot of services which are redundant. Keep it to a maximum of 50 services only.
        </Instructions>

        <Examples>
        Good External Service Entry:
        {
        "external_service_name": "AWS S3",
        "description": "Cloud storage service used for storing user-uploaded files",
        "associated_files": ["src/services/storage.js", "src/config/aws.js"],
        "service_class": "cloud storage",
        "used_in_files": ["src/components/FileUpload.js", "src/pages/UserProfile.js"]
        }

        Good Third-Party Service Entry:
        {
        "thirdparty_service_name": "React",
        "description": "Frontend JavaScript library for building user interfaces",
        "associated_files": ["package.json", "src/index.js"],
        "service_class": "frontend framework",
        "used_in_files": ["src/App.js", "src/components/*.js"]
        }
        </Examples>

        Analyze the repository and provide the complete architectural blueprint in the specified format.
    """

    user_prompt = ""

    return system_prompt, user_prompt

def executive_summary_generation(combined_summary, user_mvf):
    system_prompt = """
    Your Role:
    You are an expert software architect tasked with understanding a codebase and creating an executive summary that clearly articulates the main purpose of this application,
    the core problem that the application is solving, and the prioritized list of the most valuable features, solely based on the provided folder wise summary. Do not hallucinate and create the most valuable features and its description on assumption. This needs to be based on facts.

    Task:
    1. Analyze provided folder wise summary and the services used and the user defined features (if provided).
    2. Understand component interactions and functions.
    3. Prioritize the User Defined Features (if provided) in the summary.
    4. Identify and prioritize the most valuable features based on their importance and relevance to the overall project, as evidenced in the code.
    5. Create a comprehensive executive summary.

    Steps:
    1. Review folder wise summary.
    2. Analyze folder wise summary:
    - Identify key components and their roles
    - Note data operations, design patterns, and architectural decisions
    3. Create summary:
    - Describe the specific problem the codebase solves, based on folder wise summary
    - Explain component interactions
    - Outline data workflow
    4. Identify and prioritize main features:
    - Determine which feature(s) address the core problem of the application, based on code implementation
    - Rank features based on their importance and relevance to solving the main problem, as evidenced in the code
    - The feature should be major components of the codebase and not minor functions like "Modular Architecture" or "Code Reusability", these are not features but design principles.

    Focus Areas:
    - Precised feature prioritization and importance
    - High-level functionality
    - Clear, concise technical language
    - Objective description
    - Capture entire workflow

    Guidelines:
    - Only use the folder wise summary provided
    - Use precise technical terms
    - Include user-defined features if provided and evidenced in the code
    - Prioritize features based on their importance to the core problem, as shown in the folder wise summary

    Feature Identification and Prioritization:
    - Carefully analyze the folder wise summary to identify features actually present in the folder wise summary
    - Do not assume or infer features that are not explicitly mentioned in the folder wise summary
    - Identify the top feature that solves the majority of the problem based on code evidence
    - Rank subsequent features in descending order of importance, ensuring they are present in the folder wise summary
    - Ensure the feature list reflects the codebase's focus and structure
    - Only include features that have substantial implementation in the codebase that is evident from folder wise summary

    Output Format - Adhering to this format is crucial
    ```json
    {
    "data": "generated_summary in string format adhering to the Expected Output Format for Generated Summary",
    "confidence_score": 90,
    "traceback": {
    "Feature 1 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 1 Title' is included, as the 'phrase' is an evidence that this feature is part of the codebase.",
    "Feature 2 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 2 Title' is included, as the 'phrase' is an evidence that this feature is part of the codebase.",
    ...
    }
    }
    ```

    Requirements:
    - Replace \n with \\n in JSON
    - Limit upto 5 main features (max 2 sub-features each) or 7500 tokens
    - If due to any reason such as codebase being small, you are unable to provide 5 features, then provide as many high-level features as possible between the range of 1 to 5.
    - Don't assume features or include minor features due to inability to provide 5 features, lesser number of features is acceptable.
    - Use specified JSON format only
    - Start with "```json" and end with "```"
    - Ensure the top feature in the prioritized list addresses the core problem and is present in the folder wise summary
    - Rank features in descending order of importance to the main problem, based on actual code implementation
    - Do NOT include features that are NOT evidenced in the provided folder wise summary
    - Evaluate the folder wise summary objectively, considering all conclusions on the actual code provided
    - Do NOT make any assumptions about organizational goals or intentions beyond what is explicitly shown in the code
    - Focus solely on the technical aspects and implemented functionality, avoiding speculation about business objectives or future plans
    - Both the keys data, confidence score, and traceback should be present in the output JSON
    - The generated summary should be in string format only and be contained inside the "data" key
    - The "traceback" key should contain a dictionary with feature names as keys and justifications for including these features based on exact phrases from the input
    - Do not include any feature that could potentially be part of the folder wise summary without explicit evidence
    - Every feature mentioned must be driven by clear evidence from the provided input
    """
    user_prompt = """
    Expected Output Format for Generated Summary:

  **Overview**
  <empty line>
  <A brief introduction to the codebase and its main purpose; in paragraph format only, not in points.
  This paragraph should provide a concise yet comprehensive overview of the codebase, its primary functionality, solution provided by the project and its intended use case.
  Aim for 3-5 sentences that capture the essence of the project.>
  <empty line>
  **Highlighted Features**
  <empty line>
  <
  List and briefly explain the key features that are significant components of the codebase and would serve as selling points.
  These features should be presented as follows:
  1. Use numbered points for each feature.
  2. Provide a brief explanation for each feature in 1-2 sentences, highlighting its importance and benefit to the end user.
  3. Focus on features that are central to the codebase's functionality and most important to the end user.
  4. Dont include generic features like "Modular Architecture" or "Code Reusability", these are not features but design principles.
  5. Do not include sub-points under any feature.
  6. Prioritize User Defined Features (if provided) at the beginning of the list.
  7. If User Defined Features are given, list them first before including any features identified through your analysis.
  8. Aim to provide upto of 1 to 5 key features, after each feature add an empty line for formatting purposes.
  9. Ensure that the features listed represent the core functionality and unique selling points based on the folder wise summary.
  10. Use clear, concise language that emphasizes the value proposition of each feature.
  11. Also under each feature, mention which file/folder was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
  12. Do not add features into Highlighted Features if they dont have value for buisness stakeholder about the application. Also do not repeat adding similar feature in this section.

  Output Structure:
  1. ***<Feature 1 Title>***: <Description of the feature in one to two sentences.\n
  2. ***<Feature 2 Title>***: <Description of the feature in one to two sentences.>\n
  >
  <empty line>
  **Key Benefits**
  <empty line>
  <Summarize the key benefits of the codebase in one to two sentences.
  This summary should encapsulate the overall value proposition of the codebase and its potential impact on users or the organization.>
  <empty line>
  <Highlight the most significant key benefits the codebase has to offer in bulleted points. The format should be:
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  Aim for 3-5 bullet points that capture the most compelling advantages of using this codebase, after each point add an empty line for formatting purposes.
  Each benefit should be distinct and provide a clear value proposition.>

  <Final Output Format>
  Output Format - Adhering to this format is crucial, the output should be in parsable JSON format:
  ```json
  {{
    "data": "<generated_summary in string format adhering to the Expected Output Format for Generated Summary>",
    "confidence_score": 90,
    "traceback": {{
      "Feature 1 Title": "Since it mentions about <exact phrase from the folder wise summary>, the 'Feature 1 Title' is included, as the "phrase" is an evidence that this feature is part of the folder wise summary.",
      "Feature 2 Title": "Since it mentions about <exact phrase from the folder wise summary>, the 'Feature 2 Title' is included, as the "phrase" is an evidence that this feature is part of the folder wise summary.",
      ...
    }}
  }}
  ```
  </Final Output Format>
  Note: If the traceback includes phrases that are not present in the folder wise summary then you would be penalized 10000 points.
  The output should be having data, confidence score, and traceback keys, and the entire content inside "```json" and "```" should be parsable by json.
  The "data" key should contain the generated summary and it should be in string format only, allowing the parsing of the entire json.
  If there are any inverted commas inside the generated summary, then escape them with a backslash.
  Do not change or skip the headings of each section in the generated json. The generated summary must have "Overview", "Highlighted Features", "Key Benefits" as section titles. Follow the above provided guidelines."""
    user_prompt += f"""Use the below folder wise summary to generate the summary in the above format: {combined_summary}""" + "User Defined Features : " + str(user_mvf)
    return system_prompt, user_prompt

def db_executive_summary_generation(combined_summary, user_mvf): 
    system_prompt = """
    Role:
    You are an expert Database Architect tasked with understanding the contents of all tables and schema of the database. 
    You shall Articulate a proper executive summary that clearly captures all the main & high-level features of this database.
    The core use-case that this database is intended for, and the prioritized list of the most valuable features, solely based on the provided Table-Level summaries. 
    Do not hallucinate. Do NOT create the most valuable features and its description on pure assumptions. This needs to be based on facts, with proper backing.

    Task:
    1. Analyze provided Table wise summaries.
    2. Understand component interactions and functions.
    3. Prioritize the User Defined Features (if provided) in the summary.
    4. Identify and prioritize the most valuable features based on their importance to the core use-case the Database is solving.
    5. Create a comprehensive executive summary.

    Steps:
    1. Review Table wise summary.
    2. Analyze Table wise summary:
      - Identify all tables. 
      - Take into consideration the foreign keys, primary keys, is-a, has-a, and many-to-many relationships.
      - Deeply understand the intended-use-case of each table.
      - Note data operations, design patterns, and architectural decisions
    3. Create summary:
      - Describe the specific problem the Database is solving, based on Table wise summary
      - Explain high-level interactions and dependencies
      - Outline data workflow
    4. Identify and prioritize main features:
      - Determine which feature(s) address the core problem of the Database, based on SQL implementation and Table wise summary
      - Rank features based on their importance and relevance to solving the main problem, as evidenced in the Database
      - The feature should be major components of the Database and not minor functions like Many-to-Many Relationships, or "Foreign Keys". 
        These are implementation concepts. Not core features.

    Focus Areas:
    - Precised feature prioritization and importance
    - High-level functionality of this Database
    - Clear, concise technical language with Database-specific Language
    - Objective description
    - Capture entire data workflow

    Guidelines:
    - Only use the Table wise summary provided
    - Use precise Database-relevant technical terms
    - Include user-defined features if provided and evidenced in the Table wise summary
    - Prioritize features based on their importance to the core problem, as shown in the Table wise summary

    Feature Identification and Prioritization:
    - Carefully analyze the Table wise summary to identify features actually present in the Table wise summary
    - Do not assume or infer features that are not explicitly mentioned in the Table wise summary
    - Identify the top feature that solves the majority of the problem based on Database and SQL evidence
    - Rank subsequent features in descending order of importance, ensuring they are present in the Table wise summary
    - Ensure the feature list reflects the Database's focus and structure
    - Only include features that have substantial implementation in the Database that is evident from Table wise summary

    Output Format - Adhering to this format is crucial
    ```json
    {
    "data": "generated_summary in string format adhering to the Expected Output Format for Generated Summary",
    "confidence_score": 90,
    "traceback": {
    "Feature 1 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 1 Title' is included, as the 'phrase' is an evidence that this feature is part of the Database.",
    "Feature 2 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 2 Title' is included, as the 'phrase' is an evidence that this feature is part of the Database.",
    ...
    }
    }
    ```

    Requirements:
    - Replace \n with \\n in JSON
    - Limit upto 5 main features (max 2 sub-features each) or 7500 tokens
    - If due to any reason such as Database being small, you are unable to provide 5 features, then provide as many high-level features as possible between the range of 1 to 5.
    - Don't assume features or include minor features due to inability to provide 5 features, lesser number of features is acceptable.
    - Use specified JSON format only
    - Start with "```json" and end with "```"
    - Ensure the top feature in the prioritized list addresses the core problem and is present in the Table wise summary
    - Rank features in descending order of importance to the main problem, based on actual Database and SQL implementation
    - Do NOT include features that are NOT evidenced in the provided Table wise summary
    - Evaluate the Table wise summary objectively, considering all conclusions on the actual Database and SQL provided
    - Do NOT make any assumptions about organizational goals or intentions beyond what is explicitly shown in the Database and SQL
    - Focus solely on the technical aspects and implemented functionality, avoiding speculation about business objectives or future plans
    - Both the keys data, confidence score, and traceback should be present in the output JSON
    - The generated summary should be in string format only and be contained inside the "data" key
    - The "traceback" key should contain a dictionary with feature names as keys and justifications for including these features based on exact phrases from the input
    - Do not include any feature that could potentially be part of the Table wise summary without explicit evidence
    - Every feature mentioned must be driven by clear evidence from the provided input.
    - Strictly use an assertive and objective tone in your response. 
    - Do not be unsure about anything.
    - Do not include the "Folder Name" in your response. Ignore "dbanalysis" folder. Provide Executive Summary of the Database-ONLY.
    """

    user_prompt = """
  Expected Output Format for Generated Summary:

  **Overview**
  <empty line>
  <A brief introduction to the Database and its main purpose; in paragraph format only, not in points.
  This paragraph should provide a concise yet comprehensive overview of the Database, its primary functionality, and its intended use case.
  Aim for 3-5 sentences that capture the essence of the Database.>
  <empty line>
  **Highlighted Features**
  <empty line>
  <
  List and briefly explain the key features that are significant components of the Database and would serve as selling points.
  These features should be presented as follows:
  1. Use numbered points for each feature.
  2. Provide a brief explanation for each feature in 1-2 sentences, highlighting its importance and benefit to the END USER.
  3. Focus on features that are central to the Database's functionality and most important to the END USER.
  4. Dont include generic features like  Many-to-Many Relationships, or "Foreign Keys", these are not features but Design Principles.
  5. Do not include sub-points under any feature.
  6. Prioritize User Defined Features (if provided) at the beginning of the list.
  7. If User Defined Features are given, list them first before including any features identified through your analysis.
  8. Aim to provide upto of 1 to 5 key features, after each feature add an empty line for formatting purposes.
  9. Ensure that the features listed represent the core functionality and unique selling points based on the Table wise summary.
  10. Use clear, concise language that emphasizes the value proposition of each feature.
  11. Also under each feature, mention which file/Table was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
  12. Do not add features into Highlighted Features if they dont have value for buisness stakeholder about the application. Also do not repeat adding similar feature in this section.

  Output Structure:
  1. ***<Feature 1 Title>***: <Description of the feature in one to two sentences.\n
  2. ***<Feature 2 Title>***: <Description of the feature in one to two sentences.>\n
  >
  <empty line>
  **Key Benefits**
  <empty line>
  <Summarize the key benefits of the Database in one to two sentences.
  This summary should encapsulate the overall value proposition of the Database and its potential impact on users or the organization.>
  <empty line>
  <Highlight the most significant key benefits the Database has to offer in bulleted points. The format should be:
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  Aim for 3-5 bullet points that capture the most compelling advantages of using this Database, after each point add an empty line for formatting purposes.
  Each benefit should be distinct and provide a clear value proposition.>

  <Final Output Format>
  Output Format - Adhering to this format is crucial, the output should be in parsable JSON format:
  ```json
  {{
    "data": "<generated_summary in string format adhering to the Expected Output Format for Generated Summary>",
    "confidence_score": 90,
    "traceback": {{
      "Feature 1 Title": "Since it mentions about <exact phrase from the Table wise summary>, the 'Feature 1 Title' is included, as the "phrase" is an evidence that this feature is part of the Table wise summary.",
      "Feature 2 Title": "Since it mentions about <exact phrase from the Table wise summary>, the 'Feature 2 Title' is included, as the "phrase" is an evidence that this feature is part of the Table wise summary.",
      ...
    }}
  }}
  ```
  </Final Output Format>
  Note: If the traceback includes phrases that are not present in the Table wise summary then you would be penalized 10000 points.
  The output should be having data, confidence score, and traceback keys, and the entire content inside "```json" and "```" should be parsable by json.
  The "data" key should contain the generated summary and it should be in string format only, allowing the parsing of the entire json.
  If there are any inverted commas inside the generated summary, then escape them with a backslash.
  Do not change or skip the headings of each section in the generated json. The generated summary must have "Overview", "Highlighted Features", "Key Benefits" as section titles. Follow the above provided guidelines.
    """

    user_prompt += f"""Use the below Table wise summary to generate the summary in the above format: {combined_summary}""" + "User Defined Features : " + str(user_mvf)

    return system_prompt, user_prompt


def architecture_diagram_generation(services_data, icons_metadata):
    user_prompt = f"""
    <Input>
    $services_data = {services_data}
    $icons_metadata
    </Input>

    <Role>
    You are an expert at understanding large projects based on their executive summary and the services being used in them. Create a JSON structure for a ReactFlow diagram based on the given service class JSON.
    </Role>

    <Output Structure>
    1. Create a JSON object with a "nodes" and "edges" array.
    2. Create nodes for each external and third-party service.
    3. "nodes": An array containing all node objects.
      - "id": A unique string identifier for the node.
      - "data":   
        - "label": The name of the node.
        - "description": Description of the service.
        - "associated_files": Associated file and used in files in the service node, defaulting to "No File Available" if not present.
        - "group": The logical group name (e.g., 'Backend', 'Frontend', 'Database',etc..).
        - "subgroup": The specific subgroup within the group (e.g., Frameworks, NoSQL Databases, State Management, etc.).
        - "service": The appropriate filename of the icon based on the $icons_metadata.
      - "position" : The x and y coordinates of the node.
      - "type" : "customNode" This should be fixed.
    4. "edges" : An array having id, source, target, label, and type should be customEdge always.
    4. Ensure all services and files from the input JSON are included.
    5. The output should be in the form of a dictionary containing a "nodes" and "edges" array.
    6. Present only the code inside delimiters "```reactflow [reactflow CODE]```" without any additional explanation.
    """

    system_prompt:str = """
    <Task>
      You are tasked with creating a JSON structure for a ReactFlow diagram based on the given executive summary and the service_class_json. The executive summary contains an overview of the entire project. This JSON includes information about external services and third-party services, along with their associated files. Your output should represent this information as a network of nodes and edges.
    </Task>
    
    <Icons Context>
      $icons_metadata = """ + str(icons_metadata) + """
    </Icons Context>

    <Instructions>
      You are a solution expert, specializing in problem and solution flows. You will be given the solution overview for a project, and your task is to create an interconnected single component of graph which is detailed, and intuitive and self explanatory for:

      Follow these guidelines:
      1. Create nodes for each unique service (both external and third-party).
      2. Do not create any group nodes.
      4. In the data key for each service node, include two additional fields called group and subgroup. The group field should contain the logical group name (e.g., Frontend, Backend, Databases, etc..), and the subgroup field should provide more specific categorization (e.g., Frameworks, NoSQL Databases, etc..). For example, for a service node representing React, the group would be Frontend and the subgroup would be Frameworks.
      5. For each node, check which icon will be the most suitable from the $icons_metadata in the <Icons Context>
      6. Ensure all information from the input is represented in the output.
      7. The position coordinates must be proper for all the nodes.
    </Instructions>

    <Rules>
      **Ensure all nodes in the generated graph are interconnected such that every node has at least one edge, forming a single connected component without any isolated or disjoint sections. (High Priority Requirement)**
      Important Rules to be followed:
      1. Give detailed technical architecture flow and the JSON object following the below output format.
      2. Make sure that the flow and order of new solution approach is explained well in the graph with appropriate edges. Use as many edges you want to describe the data and user flow properly.
      3. The whole user and data flow should be clear.
      4. Do not add unnecessary nodes and edges. Do not create duplicate nodes that perform same task.
      5. Make the Node descriptions detailed, breaking tasks into multiple sub-tasks if needed.
      6. Ensure your edges show the actual flow, and not just connections of what's related. The connections are meant to show the logical flow, and not the relatedness/similarity.
      7. The group name is meant to classify clusters of nodes within each graph. For instance, if we have multiple nodes in features, they would all have "feature" as group. In Architecture Flow, the "Group" should show the layer each node is in, for instance "Backend Layer", "Database Layer" etc.
      9. for a hierarchy of nodes A -> B -> C; ensure that there is not a connection between A -> C.
    </Rules>
    
    <output_format>
    The output should be in between the delimeters ```reactflow and ```. Only provide the json output. Don't give unnecesary explanation.
    ```reactflow
    {
      "nodes": [
        { 
          "id": "unique_node_identifier_string",
          "data" : {
            "label": "name_of_the_service",
            "description": "description of the service",
            "associated_files": ["file_path_1", "file_path_2", "file_path_3", etc.],  // (default: ["No File Available"] if not present)
            "group": "name_of_group",  // Add the logical group name (e.g., "Frontend", "Backend", etc..)
            "subgroup": "name_of_subgroup",  // Add a more specific subgroup name (e.g., "Frameworks", "NoSQL Databases", etc..)
            "service": "filename" //taken from the $icons_metadata,
          }
          "position":{ "x": "Xcoordinate", "y": "Ycoordinate" },
          "type" : "customNode" //this is hardcoded and will be constant
        }
      ],
      "edges": [
        {
          "id": "unique_egde_identifier_string",
          "source": "label A",
          "target": "label B",
          "label": "Showcase what comes from the source node, to the target node. Be concise and specific with labels, such as 'Ingested Data', 'Converted Text', 'User Query' etc. Use at max 5 words",
          "type" : "customEdge" //this is hardcoded and will be constant
        }
      ]
    }```
    </output_format>
    """
    return system_prompt, user_prompt
  

def erd_generation(services_data, icons_metadata):
  tables_metadata = []
  for entry in services_data:
      table_name = entry["table_name"]
      ddl = entry["ddl"]
      columns, primary_keys, foreign_keys = parse_ddl(ddl)
      tables_metadata.append({
          "table_name": table_name,
          "columns": columns,
          "primary_keys": primary_keys,
          "foreign_keys": foreign_keys
      })

  dot = generate_combined_graph(tables_metadata)

  system_prompt:str = """
    You are tasked with creating a JSON structure for a ReactFlow diagram based on the given database ER diagram and schema JSON. This JSON includes information about database columns and their relationships.Your output should represent this information as a network of nodes and edges.
    </Task>
    
    <Icons Context>
      $icons_metadata = """ + str(icons_metadata) + """
    </Icons Context>

    <Instructions>
      You are a solution expert, specializing in problem and solution flows. You will be given the database schema information of a database, and your task is to create an interconnected single component of graph which is detailed, and intuitive and self explanatory for:

      Follow these guidelines:
      1. Create nodes for each unique service (both external and third-party).
      2. Do not create any group nodes.
      4. In the data key for each service node, include two additional fields called group and subgroup. The group field should contain the logical group name (e.g.,Databases, etc..), and the subgroup field should provide more specific categorization (e.g., 'Transactional Tables', 'Reference Tables' etc..). For example, for a service node representing daily transactions, the group would be Database and the subgroup would be Transactional Tables.
      5. For each node, check which icon will be the most suitable from the $icons_metadata in the <Icons Context>
      6. Ensure all information from the input is represented in the output.
      7. The position coordinates must be proper for all the nodes.
    </Instructions>

    <Rules>
      Important Rules to be followed:
      1. Give detailed technical architecture flow and the JSON object following the below output format.
      2. Make sure that the flow and order of new solution approach is explained well in the graph with appropriate edges. Use as many edges you want to describe the data and user flow properly.
      3. The whole user and data flow should be clear.
      4. Do not add unnecessary nodes and edges. Do not create duplicate nodes that perform same task.
      5. Make the Node descriptions detailed, breaking tasks into multiple sub-tasks if needed.
      6. Ensure your edges show the actual flow, and not just connections of what's related. The connections are meant to show the logical flow, and not the relatedness/similarity.
      7. The group name is meant to classify clusters of nodes within each graph. For instance, if we have multiple nodes in features, they would all have "feature" as group. In Architecture Flow, the "Group" should show the layer each node is in, for instance "Database Layer" etc.
      9. for a hierarchy of nodes A -> B -> C; ensure that there is not a connection between A -> C.
    </Rules>
    
    <output_format>
    The output should be in between the delimeters ```reactflow and ```. Only provide the json output. Don't give unnecesary explanation.
    ```reactflow
    {
      "nodes": [
        { 
          "id": "unique_node_identifier_string",
          "data" : {
            "label": "name_of_the_table",
            "description": "description of the table",
  	    "columns": ["order_id [PK]", "product_sku [PK]", "quantity", "unit_price"]
            "group": "name_of_group",  // Add the logical group name (e.g., "Database", etc..)
            "subgroup": "name_of_subgroup",  // Add a more specific subgroup name (e.g., 'Transactional Tables', 'Reference Tables', etc..)
            "service": "filename" //taken from the $icons_metadata,
          }
          "position":{ "x": "Xcoordinate", "y": "Ycoordinate" },
          "type" : "customNode" //this is hardcoded and will be constant
        }
      ],
      "edges": [
        {
          "id": "unique_egde_identifier_string",
          "source": "label A",
          "target": "label B",
          "label": "Showcase what comes from the source node, to the target node. Be concise and specific with labels, such as 'Ingested Data', 'Converted Text', 'User Query' etc. Use at max 5 words",
          "type" : "customEdge" //this is hardcoded and will be constant
        }
      ]
    }```
    </output_format>
    """
    
  user_prompt:str = f"""
    <Input>
    $database_tables = {dot}
    $icons_metadata
    </Input>

    <Role>
    You are an expert at understanding database architecture based on ER diagrams and relational structures. Create a JSON structure for a ReactFlow diagram based on the given database schema.
    </Role>
    <Output Structure>
      1. Create a JSON object with a "nodes" and "edges" array.
      2. Create nodes for each table in the schema.
      3. "nodes": An array containing all node objects.
      - "id": A unique string identifier for the node.
      - "data":  
        - "label": The name of the table.
        - "description": A brief summary of the table's role or content.
        - "columns": List of column names (mark primary keys with [PK], foreign keys with [FK]).
        - "group": The logical group name (e.g., 'Database').
        - "subgroup": The specific subgroup within the group (e.g., 'Transactional Tables', 'Reference Tables').
        - "service": The appropriate filename of the icon based on the $icons_metadata.
      - "position" : The x and y coordinates of the node.
      - "type" : "customNode" This should be fixed.
      4. "edges" : An array having id, source, target, label, and type should be customEdge always.
      5. The label of the edge should describe the relationship, like "order_id â†’ order_id". 
      6. The output should be in the form of a dictionary containing a "nodes" and "edges" array.
      7. Present only the code inside delimiters "```reactflow [reactflow CODE]```" without any additional explanation.
    """
    
  return system_prompt, user_prompt
    

def feature_summary_generation(formatted_data, user_mvf, executive_summary):
    # if input_type is None:
    #     formatted_data = file_summary_list
    # elif input_type == "batch_summary":
    #     formatted_data = format_batchwise_summary_metadata_for_services(file_summary_list)
    # else:
    #     formatted_data = format_file_summaries(file_summary_list)

    user_prompt = """
    Role: You are an AI code analyst specializing in creating concise, feature-level summaries of codebases.

    Objective: Provide a comprehensive yet concise feature-level summary of a given codebase, highlighting key components, functionality, and the project's overall workflow.

    Input: You will receive information about a codebase, which may include an executive summary or other project details.

    Steps:
    1. Analyze the provided codebase information.
    2. Identify the main features (maximum 5) of the project from the executive summary (if provided in same order)
    3. Create a summary following the specified format, including:
        a. An overview of the project
        b. A list of key features with brief descriptions
        c. A closure statement
    4. Self-evaluate the generated summary and assign a confidence score.
    5. Format the output as specified in the instructions.

    Output Format:
    ```json
    {
        "data": "generated_summary in string format adhering to the Detailed Instructions for Output Format",
        "confidence_score": 90
    }
    ```

    Detailed Instructions for Output Format:

    **Overview**
    <empty line>
    < 
        Summarize all features in 2-3 sentences, introducing the project and its purpose.
        Provide a 2-3 sentence summary of key benefits, highlighting core architecture and value proposition.
    >
    <empty line>
    **Key Features**
    <empty line>
    <   
        List a maximum of 5 main features.
        For each feature, provide up to 2 sub-points describing its functionality.
        Ensure clear explanation of how features interact and contribute to the project's goals.
        1. ***<Key Feature Title>*** : 
        * <Sub point 1 description>
        * <Sub point 2 description>
        <empty line>
    >
    <empty line>
    < 
        Summarize the overall impact and value proposition of the project in one sentence as a conclusion statement.
    >
    <empty line>
    
    -> Self-Evaluation:
        - Score the summary out of 100 based on clarity, precision, detail, knowledge, accuracy, technical correctness, and understanding of the data.

    -> Formatting Requirements:
        - Replace all newline characters (\n) with \\n in the JSON output.
        - Ensure the complete JSON is less than 7500 tokens.
        - Start the output with "```json" and end with "```".
        - If an executive summary is provided, use only the highlighted features from it.

    Example Output Structure:
    ```json
    {
        "data": "**Overview**\\n\\n[Project overview]\\n\\n[Benefits summary]\\n\\n**Key Features**\\n\\n1. *Feature 1*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n2. *Feature 2*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n[...continue for up to 5 features...]\\n\\n[Closure statement]",
        "confidence_score": 90
    }
    ```

    Remember: Adhere strictly to the output format and instructions to maintain consistency and accuracy in your summary.
    """

    user_prompt += "User Defined Features : " + str(user_mvf)

    system_prompt = f"""
        <role>
        You are an assistant to a Senior Software Engineer. You are very capable in reading and understanding huge codebases.
        There is no edge-case, no mistake, no functionality no matter how small goes unnoticed by you.
        You will be given a large codebase and be asked queries regarding it.
        </role>

        <Task>
        You will be given relevant files from a production codebase. The Senior Engineer will consult you to clear his doubts and ask for critical code-level and functionality level analysis of the same.
        <Important>
        1. You will be clear. Feel free to be descriptive but Avoid Jargon
        2. You shall perform critical analysis on the code before responding.
        3. Note that the codebase will be quite complex and have dependencies everywhere, be mindful of them all.
        4. Enclose code in (triple backticks)``` code ```
        </Important>
        </Task>

        Files from Codebase goes here :
        <Repo Structure>
        {formatted_data}
        </Repo Structure>
    """

    start_index = executive_summary.find("Highlighted Features")
    end_index = executive_summary.find("Key Benefits")

    if start_index != -1 and end_index != -1:
        executive_summary = executive_summary[start_index:end_index].strip()

    user_prompt += "Executive Summary : " + str(executive_summary)

    return system_prompt, user_prompt

def feature_summary_generation_db(formatted_data, user_mvf, executive_summary):
    # if input_type is None:
    #     formatted_data = file_summary_list
    # elif input_type == "batch_summary":
    #     formatted_data = format_batchwise_summary_metadata_for_services(file_summary_list)
    # else:
    #     formatted_data = format_file_summaries(file_summary_list)

    user_prompt = """
    Role: You are an AI Database Analyst specializing in creating concise, feature-level summaries of complex database schemas and architectures.

    Objective: Provide a comprehensive yet concise feature-level summary of a given database schema information, highlighting key components, entities, relationships, and the overall data architecture workflow.

    Input: You will receive information about a database design, which may include an executive summary or other schema-level details.

    Steps:
    1. Analyze the provided database schema information.
    2. Identify the main features (maximum 5) of the database from the executive summary (if provided in same order)
    3. Create a summary following the specified format, including:
        a. An overview of the database
        b. A list of key features with brief descriptions
        c. A closure statement
    4. Self-evaluate the generated summary and assign a confidence score.
    5. Format the output as specified in the instructions.

    Output Format:
    ```json
    {
        "data": "generated_summary in string format adhering to the Detailed Instructions for Output Format",
        "confidence_score": 90
    }
    ```

    Detailed Instructions for Output Format:

    **Overview**
    <empty line>
    < 
        Summarize all features in 2-3 sentences, introducing the database and its purpose.
        Provide a 2-3 sentence summary of key benefits, highlighting schema structure, normalization or denormalization logic, and value proposition in handling data.
    >
    <empty line>
    **Key Features**
    <empty line>
    <   
        List a maximum of 5 main features.
        For each feature, provide up to 2 sub-points describing its data handling, relationships, or optimization logic.
        Ensure clear explanation of how features contribute to performance, consistency, and data integrity.
        1. ***<Key Feature Title>*** : 
        * <Sub point 1 description>
        * <Sub point 2 description>
        <empty line>
    >
    <empty line>
    < 
        Summarize the overall impact and value proposition of the database in one sentence as a conclusion statement.
    >
    <empty line>
    
    -> Self-Evaluation:
        - Score the summary out of 100 based on clarity, precision, detail, knowledge, accuracy, technical correctness, and understanding of the schema information.

    -> Formatting Requirements:
        - Replace all newline characters (\n) with \\n in the JSON output.
        - Ensure the complete JSON is less than 7500 tokens.
        - Start the output with "```json" and end with "```".
        - If an executive summary is provided, use only the highlighted features from it.

    Example Output Structure:
    ```json
    {
        "data": "**Overview**\\n\\n[Database overview]\\n\\n[Benefits summary]\\n\\n**Key Features**\\n\\n1. *Feature 1*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n2. *Feature 2*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n[...continue for up to 5 features...]\\n\\n[Closure statement]",
        "confidence_score": 90
    }
    ```

    Remember: Adhere strictly to the output format and instructions to maintain consistency and accuracy in your summary.
    """

    user_prompt += "User Defined Features : " + str(user_mvf)

    system_prompt = f"""
        <role>
        You are an assistant to a Senior Data Architect. You are very capable in reading, analyzing, and understanding complex database schemas and data models.
        No entity, constraint, relationship, or optimization logic goes unnoticed by you.
        You will be given a comprehensive database structure or schema information and will be asked to analyze, explain, and summarize it at a structural and functional level.
        </role>

        <Task>
        You will be given relevant database schema files or DDL definitions. The Senior Data Architect will consult you to clear doubts and ask for critical schema-level and data model-level analysis.
        <Important>
        1. You will be clear. Feel free to be descriptive but Avoid Jargon
        2. Perform a critical and deep analysis of the schema and the information given before responding.
        3. The schema will often involve multiple tables, foreign keys, views, procedures, and indexing strategies â€” be mindful of their dependencies and relationships.
        4. Enclose code or schema in (triple backticks)``` code ```
        </Important>
        </Task>

        Files from Database schema goes here :
        <Database Structure>
        {formatted_data}
        </Database Structure>
    """

    start_index = executive_summary.find("Highlighted Features")
    end_index = executive_summary.find("Key Benefits")

    if start_index != -1 and end_index != -1:
        executive_summary = executive_summary[start_index:end_index].strip()

    user_prompt += "Executive Summary : " + str(executive_summary)

    return system_prompt, user_prompt


#FEATURE HIERARCHY:
generate_features_system_prompt = """
  <Role>
    You are a Software Architect with expertise in analyzing large summaries from code files of an application. 
    You can comprehend summaries from code files that are complex, production-grade and are written in various programming languages to generate most important features, their description and the subfeatures with their description belonging to the most important features along with the other relevant information requested below.
    
    You will follow 2 Events before responding : 
    1. Generation of Feature Hierarchy as given in "Output_Format".
    2. Critical Evaluation of Every Confidence Score.  
  </Role> 

    <Task 1>
    You are provided with multiple relative file paths and file-wise code summaries from a application codebase.
    1. Analyze the file summaries carefully, leveraging your expertise to deduce the frameworks, functionality, and features.
    2. Perform a critical assessment of the code's functionality and interdependencies before responding.
    3. The codebase is complex and likely contains dependencies across various modules. Be mindful of these.
    4. Analyse every file summary and assign the features and sub-features based on the information provided.
    5. Respond strictly in the structured JSON format provided below.
    6. In each sub-feature's 'file_path' array:
        - Set 'critical: true' ONLY for files that are CORE & NON-REPLACEABLE to the sub-feature's main functionality.
        - Set 'critical: false' for ALL supporting, secondary, or replaceable files  
        - Each sub-feature should have both true and false entries.
        - If unsure, default to false (be EXTREMELY selective with 'true')
        - Make sure each sub-feature atleast have one file as true.

    Explanation of the Output terms:
    Feature - Features are most valuable and high level features extracted from the list of summaries that are provided to you. 
    Feature description - Description of the features explaining the high level value and impact that it creates for the project. Define the Feature. The description should be crisp, precise, well formatted and must be between 2-3 lines.
    Subfeature - Subfeatures are micro most valuable features that are extracted from the list of summaries and belong to the Most related and similar Features.
    Subfeature description - Description of the subfeatures explaining the specific value, technical and non-technical functionalites that it provided to the project. Define the subfeature and also explain how its related to the feature. The description should be crisp, precise, well formatted and must be between 2-3 lines.
    
    Points to Remember:
    1. Do not extract any feature or subfeature where there are no reference/citations from the application summaries.
    2. The description must be precise, valuable, well-formatted and must be between 2-3 lines.
    3. The Feature titles should be precise, specific, self explanaible, independent and not have similar feature titles. The Feature titles should not be highly generalized.
    4. The SubFeatures titles should be precise, self explanaible and not have similar subfeature titles. The SubFeature titles should not be highly generalized.
    5. SubFeatures should not be very low level that it explains code functions, code process like 'Json handling', 'Reading csv', readME etc.
    6. If similar subfeatures are present, then group them under one common Feature itself. Do not create multuple Features for similar subfeatures.
    6. If Unit testing related summaries are found, then create that as another Feature named 'Unit Testing' and assign the specific testing subfeatures under this feature.
    </Task 1>

  <Task 2>
  You shall now Assign and Justify Confidence Scores for each feature.

  <Critical Evaluation of Confidence Scores> 

  <Evaluation MODE>
  - You will now Forget everything that was done beforehand and act as an unbiased judge.
  - $Project-Summaries-&-Paths (INPUT).
  </Evaluation MODE>
  <Important>
  Critically analyze every "Feature" and "SubFeature" based on the following metrics. 
  You shall generate a confidence score between 0-100 for each of the following :
  1. Is the "Feature" & "SubFeature" name accurate to its functionality ? (Accuracy)
  2. Does the "Feature" & "SubFeature" include files with an unrelated function ? (Feature Dilution Rate)
  3. Important : Does this "Feature" & "SubFeature" make sense given the Overall Purpose of the Application ? (Consistency)
  4. Are all the files in "Feature" & "SubFeature" included ? (Completeness)

  <Strict>
  1. You will now generate a list of 4 confidence scores between 0-100 for above criteria under "confidence_score" key.
  2. Based on above criteria, you shall provide a VERY BRIEF logical explanation (10-20 words) for Confidence Score under "confidence_score_justification" key.
  3. Make sure to mention the entire filepath without omitting the prefix.
  4. Make sure all the filepaths are present.
  <Important> STRICTLY Don't Comment on Missing Files. Don't Overestimate. Don't Underestimate.</Important> 
  </Strict>

  </Important>

  </Critical Evaluation of Confidence Scores> 
  </Step 2>


      <Output_Format>
    Return a response in JSON format. Do not include any extra information or explanations. Strictly DON'T deviate from mentioned KEYS.
    Example:
```json
[
  {
    "name": "User Authentication and Management",
    "feature_description": "Comprehensive user account system with secure login, registration, profile management, and role-based access control.",
    "feature_description_confidence_score": [95, 70, 100, 70],
    "sub_features": [
      {
        "name": "User Registration",
        "description": "Allows new users to create accounts by providing necessary information such as username, email, and password. Implements email verification, password strength checks, and duplicate account prevention. Stores user data securely in the database with password hashing.",
        "file_path": [
          {
            "module_name": "RegistrationController",
            "path": "Controllers/Account/RegistrationController.cs",
            "critical": true
          },
          {
            "module_name": "RegisterView",
            "path": "Views/Account/Register.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [75, 80, 85, 65],
        "sub_feature_confidence_score_justification": "No feature dilution, might have missed some file."
      },
      {
        "name": "User Login",
        "description": "Authenticates users using their credentials, creates and manages user sessions, and implements security measures such as login attempt limiting and two-factor authentication (2FA). Provides password reset functionality for forgotten passwords.",
        "file_path": [
          {
            "module_name": "LoginController",
            "path": "Controllers/Account/LoginController.cs",
            "critical": true
          },
          {
            "module_name": "LoginView",
            "path": "Views/Account/Login.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [80, 100, 80, 75],
        "sub_feature_confidence_score_justification": "High chance of missing files."
      }
    ],
    "feature_confidence_score_justification": "No feature dilution, duplication or missing files. Accurate Naming."
  },
  {
    "name": "Product Catalog Management",
    "feature_description": "Comprehensive system for managing product listings, categories, and inventory across the e-commerce platform.",
    "feature_description_confidence_score": [95, 65, 70, 80],
    "sub_features": [
      {
        "name": "Product CRUD Operations",
        "description": "Enables administrators to create, read, update, and delete product listings. Includes functionality for managing product details such as name, description, price, images, and inventory levels. Implements validation to ensure data integrity and consistency across the product catalog.",
        "file_path": [
          {
            "module_name": "ProductController",
            "path": "Controllers/ProductController.cs",
            "critical": true
          },
          {
            "module_name": "ProductView",
            "path": "Views/Product/Index.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [90, 85, 100, 70],
        "sub_feature_confidence_score_justification": "High confidence with no duplication or dilution."
      },
      {
        "name": "Category Management",
        "description": "Allows for the creation and management of product categories and subcategories. Implements a hierarchical structure for organizing products, enabling efficient navigation and filtering of the product catalog for both administrators and customers.",
        "file_path": [
          {
            "module_name": "CategoryController",
            "path": "Controllers/CategoryController.cs",
            "critical": true
          },
          {
            "module_name": "CategoryView",
            "path": "Views/Category/Index.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [85, 75, 90, 95],
        "sub_feature_confidence_score_justification": "High confidence without any duplication or dilution."
      }
    ],
    "feature_confidence_score_justification": "All files refer to single overall functionality. Might have missed some files."
  }
]
```
  </Output_Format>

"""

generate_features_user_message = """
<Strictly Remember>
1. As input you will be given a batch of `file_path` and `file_summary` from a production codebase. Keep it in mind that it could be a file from a very large repository with lot of inter-dependencies.
2. Understand all the file description first, then try to determine the feature, sub-features and their description. For **each file** it should have a feature or sub-features whenever the conditions are met.
3. The response should contain all the fields given in the example output format. The response should be strictly in json format.
4. The description of features/subfeatures must be in the length of 2-3 lines. The response should be structured and well-formatted.
5. Don't generate any additional explanation or description. Provide the structured response in json only.
</Strictly Remember>
  
<Input file wise summary>
{file_summary}
</Input file wise summary>
<Response>
"""

merge_features_in_hierarchy_user_prompt = """You are a software feature analyzer. Given a list of related features that have been clustered together, create a merged feature that encompasses all the functionality.

Features to merge:
{feature_list}

Generate a JSON response that includes:
1. A name for the merged feature representing accurate feature name. Do not mention its merged or unified or anything as such. The feature name should accurately represent a major funcationality of a repository.
2. A detailed description that covers all functionality
3. A confidence score (0-100) for the merge
4. A justification for the confidence score

Respond with a JSON object in the following format:
```json
{{
    "name": "Merged feature name",
    "description": "Comprehensive description",
    "confidence_score": 85,
    "confidence_justification": "Reason for the confidence score"
}}
```
Give only JSON and nothing else. Do not include any explanations or additional text outside the JSON block. Make sure to start with ```json and end with ``` only.
"""

mapping_names_for_merged_features_user_prompt = """  <Role>
    You are a smart AI cassistant with strong expertise in Software Engineering. You can understand complex, production-grade codebases written in various programming languages and summarize them effectively.
  </Role>
  <Task>
  You will be given a brief description of  features of a large codebase and your task is to generate a relevant feature name, brief description, and priority level.
  <Important>
   1. The feature name should be brief, relevant and should represent the entire description provided.
   2. Generate a relevant description which is basically a overall summary of the description provided.
   3. Assign a priority level (high, medium, low) based on the significance, importance and complexity of the feature to the overall system. 
  </important>
  </Task>
  <Example output>
  ```json
    {
        "name": <feature_name>, //string
        "feature_description": <feature_description>, //string
        "priority": <priority> //string (high, medium, or low)
    }
    ```
  </Example output>
  <Strictly Remember>
1. The feature name should be relevant and at the same time interpretable, easy to understand.
2. The feature description should represnt the entire description given for summarisation, it should be simple and easy to understant.
3. The priority should be one of: high, medium, or low.
4. The response should be strictly in json format specified above.
5. Strictly make sure Feature Description is not more than 200 words.
  </Strictly Remember>

<code summary>
The code summary is given below:
"""


reducing_sub_features_user_prompt = """
    You are a software feature consolidation expert. Your task is to merge similar sub-features into one comprehensive sub-feature.

    Here are the sub-features that need to be merged:
    {sub_features_list}

    For each sub-feature, we have:
    - Name: The sub-feature name
    - Description: The sub-feature description (if available)
    - Confidence Score: The confidence score (if available)

    Your output should be a JSON object containing:
    1. A unified sub-feature name that encompasses all the input sub-features
    2. A comprehensive description that covers all aspects of the input sub-features
    3. A confidence score (use the highest available from input sub-features)
    4. A justification for the confidence score

    Return the output in JSON format starting with ```json and ending with ```.

    Example output format:
    ```json
    {{
        "name": "Unified Sub-Feature Name",
        "description": "Comprehensive description covering all aspects",
        "sub_feature_confidence_score": 95,
        "sub_feature_confidence_score_justification": "Merged from similar sub-features with high semantic similarity"
    }}
    ```
    """


post_processing_feature_name_description_system_prompt="""
  <Role>
    You are a smart AI assistant with strong expertise in Software Engineering. You can understand complex, production-grade codebases written in various programming languages and summarize them effectively.
  </Role>
  <Task>
  You will be given a brief description of modules or features of a large codebase and your task is to generate a relevant feature name and brief description.
  <Important>
   1. The feature name should be brief, relevant and should represent the entire description provided.
   2. Generate a relevant description which is basically a overall summary of the description provided.
   3. Also generate a confidence score in a scale of 0 - 100.
  </important>
  </Task>
  <Example output>
  ```json
    {
        "name": <feature_name>,
        "feature_description_confidence_score": <score 0 - 100>,
        "feature_description": <feature_description>
    }```
  </Example output>"""

post_processing_feature_name_description_user_prompt = """<Strictly Remember>
1. The feature name should be relevant and at the same time interpretable, easy to understant.
2. The confidence score should represent the ability to summarise the description.
3. The feature description should represnt the entire description given for summarisation, it should be simple and easy to understant.
4. The response should be strictly in json format specified above.
</Strictly Remember>
<code summary>
The code summary is given below: \n
{feature_description}
</code_summary>
<response>
Your response in json goes here:
"""

merge_similar_features_system_prompt = """You are a solution architect. Your task is to carefully review each feature and its description, and combine them into a single high-level feature.

The final high-level features should represent what an end user would perceive, e.g., Messenger, Google Chat, Messaging, Reels, etc.

Based on the generated features provided, identify which features can be merged into a single high-level feature. 
Strictly output them in the following format:
{{ 
  <High-Level Feature Name 1>: [<Merged Feature 1>, <Merged Feature 2>, <Merged Feature 3>, ...],
  <High-Level Feature Name 2>: [<Merged Feature 1>, <Merged Feature 2>, <Merged Feature 3>, ...],
  ...
}}

INPUT:
Feature names and descriptions are provided in the format: 
[1. Feature name: <feature name> 
Feature description: <feature description>, 
2. ...]

{feature_texts}

MVFS:
{total_MVFs}

Points to remember:
1. While merging features and naming high-level features, always prefer names from the user-defined MVFs provided. All relevant features can be grouped under these high-level features.
2. If certain features do not fit under the user-defined MVFs, choose a better name than the existing one for the new high-level feature if necessary.
3. The names of the features being merged must remain exactly as provided in the INPUT section; do not modify them. Do not consider Feature description in Feature Names.
4. Follow the output structure strictly: high-level feature names as dictionary keys and merged features as values in list format.
5. If a feature is already a high-level feature, you do not need to forcibly merge it. If a feature seems to be function-level/low-level  features, merge them into a High-level feature.
6. Merge similar features into a single high-level feature based on their names and descriptions, when applicable. Each final high-level feature should be independent of the others.
7. Do not assign the same feature to multiple high-level features.
8. If user-defined MVFs are empty, skip point 1 and begin with point 2.
9. Do **not** include any Feature descriptions in the final output."""


merging_description_user_prompt = """You are a Solution Architect. Your task is to summarize the multiple feature descriptions provided into a brief, coherent summary of **no more than two sentences**.

  The summary must:
  - Accurately capture all key components from the provided descriptions.
  - Align clearly with the given high-level feature name.
  - Serve as the final description of the high-level feature.

  Only the final summarized description should be included in the output â€” no additional commentary or formatting.

  INPUT:
  Multiple descriptions: {merging_feature_description}

  High-Level Feature Name: {high_level_feature}
  """


micro_sub_feature_prompt = """You are an expert system analyst specializing in decomposing SubFeatures into granular, logically independent components. You support **two levels** of splitting:

1. **Horizontal splitting**: Split a subfeature into multiple *same-level subfeatures* when it encompasses multiple independently meaningful functionalities. The subfeatures created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.
2. **Vertical splitting**: Further break each of those subfeatures into *microsubfeatures* (if applicable), ensuring each micro-sub-features/micro-user-story describes a single goal or operation. The micro-sub-features/micro-user-story created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.

---

### ðŸ”§ TASK OVERVIEW

Given a Macro-Feature, Subfeature, its description, associated module files and its summary:

- Decide if the subfeature should be split horizontally into multiple same-level subfeatures.
- For each resulting subfeature (or original if not split), analyze whether it can be split vertically into **microsubfeatures** (fine-grained user stories).
- Provide the confidence scores for the subfeature that is split, whether horizontally or vertically.
- Provide the files that are related to the sub_features too, not just the micro_sub_features.
- Each leaf user-story must have files assigned to them, else you should not create/split these subfeatures.
- Provide description of generated subfeature/sub-user-stories in 2-4 lines but only valid information. Do not assume or hallucinate to generate description.
Apply this recursively: if horizontal splitting occurs, then attempt vertical splitting for each. But remember, not to create any duplicates in the process. 

---

### SPLITTING DECISIONS

#### Horizontal Splitting (Same-level Subfeatures):
Split if:
- The subfeature covers multiple high-level functionalities
- Each function could be planned, developed, and deployed independently
- Each component has a clear boundary and responsibility

#### Vertical Splitting (Microsubfeatures):
Split further if:
- A subfeature contains multiple independent operations or logical stages
- These operations can be implemented, tested, or tracked separately
- Each micro-subfeature represents one atomic, non-overlapping functionality

---

### DO NOT SPLIT IF:
- sub-user-stories are tightly coupled in the Subfeature and cannot function independently.
- Do not split subfeatures into sub-user-stories that are hardly single line of code and cannot be considered as a proper functionality, but just a config/parameter.
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across actions are too complex to isolate.
- There are no files that can be mapped to the generated user-story.
- Do not split if the user-story is barely a functionality. The split user-stories must have independent functionality that contributes to the subfeature and feature and if not, do not split.
- Don not split ReadMe & .md files into sub-user-stories.
- Do not split horizontall for granullar subfeatures as they are not user stories but mid level features.
---

### FILE MAPPING RULES:
- For each subfeature or microsubfeature, cite only directly relevant files.
- Use only the provided input data to match files â€” no guessing.
- Avoid duplication unless a file is clearly shared between components.

Each `file_path` entry must include:
```json
{
  "module_name": "<Name>",
  "path": "<Path>",
  "critical": <true/false>,
  "git_url": "<Git URL>"
}

OUTPUT FORMAT
If the subfeature should NOT be split:
Return: "None"

If the subfeature should be split, return a list of Parent User Stories with subfeatures inside.
If a subfeature itself can be further split into microsubfeatures, nest them under micro_sub_features like so:

[
  {
    "name": "Parent User Story Title 1",
    "description": "Full description of the original or updated user story and its purpose.",
    "file_path": [...],
    "sub_feature_confidence_score":"confidence score of the subfeature with respect to the Feature, as a percentage (e.g., 80)"
    "micro_sub_features": [
      {
        "name": "Sub-User Story Title 1",
        "description": "Standalone description of a single functionality.",
        "file_path": [...],
        "micro_sub_feature_confidence_score":"confidence score of the micro_sub_feature with respect to the sub_feature, as a percentage (e.g., 90)"
        }
          ...
        ]
      },
      ...
    ]
  }
]
Each layer must preserve independence, clarity, and singular focus of each story.

VALIDATION CHECKLIST
- Each title must express one functionality only (no imperative phrasing)
- description must avoid assumptions and describe the real function. It must be as detailled as possible.
- Each story must make sense independently and fit in the broader feature flow
- if there are multiple user-story under the subfeature, it needs to be in sequence of business logic.
- File mappings must be relevant and scoped accurately
- Do no miss/skip any values in the output json. The output structure must be maintained strictly.
- All subfeature and sub-user-story names and descriptions must be strictly in a declarative tone, not imperative.

* Use generic or speculative statements
"""


db_micro_sub_feature_prompt = """
<Role>
You are an expert Database analyst specializing in decomposing SubFeatures into granular, logically independent components. You support **two levels** of splitting:
You shall ALWAYS process features from a Database perspective ONLY. 
There can be more than one Table in the DB context provided to you.
</Role>

1. **Horizontal splitting**: Split a subfeature into multiple *same-level subfeatures* when it encompasses multiple independently meaningful functionalities. The subfeatures created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.
2. **Vertical splitting**: Further break each of those subfeatures into *microsubfeatures* (if applicable), ensuring each micro-sub-features/micro-user-story describes a single goal or operation. The micro-sub-features/micro-user-story created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.

<Strict Constraints> 
- You are dealing with Database Information. 
- No matter what, STRICTLY use Database-Specific Language ALWAYS. 
- Use words like Columns / Fields / Schema / DataTypes / Constraints / Foreign Keys / Primary Keys etc.
- Strictly Do not start descriptions with or start with "this micro-feature" / or "this sub-feature".
- You shall do this regardless of the input context and nature.
Remember : Every "FILE" given to you is information of a table. Therefore in your response, ALWAYS refer to "Table" instead of "File".

</Strict Constraints> 


### ðŸ”§ TASK OVERVIEW

Given a Macro-Feature, Subfeature, its description, associated module files and its summary:

- Decide if the subfeature should be split horizontally into multiple same-level subfeatures.
- For each resulting subfeature (or original if not split), analyze whether it can be split vertically into **microsubfeatures** (fine-grained user stories).
- Provide the confidence scores for the subfeature that is split, whether horizontally or vertically.
- Provide the files that are related to the sub_features too, not just the micro_sub_features.
- Each leaf user-story must have files assigned to them, else you should not create/split these subfeatures.
- Provide description of generated subfeature/sub-user-stories in 2-4 lines but only valid information. Do not assume or hallucinate to generate description.
Apply this recursively: if horizontal splitting occurs, then attempt vertical splitting for each. But remember, not to create any duplicates in the process. 

---

### SPLITTING DECISIONS

#### Horizontal Splitting (Same-level Subfeatures):
Split if:
- The subfeature covers ONE / MORE THAN ONE high-level functionalities
- Each function could be planned and developed independently
- Each component has some clear boundaries and responsibilities

#### Vertical Splitting (Microsubfeatures):
Split further if:
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across actions are too complex to isolate.
- There are no tables that can be mapped to the generated user-story.
- The subfeature is too complex to be planned, developed, and deployed independently
- Each micro-subfeature represents one atomic, non-overlapping functionality
Note: Maintain at least 2 subfeatures unless the database has only one table.
- Prioritize brevity, consistency and no informaiton leakage across subfeatures.
- Ensure crisp segregation.
---

### DO NOT SPLIT IF:
- sub-user-stories are tightly coupled in the Subfeature and cannot function independently.
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across tables in two features are too complex to isolate.
- There are no tables that can be mapped to the generated user-story.
Note: Maintain at least 2 subfeatures and 1 or more microsubfeatures per subfeature, Unless the database has only one table.
Note : Maintain brevity during splitting at the same level. Do NOT overload the a single feature with too many subfeatures.
---


### FILE MAPPING RULES:
- For each subfeature or microsubfeature, cite only directly relevant tables.
- Use only the provided input data to match files â€” no guessing.
- Avoid duplication unless a file is clearly shared between components.

Each `file_path` entry must include:
```json
{
  "module_name": "<Name>",
  "path": "<Path>",
  "critical": <true/false>,
  "git_url": "<Git URL>"
}

OUTPUT FORMAT
If the subfeature should NOT be split:
Return: "None"

If the subfeature should be split, return a list of Parent User Stories with subfeatures inside.
If a subfeature itself can be further split into microsubfeatures, nest them under micro_sub_features like so:

[
  {
    "name": "Parent User Story Title 1",
    "description": "Full description of the original or updated user story and its purpose.",
    "file_path": [...],
    "sub_feature_confidence_score":"confidence score of the subfeature with respect to the Feature, as a percentage (e.g., 80)"
    "micro_sub_features": [
      {
        "name": "Sub-User Story Title 1",
        "description": "Standalone description of a single functionality.",
        "file_path": [...],
        "micro_sub_feature_confidence_score":"confidence score of the micro_sub_feature with respect to the sub_feature, as a percentage (e.g., 90)"
        }
          ...
        ]
      },
      ...
    ]
  }
]
Each layer must preserve independence, clarity, and singular focus of each story.

VALIDATION CHECKLIST
- Each title must express one functionality only (no imperative phrasing)
- description must avoid assumptions and describe the real function. It must be as detailled as possible.
- Each story must make sense independently and fit in the broader feature flow
- if there are multiple user-story under the subfeature, it needs to be in sequence of business logic.
- File mappings must be relevant and scoped accurately
- Do no miss/skip any values in the output json. The output structure must be maintained strictly.
- All subfeature and sub-user-story names and descriptions must be strictly in a declarative tone, not imperative.
- Use Database-specific schema only. Do not include words like "Attributes" / "Code Files" in your response. 
- Strictly Do not start descriptions with or start with "this micro-feature" / or "this sub-feature".
* Use generic or speculative statements

"""import os
from graphviz import Digraph
import re 
import json

def parse_ddl(ddl: str):
    """
    Parse the DDL to extract columns, primary keys, and foreign keys.
    """
    lines = ddl.splitlines()
    column_lines = []

    for line in lines:
        line = line.strip()
        if (
            line.upper().startswith("CREATE")
            or line.upper().startswith("PRIMARY")
            or line.upper().startswith("FOREIGN")
            or line.upper().startswith(")")
            or line == ""
        ):
            continue

        match = re.match(r'(\w+)\s+\w+', line)
        if match:
            column_lines.append(match.group(1))

    pk_match = re.search(r'PRIMARY KEY\s*\((.*?)\)', ddl)
    primary_keys = [key.strip() for key in pk_match.group(1).split(",")] if pk_match else []

    foreign_keys = []
    for match in re.finditer(r'FOREIGN KEY\s*\(([^)]+)\)\s+REFERENCES\s+`?[\w]+\.(\w+)`\(([^)]+)\)', ddl):
        fk_col = match.group(1).strip()
        ref_table = match.group(2).strip()
        ref_col = match.group(3).strip()
        foreign_keys.append((fk_col, ref_table, ref_col))

    return column_lines, primary_keys, foreign_keys


def generate_combined_graph(tables_data):
    """
    Generate a single combined graph from multiple tables.
    """
    dot = Digraph(comment='Combined Table Diagram')
    dot.attr(rankdir='LR')

    # Store individual table nodes
    for table in tables_data:
        table_name = table['table_name']
        columns = table['columns']
        primary_keys = table['primary_keys']
        
        label_lines = []
        for col in columns:
            if col in primary_keys:
                label_lines.append(f"{col} [PK]")
            else:
                label_lines.append(col)
        dot.node(table_name, shape='box', label=f'{table_name}\\n' + "\\n".join(label_lines))

    # Add relationships
    for table in tables_data:
        table_name = table['table_name']
        for fk_col, ref_table, ref_col in table['foreign_keys']:
            dot.edge(table_name, ref_table, label=f'{fk_col} â†’ {ref_col}')

    return dot

def folder_summary_generation_prompts(
        total_allocated_tokens, 
        file_list, folder_name, 
        folder_path,
        subfolder_list,
        formatted_file_summaries,
        formatted_file_services,
        formatted_subfolder_summaries,
        formatted_subfolder_services,
        formatted_subfolder_features
    ):
    
    system_prompt = f"""
        You are an expert code analyst specialized in creating detailed, informative summaries of software project folders. Your task is to thoroughly analyze files and subfolders to provide a comprehensive understanding of the application or project and provide combined summaries along with required details. These summaries must be detailled enough for further summarization.

        Follow these guidelines:
        1. Conduct a deep analysis of the features to identify its core purpose and functionality
        2. Provide detailed explanation of key implementations and technical approaches of the features
        3. Thoroughly examine the summaries based on files and folders to understand relationship between features and combined smaller features into larger high level application level features.
        4. Explain the features within the broader project architecture with specific connections
        5. Describe technical patterns, design decisions, and architectural choices evident in the code
        6. Include specific functions, classes, and methods that define the feature's behavior
        7. Note dependencies, imports, and external connections that shape the folder's functionality
        8. Identify potential architectural strengths and areas for improvement when evident
        9. Identify all services represented in this folder based on file and subfolder services information
        10. Identify and articulate high-level features or functionalities represented by the folder into the feature_details section, when consolidating multiple subfolders or lower-level files. Derive these insights from both file-level and subfolder-level summaries. Also under each feature, mention which file/folder was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
        11. Do not miss any features that could be formed based on these summaries as this information is required to understand the application's buisness logic.
        12. Gather insights from the summaries provided to generate a high level detailled executive summary that could be used by business stakeholders to understand the folder/project.
        13. When analyzing the root folder, both the executive summary and the features must be strictly formed in a high level business logic standpoint of an application.
        
        IMPORTANT: 
        - Your summary should be thorough and detailed({total_allocated_tokens}) while maintaining technical/business precision and depth. Focus on providing insights that would help both stakeholders and developers understand the application better.
        - feature_details must contain high level feature name and feature description(value of the files/folders) strictly in concise bullet points. The feature inforamtion must be in detail to capture the complete high level knowledge for that feature but not the function level details. Feature names cannot be programmatic function names like Dependency management, json handling etc. instead it should be inventory management, order processing etc. 
        - Your services list should be comprehensive and include all services represented in this folder.
        - is_reuasble_lib if a folder is used as reusable lib make it True otherwise False
        - lib_name if is_reusable_lib is True then provide the name of the reusable lib/component If is_reusable_lib False then add Not Applicable
        - category if is_reusable_lib is True then provide category only between 'Frontend' and 'Backend' If is_reusable_lib False then add Not Applicable
        - sub_category if is_reusable_lib is True then provide sub category only between 'UI Component','Custom Hooks', 'http_client', 'Utils', 'Others' In Frontend & 'Middleware', 'Error Handling', 'Auth', 'Utils', 'Others' In Backend If is_reusable_lib False then add Not Applicable
        - when_to_use if is_reusable_lib is True then provide where this reusable lib/component can be used If is_reusable_lib False then add Not Applicable 
        - associated_files if is_reusable_lib is True then provide the list of files associated(give complete path for the assosciated file) with this reusable lib/component If is_reusable_lib False then add Not Applicable
        - summary must not be technical and only explain the high level details of the folder/project. Understand the file and folder summaries provided to combine the knowledge to form the executive summary. Make it as detailled as possible.
        - Use clear and concise language, avoiding jargon where possible.
        
        - You must provide your response in this exact format:
        ```summary
        [Your detailled high-level executive summary for the folder for business stakeholders]
        ```
        ```feature_details
        [List of high-level features or functionalities represented in this folder]
        ```
        ```services_namess
        [Comma-separated list of all services represented in this folder]
        ```
        ```is_reuasble_lib
        Boolean Value
        ```
        ```lib_name
        [Name of the reusable library if applicable]
        ```
        ```category
        [Category of the reusable library if applicable]
        ```
        ```sub_category
            [Sub category of the reusable library if applicable]
        ```
        ```when_to_use
        [Your detailed use case where or when this reuasble_lib can be usefull]
        ```
        ```associated_files
            [Comma-separated list of associated files with the reusable library, Give the Complete file path as mentioned in the file list]
        ```
        ```example_usage
            [Example code snippet of how to use this reusable library]
        ```
    """

    user_prompt = f"""
        Generate a summary and services list for the folder: "{folder_name}" (Path: {folder_path})

        FOLDER CONTENTS:
        - Files ({len(file_list)}): {", ".join(file_list) if file_list else "None"}
        - Subfolders ({len(subfolder_list)}): {", ".join(subfolder_list) if subfolder_list else "None"}

        FILE SUMMARIES:
        {os.linesep.join(formatted_file_summaries) if formatted_file_summaries else "No file summaries available"}

        FILE SERVICES:
        {os.linesep.join(formatted_file_services) if formatted_file_services else "No file services available"}

        SUBFOLDER SUMMARIES:
        {os.linesep.join(formatted_subfolder_summaries) if formatted_subfolder_summaries else "No subfolder summaries available"}

        SUBFOLDER SERVICES:
        {os.linesep.join(formatted_subfolder_services) if formatted_subfolder_services else "No subfolder services available"}

        SUBFOLDER FEATURES:
        {os.linesep.join(formatted_subfolder_features) if formatted_subfolder_features else "No subfolder features available"}
        
        Based on these components:
        1. Provide a thorough technical summary explaining the folder's purpose, implementation details, and architectural significance
        2. Compile a comprehensive list of all services represented in this folder based on file and subfolder services information
        
        Follow the exact format specified in the system instructions for your response.
    """

    return system_prompt, user_prompt

def services_generation():
    system_prompt = """
        <Task>
        Create an architectural blueprint of the given repository by identifying and classifying both external services and third-party services with no overlap between categories.
        </Task>

        <Definitions>
        - External services: Company-provided services hosted outside the application (AWS S3, Google Cloud, Stripe, Twilio)
        - Third-party services: Libraries, frameworks, and SDKs that are part of the core application stack (Django, React, MongoDB, Redux)
        </Definitions>

        <Output_Format>
        {
        "external_services": [
            {
            "external_service_name": "string",
            "description": "string",
            "associated_files": ["string"],
            "service_class": "string",
            "used_in_files": ["string"]
            }
        ],
        "thirdparty_services": [
            {
            "thirdparty_service_name": "string",
            "description": "string",
            "associated_files": ["string"],
            "service_class": "string",
            "used_in_files": ["string"]
            }
        ]
        }
        </Output_Format>

        <Instructions>
        1. Conduct a thorough repository analysis to identify all services
        2. Classify each service into exactly ONE category:
        - External services: Cloud platforms, payment processors, authentication providers
        - Third-party services: Frameworks, libraries, SDKs integrated into the codebase
        3. For each service, provide:
        - Name: Exact service name
        - Description: Concise explanation of functionality and purpose
        - Associated files: All files directly importing or using the service
        - Service class: Category (e.g., "cloud storage", "web framework", "database")
        - Used in files: Complete paths of files utilizing the service
        4. Ensure ZERO overlap between categories
        5. Prioritize accuracy over comprehensiveness
        6. Validate that identified services are actively used in the project
        7. Include only services with clear evidence of implementation
        8. Do not create a lot of services which are redundant. Keep it to a maximum of 50 services only.
        </Instructions>

        <Examples>
        Good External Service Entry:
        {
        "external_service_name": "AWS S3",
        "description": "Cloud storage service used for storing user-uploaded files",
        "associated_files": ["src/services/storage.js", "src/config/aws.js"],
        "service_class": "cloud storage",
        "used_in_files": ["src/components/FileUpload.js", "src/pages/UserProfile.js"]
        }

        Good Third-Party Service Entry:
        {
        "thirdparty_service_name": "React",
        "description": "Frontend JavaScript library for building user interfaces",
        "associated_files": ["package.json", "src/index.js"],
        "service_class": "frontend framework",
        "used_in_files": ["src/App.js", "src/components/*.js"]
        }
        </Examples>

        Analyze the repository and provide the complete architectural blueprint in the specified format.
    """

    user_prompt = ""

    return system_prompt, user_prompt

def executive_summary_generation(combined_summary, user_mvf):
    system_prompt = """
    Your Role:
    You are an expert software architect tasked with understanding a codebase and creating an executive summary that clearly articulates the main purpose of this application,
    the core problem that the application is solving, and the prioritized list of the most valuable features, solely based on the provided folder wise summary. Do not hallucinate and create the most valuable features and its description on assumption. This needs to be based on facts.

    Task:
    1. Analyze provided folder wise summary and the services used and the user defined features (if provided).
    2. Understand component interactions and functions.
    3. Prioritize the User Defined Features (if provided) in the summary.
    4. Identify and prioritize the most valuable features based on their importance and relevance to the overall project, as evidenced in the code.
    5. Create a comprehensive executive summary.

    Steps:
    1. Review folder wise summary.
    2. Analyze folder wise summary:
    - Identify key components and their roles
    - Note data operations, design patterns, and architectural decisions
    3. Create summary:
    - Describe the specific problem the codebase solves, based on folder wise summary
    - Explain component interactions
    - Outline data workflow
    4. Identify and prioritize main features:
    - Determine which feature(s) address the core problem of the application, based on code implementation
    - Rank features based on their importance and relevance to solving the main problem, as evidenced in the code
    - The feature should be major components of the codebase and not minor functions like "Modular Architecture" or "Code Reusability", these are not features but design principles.

    Focus Areas:
    - Precised feature prioritization and importance
    - High-level functionality
    - Clear, concise technical language
    - Objective description
    - Capture entire workflow

    Guidelines:
    - Only use the folder wise summary provided
    - Use precise technical terms
    - Include user-defined features if provided and evidenced in the code
    - Prioritize features based on their importance to the core problem, as shown in the folder wise summary

    Feature Identification and Prioritization:
    - Carefully analyze the folder wise summary to identify features actually present in the folder wise summary
    - Do not assume or infer features that are not explicitly mentioned in the folder wise summary
    - Identify the top feature that solves the majority of the problem based on code evidence
    - Rank subsequent features in descending order of importance, ensuring they are present in the folder wise summary
    - Ensure the feature list reflects the codebase's focus and structure
    - Only include features that have substantial implementation in the codebase that is evident from folder wise summary

    Output Format - Adhering to this format is crucial
    ```json
    {
    "data": "generated_summary in string format adhering to the Expected Output Format for Generated Summary",
    "confidence_score": 90,
    "traceback": {
    "Feature 1 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 1 Title' is included, as the 'phrase' is an evidence that this feature is part of the codebase.",
    "Feature 2 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 2 Title' is included, as the 'phrase' is an evidence that this feature is part of the codebase.",
    ...
    }
    }
    ```

    Requirements:
    - Replace \n with \\n in JSON
    - Limit upto 5 main features (max 2 sub-features each) or 7500 tokens
    - If due to any reason such as codebase being small, you are unable to provide 5 features, then provide as many high-level features as possible between the range of 1 to 5.
    - Don't assume features or include minor features due to inability to provide 5 features, lesser number of features is acceptable.
    - Use specified JSON format only
    - Start with "```json" and end with "```"
    - Ensure the top feature in the prioritized list addresses the core problem and is present in the folder wise summary
    - Rank features in descending order of importance to the main problem, based on actual code implementation
    - Do NOT include features that are NOT evidenced in the provided folder wise summary
    - Evaluate the folder wise summary objectively, considering all conclusions on the actual code provided
    - Do NOT make any assumptions about organizational goals or intentions beyond what is explicitly shown in the code
    - Focus solely on the technical aspects and implemented functionality, avoiding speculation about business objectives or future plans
    - Both the keys data, confidence score, and traceback should be present in the output JSON
    - The generated summary should be in string format only and be contained inside the "data" key
    - The "traceback" key should contain a dictionary with feature names as keys and justifications for including these features based on exact phrases from the input
    - Do not include any feature that could potentially be part of the folder wise summary without explicit evidence
    - Every feature mentioned must be driven by clear evidence from the provided input
    """
    user_prompt = """
    Expected Output Format for Generated Summary:

  **Overview**
  <empty line>
  <A brief introduction to the codebase and its main purpose; in paragraph format only, not in points.
  This paragraph should provide a concise yet comprehensive overview of the codebase, its primary functionality, solution provided by the project and its intended use case.
  Aim for 3-5 sentences that capture the essence of the project.>
  <empty line>
  **Highlighted Features**
  <empty line>
  <
  List and briefly explain the key features that are significant components of the codebase and would serve as selling points.
  These features should be presented as follows:
  1. Use numbered points for each feature.
  2. Provide a brief explanation for each feature in 1-2 sentences, highlighting its importance and benefit to the end user.
  3. Focus on features that are central to the codebase's functionality and most important to the end user.
  4. Dont include generic features like "Modular Architecture" or "Code Reusability", these are not features but design principles.
  5. Do not include sub-points under any feature.
  6. Prioritize User Defined Features (if provided) at the beginning of the list.
  7. If User Defined Features are given, list them first before including any features identified through your analysis.
  8. Aim to provide upto of 1 to 5 key features, after each feature add an empty line for formatting purposes.
  9. Ensure that the features listed represent the core functionality and unique selling points based on the folder wise summary.
  10. Use clear, concise language that emphasizes the value proposition of each feature.
  11. Also under each feature, mention which file/folder was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
  12. Do not add features into Highlighted Features if they dont have value for buisness stakeholder about the application. Also do not repeat adding similar feature in this section.

  Output Structure:
  1. ***<Feature 1 Title>***: <Description of the feature in one to two sentences.\n
  2. ***<Feature 2 Title>***: <Description of the feature in one to two sentences.>\n
  >
  <empty line>
  **Key Benefits**
  <empty line>
  <Summarize the key benefits of the codebase in one to two sentences.
  This summary should encapsulate the overall value proposition of the codebase and its potential impact on users or the organization.>
  <empty line>
  <Highlight the most significant key benefits the codebase has to offer in bulleted points. The format should be:
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  Aim for 3-5 bullet points that capture the most compelling advantages of using this codebase, after each point add an empty line for formatting purposes.
  Each benefit should be distinct and provide a clear value proposition.>

  <Final Output Format>
  Output Format - Adhering to this format is crucial, the output should be in parsable JSON format:
  ```json
  {{
    "data": "<generated_summary in string format adhering to the Expected Output Format for Generated Summary>",
    "confidence_score": 90,
    "traceback": {{
      "Feature 1 Title": "Since it mentions about <exact phrase from the folder wise summary>, the 'Feature 1 Title' is included, as the "phrase" is an evidence that this feature is part of the folder wise summary.",
      "Feature 2 Title": "Since it mentions about <exact phrase from the folder wise summary>, the 'Feature 2 Title' is included, as the "phrase" is an evidence that this feature is part of the folder wise summary.",
      ...
    }}
  }}
  ```
  </Final Output Format>
  Note: If the traceback includes phrases that are not present in the folder wise summary then you would be penalized 10000 points.
  The output should be having data, confidence score, and traceback keys, and the entire content inside "```json" and "```" should be parsable by json.
  The "data" key should contain the generated summary and it should be in string format only, allowing the parsing of the entire json.
  If there are any inverted commas inside the generated summary, then escape them with a backslash.
  Do not change or skip the headings of each section in the generated json. The generated summary must have "Overview", "Highlighted Features", "Key Benefits" as section titles. Follow the above provided guidelines."""
    user_prompt += f"""Use the below folder wise summary to generate the summary in the above format: {combined_summary}""" + "User Defined Features : " + str(user_mvf)
    return system_prompt, user_prompt

def db_executive_summary_generation(combined_summary, user_mvf): 
    system_prompt = """
    Role:
    You are an expert Database Architect tasked with understanding the contents of all tables and schema of the database. 
    You shall Articulate a proper executive summary that clearly captures all the main & high-level features of this database.
    The core use-case that this database is intended for, and the prioritized list of the most valuable features, solely based on the provided Table-Level summaries. 
    Do not hallucinate. Do NOT create the most valuable features and its description on pure assumptions. This needs to be based on facts, with proper backing.

    Task:
    1. Analyze provided Table wise summaries.
    2. Understand component interactions and functions.
    3. Prioritize the User Defined Features (if provided) in the summary.
    4. Identify and prioritize the most valuable features based on their importance to the core use-case the Database is solving.
    5. Create a comprehensive executive summary.

    Steps:
    1. Review Table wise summary.
    2. Analyze Table wise summary:
      - Identify all tables. 
      - Take into consideration the foreign keys, primary keys, is-a, has-a, and many-to-many relationships.
      - Deeply understand the intended-use-case of each table.
      - Note data operations, design patterns, and architectural decisions
    3. Create summary:
      - Describe the specific problem the Database is solving, based on Table wise summary
      - Explain high-level interactions and dependencies
      - Outline data workflow
    4. Identify and prioritize main features:
      - Determine which feature(s) address the core problem of the Database, based on SQL implementation and Table wise summary
      - Rank features based on their importance and relevance to solving the main problem, as evidenced in the Database
      - The feature should be major components of the Database and not minor functions like Many-to-Many Relationships, or "Foreign Keys". 
        These are implementation concepts. Not core features.

    Focus Areas:
    - Precised feature prioritization and importance
    - High-level functionality of this Database
    - Clear, concise technical language with Database-specific Language
    - Objective description
    - Capture entire data workflow

    Guidelines:
    - Only use the Table wise summary provided
    - Use precise Database-relevant technical terms
    - Include user-defined features if provided and evidenced in the Table wise summary
    - Prioritize features based on their importance to the core problem, as shown in the Table wise summary

    Feature Identification and Prioritization:
    - Carefully analyze the Table wise summary to identify features actually present in the Table wise summary
    - Do not assume or infer features that are not explicitly mentioned in the Table wise summary
    - Identify the top feature that solves the majority of the problem based on Database and SQL evidence
    - Rank subsequent features in descending order of importance, ensuring they are present in the Table wise summary
    - Ensure the feature list reflects the Database's focus and structure
    - Only include features that have substantial implementation in the Database that is evident from Table wise summary

    Output Format - Adhering to this format is crucial
    ```json
    {
    "data": "generated_summary in string format adhering to the Expected Output Format for Generated Summary",
    "confidence_score": 90,
    "traceback": {
    "Feature 1 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 1 Title' is included, as the 'phrase' is an evidence that this feature is part of the Database.",
    "Feature 2 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 2 Title' is included, as the 'phrase' is an evidence that this feature is part of the Database.",
    ...
    }
    }
    ```

    Requirements:
    - Replace \n with \\n in JSON
    - Limit upto 5 main features (max 2 sub-features each) or 7500 tokens
    - If due to any reason such as Database being small, you are unable to provide 5 features, then provide as many high-level features as possible between the range of 1 to 5.
    - Don't assume features or include minor features due to inability to provide 5 features, lesser number of features is acceptable.
    - Use specified JSON format only
    - Start with "```json" and end with "```"
    - Ensure the top feature in the prioritized list addresses the core problem and is present in the Table wise summary
    - Rank features in descending order of importance to the main problem, based on actual Database and SQL implementation
    - Do NOT include features that are NOT evidenced in the provided Table wise summary
    - Evaluate the Table wise summary objectively, considering all conclusions on the actual Database and SQL provided
    - Do NOT make any assumptions about organizational goals or intentions beyond what is explicitly shown in the Database and SQL
    - Focus solely on the technical aspects and implemented functionality, avoiding speculation about business objectives or future plans
    - Both the keys data, confidence score, and traceback should be present in the output JSON
    - The generated summary should be in string format only and be contained inside the "data" key
    - The "traceback" key should contain a dictionary with feature names as keys and justifications for including these features based on exact phrases from the input
    - Do not include any feature that could potentially be part of the Table wise summary without explicit evidence
    - Every feature mentioned must be driven by clear evidence from the provided input.
    - Strictly use an assertive and objective tone in your response. 
    - Do not be unsure about anything.
    - Do not include the "Folder Name" in your response. Ignore "dbanalysis" folder. Provide Executive Summary of the Database-ONLY.
    """

    user_prompt = """
  Expected Output Format for Generated Summary:

  **Overview**
  <empty line>
  <A brief introduction to the Database and its main purpose; in paragraph format only, not in points.
  This paragraph should provide a concise yet comprehensive overview of the Database, its primary functionality, and its intended use case.
  Aim for 3-5 sentences that capture the essence of the Database.>
  <empty line>
  **Highlighted Features**
  <empty line>
  <
  List and briefly explain the key features that are significant components of the Database and would serve as selling points.
  These features should be presented as follows:
  1. Use numbered points for each feature.
  2. Provide a brief explanation for each feature in 1-2 sentences, highlighting its importance and benefit to the END USER.
  3. Focus on features that are central to the Database's functionality and most important to the END USER.
  4. Dont include generic features like  Many-to-Many Relationships, or "Foreign Keys", these are not features but Design Principles.
  5. Do not include sub-points under any feature.
  6. Prioritize User Defined Features (if provided) at the beginning of the list.
  7. If User Defined Features are given, list them first before including any features identified through your analysis.
  8. Aim to provide upto of 1 to 5 key features, after each feature add an empty line for formatting purposes.
  9. Ensure that the features listed represent the core functionality and unique selling points based on the Table wise summary.
  10. Use clear, concise language that emphasizes the value proposition of each feature.
  11. Also under each feature, mention which file/Table was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
  12. Do not add features into Highlighted Features if they dont have value for buisness stakeholder about the application. Also do not repeat adding similar feature in this section.

  Output Structure:
  1. ***<Feature 1 Title>***: <Description of the feature in one to two sentences.\n
  2. ***<Feature 2 Title>***: <Description of the feature in one to two sentences.>\n
  >
  <empty line>
  **Key Benefits**
  <empty line>
  <Summarize the key benefits of the Database in one to two sentences.
  This summary should encapsulate the overall value proposition of the Database and its potential impact on users or the organization.>
  <empty line>
  <Highlight the most significant key benefits the Database has to offer in bulleted points. The format should be:
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  Aim for 3-5 bullet points that capture the most compelling advantages of using this Database, after each point add an empty line for formatting purposes.
  Each benefit should be distinct and provide a clear value proposition.>

  <Final Output Format>
  Output Format - Adhering to this format is crucial, the output should be in parsable JSON format:
  ```json
  {{
    "data": "<generated_summary in string format adhering to the Expected Output Format for Generated Summary>",
    "confidence_score": 90,
    "traceback": {{
      "Feature 1 Title": "Since it mentions about <exact phrase from the Table wise summary>, the 'Feature 1 Title' is included, as the "phrase" is an evidence that this feature is part of the Table wise summary.",
      "Feature 2 Title": "Since it mentions about <exact phrase from the Table wise summary>, the 'Feature 2 Title' is included, as the "phrase" is an evidence that this feature is part of the Table wise summary.",
      ...
    }}
  }}
  ```
  </Final Output Format>
  Note: If the traceback includes phrases that are not present in the Table wise summary then you would be penalized 10000 points.
  The output should be having data, confidence score, and traceback keys, and the entire content inside "```json" and "```" should be parsable by json.
  The "data" key should contain the generated summary and it should be in string format only, allowing the parsing of the entire json.
  If there are any inverted commas inside the generated summary, then escape them with a backslash.
  Do not change or skip the headings of each section in the generated json. The generated summary must have "Overview", "Highlighted Features", "Key Benefits" as section titles. Follow the above provided guidelines.
    """

    user_prompt += f"""Use the below Table wise summary to generate the summary in the above format: {combined_summary}""" + "User Defined Features : " + str(user_mvf)

    return system_prompt, user_prompt


def architecture_diagram_generation(services_data, icons_metadata):
    user_prompt = f"""
    <Input>
    $services_data = {services_data}
    $icons_metadata
    </Input>

    <Role>
    You are an expert at understanding large projects based on their executive summary and the services being used in them. Create a JSON structure for a ReactFlow diagram based on the given service class JSON.
    </Role>

    <Output Structure>
    1. Create a JSON object with a "nodes" and "edges" array.
    2. Create nodes for each external and third-party service.
    3. "nodes": An array containing all node objects.
      - "id": A unique string identifier for the node.
      - "data":   
        - "label": The name of the node.
        - "description": Description of the service.
        - "associated_files": Associated file and used in files in the service node, defaulting to "No File Available" if not present.
        - "group": The logical group name (e.g., 'Backend', 'Frontend', 'Database',etc..).
        - "subgroup": The specific subgroup within the group (e.g., Frameworks, NoSQL Databases, State Management, etc.).
        - "service": The appropriate filename of the icon based on the $icons_metadata.
      - "position" : The x and y coordinates of the node.
      - "type" : "customNode" This should be fixed.
    4. "edges" : An array having id, source, target, label, and type should be customEdge always.
    4. Ensure all services and files from the input JSON are included.
    5. The output should be in the form of a dictionary containing a "nodes" and "edges" array.
    6. Present only the code inside delimiters "```reactflow [reactflow CODE]```" without any additional explanation.
    """

    system_prompt:str = """
    <Task>
      You are tasked with creating a JSON structure for a ReactFlow diagram based on the given executive summary and the service_class_json. The executive summary contains an overview of the entire project. This JSON includes information about external services and third-party services, along with their associated files. Your output should represent this information as a network of nodes and edges.
    </Task>
    
    <Icons Context>
      $icons_metadata = """ + str(icons_metadata) + """
    </Icons Context>

    <Instructions>
      You are a solution expert, specializing in problem and solution flows. You will be given the solution overview for a project, and your task is to create an interconnected single component of graph which is detailed, and intuitive and self explanatory for:

      Follow these guidelines:
      1. Create nodes for each unique service (both external and third-party).
      2. Do not create any group nodes.
      4. In the data key for each service node, include two additional fields called group and subgroup. The group field should contain the logical group name (e.g., Frontend, Backend, Databases, etc..), and the subgroup field should provide more specific categorization (e.g., Frameworks, NoSQL Databases, etc..). For example, for a service node representing React, the group would be Frontend and the subgroup would be Frameworks.
      5. For each node, check which icon will be the most suitable from the $icons_metadata in the <Icons Context>
      6. Ensure all information from the input is represented in the output.
      7. The position coordinates must be proper for all the nodes.
    </Instructions>

    <Rules>
      **Ensure all nodes in the generated graph are interconnected such that every node has at least one edge, forming a single connected component without any isolated or disjoint sections. (High Priority Requirement)**
      Important Rules to be followed:
      1. Give detailed technical architecture flow and the JSON object following the below output format.
      2. Make sure that the flow and order of new solution approach is explained well in the graph with appropriate edges. Use as many edges you want to describe the data and user flow properly.
      3. The whole user and data flow should be clear.
      4. Do not add unnecessary nodes and edges. Do not create duplicate nodes that perform same task.
      5. Make the Node descriptions detailed, breaking tasks into multiple sub-tasks if needed.
      6. Ensure your edges show the actual flow, and not just connections of what's related. The connections are meant to show the logical flow, and not the relatedness/similarity.
      7. The group name is meant to classify clusters of nodes within each graph. For instance, if we have multiple nodes in features, they would all have "feature" as group. In Architecture Flow, the "Group" should show the layer each node is in, for instance "Backend Layer", "Database Layer" etc.
      9. for a hierarchy of nodes A -> B -> C; ensure that there is not a connection between A -> C.
    </Rules>
    
    <output_format>
    The output should be in between the delimeters ```reactflow and ```. Only provide the json output. Don't give unnecesary explanation.
    ```reactflow
    {
      "nodes": [
        { 
          "id": "unique_node_identifier_string",
          "data" : {
            "label": "name_of_the_service",
            "description": "description of the service",
            "associated_files": ["file_path_1", "file_path_2", "file_path_3", etc.],  // (default: ["No File Available"] if not present)
            "group": "name_of_group",  // Add the logical group name (e.g., "Frontend", "Backend", etc..)
            "subgroup": "name_of_subgroup",  // Add a more specific subgroup name (e.g., "Frameworks", "NoSQL Databases", etc..)
            "service": "filename" //taken from the $icons_metadata,
          }
          "position":{ "x": "Xcoordinate", "y": "Ycoordinate" },
          "type" : "customNode" //this is hardcoded and will be constant
        }
      ],
      "edges": [
        {
          "id": "unique_egde_identifier_string",
          "source": "label A",
          "target": "label B",
          "label": "Showcase what comes from the source node, to the target node. Be concise and specific with labels, such as 'Ingested Data', 'Converted Text', 'User Query' etc. Use at max 5 words",
          "type" : "customEdge" //this is hardcoded and will be constant
        }
      ]
    }```
    </output_format>
    """
    return system_prompt, user_prompt
  

def erd_generation(services_data, icons_metadata):
  tables_metadata = []
  for entry in services_data:
      table_name = entry["table_name"]
      ddl = entry["ddl"]
      columns, primary_keys, foreign_keys = parse_ddl(ddl)
      tables_metadata.append({
          "table_name": table_name,
          "columns": columns,
          "primary_keys": primary_keys,
          "foreign_keys": foreign_keys
      })

  dot = generate_combined_graph(tables_metadata)

  system_prompt:str = """
    You are tasked with creating a JSON structure for a ReactFlow diagram based on the given database ER diagram and schema JSON. This JSON includes information about database columns and their relationships.Your output should represent this information as a network of nodes and edges.
    </Task>
    
    <Icons Context>
      $icons_metadata = """ + str(icons_metadata) + """
    </Icons Context>

    <Instructions>
      You are a solution expert, specializing in problem and solution flows. You will be given the database schema information of a database, and your task is to create an interconnected single component of graph which is detailed, and intuitive and self explanatory for:

      Follow these guidelines:
      1. Create nodes for each unique service (both external and third-party).
      2. Do not create any group nodes.
      4. In the data key for each service node, include two additional fields called group and subgroup. The group field should contain the logical group name (e.g.,Databases, etc..), and the subgroup field should provide more specific categorization (e.g., 'Transactional Tables', 'Reference Tables' etc..). For example, for a service node representing daily transactions, the group would be Database and the subgroup would be Transactional Tables.
      5. For each node, check which icon will be the most suitable from the $icons_metadata in the <Icons Context>
      6. Ensure all information from the input is represented in the output.
      7. The position coordinates must be proper for all the nodes.
    </Instructions>

    <Rules>
      Important Rules to be followed:
      1. Give detailed technical architecture flow and the JSON object following the below output format.
      2. Make sure that the flow and order of new solution approach is explained well in the graph with appropriate edges. Use as many edges you want to describe the data and user flow properly.
      3. The whole user and data flow should be clear.
      4. Do not add unnecessary nodes and edges. Do not create duplicate nodes that perform same task.
      5. Make the Node descriptions detailed, breaking tasks into multiple sub-tasks if needed.
      6. Ensure your edges show the actual flow, and not just connections of what's related. The connections are meant to show the logical flow, and not the relatedness/similarity.
      7. The group name is meant to classify clusters of nodes within each graph. For instance, if we have multiple nodes in features, they would all have "feature" as group. In Architecture Flow, the "Group" should show the layer each node is in, for instance "Database Layer" etc.
      9. for a hierarchy of nodes A -> B -> C; ensure that there is not a connection between A -> C.
    </Rules>
    
    <output_format>
    The output should be in between the delimeters ```reactflow and ```. Only provide the json output. Don't give unnecesary explanation.
    ```reactflow
    {
      "nodes": [
        { 
          "id": "unique_node_identifier_string",
          "data" : {
            "label": "name_of_the_table",
            "description": "description of the table",
  	    "columns": ["order_id [PK]", "product_sku [PK]", "quantity", "unit_price"]
            "group": "name_of_group",  // Add the logical group name (e.g., "Database", etc..)
            "subgroup": "name_of_subgroup",  // Add a more specific subgroup name (e.g., 'Transactional Tables', 'Reference Tables', etc..)
            "service": "filename" //taken from the $icons_metadata,
          }
          "position":{ "x": "Xcoordinate", "y": "Ycoordinate" },
          "type" : "customNode" //this is hardcoded and will be constant
        }
      ],
      "edges": [
        {
          "id": "unique_egde_identifier_string",
          "source": "label A",
          "target": "label B",
          "label": "Showcase what comes from the source node, to the target node. Be concise and specific with labels, such as 'Ingested Data', 'Converted Text', 'User Query' etc. Use at max 5 words",
          "type" : "customEdge" //this is hardcoded and will be constant
        }
      ]
    }```
    </output_format>
    """
    
  user_prompt:str = f"""
    <Input>
    $database_tables = {dot}
    $icons_metadata
    </Input>

    <Role>
    You are an expert at understanding database architecture based on ER diagrams and relational structures. Create a JSON structure for a ReactFlow diagram based on the given database schema.
    </Role>
    <Output Structure>
      1. Create a JSON object with a "nodes" and "edges" array.
      2. Create nodes for each table in the schema.
      3. "nodes": An array containing all node objects.
      - "id": A unique string identifier for the node.
      - "data":  
        - "label": The name of the table.
        - "description": A brief summary of the table's role or content.
        - "columns": List of column names (mark primary keys with [PK], foreign keys with [FK]).
        - "group": The logical group name (e.g., 'Database').
        - "subgroup": The specific subgroup within the group (e.g., 'Transactional Tables', 'Reference Tables').
        - "service": The appropriate filename of the icon based on the $icons_metadata.
      - "position" : The x and y coordinates of the node.
      - "type" : "customNode" This should be fixed.
      4. "edges" : An array having id, source, target, label, and type should be customEdge always.
      5. The label of the edge should describe the relationship, like "order_id â†’ order_id". 
      6. The output should be in the form of a dictionary containing a "nodes" and "edges" array.
      7. Present only the code inside delimiters "```reactflow [reactflow CODE]```" without any additional explanation.
    """
    
  return system_prompt, user_prompt
    

def feature_summary_generation(formatted_data, user_mvf, executive_summary):
    # if input_type is None:
    #     formatted_data = file_summary_list
    # elif input_type == "batch_summary":
    #     formatted_data = format_batchwise_summary_metadata_for_services(file_summary_list)
    # else:
    #     formatted_data = format_file_summaries(file_summary_list)

    user_prompt = """
    Role: You are an AI code analyst specializing in creating concise, feature-level summaries of codebases.

    Objective: Provide a comprehensive yet concise feature-level summary of a given codebase, highlighting key components, functionality, and the project's overall workflow.

    Input: You will receive information about a codebase, which may include an executive summary or other project details.

    Steps:
    1. Analyze the provided codebase information.
    2. Identify the main features (maximum 5) of the project from the executive summary (if provided in same order)
    3. Create a summary following the specified format, including:
        a. An overview of the project
        b. A list of key features with brief descriptions
        c. A closure statement
    4. Self-evaluate the generated summary and assign a confidence score.
    5. Format the output as specified in the instructions.

    Output Format:
    ```json
    {
        "data": "generated_summary in string format adhering to the Detailed Instructions for Output Format",
        "confidence_score": 90
    }
    ```

    Detailed Instructions for Output Format:

    **Overview**
    <empty line>
    < 
        Summarize all features in 2-3 sentences, introducing the project and its purpose.
        Provide a 2-3 sentence summary of key benefits, highlighting core architecture and value proposition.
    >
    <empty line>
    **Key Features**
    <empty line>
    <   
        List a maximum of 5 main features.
        For each feature, provide up to 2 sub-points describing its functionality.
        Ensure clear explanation of how features interact and contribute to the project's goals.
        1. ***<Key Feature Title>*** : 
        * <Sub point 1 description>
        * <Sub point 2 description>
        <empty line>
    >
    <empty line>
    < 
        Summarize the overall impact and value proposition of the project in one sentence as a conclusion statement.
    >
    <empty line>
    
    -> Self-Evaluation:
        - Score the summary out of 100 based on clarity, precision, detail, knowledge, accuracy, technical correctness, and understanding of the data.

    -> Formatting Requirements:
        - Replace all newline characters (\n) with \\n in the JSON output.
        - Ensure the complete JSON is less than 7500 tokens.
        - Start the output with "```json" and end with "```".
        - If an executive summary is provided, use only the highlighted features from it.

    Example Output Structure:
    ```json
    {
        "data": "**Overview**\\n\\n[Project overview]\\n\\n[Benefits summary]\\n\\n**Key Features**\\n\\n1. *Feature 1*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n2. *Feature 2*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n[...continue for up to 5 features...]\\n\\n[Closure statement]",
        "confidence_score": 90
    }
    ```

    Remember: Adhere strictly to the output format and instructions to maintain consistency and accuracy in your summary.
    """

    user_prompt += "User Defined Features : " + str(user_mvf)

    system_prompt = f"""
        <role>
        You are an assistant to a Senior Software Engineer. You are very capable in reading and understanding huge codebases.
        There is no edge-case, no mistake, no functionality no matter how small goes unnoticed by you.
        You will be given a large codebase and be asked queries regarding it.
        </role>

        <Task>
        You will be given relevant files from a production codebase. The Senior Engineer will consult you to clear his doubts and ask for critical code-level and functionality level analysis of the same.
        <Important>
        1. You will be clear. Feel free to be descriptive but Avoid Jargon
        2. You shall perform critical analysis on the code before responding.
        3. Note that the codebase will be quite complex and have dependencies everywhere, be mindful of them all.
        4. Enclose code in (triple backticks)``` code ```
        </Important>
        </Task>

        Files from Codebase goes here :
        <Repo Structure>
        {formatted_data}
        </Repo Structure>
    """

    start_index = executive_summary.find("Highlighted Features")
    end_index = executive_summary.find("Key Benefits")

    if start_index != -1 and end_index != -1:
        executive_summary = executive_summary[start_index:end_index].strip()

    user_prompt += "Executive Summary : " + str(executive_summary)

    return system_prompt, user_prompt

def feature_summary_generation_db(formatted_data, user_mvf, executive_summary):
    # if input_type is None:
    #     formatted_data = file_summary_list
    # elif input_type == "batch_summary":
    #     formatted_data = format_batchwise_summary_metadata_for_services(file_summary_list)
    # else:
    #     formatted_data = format_file_summaries(file_summary_list)

    user_prompt = """
    Role: You are an AI Database Analyst specializing in creating concise, feature-level summaries of complex database schemas and architectures.

    Objective: Provide a comprehensive yet concise feature-level summary of a given database schema information, highlighting key components, entities, relationships, and the overall data architecture workflow.

    Input: You will receive information about a database design, which may include an executive summary or other schema-level details.

    Steps:
    1. Analyze the provided database schema information.
    2. Identify the main features (maximum 5) of the database from the executive summary (if provided in same order)
    3. Create a summary following the specified format, including:
        a. An overview of the database
        b. A list of key features with brief descriptions
        c. A closure statement
    4. Self-evaluate the generated summary and assign a confidence score.
    5. Format the output as specified in the instructions.

    Output Format:
    ```json
    {
        "data": "generated_summary in string format adhering to the Detailed Instructions for Output Format",
        "confidence_score": 90
    }
    ```

    Detailed Instructions for Output Format:

    **Overview**
    <empty line>
    < 
        Summarize all features in 2-3 sentences, introducing the database and its purpose.
        Provide a 2-3 sentence summary of key benefits, highlighting schema structure, normalization or denormalization logic, and value proposition in handling data.
    >
    <empty line>
    **Key Features**
    <empty line>
    <   
        List a maximum of 5 main features.
        For each feature, provide up to 2 sub-points describing its data handling, relationships, or optimization logic.
        Ensure clear explanation of how features contribute to performance, consistency, and data integrity.
        1. ***<Key Feature Title>*** : 
        * <Sub point 1 description>
        * <Sub point 2 description>
        <empty line>
    >
    <empty line>
    < 
        Summarize the overall impact and value proposition of the database in one sentence as a conclusion statement.
    >
    <empty line>
    
    -> Self-Evaluation:
        - Score the summary out of 100 based on clarity, precision, detail, knowledge, accuracy, technical correctness, and understanding of the schema information.

    -> Formatting Requirements:
        - Replace all newline characters (\n) with \\n in the JSON output.
        - Ensure the complete JSON is less than 7500 tokens.
        - Start the output with "```json" and end with "```".
        - If an executive summary is provided, use only the highlighted features from it.

    Example Output Structure:
    ```json
    {
        "data": "**Overview**\\n\\n[Database overview]\\n\\n[Benefits summary]\\n\\n**Key Features**\\n\\n1. *Feature 1*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n2. *Feature 2*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n[...continue for up to 5 features...]\\n\\n[Closure statement]",
        "confidence_score": 90
    }
    ```

    Remember: Adhere strictly to the output format and instructions to maintain consistency and accuracy in your summary.
    """

    user_prompt += "User Defined Features : " + str(user_mvf)

    system_prompt = f"""
        <role>
        You are an assistant to a Senior Data Architect. You are very capable in reading, analyzing, and understanding complex database schemas and data models.
        No entity, constraint, relationship, or optimization logic goes unnoticed by you.
        You will be given a comprehensive database structure or schema information and will be asked to analyze, explain, and summarize it at a structural and functional level.
        </role>

        <Task>
        You will be given relevant database schema files or DDL definitions. The Senior Data Architect will consult you to clear doubts and ask for critical schema-level and data model-level analysis.
        <Important>
        1. You will be clear. Feel free to be descriptive but Avoid Jargon
        2. Perform a critical and deep analysis of the schema and the information given before responding.
        3. The schema will often involve multiple tables, foreign keys, views, procedures, and indexing strategies â€” be mindful of their dependencies and relationships.
        4. Enclose code or schema in (triple backticks)``` code ```
        </Important>
        </Task>

        Files from Database schema goes here :
        <Database Structure>
        {formatted_data}
        </Database Structure>
    """

    start_index = executive_summary.find("Highlighted Features")
    end_index = executive_summary.find("Key Benefits")

    if start_index != -1 and end_index != -1:
        executive_summary = executive_summary[start_index:end_index].strip()

    user_prompt += "Executive Summary : " + str(executive_summary)

    return system_prompt, user_prompt


#FEATURE HIERARCHY:
generate_features_system_prompt = """
  <Role>
    You are a Software Architect with expertise in analyzing large summaries from code files of an application. 
    You can comprehend summaries from code files that are complex, production-grade and are written in various programming languages to generate most important features, their description and the subfeatures with their description belonging to the most important features along with the other relevant information requested below.
    
    You will follow 2 Events before responding : 
    1. Generation of Feature Hierarchy as given in "Output_Format".
    2. Critical Evaluation of Every Confidence Score.  
  </Role> 

    <Task 1>
    You are provided with multiple relative file paths and file-wise code summaries from a application codebase.
    1. Analyze the file summaries carefully, leveraging your expertise to deduce the frameworks, functionality, and features.
    2. Perform a critical assessment of the code's functionality and interdependencies before responding.
    3. The codebase is complex and likely contains dependencies across various modules. Be mindful of these.
    4. Analyse every file summary and assign the features and sub-features based on the information provided.
    5. Respond strictly in the structured JSON format provided below.
    6. In each sub-feature's 'file_path' array:
        - Set 'critical: true' ONLY for files that are CORE & NON-REPLACEABLE to the sub-feature's main functionality.
        - Set 'critical: false' for ALL supporting, secondary, or replaceable files  
        - Each sub-feature should have both true and false entries.
        - If unsure, default to false (be EXTREMELY selective with 'true')
        - Make sure each sub-feature atleast have one file as true.

    Explanation of the Output terms:
    Feature - Features are most valuable and high level features extracted from the list of summaries that are provided to you. 
    Feature description - Description of the features explaining the high level value and impact that it creates for the project. Define the Feature. The description should be crisp, precise, well formatted and must be between 2-3 lines.
    Subfeature - Subfeatures are micro most valuable features that are extracted from the list of summaries and belong to the Most related and similar Features.
    Subfeature description - Description of the subfeatures explaining the specific value, technical and non-technical functionalites that it provided to the project. Define the subfeature and also explain how its related to the feature. The description should be crisp, precise, well formatted and must be between 2-3 lines.
    
    Points to Remember:
    1. Do not extract any feature or subfeature where there are no reference/citations from the application summaries.
    2. The description must be precise, valuable, well-formatted and must be between 2-3 lines.
    3. The Feature titles should be precise, specific, self explanaible, independent and not have similar feature titles. The Feature titles should not be highly generalized.
    4. The SubFeatures titles should be precise, self explanaible and not have similar subfeature titles. The SubFeature titles should not be highly generalized.
    5. SubFeatures should not be very low level that it explains code functions, code process like 'Json handling', 'Reading csv', readME etc.
    6. If similar subfeatures are present, then group them under one common Feature itself. Do not create multuple Features for similar subfeatures.
    6. If Unit testing related summaries are found, then create that as another Feature named 'Unit Testing' and assign the specific testing subfeatures under this feature.
    </Task 1>

  <Task 2>
  You shall now Assign and Justify Confidence Scores for each feature.

  <Critical Evaluation of Confidence Scores> 

  <Evaluation MODE>
  - You will now Forget everything that was done beforehand and act as an unbiased judge.
  - $Project-Summaries-&-Paths (INPUT).
  </Evaluation MODE>
  <Important>
  Critically analyze every "Feature" and "SubFeature" based on the following metrics. 
  You shall generate a confidence score between 0-100 for each of the following :
  1. Is the "Feature" & "SubFeature" name accurate to its functionality ? (Accuracy)
  2. Does the "Feature" & "SubFeature" include files with an unrelated function ? (Feature Dilution Rate)
  3. Important : Does this "Feature" & "SubFeature" make sense given the Overall Purpose of the Application ? (Consistency)
  4. Are all the files in "Feature" & "SubFeature" included ? (Completeness)

  <Strict>
  1. You will now generate a list of 4 confidence scores between 0-100 for above criteria under "confidence_score" key.
  2. Based on above criteria, you shall provide a VERY BRIEF logical explanation (10-20 words) for Confidence Score under "confidence_score_justification" key.
  3. Make sure to mention the entire filepath without omitting the prefix.
  4. Make sure all the filepaths are present.
  <Important> STRICTLY Don't Comment on Missing Files. Don't Overestimate. Don't Underestimate.</Important> 
  </Strict>

  </Important>

  </Critical Evaluation of Confidence Scores> 
  </Step 2>


      <Output_Format>
    Return a response in JSON format. Do not include any extra information or explanations. Strictly DON'T deviate from mentioned KEYS.
    Example:
```json
[
  {
    "name": "User Authentication and Management",
    "feature_description": "Comprehensive user account system with secure login, registration, profile management, and role-based access control.",
    "feature_description_confidence_score": [95, 70, 100, 70],
    "sub_features": [
      {
        "name": "User Registration",
        "description": "Allows new users to create accounts by providing necessary information such as username, email, and password. Implements email verification, password strength checks, and duplicate account prevention. Stores user data securely in the database with password hashing.",
        "file_path": [
          {
            "module_name": "RegistrationController",
            "path": "Controllers/Account/RegistrationController.cs",
            "critical": true
          },
          {
            "module_name": "RegisterView",
            "path": "Views/Account/Register.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [75, 80, 85, 65],
        "sub_feature_confidence_score_justification": "No feature dilution, might have missed some file."
      },
      {
        "name": "User Login",
        "description": "Authenticates users using their credentials, creates and manages user sessions, and implements security measures such as login attempt limiting and two-factor authentication (2FA). Provides password reset functionality for forgotten passwords.",
        "file_path": [
          {
            "module_name": "LoginController",
            "path": "Controllers/Account/LoginController.cs",
            "critical": true
          },
          {
            "module_name": "LoginView",
            "path": "Views/Account/Login.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [80, 100, 80, 75],
        "sub_feature_confidence_score_justification": "High chance of missing files."
      }
    ],
    "feature_confidence_score_justification": "No feature dilution, duplication or missing files. Accurate Naming."
  },
  {
    "name": "Product Catalog Management",
    "feature_description": "Comprehensive system for managing product listings, categories, and inventory across the e-commerce platform.",
    "feature_description_confidence_score": [95, 65, 70, 80],
    "sub_features": [
      {
        "name": "Product CRUD Operations",
        "description": "Enables administrators to create, read, update, and delete product listings. Includes functionality for managing product details such as name, description, price, images, and inventory levels. Implements validation to ensure data integrity and consistency across the product catalog.",
        "file_path": [
          {
            "module_name": "ProductController",
            "path": "Controllers/ProductController.cs",
            "critical": true
          },
          {
            "module_name": "ProductView",
            "path": "Views/Product/Index.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [90, 85, 100, 70],
        "sub_feature_confidence_score_justification": "High confidence with no duplication or dilution."
      },
      {
        "name": "Category Management",
        "description": "Allows for the creation and management of product categories and subcategories. Implements a hierarchical structure for organizing products, enabling efficient navigation and filtering of the product catalog for both administrators and customers.",
        "file_path": [
          {
            "module_name": "CategoryController",
            "path": "Controllers/CategoryController.cs",
            "critical": true
          },
          {
            "module_name": "CategoryView",
            "path": "Views/Category/Index.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [85, 75, 90, 95],
        "sub_feature_confidence_score_justification": "High confidence without any duplication or dilution."
      }
    ],
    "feature_confidence_score_justification": "All files refer to single overall functionality. Might have missed some files."
  }
]
```
  </Output_Format>

"""

generate_features_user_message = """
<Strictly Remember>
1. As input you will be given a batch of `file_path` and `file_summary` from a production codebase. Keep it in mind that it could be a file from a very large repository with lot of inter-dependencies.
2. Understand all the file description first, then try to determine the feature, sub-features and their description. For **each file** it should have a feature or sub-features whenever the conditions are met.
3. The response should contain all the fields given in the example output format. The response should be strictly in json format.
4. The description of features/subfeatures must be in the length of 2-3 lines. The response should be structured and well-formatted.
5. Don't generate any additional explanation or description. Provide the structured response in json only.
</Strictly Remember>
  
<Input file wise summary>
{file_summary}
</Input file wise summary>
<Response>
"""

merge_features_in_hierarchy_user_prompt = """You are a software feature analyzer. Given a list of related features that have been clustered together, create a merged feature that encompasses all the functionality.

Features to merge:
{feature_list}

Generate a JSON response that includes:
1. A name for the merged feature representing accurate feature name. Do not mention its merged or unified or anything as such. The feature name should accurately represent a major funcationality of a repository.
2. A detailed description that covers all functionality
3. A confidence score (0-100) for the merge
4. A justification for the confidence score

Respond with a JSON object in the following format:
```json
{{
    "name": "Merged feature name",
    "description": "Comprehensive description",
    "confidence_score": 85,
    "confidence_justification": "Reason for the confidence score"
}}
```
Give only JSON and nothing else. Do not include any explanations or additional text outside the JSON block. Make sure to start with ```json and end with ``` only.
"""

mapping_names_for_merged_features_user_prompt = """  <Role>
    You are a smart AI cassistant with strong expertise in Software Engineering. You can understand complex, production-grade codebases written in various programming languages and summarize them effectively.
  </Role>
  <Task>
  You will be given a brief description of  features of a large codebase and your task is to generate a relevant feature name, brief description, and priority level.
  <Important>
   1. The feature name should be brief, relevant and should represent the entire description provided.
   2. Generate a relevant description which is basically a overall summary of the description provided.
   3. Assign a priority level (high, medium, low) based on the significance, importance and complexity of the feature to the overall system. 
  </important>
  </Task>
  <Example output>
  ```json
    {
        "name": <feature_name>, //string
        "feature_description": <feature_description>, //string
        "priority": <priority> //string (high, medium, or low)
    }
    ```
  </Example output>
  <Strictly Remember>
1. The feature name should be relevant and at the same time interpretable, easy to understand.
2. The feature description should represnt the entire description given for summarisation, it should be simple and easy to understant.
3. The priority should be one of: high, medium, or low.
4. The response should be strictly in json format specified above.
5. Strictly make sure Feature Description is not more than 200 words.
  </Strictly Remember>

<code summary>
The code summary is given below:
"""


reducing_sub_features_user_prompt = """
    You are a software feature consolidation expert. Your task is to merge similar sub-features into one comprehensive sub-feature.

    Here are the sub-features that need to be merged:
    {sub_features_list}

    For each sub-feature, we have:
    - Name: The sub-feature name
    - Description: The sub-feature description (if available)
    - Confidence Score: The confidence score (if available)

    Your output should be a JSON object containing:
    1. A unified sub-feature name that encompasses all the input sub-features
    2. A comprehensive description that covers all aspects of the input sub-features
    3. A confidence score (use the highest available from input sub-features)
    4. A justification for the confidence score

    Return the output in JSON format starting with ```json and ending with ```.

    Example output format:
    ```json
    {{
        "name": "Unified Sub-Feature Name",
        "description": "Comprehensive description covering all aspects",
        "sub_feature_confidence_score": 95,
        "sub_feature_confidence_score_justification": "Merged from similar sub-features with high semantic similarity"
    }}
    ```
    """


post_processing_feature_name_description_system_prompt="""
  <Role>
    You are a smart AI assistant with strong expertise in Software Engineering. You can understand complex, production-grade codebases written in various programming languages and summarize them effectively.
  </Role>
  <Task>
  You will be given a brief description of modules or features of a large codebase and your task is to generate a relevant feature name and brief description.
  <Important>
   1. The feature name should be brief, relevant and should represent the entire description provided.
   2. Generate a relevant description which is basically a overall summary of the description provided.
   3. Also generate a confidence score in a scale of 0 - 100.
  </important>
  </Task>
  <Example output>
  ```json
    {
        "name": <feature_name>,
        "feature_description_confidence_score": <score 0 - 100>,
        "feature_description": <feature_description>
    }```
  </Example output>"""

post_processing_feature_name_description_user_prompt = """<Strictly Remember>
1. The feature name should be relevant and at the same time interpretable, easy to understant.
2. The confidence score should represent the ability to summarise the description.
3. The feature description should represnt the entire description given for summarisation, it should be simple and easy to understant.
4. The response should be strictly in json format specified above.
</Strictly Remember>
<code summary>
The code summary is given below: \n
{feature_description}
</code_summary>
<response>
Your response in json goes here:
"""

merge_similar_features_system_prompt = """You are a solution architect. Your task is to carefully review each feature and its description, and combine them into a single high-level feature.

The final high-level features should represent what an end user would perceive, e.g., Messenger, Google Chat, Messaging, Reels, etc.

Based on the generated features provided, identify which features can be merged into a single high-level feature. 
Strictly output them in the following format:
{{ 
  <High-Level Feature Name 1>: [<Merged Feature 1>, <Merged Feature 2>, <Merged Feature 3>, ...],
  <High-Level Feature Name 2>: [<Merged Feature 1>, <Merged Feature 2>, <Merged Feature 3>, ...],
  ...
}}

INPUT:
Feature names and descriptions are provided in the format: 
[1. Feature name: <feature name> 
Feature description: <feature description>, 
2. ...]

{feature_texts}

MVFS:
{total_MVFs}

Points to remember:
1. While merging features and naming high-level features, always prefer names from the user-defined MVFs provided. All relevant features can be grouped under these high-level features.
2. If certain features do not fit under the user-defined MVFs, choose a better name than the existing one for the new high-level feature if necessary.
3. The names of the features being merged must remain exactly as provided in the INPUT section; do not modify them. Do not consider Feature description in Feature Names.
4. Follow the output structure strictly: high-level feature names as dictionary keys and merged features as values in list format.
5. If a feature is already a high-level feature, you do not need to forcibly merge it. If a feature seems to be function-level/low-level  features, merge them into a High-level feature.
6. Merge similar features into a single high-level feature based on their names and descriptions, when applicable. Each final high-level feature should be independent of the others.
7. Do not assign the same feature to multiple high-level features.
8. If user-defined MVFs are empty, skip point 1 and begin with point 2.
9. Do **not** include any Feature descriptions in the final output."""


merging_description_user_prompt = """You are a Solution Architect. Your task is to summarize the multiple feature descriptions provided into a brief, coherent summary of **no more than two sentences**.

  The summary must:
  - Accurately capture all key components from the provided descriptions.
  - Align clearly with the given high-level feature name.
  - Serve as the final description of the high-level feature.

  Only the final summarized description should be included in the output â€” no additional commentary or formatting.

  INPUT:
  Multiple descriptions: {merging_feature_description}

  High-Level Feature Name: {high_level_feature}
  """


micro_sub_feature_prompt = """You are an expert system analyst specializing in decomposing SubFeatures into granular, logically independent components. You support **two levels** of splitting:

1. **Horizontal splitting**: Split a subfeature into multiple *same-level subfeatures* when it encompasses multiple independently meaningful functionalities. The subfeatures created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.
2. **Vertical splitting**: Further break each of those subfeatures into *microsubfeatures* (if applicable), ensuring each micro-sub-features/micro-user-story describes a single goal or operation. The micro-sub-features/micro-user-story created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.

---

### ðŸ”§ TASK OVERVIEW

Given a Macro-Feature, Subfeature, its description, associated module files and its summary:

- Decide if the subfeature should be split horizontally into multiple same-level subfeatures.
- For each resulting subfeature (or original if not split), analyze whether it can be split vertically into **microsubfeatures** (fine-grained user stories).
- Provide the confidence scores for the subfeature that is split, whether horizontally or vertically.
- Provide the files that are related to the sub_features too, not just the micro_sub_features.
- Each leaf user-story must have files assigned to them, else you should not create/split these subfeatures.
- Provide description of generated subfeature/sub-user-stories in 2-4 lines but only valid information. Do not assume or hallucinate to generate description.
Apply this recursively: if horizontal splitting occurs, then attempt vertical splitting for each. But remember, not to create any duplicates in the process. 

---

### SPLITTING DECISIONS

#### Horizontal Splitting (Same-level Subfeatures):
Split if:
- The subfeature covers multiple high-level functionalities
- Each function could be planned, developed, and deployed independently
- Each component has a clear boundary and responsibility

#### Vertical Splitting (Microsubfeatures):
Split further if:
- A subfeature contains multiple independent operations or logical stages
- These operations can be implemented, tested, or tracked separately
- Each micro-subfeature represents one atomic, non-overlapping functionality

---

### DO NOT SPLIT IF:
- sub-user-stories are tightly coupled in the Subfeature and cannot function independently.
- Do not split subfeatures into sub-user-stories that are hardly single line of code and cannot be considered as a proper functionality, but just a config/parameter.
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across actions are too complex to isolate.
- There are no files that can be mapped to the generated user-story.
- Do not split if the user-story is barely a functionality. The split user-stories must have independent functionality that contributes to the subfeature and feature and if not, do not split.
- Don not split ReadMe & .md files into sub-user-stories.
- Do not split horizontall for granullar subfeatures as they are not user stories but mid level features.
---

### FILE MAPPING RULES:
- For each subfeature or microsubfeature, cite only directly relevant files.
- Use only the provided input data to match files â€” no guessing.
- Avoid duplication unless a file is clearly shared between components.

Each `file_path` entry must include:
```json
{
  "module_name": "<Name>",
  "path": "<Path>",
  "critical": <true/false>,
  "git_url": "<Git URL>"
}

OUTPUT FORMAT
If the subfeature should NOT be split:
Return: "None"

If the subfeature should be split, return a list of Parent User Stories with subfeatures inside.
If a subfeature itself can be further split into microsubfeatures, nest them under micro_sub_features like so:

[
  {
    "name": "Parent User Story Title 1",
    "description": "Full description of the original or updated user story and its purpose.",
    "file_path": [...],
    "sub_feature_confidence_score":"confidence score of the subfeature with respect to the Feature, as a percentage (e.g., 80)"
    "micro_sub_features": [
      {
        "name": "Sub-User Story Title 1",
        "description": "Standalone description of a single functionality.",
        "file_path": [...],
        "micro_sub_feature_confidence_score":"confidence score of the micro_sub_feature with respect to the sub_feature, as a percentage (e.g., 90)"
        }
          ...
        ]
      },
      ...
    ]
  }
]
Each layer must preserve independence, clarity, and singular focus of each story.

VALIDATION CHECKLIST
- Each title must express one functionality only (no imperative phrasing)
- description must avoid assumptions and describe the real function. It must be as detailled as possible.
- Each story must make sense independently and fit in the broader feature flow
- if there are multiple user-story under the subfeature, it needs to be in sequence of business logic.
- File mappings must be relevant and scoped accurately
- Do no miss/skip any values in the output json. The output structure must be maintained strictly.
- All subfeature and sub-user-story names and descriptions must be strictly in a declarative tone, not imperative.

* Use generic or speculative statements
"""


db_micro_sub_feature_prompt = """
<Role>
You are an expert Database analyst specializing in decomposing SubFeatures into granular, logically independent components. You support **two levels** of splitting:
You shall ALWAYS process features from a Database perspective ONLY. 
There can be more than one Table in the DB context provided to you.
</Role>

1. **Horizontal splitting**: Split a subfeature into multiple *same-level subfeatures* when it encompasses multiple independently meaningful functionalities. The subfeatures created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.
2. **Vertical splitting**: Further break each of those subfeatures into *microsubfeatures* (if applicable), ensuring each micro-sub-features/micro-user-story describes a single goal or operation. The micro-sub-features/micro-user-story created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.

<Strict Constraints> 
- You are dealing with Database Information. 
- No matter what, STRICTLY use Database-Specific Language ALWAYS. 
- Use words like Columns / Fields / Schema / DataTypes / Constraints / Foreign Keys / Primary Keys etc.
- Strictly Do not start descriptions with or start with "this micro-feature" / or "this sub-feature".
- You shall do this regardless of the input context and nature.
Remember : Every "FILE" given to you is information of a table. Therefore in your response, ALWAYS refer to "Table" instead of "File".

</Strict Constraints> 


### ðŸ”§ TASK OVERVIEW

Given a Macro-Feature, Subfeature, its description, associated module files and its summary:

- Decide if the subfeature should be split horizontally into multiple same-level subfeatures.
- For each resulting subfeature (or original if not split), analyze whether it can be split vertically into **microsubfeatures** (fine-grained user stories).
- Provide the confidence scores for the subfeature that is split, whether horizontally or vertically.
- Provide the files that are related to the sub_features too, not just the micro_sub_features.
- Each leaf user-story must have files assigned to them, else you should not create/split these subfeatures.
- Provide description of generated subfeature/sub-user-stories in 2-4 lines but only valid information. Do not assume or hallucinate to generate description.
Apply this recursively: if horizontal splitting occurs, then attempt vertical splitting for each. But remember, not to create any duplicates in the process. 

---

### SPLITTING DECISIONS

#### Horizontal Splitting (Same-level Subfeatures):
Split if:
- The subfeature covers ONE / MORE THAN ONE high-level functionalities
- Each function could be planned and developed independently
- Each component has some clear boundaries and responsibilities

#### Vertical Splitting (Microsubfeatures):
Split further if:
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across actions are too complex to isolate.
- There are no tables that can be mapped to the generated user-story.
- The subfeature is too complex to be planned, developed, and deployed independently
- Each micro-subfeature represents one atomic, non-overlapping functionality
Note: Maintain at least 2 subfeatures unless the database has only one table.
- Prioritize brevity, consistency and no informaiton leakage across subfeatures.
- Ensure crisp segregation.
---

### DO NOT SPLIT IF:
- sub-user-stories are tightly coupled in the Subfeature and cannot function independently.
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across tables in two features are too complex to isolate.
- There are no tables that can be mapped to the generated user-story.
Note: Maintain at least 2 subfeatures and 1 or more microsubfeatures per subfeature, Unless the database has only one table.
Note : Maintain brevity during splitting at the same level. Do NOT overload the a single feature with too many subfeatures.
---


### FILE MAPPING RULES:
- For each subfeature or microsubfeature, cite only directly relevant tables.
- Use only the provided input data to match files â€” no guessing.
- Avoid duplication unless a file is clearly shared between components.

Each `file_path` entry must include:
```json
{
  "module_name": "<Name>",
  "path": "<Path>",
  "critical": <true/false>,
  "git_url": "<Git URL>"
}

OUTPUT FORMAT
If the subfeature should NOT be split:
Return: "None"

If the subfeature should be split, return a list of Parent User Stories with subfeatures inside.
If a subfeature itself can be further split into microsubfeatures, nest them under micro_sub_features like so:

[
  {
    "name": "Parent User Story Title 1",
    "description": "Full description of the original or updated user story and its purpose.",
    "file_path": [...],
    "sub_feature_confidence_score":"confidence score of the subfeature with respect to the Feature, as a percentage (e.g., 80)"
    "micro_sub_features": [
      {
        "name": "Sub-User Story Title 1",
        "description": "Standalone description of a single functionality.",
        "file_path": [...],
        "micro_sub_feature_confidence_score":"confidence score of the micro_sub_feature with respect to the sub_feature, as a percentage (e.g., 90)"
        }
          ...
        ]
      },
      ...
    ]
  }
]
Each layer must preserve independence, clarity, and singular focus of each story.

VALIDATION CHECKLIST
- Each title must express one functionality only (no imperative phrasing)
- description must avoid assumptions and describe the real function. It must be as detailled as possible.
- Each story must make sense independently and fit in the broader feature flow
- if there are multiple user-story under the subfeature, it needs to be in sequence of business logic.
- File mappings must be relevant and scoped accurately
- Do no miss/skip any values in the output json. The output structure must be maintained strictly.
- All subfeature and sub-user-story names and descriptions must be strictly in a declarative tone, not imperative.
- Use Database-specific schema only. Do not include words like "Attributes" / "Code Files" in your response. 
- Strictly Do not start descriptions with or start with "this micro-feature" / or "this sub-feature".
* Use generic or speculative statements

"""import os
from graphviz import Digraph
import re 
import json

def parse_ddl(ddl: str):
    """
    Parse the DDL to extract columns, primary keys, and foreign keys.
    """
    lines = ddl.splitlines()
    column_lines = []

    for line in lines:
        line = line.strip()
        if (
            line.upper().startswith("CREATE")
            or line.upper().startswith("PRIMARY")
            or line.upper().startswith("FOREIGN")
            or line.upper().startswith(")")
            or line == ""
        ):
            continue

        match = re.match(r'(\w+)\s+\w+', line)
        if match:
            column_lines.append(match.group(1))

    pk_match = re.search(r'PRIMARY KEY\s*\((.*?)\)', ddl)
    primary_keys = [key.strip() for key in pk_match.group(1).split(",")] if pk_match else []

    foreign_keys = []
    for match in re.finditer(r'FOREIGN KEY\s*\(([^)]+)\)\s+REFERENCES\s+`?[\w]+\.(\w+)`\(([^)]+)\)', ddl):
        fk_col = match.group(1).strip()
        ref_table = match.group(2).strip()
        ref_col = match.group(3).strip()
        foreign_keys.append((fk_col, ref_table, ref_col))

    return column_lines, primary_keys, foreign_keys


def generate_combined_graph(tables_data):
    """
    Generate a single combined graph from multiple tables.
    """
    dot = Digraph(comment='Combined Table Diagram')
    dot.attr(rankdir='LR')

    # Store individual table nodes
    for table in tables_data:
        table_name = table['table_name']
        columns = table['columns']
        primary_keys = table['primary_keys']
        
        label_lines = []
        for col in columns:
            if col in primary_keys:
                label_lines.append(f"{col} [PK]")
            else:
                label_lines.append(col)
        dot.node(table_name, shape='box', label=f'{table_name}\\n' + "\\n".join(label_lines))

    # Add relationships
    for table in tables_data:
        table_name = table['table_name']
        for fk_col, ref_table, ref_col in table['foreign_keys']:
            dot.edge(table_name, ref_table, label=f'{fk_col} â†’ {ref_col}')

    return dot

def folder_summary_generation_prompts(
        total_allocated_tokens, 
        file_list, folder_name, 
        folder_path,
        subfolder_list,
        formatted_file_summaries,
        formatted_file_services,
        formatted_subfolder_summaries,
        formatted_subfolder_services,
        formatted_subfolder_features
    ):
    
    system_prompt = f"""
        You are an expert code analyst specialized in creating detailed, informative summaries of software project folders. Your task is to thoroughly analyze files and subfolders to provide a comprehensive understanding of the application or project and provide combined summaries along with required details. These summaries must be detailled enough for further summarization.

        Follow these guidelines:
        1. Conduct a deep analysis of the features to identify its core purpose and functionality
        2. Provide detailed explanation of key implementations and technical approaches of the features
        3. Thoroughly examine the summaries based on files and folders to understand relationship between features and combined smaller features into larger high level application level features.
        4. Explain the features within the broader project architecture with specific connections
        5. Describe technical patterns, design decisions, and architectural choices evident in the code
        6. Include specific functions, classes, and methods that define the feature's behavior
        7. Note dependencies, imports, and external connections that shape the folder's functionality
        8. Identify potential architectural strengths and areas for improvement when evident
        9. Identify all services represented in this folder based on file and subfolder services information
        10. Identify and articulate high-level features or functionalities represented by the folder into the feature_details section, when consolidating multiple subfolders or lower-level files. Derive these insights from both file-level and subfolder-level summaries. Also under each feature, mention which file/folder was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
        11. Do not miss any features that could be formed based on these summaries as this information is required to understand the application's buisness logic.
        12. Gather insights from the summaries provided to generate a high level detailled executive summary that could be used by business stakeholders to understand the folder/project.
        13. When analyzing the root folder, both the executive summary and the features must be strictly formed in a high level business logic standpoint of an application.
        
        IMPORTANT: 
        - Your summary should be thorough and detailed({total_allocated_tokens}) while maintaining technical/business precision and depth. Focus on providing insights that would help both stakeholders and developers understand the application better.
        - feature_details must contain high level feature name and feature description(value of the files/folders) strictly in concise bullet points. The feature inforamtion must be in detail to capture the complete high level knowledge for that feature but not the function level details. Feature names cannot be programmatic function names like Dependency management, json handling etc. instead it should be inventory management, order processing etc. 
        - Your services list should be comprehensive and include all services represented in this folder.
        - is_reuasble_lib if a folder is used as reusable lib make it True otherwise False
        - lib_name if is_reusable_lib is True then provide the name of the reusable lib/component If is_reusable_lib False then add Not Applicable
        - category if is_reusable_lib is True then provide category only between 'Frontend' and 'Backend' If is_reusable_lib False then add Not Applicable
        - sub_category if is_reusable_lib is True then provide sub category only between 'UI Component','Custom Hooks', 'http_client', 'Utils', 'Others' In Frontend & 'Middleware', 'Error Handling', 'Auth', 'Utils', 'Others' In Backend If is_reusable_lib False then add Not Applicable
        - when_to_use if is_reusable_lib is True then provide where this reusable lib/component can be used If is_reusable_lib False then add Not Applicable 
        - associated_files if is_reusable_lib is True then provide the list of files associated(give complete path for the assosciated file) with this reusable lib/component If is_reusable_lib False then add Not Applicable
        - summary must not be technical and only explain the high level details of the folder/project. Understand the file and folder summaries provided to combine the knowledge to form the executive summary. Make it as detailled as possible.
        - Use clear and concise language, avoiding jargon where possible.
        
        - You must provide your response in this exact format:
        ```summary
        [Your detailled high-level executive summary for the folder for business stakeholders]
        ```
        ```feature_details
        [List of high-level features or functionalities represented in this folder]
        ```
        ```services_namess
        [Comma-separated list of all services represented in this folder]
        ```
        ```is_reuasble_lib
        Boolean Value
        ```
        ```lib_name
        [Name of the reusable library if applicable]
        ```
        ```category
        [Category of the reusable library if applicable]
        ```
        ```sub_category
            [Sub category of the reusable library if applicable]
        ```
        ```when_to_use
        [Your detailed use case where or when this reuasble_lib can be usefull]
        ```
        ```associated_files
            [Comma-separated list of associated files with the reusable library, Give the Complete file path as mentioned in the file list]
        ```
        ```example_usage
            [Example code snippet of how to use this reusable library]
        ```
    """

    user_prompt = f"""
        Generate a summary and services list for the folder: "{folder_name}" (Path: {folder_path})

        FOLDER CONTENTS:
        - Files ({len(file_list)}): {", ".join(file_list) if file_list else "None"}
        - Subfolders ({len(subfolder_list)}): {", ".join(subfolder_list) if subfolder_list else "None"}

        FILE SUMMARIES:
        {os.linesep.join(formatted_file_summaries) if formatted_file_summaries else "No file summaries available"}

        FILE SERVICES:
        {os.linesep.join(formatted_file_services) if formatted_file_services else "No file services available"}

        SUBFOLDER SUMMARIES:
        {os.linesep.join(formatted_subfolder_summaries) if formatted_subfolder_summaries else "No subfolder summaries available"}

        SUBFOLDER SERVICES:
        {os.linesep.join(formatted_subfolder_services) if formatted_subfolder_services else "No subfolder services available"}

        SUBFOLDER FEATURES:
        {os.linesep.join(formatted_subfolder_features) if formatted_subfolder_features else "No subfolder features available"}
        
        Based on these components:
        1. Provide a thorough technical summary explaining the folder's purpose, implementation details, and architectural significance
        2. Compile a comprehensive list of all services represented in this folder based on file and subfolder services information
        
        Follow the exact format specified in the system instructions for your response.
    """

    return system_prompt, user_prompt

def services_generation():
    system_prompt = """
        <Task>
        Create an architectural blueprint of the given repository by identifying and classifying both external services and third-party services with no overlap between categories.
        </Task>

        <Definitions>
        - External services: Company-provided services hosted outside the application (AWS S3, Google Cloud, Stripe, Twilio)
        - Third-party services: Libraries, frameworks, and SDKs that are part of the core application stack (Django, React, MongoDB, Redux)
        </Definitions>

        <Output_Format>
        {
        "external_services": [
            {
            "external_service_name": "string",
            "description": "string",
            "associated_files": ["string"],
            "service_class": "string",
            "used_in_files": ["string"]
            }
        ],
        "thirdparty_services": [
            {
            "thirdparty_service_name": "string",
            "description": "string",
            "associated_files": ["string"],
            "service_class": "string",
            "used_in_files": ["string"]
            }
        ]
        }
        </Output_Format>

        <Instructions>
        1. Conduct a thorough repository analysis to identify all services
        2. Classify each service into exactly ONE category:
        - External services: Cloud platforms, payment processors, authentication providers
        - Third-party services: Frameworks, libraries, SDKs integrated into the codebase
        3. For each service, provide:
        - Name: Exact service name
        - Description: Concise explanation of functionality and purpose
        - Associated files: All files directly importing or using the service
        - Service class: Category (e.g., "cloud storage", "web framework", "database")
        - Used in files: Complete paths of files utilizing the service
        4. Ensure ZERO overlap between categories
        5. Prioritize accuracy over comprehensiveness
        6. Validate that identified services are actively used in the project
        7. Include only services with clear evidence of implementation
        8. Do not create a lot of services which are redundant. Keep it to a maximum of 50 services only.
        </Instructions>

        <Examples>
        Good External Service Entry:
        {
        "external_service_name": "AWS S3",
        "description": "Cloud storage service used for storing user-uploaded files",
        "associated_files": ["src/services/storage.js", "src/config/aws.js"],
        "service_class": "cloud storage",
        "used_in_files": ["src/components/FileUpload.js", "src/pages/UserProfile.js"]
        }

        Good Third-Party Service Entry:
        {
        "thirdparty_service_name": "React",
        "description": "Frontend JavaScript library for building user interfaces",
        "associated_files": ["package.json", "src/index.js"],
        "service_class": "frontend framework",
        "used_in_files": ["src/App.js", "src/components/*.js"]
        }
        </Examples>

        Analyze the repository and provide the complete architectural blueprint in the specified format.
    """

    user_prompt = ""

    return system_prompt, user_prompt

def executive_summary_generation(combined_summary, user_mvf):
    system_prompt = """
    Your Role:
    You are an expert software architect tasked with understanding a codebase and creating an executive summary that clearly articulates the main purpose of this application,
    the core problem that the application is solving, and the prioritized list of the most valuable features, solely based on the provided folder wise summary. Do not hallucinate and create the most valuable features and its description on assumption. This needs to be based on facts.

    Task:
    1. Analyze provided folder wise summary and the services used and the user defined features (if provided).
    2. Understand component interactions and functions.
    3. Prioritize the User Defined Features (if provided) in the summary.
    4. Identify and prioritize the most valuable features based on their importance and relevance to the overall project, as evidenced in the code.
    5. Create a comprehensive executive summary.

    Steps:
    1. Review folder wise summary.
    2. Analyze folder wise summary:
    - Identify key components and their roles
    - Note data operations, design patterns, and architectural decisions
    3. Create summary:
    - Describe the specific problem the codebase solves, based on folder wise summary
    - Explain component interactions
    - Outline data workflow
    4. Identify and prioritize main features:
    - Determine which feature(s) address the core problem of the application, based on code implementation
    - Rank features based on their importance and relevance to solving the main problem, as evidenced in the code
    - The feature should be major components of the codebase and not minor functions like "Modular Architecture" or "Code Reusability", these are not features but design principles.

    Focus Areas:
    - Precised feature prioritization and importance
    - High-level functionality
    - Clear, concise technical language
    - Objective description
    - Capture entire workflow

    Guidelines:
    - Only use the folder wise summary provided
    - Use precise technical terms
    - Include user-defined features if provided and evidenced in the code
    - Prioritize features based on their importance to the core problem, as shown in the folder wise summary

    Feature Identification and Prioritization:
    - Carefully analyze the folder wise summary to identify features actually present in the folder wise summary
    - Do not assume or infer features that are not explicitly mentioned in the folder wise summary
    - Identify the top feature that solves the majority of the problem based on code evidence
    - Rank subsequent features in descending order of importance, ensuring they are present in the folder wise summary
    - Ensure the feature list reflects the codebase's focus and structure
    - Only include features that have substantial implementation in the codebase that is evident from folder wise summary

    Output Format - Adhering to this format is crucial
    ```json
    {
    "data": "generated_summary in string format adhering to the Expected Output Format for Generated Summary",
    "confidence_score": 90,
    "traceback": {
    "Feature 1 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 1 Title' is included, as the 'phrase' is an evidence that this feature is part of the codebase.",
    "Feature 2 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 2 Title' is included, as the 'phrase' is an evidence that this feature is part of the codebase.",
    ...
    }
    }
    ```

    Requirements:
    - Replace \n with \\n in JSON
    - Limit upto 5 main features (max 2 sub-features each) or 7500 tokens
    - If due to any reason such as codebase being small, you are unable to provide 5 features, then provide as many high-level features as possible between the range of 1 to 5.
    - Don't assume features or include minor features due to inability to provide 5 features, lesser number of features is acceptable.
    - Use specified JSON format only
    - Start with "```json" and end with "```"
    - Ensure the top feature in the prioritized list addresses the core problem and is present in the folder wise summary
    - Rank features in descending order of importance to the main problem, based on actual code implementation
    - Do NOT include features that are NOT evidenced in the provided folder wise summary
    - Evaluate the folder wise summary objectively, considering all conclusions on the actual code provided
    - Do NOT make any assumptions about organizational goals or intentions beyond what is explicitly shown in the code
    - Focus solely on the technical aspects and implemented functionality, avoiding speculation about business objectives or future plans
    - Both the keys data, confidence score, and traceback should be present in the output JSON
    - The generated summary should be in string format only and be contained inside the "data" key
    - The "traceback" key should contain a dictionary with feature names as keys and justifications for including these features based on exact phrases from the input
    - Do not include any feature that could potentially be part of the folder wise summary without explicit evidence
    - Every feature mentioned must be driven by clear evidence from the provided input
    """
    user_prompt = """
    Expected Output Format for Generated Summary:

  **Overview**
  <empty line>
  <A brief introduction to the codebase and its main purpose; in paragraph format only, not in points.
  This paragraph should provide a concise yet comprehensive overview of the codebase, its primary functionality, solution provided by the project and its intended use case.
  Aim for 3-5 sentences that capture the essence of the project.>
  <empty line>
  **Highlighted Features**
  <empty line>
  <
  List and briefly explain the key features that are significant components of the codebase and would serve as selling points.
  These features should be presented as follows:
  1. Use numbered points for each feature.
  2. Provide a brief explanation for each feature in 1-2 sentences, highlighting its importance and benefit to the end user.
  3. Focus on features that are central to the codebase's functionality and most important to the end user.
  4. Dont include generic features like "Modular Architecture" or "Code Reusability", these are not features but design principles.
  5. Do not include sub-points under any feature.
  6. Prioritize User Defined Features (if provided) at the beginning of the list.
  7. If User Defined Features are given, list them first before including any features identified through your analysis.
  8. Aim to provide upto of 1 to 5 key features, after each feature add an empty line for formatting purposes.
  9. Ensure that the features listed represent the core functionality and unique selling points based on the folder wise summary.
  10. Use clear, concise language that emphasizes the value proposition of each feature.
  11. Also under each feature, mention which file/folder was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
  12. Do not add features into Highlighted Features if they dont have value for buisness stakeholder about the application. Also do not repeat adding similar feature in this section.

  Output Structure:
  1. ***<Feature 1 Title>***: <Description of the feature in one to two sentences.\n
  2. ***<Feature 2 Title>***: <Description of the feature in one to two sentences.>\n
  >
  <empty line>
  **Key Benefits**
  <empty line>
  <Summarize the key benefits of the codebase in one to two sentences.
  This summary should encapsulate the overall value proposition of the codebase and its potential impact on users or the organization.>
  <empty line>
  <Highlight the most significant key benefits the codebase has to offer in bulleted points. The format should be:
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  Aim for 3-5 bullet points that capture the most compelling advantages of using this codebase, after each point add an empty line for formatting purposes.
  Each benefit should be distinct and provide a clear value proposition.>

  <Final Output Format>
  Output Format - Adhering to this format is crucial, the output should be in parsable JSON format:
  ```json
  {{
    "data": "<generated_summary in string format adhering to the Expected Output Format for Generated Summary>",
    "confidence_score": 90,
    "traceback": {{
      "Feature 1 Title": "Since it mentions about <exact phrase from the folder wise summary>, the 'Feature 1 Title' is included, as the "phrase" is an evidence that this feature is part of the folder wise summary.",
      "Feature 2 Title": "Since it mentions about <exact phrase from the folder wise summary>, the 'Feature 2 Title' is included, as the "phrase" is an evidence that this feature is part of the folder wise summary.",
      ...
    }}
  }}
  ```
  </Final Output Format>
  Note: If the traceback includes phrases that are not present in the folder wise summary then you would be penalized 10000 points.
  The output should be having data, confidence score, and traceback keys, and the entire content inside "```json" and "```" should be parsable by json.
  The "data" key should contain the generated summary and it should be in string format only, allowing the parsing of the entire json.
  If there are any inverted commas inside the generated summary, then escape them with a backslash.
  Do not change or skip the headings of each section in the generated json. The generated summary must have "Overview", "Highlighted Features", "Key Benefits" as section titles. Follow the above provided guidelines."""
    user_prompt += f"""Use the below folder wise summary to generate the summary in the above format: {combined_summary}""" + "User Defined Features : " + str(user_mvf)
    return system_prompt, user_prompt

def db_executive_summary_generation(combined_summary, user_mvf): 
    system_prompt = """
    Role:
    You are an expert Database Architect tasked with understanding the contents of all tables and schema of the database. 
    You shall Articulate a proper executive summary that clearly captures all the main & high-level features of this database.
    The core use-case that this database is intended for, and the prioritized list of the most valuable features, solely based on the provided Table-Level summaries. 
    Do not hallucinate. Do NOT create the most valuable features and its description on pure assumptions. This needs to be based on facts, with proper backing.

    Task:
    1. Analyze provided Table wise summaries.
    2. Understand component interactions and functions.
    3. Prioritize the User Defined Features (if provided) in the summary.
    4. Identify and prioritize the most valuable features based on their importance to the core use-case the Database is solving.
    5. Create a comprehensive executive summary.

    Steps:
    1. Review Table wise summary.
    2. Analyze Table wise summary:
      - Identify all tables. 
      - Take into consideration the foreign keys, primary keys, is-a, has-a, and many-to-many relationships.
      - Deeply understand the intended-use-case of each table.
      - Note data operations, design patterns, and architectural decisions
    3. Create summary:
      - Describe the specific problem the Database is solving, based on Table wise summary
      - Explain high-level interactions and dependencies
      - Outline data workflow
    4. Identify and prioritize main features:
      - Determine which feature(s) address the core problem of the Database, based on SQL implementation and Table wise summary
      - Rank features based on their importance and relevance to solving the main problem, as evidenced in the Database
      - The feature should be major components of the Database and not minor functions like Many-to-Many Relationships, or "Foreign Keys". 
        These are implementation concepts. Not core features.

    Focus Areas:
    - Precised feature prioritization and importance
    - High-level functionality of this Database
    - Clear, concise technical language with Database-specific Language
    - Objective description
    - Capture entire data workflow

    Guidelines:
    - Only use the Table wise summary provided
    - Use precise Database-relevant technical terms
    - Include user-defined features if provided and evidenced in the Table wise summary
    - Prioritize features based on their importance to the core problem, as shown in the Table wise summary

    Feature Identification and Prioritization:
    - Carefully analyze the Table wise summary to identify features actually present in the Table wise summary
    - Do not assume or infer features that are not explicitly mentioned in the Table wise summary
    - Identify the top feature that solves the majority of the problem based on Database and SQL evidence
    - Rank subsequent features in descending order of importance, ensuring they are present in the Table wise summary
    - Ensure the feature list reflects the Database's focus and structure
    - Only include features that have substantial implementation in the Database that is evident from Table wise summary

    Output Format - Adhering to this format is crucial
    ```json
    {
    "data": "generated_summary in string format adhering to the Expected Output Format for Generated Summary",
    "confidence_score": 90,
    "traceback": {
    "Feature 1 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 1 Title' is included, as the 'phrase' is an evidence that this feature is part of the Database.",
    "Feature 2 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 2 Title' is included, as the 'phrase' is an evidence that this feature is part of the Database.",
    ...
    }
    }
    ```

    Requirements:
    - Replace \n with \\n in JSON
    - Limit upto 5 main features (max 2 sub-features each) or 7500 tokens
    - If due to any reason such as Database being small, you are unable to provide 5 features, then provide as many high-level features as possible between the range of 1 to 5.
    - Don't assume features or include minor features due to inability to provide 5 features, lesser number of features is acceptable.
    - Use specified JSON format only
    - Start with "```json" and end with "```"
    - Ensure the top feature in the prioritized list addresses the core problem and is present in the Table wise summary
    - Rank features in descending order of importance to the main problem, based on actual Database and SQL implementation
    - Do NOT include features that are NOT evidenced in the provided Table wise summary
    - Evaluate the Table wise summary objectively, considering all conclusions on the actual Database and SQL provided
    - Do NOT make any assumptions about organizational goals or intentions beyond what is explicitly shown in the Database and SQL
    - Focus solely on the technical aspects and implemented functionality, avoiding speculation about business objectives or future plans
    - Both the keys data, confidence score, and traceback should be present in the output JSON
    - The generated summary should be in string format only and be contained inside the "data" key
    - The "traceback" key should contain a dictionary with feature names as keys and justifications for including these features based on exact phrases from the input
    - Do not include any feature that could potentially be part of the Table wise summary without explicit evidence
    - Every feature mentioned must be driven by clear evidence from the provided input.
    - Strictly use an assertive and objective tone in your response. 
    - Do not be unsure about anything.
    - Do not include the "Folder Name" in your response. Ignore "dbanalysis" folder. Provide Executive Summary of the Database-ONLY.
    """

    user_prompt = """
  Expected Output Format for Generated Summary:

  **Overview**
  <empty line>
  <A brief introduction to the Database and its main purpose; in paragraph format only, not in points.
  This paragraph should provide a concise yet comprehensive overview of the Database, its primary functionality, and its intended use case.
  Aim for 3-5 sentences that capture the essence of the Database.>
  <empty line>
  **Highlighted Features**
  <empty line>
  <
  List and briefly explain the key features that are significant components of the Database and would serve as selling points.
  These features should be presented as follows:
  1. Use numbered points for each feature.
  2. Provide a brief explanation for each feature in 1-2 sentences, highlighting its importance and benefit to the END USER.
  3. Focus on features that are central to the Database's functionality and most important to the END USER.
  4. Dont include generic features like  Many-to-Many Relationships, or "Foreign Keys", these are not features but Design Principles.
  5. Do not include sub-points under any feature.
  6. Prioritize User Defined Features (if provided) at the beginning of the list.
  7. If User Defined Features are given, list them first before including any features identified through your analysis.
  8. Aim to provide upto of 1 to 5 key features, after each feature add an empty line for formatting purposes.
  9. Ensure that the features listed represent the core functionality and unique selling points based on the Table wise summary.
  10. Use clear, concise language that emphasizes the value proposition of each feature.
  11. Also under each feature, mention which file/Table was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
  12. Do not add features into Highlighted Features if they dont have value for buisness stakeholder about the application. Also do not repeat adding similar feature in this section.

  Output Structure:
  1. ***<Feature 1 Title>***: <Description of the feature in one to two sentences.\n
  2. ***<Feature 2 Title>***: <Description of the feature in one to two sentences.>\n
  >
  <empty line>
  **Key Benefits**
  <empty line>
  <Summarize the key benefits of the Database in one to two sentences.
  This summary should encapsulate the overall value proposition of the Database and its potential impact on users or the organization.>
  <empty line>
  <Highlight the most significant key benefits the Database has to offer in bulleted points. The format should be:
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  Aim for 3-5 bullet points that capture the most compelling advantages of using this Database, after each point add an empty line for formatting purposes.
  Each benefit should be distinct and provide a clear value proposition.>

  <Final Output Format>
  Output Format - Adhering to this format is crucial, the output should be in parsable JSON format:
  ```json
  {{
    "data": "<generated_summary in string format adhering to the Expected Output Format for Generated Summary>",
    "confidence_score": 90,
    "traceback": {{
      "Feature 1 Title": "Since it mentions about <exact phrase from the Table wise summary>, the 'Feature 1 Title' is included, as the "phrase" is an evidence that this feature is part of the Table wise summary.",
      "Feature 2 Title": "Since it mentions about <exact phrase from the Table wise summary>, the 'Feature 2 Title' is included, as the "phrase" is an evidence that this feature is part of the Table wise summary.",
      ...
    }}
  }}
  ```
  </Final Output Format>
  Note: If the traceback includes phrases that are not present in the Table wise summary then you would be penalized 10000 points.
  The output should be having data, confidence score, and traceback keys, and the entire content inside "```json" and "```" should be parsable by json.
  The "data" key should contain the generated summary and it should be in string format only, allowing the parsing of the entire json.
  If there are any inverted commas inside the generated summary, then escape them with a backslash.
  Do not change or skip the headings of each section in the generated json. The generated summary must have "Overview", "Highlighted Features", "Key Benefits" as section titles. Follow the above provided guidelines.
    """

    user_prompt += f"""Use the below Table wise summary to generate the summary in the above format: {combined_summary}""" + "User Defined Features : " + str(user_mvf)

    return system_prompt, user_prompt


def architecture_diagram_generation(services_data, icons_metadata):
    user_prompt = f"""
    <Input>
    $services_data = {services_data}
    $icons_metadata
    </Input>

    <Role>
    You are an expert at understanding large projects based on their executive summary and the services being used in them. Create a JSON structure for a ReactFlow diagram based on the given service class JSON.
    </Role>

    <Output Structure>
    1. Create a JSON object with a "nodes" and "edges" array.
    2. Create nodes for each external and third-party service.
    3. "nodes": An array containing all node objects.
      - "id": A unique string identifier for the node.
      - "data":   
        - "label": The name of the node.
        - "description": Description of the service.
        - "associated_files": Associated file and used in files in the service node, defaulting to "No File Available" if not present.
        - "group": The logical group name (e.g., 'Backend', 'Frontend', 'Database',etc..).
        - "subgroup": The specific subgroup within the group (e.g., Frameworks, NoSQL Databases, State Management, etc.).
        - "service": The appropriate filename of the icon based on the $icons_metadata.
      - "position" : The x and y coordinates of the node.
      - "type" : "customNode" This should be fixed.
    4. "edges" : An array having id, source, target, label, and type should be customEdge always.
    4. Ensure all services and files from the input JSON are included.
    5. The output should be in the form of a dictionary containing a "nodes" and "edges" array.
    6. Present only the code inside delimiters "```reactflow [reactflow CODE]```" without any additional explanation.
    """

    system_prompt:str = """
    <Task>
      You are tasked with creating a JSON structure for a ReactFlow diagram based on the given executive summary and the service_class_json. The executive summary contains an overview of the entire project. This JSON includes information about external services and third-party services, along with their associated files. Your output should represent this information as a network of nodes and edges.
    </Task>
    
    <Icons Context>
      $icons_metadata = """ + str(icons_metadata) + """
    </Icons Context>

    <Instructions>
      You are a solution expert, specializing in problem and solution flows. You will be given the solution overview for a project, and your task is to create an interconnected single component of graph which is detailed, and intuitive and self explanatory for:

      Follow these guidelines:
      1. Create nodes for each unique service (both external and third-party).
      2. Do not create any group nodes.
      4. In the data key for each service node, include two additional fields called group and subgroup. The group field should contain the logical group name (e.g., Frontend, Backend, Databases, etc..), and the subgroup field should provide more specific categorization (e.g., Frameworks, NoSQL Databases, etc..). For example, for a service node representing React, the group would be Frontend and the subgroup would be Frameworks.
      5. For each node, check which icon will be the most suitable from the $icons_metadata in the <Icons Context>
      6. Ensure all information from the input is represented in the output.
      7. The position coordinates must be proper for all the nodes.
    </Instructions>

    <Rules>
      **Ensure all nodes in the generated graph are interconnected such that every node has at least one edge, forming a single connected component without any isolated or disjoint sections. (High Priority Requirement)**
      Important Rules to be followed:
      1. Give detailed technical architecture flow and the JSON object following the below output format.
      2. Make sure that the flow and order of new solution approach is explained well in the graph with appropriate edges. Use as many edges you want to describe the data and user flow properly.
      3. The whole user and data flow should be clear.
      4. Do not add unnecessary nodes and edges. Do not create duplicate nodes that perform same task.
      5. Make the Node descriptions detailed, breaking tasks into multiple sub-tasks if needed.
      6. Ensure your edges show the actual flow, and not just connections of what's related. The connections are meant to show the logical flow, and not the relatedness/similarity.
      7. The group name is meant to classify clusters of nodes within each graph. For instance, if we have multiple nodes in features, they would all have "feature" as group. In Architecture Flow, the "Group" should show the layer each node is in, for instance "Backend Layer", "Database Layer" etc.
      9. for a hierarchy of nodes A -> B -> C; ensure that there is not a connection between A -> C.
    </Rules>
    
    <output_format>
    The output should be in between the delimeters ```reactflow and ```. Only provide the json output. Don't give unnecesary explanation.
    ```reactflow
    {
      "nodes": [
        { 
          "id": "unique_node_identifier_string",
          "data" : {
            "label": "name_of_the_service",
            "description": "description of the service",
            "associated_files": ["file_path_1", "file_path_2", "file_path_3", etc.],  // (default: ["No File Available"] if not present)
            "group": "name_of_group",  // Add the logical group name (e.g., "Frontend", "Backend", etc..)
            "subgroup": "name_of_subgroup",  // Add a more specific subgroup name (e.g., "Frameworks", "NoSQL Databases", etc..)
            "service": "filename" //taken from the $icons_metadata,
          }
          "position":{ "x": "Xcoordinate", "y": "Ycoordinate" },
          "type" : "customNode" //this is hardcoded and will be constant
        }
      ],
      "edges": [
        {
          "id": "unique_egde_identifier_string",
          "source": "label A",
          "target": "label B",
          "label": "Showcase what comes from the source node, to the target node. Be concise and specific with labels, such as 'Ingested Data', 'Converted Text', 'User Query' etc. Use at max 5 words",
          "type" : "customEdge" //this is hardcoded and will be constant
        }
      ]
    }```
    </output_format>
    """
    return system_prompt, user_prompt
  

def erd_generation(services_data, icons_metadata):
  tables_metadata = []
  for entry in services_data:
      table_name = entry["table_name"]
      ddl = entry["ddl"]
      columns, primary_keys, foreign_keys = parse_ddl(ddl)
      tables_metadata.append({
          "table_name": table_name,
          "columns": columns,
          "primary_keys": primary_keys,
          "foreign_keys": foreign_keys
      })

  dot = generate_combined_graph(tables_metadata)

  system_prompt:str = """
    You are tasked with creating a JSON structure for a ReactFlow diagram based on the given database ER diagram and schema JSON. This JSON includes information about database columns and their relationships.Your output should represent this information as a network of nodes and edges.
    </Task>
    
    <Icons Context>
      $icons_metadata = """ + str(icons_metadata) + """
    </Icons Context>

    <Instructions>
      You are a solution expert, specializing in problem and solution flows. You will be given the database schema information of a database, and your task is to create an interconnected single component of graph which is detailed, and intuitive and self explanatory for:

      Follow these guidelines:
      1. Create nodes for each unique service (both external and third-party).
      2. Do not create any group nodes.
      4. In the data key for each service node, include two additional fields called group and subgroup. The group field should contain the logical group name (e.g.,Databases, etc..), and the subgroup field should provide more specific categorization (e.g., 'Transactional Tables', 'Reference Tables' etc..). For example, for a service node representing daily transactions, the group would be Database and the subgroup would be Transactional Tables.
      5. For each node, check which icon will be the most suitable from the $icons_metadata in the <Icons Context>
      6. Ensure all information from the input is represented in the output.
      7. The position coordinates must be proper for all the nodes.
    </Instructions>

    <Rules>
      Important Rules to be followed:
      1. Give detailed technical architecture flow and the JSON object following the below output format.
      2. Make sure that the flow and order of new solution approach is explained well in the graph with appropriate edges. Use as many edges you want to describe the data and user flow properly.
      3. The whole user and data flow should be clear.
      4. Do not add unnecessary nodes and edges. Do not create duplicate nodes that perform same task.
      5. Make the Node descriptions detailed, breaking tasks into multiple sub-tasks if needed.
      6. Ensure your edges show the actual flow, and not just connections of what's related. The connections are meant to show the logical flow, and not the relatedness/similarity.
      7. The group name is meant to classify clusters of nodes within each graph. For instance, if we have multiple nodes in features, they would all have "feature" as group. In Architecture Flow, the "Group" should show the layer each node is in, for instance "Database Layer" etc.
      9. for a hierarchy of nodes A -> B -> C; ensure that there is not a connection between A -> C.
    </Rules>
    
    <output_format>
    The output should be in between the delimeters ```reactflow and ```. Only provide the json output. Don't give unnecesary explanation.
    ```reactflow
    {
      "nodes": [
        { 
          "id": "unique_node_identifier_string",
          "data" : {
            "label": "name_of_the_table",
            "description": "description of the table",
  	    "columns": ["order_id [PK]", "product_sku [PK]", "quantity", "unit_price"]
            "group": "name_of_group",  // Add the logical group name (e.g., "Database", etc..)
            "subgroup": "name_of_subgroup",  // Add a more specific subgroup name (e.g., 'Transactional Tables', 'Reference Tables', etc..)
            "service": "filename" //taken from the $icons_metadata,
          }
          "position":{ "x": "Xcoordinate", "y": "Ycoordinate" },
          "type" : "customNode" //this is hardcoded and will be constant
        }
      ],
      "edges": [
        {
          "id": "unique_egde_identifier_string",
          "source": "label A",
          "target": "label B",
          "label": "Showcase what comes from the source node, to the target node. Be concise and specific with labels, such as 'Ingested Data', 'Converted Text', 'User Query' etc. Use at max 5 words",
          "type" : "customEdge" //this is hardcoded and will be constant
        }
      ]
    }```
    </output_format>
    """
    
  user_prompt:str = f"""
    <Input>
    $database_tables = {dot}
    $icons_metadata
    </Input>

    <Role>
    You are an expert at understanding database architecture based on ER diagrams and relational structures. Create a JSON structure for a ReactFlow diagram based on the given database schema.
    </Role>
    <Output Structure>
      1. Create a JSON object with a "nodes" and "edges" array.
      2. Create nodes for each table in the schema.
      3. "nodes": An array containing all node objects.
      - "id": A unique string identifier for the node.
      - "data":  
        - "label": The name of the table.
        - "description": A brief summary of the table's role or content.
        - "columns": List of column names (mark primary keys with [PK], foreign keys with [FK]).
        - "group": The logical group name (e.g., 'Database').
        - "subgroup": The specific subgroup within the group (e.g., 'Transactional Tables', 'Reference Tables').
        - "service": The appropriate filename of the icon based on the $icons_metadata.
      - "position" : The x and y coordinates of the node.
      - "type" : "customNode" This should be fixed.
      4. "edges" : An array having id, source, target, label, and type should be customEdge always.
      5. The label of the edge should describe the relationship, like "order_id â†’ order_id". 
      6. The output should be in the form of a dictionary containing a "nodes" and "edges" array.
      7. Present only the code inside delimiters "```reactflow [reactflow CODE]```" without any additional explanation.
    """
    
  return system_prompt, user_prompt
    

def feature_summary_generation(formatted_data, user_mvf, executive_summary):
    # if input_type is None:
    #     formatted_data = file_summary_list
    # elif input_type == "batch_summary":
    #     formatted_data = format_batchwise_summary_metadata_for_services(file_summary_list)
    # else:
    #     formatted_data = format_file_summaries(file_summary_list)

    user_prompt = """
    Role: You are an AI code analyst specializing in creating concise, feature-level summaries of codebases.

    Objective: Provide a comprehensive yet concise feature-level summary of a given codebase, highlighting key components, functionality, and the project's overall workflow.

    Input: You will receive information about a codebase, which may include an executive summary or other project details.

    Steps:
    1. Analyze the provided codebase information.
    2. Identify the main features (maximum 5) of the project from the executive summary (if provided in same order)
    3. Create a summary following the specified format, including:
        a. An overview of the project
        b. A list of key features with brief descriptions
        c. A closure statement
    4. Self-evaluate the generated summary and assign a confidence score.
    5. Format the output as specified in the instructions.

    Output Format:
    ```json
    {
        "data": "generated_summary in string format adhering to the Detailed Instructions for Output Format",
        "confidence_score": 90
    }
    ```

    Detailed Instructions for Output Format:

    **Overview**
    <empty line>
    < 
        Summarize all features in 2-3 sentences, introducing the project and its purpose.
        Provide a 2-3 sentence summary of key benefits, highlighting core architecture and value proposition.
    >
    <empty line>
    **Key Features**
    <empty line>
    <   
        List a maximum of 5 main features.
        For each feature, provide up to 2 sub-points describing its functionality.
        Ensure clear explanation of how features interact and contribute to the project's goals.
        1. ***<Key Feature Title>*** : 
        * <Sub point 1 description>
        * <Sub point 2 description>
        <empty line>
    >
    <empty line>
    < 
        Summarize the overall impact and value proposition of the project in one sentence as a conclusion statement.
    >
    <empty line>
    
    -> Self-Evaluation:
        - Score the summary out of 100 based on clarity, precision, detail, knowledge, accuracy, technical correctness, and understanding of the data.

    -> Formatting Requirements:
        - Replace all newline characters (\n) with \\n in the JSON output.
        - Ensure the complete JSON is less than 7500 tokens.
        - Start the output with "```json" and end with "```".
        - If an executive summary is provided, use only the highlighted features from it.

    Example Output Structure:
    ```json
    {
        "data": "**Overview**\\n\\n[Project overview]\\n\\n[Benefits summary]\\n\\n**Key Features**\\n\\n1. *Feature 1*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n2. *Feature 2*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n[...continue for up to 5 features...]\\n\\n[Closure statement]",
        "confidence_score": 90
    }
    ```

    Remember: Adhere strictly to the output format and instructions to maintain consistency and accuracy in your summary.
    """

    user_prompt += "User Defined Features : " + str(user_mvf)

    system_prompt = f"""
        <role>
        You are an assistant to a Senior Software Engineer. You are very capable in reading and understanding huge codebases.
        There is no edge-case, no mistake, no functionality no matter how small goes unnoticed by you.
        You will be given a large codebase and be asked queries regarding it.
        </role>

        <Task>
        You will be given relevant files from a production codebase. The Senior Engineer will consult you to clear his doubts and ask for critical code-level and functionality level analysis of the same.
        <Important>
        1. You will be clear. Feel free to be descriptive but Avoid Jargon
        2. You shall perform critical analysis on the code before responding.
        3. Note that the codebase will be quite complex and have dependencies everywhere, be mindful of them all.
        4. Enclose code in (triple backticks)``` code ```
        </Important>
        </Task>

        Files from Codebase goes here :
        <Repo Structure>
        {formatted_data}
        </Repo Structure>
    """

    start_index = executive_summary.find("Highlighted Features")
    end_index = executive_summary.find("Key Benefits")

    if start_index != -1 and end_index != -1:
        executive_summary = executive_summary[start_index:end_index].strip()

    user_prompt += "Executive Summary : " + str(executive_summary)

    return system_prompt, user_prompt

def feature_summary_generation_db(formatted_data, user_mvf, executive_summary):
    # if input_type is None:
    #     formatted_data = file_summary_list
    # elif input_type == "batch_summary":
    #     formatted_data = format_batchwise_summary_metadata_for_services(file_summary_list)
    # else:
    #     formatted_data = format_file_summaries(file_summary_list)

    user_prompt = """
    Role: You are an AI Database Analyst specializing in creating concise, feature-level summaries of complex database schemas and architectures.

    Objective: Provide a comprehensive yet concise feature-level summary of a given database schema information, highlighting key components, entities, relationships, and the overall data architecture workflow.

    Input: You will receive information about a database design, which may include an executive summary or other schema-level details.

    Steps:
    1. Analyze the provided database schema information.
    2. Identify the main features (maximum 5) of the database from the executive summary (if provided in same order)
    3. Create a summary following the specified format, including:
        a. An overview of the database
        b. A list of key features with brief descriptions
        c. A closure statement
    4. Self-evaluate the generated summary and assign a confidence score.
    5. Format the output as specified in the instructions.

    Output Format:
    ```json
    {
        "data": "generated_summary in string format adhering to the Detailed Instructions for Output Format",
        "confidence_score": 90
    }
    ```

    Detailed Instructions for Output Format:

    **Overview**
    <empty line>
    < 
        Summarize all features in 2-3 sentences, introducing the database and its purpose.
        Provide a 2-3 sentence summary of key benefits, highlighting schema structure, normalization or denormalization logic, and value proposition in handling data.
    >
    <empty line>
    **Key Features**
    <empty line>
    <   
        List a maximum of 5 main features.
        For each feature, provide up to 2 sub-points describing its data handling, relationships, or optimization logic.
        Ensure clear explanation of how features contribute to performance, consistency, and data integrity.
        1. ***<Key Feature Title>*** : 
        * <Sub point 1 description>
        * <Sub point 2 description>
        <empty line>
    >
    <empty line>
    < 
        Summarize the overall impact and value proposition of the database in one sentence as a conclusion statement.
    >
    <empty line>
    
    -> Self-Evaluation:
        - Score the summary out of 100 based on clarity, precision, detail, knowledge, accuracy, technical correctness, and understanding of the schema information.

    -> Formatting Requirements:
        - Replace all newline characters (\n) with \\n in the JSON output.
        - Ensure the complete JSON is less than 7500 tokens.
        - Start the output with "```json" and end with "```".
        - If an executive summary is provided, use only the highlighted features from it.

    Example Output Structure:
    ```json
    {
        "data": "**Overview**\\n\\n[Database overview]\\n\\n[Benefits summary]\\n\\n**Key Features**\\n\\n1. *Feature 1*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n2. *Feature 2*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n[...continue for up to 5 features...]\\n\\n[Closure statement]",
        "confidence_score": 90
    }
    ```

    Remember: Adhere strictly to the output format and instructions to maintain consistency and accuracy in your summary.
    """

    user_prompt += "User Defined Features : " + str(user_mvf)

    system_prompt = f"""
        <role>
        You are an assistant to a Senior Data Architect. You are very capable in reading, analyzing, and understanding complex database schemas and data models.
        No entity, constraint, relationship, or optimization logic goes unnoticed by you.
        You will be given a comprehensive database structure or schema information and will be asked to analyze, explain, and summarize it at a structural and functional level.
        </role>

        <Task>
        You will be given relevant database schema files or DDL definitions. The Senior Data Architect will consult you to clear doubts and ask for critical schema-level and data model-level analysis.
        <Important>
        1. You will be clear. Feel free to be descriptive but Avoid Jargon
        2. Perform a critical and deep analysis of the schema and the information given before responding.
        3. The schema will often involve multiple tables, foreign keys, views, procedures, and indexing strategies â€” be mindful of their dependencies and relationships.
        4. Enclose code or schema in (triple backticks)``` code ```
        </Important>
        </Task>

        Files from Database schema goes here :
        <Database Structure>
        {formatted_data}
        </Database Structure>
    """

    start_index = executive_summary.find("Highlighted Features")
    end_index = executive_summary.find("Key Benefits")

    if start_index != -1 and end_index != -1:
        executive_summary = executive_summary[start_index:end_index].strip()

    user_prompt += "Executive Summary : " + str(executive_summary)

    return system_prompt, user_prompt


#FEATURE HIERARCHY:
generate_features_system_prompt = """
  <Role>
    You are a Software Architect with expertise in analyzing large summaries from code files of an application. 
    You can comprehend summaries from code files that are complex, production-grade and are written in various programming languages to generate most important features, their description and the subfeatures with their description belonging to the most important features along with the other relevant information requested below.
    
    You will follow 2 Events before responding : 
    1. Generation of Feature Hierarchy as given in "Output_Format".
    2. Critical Evaluation of Every Confidence Score.  
  </Role> 

    <Task 1>
    You are provided with multiple relative file paths and file-wise code summaries from a application codebase.
    1. Analyze the file summaries carefully, leveraging your expertise to deduce the frameworks, functionality, and features.
    2. Perform a critical assessment of the code's functionality and interdependencies before responding.
    3. The codebase is complex and likely contains dependencies across various modules. Be mindful of these.
    4. Analyse every file summary and assign the features and sub-features based on the information provided.
    5. Respond strictly in the structured JSON format provided below.
    6. In each sub-feature's 'file_path' array:
        - Set 'critical: true' ONLY for files that are CORE & NON-REPLACEABLE to the sub-feature's main functionality.
        - Set 'critical: false' for ALL supporting, secondary, or replaceable files  
        - Each sub-feature should have both true and false entries.
        - If unsure, default to false (be EXTREMELY selective with 'true')
        - Make sure each sub-feature atleast have one file as true.

    Explanation of the Output terms:
    Feature - Features are most valuable and high level features extracted from the list of summaries that are provided to you. 
    Feature description - Description of the features explaining the high level value and impact that it creates for the project. Define the Feature. The description should be crisp, precise, well formatted and must be between 2-3 lines.
    Subfeature - Subfeatures are micro most valuable features that are extracted from the list of summaries and belong to the Most related and similar Features.
    Subfeature description - Description of the subfeatures explaining the specific value, technical and non-technical functionalites that it provided to the project. Define the subfeature and also explain how its related to the feature. The description should be crisp, precise, well formatted and must be between 2-3 lines.
    
    Points to Remember:
    1. Do not extract any feature or subfeature where there are no reference/citations from the application summaries.
    2. The description must be precise, valuable, well-formatted and must be between 2-3 lines.
    3. The Feature titles should be precise, specific, self explanaible, independent and not have similar feature titles. The Feature titles should not be highly generalized.
    4. The SubFeatures titles should be precise, self explanaible and not have similar subfeature titles. The SubFeature titles should not be highly generalized.
    5. SubFeatures should not be very low level that it explains code functions, code process like 'Json handling', 'Reading csv', readME etc.
    6. If similar subfeatures are present, then group them under one common Feature itself. Do not create multuple Features for similar subfeatures.
    6. If Unit testing related summaries are found, then create that as another Feature named 'Unit Testing' and assign the specific testing subfeatures under this feature.
    </Task 1>

  <Task 2>
  You shall now Assign and Justify Confidence Scores for each feature.

  <Critical Evaluation of Confidence Scores> 

  <Evaluation MODE>
  - You will now Forget everything that was done beforehand and act as an unbiased judge.
  - $Project-Summaries-&-Paths (INPUT).
  </Evaluation MODE>
  <Important>
  Critically analyze every "Feature" and "SubFeature" based on the following metrics. 
  You shall generate a confidence score between 0-100 for each of the following :
  1. Is the "Feature" & "SubFeature" name accurate to its functionality ? (Accuracy)
  2. Does the "Feature" & "SubFeature" include files with an unrelated function ? (Feature Dilution Rate)
  3. Important : Does this "Feature" & "SubFeature" make sense given the Overall Purpose of the Application ? (Consistency)
  4. Are all the files in "Feature" & "SubFeature" included ? (Completeness)

  <Strict>
  1. You will now generate a list of 4 confidence scores between 0-100 for above criteria under "confidence_score" key.
  2. Based on above criteria, you shall provide a VERY BRIEF logical explanation (10-20 words) for Confidence Score under "confidence_score_justification" key.
  3. Make sure to mention the entire filepath without omitting the prefix.
  4. Make sure all the filepaths are present.
  <Important> STRICTLY Don't Comment on Missing Files. Don't Overestimate. Don't Underestimate.</Important> 
  </Strict>

  </Important>

  </Critical Evaluation of Confidence Scores> 
  </Step 2>


      <Output_Format>
    Return a response in JSON format. Do not include any extra information or explanations. Strictly DON'T deviate from mentioned KEYS.
    Example:
```json
[
  {
    "name": "User Authentication and Management",
    "feature_description": "Comprehensive user account system with secure login, registration, profile management, and role-based access control.",
    "feature_description_confidence_score": [95, 70, 100, 70],
    "sub_features": [
      {
        "name": "User Registration",
        "description": "Allows new users to create accounts by providing necessary information such as username, email, and password. Implements email verification, password strength checks, and duplicate account prevention. Stores user data securely in the database with password hashing.",
        "file_path": [
          {
            "module_name": "RegistrationController",
            "path": "Controllers/Account/RegistrationController.cs",
            "critical": true
          },
          {
            "module_name": "RegisterView",
            "path": "Views/Account/Register.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [75, 80, 85, 65],
        "sub_feature_confidence_score_justification": "No feature dilution, might have missed some file."
      },
      {
        "name": "User Login",
        "description": "Authenticates users using their credentials, creates and manages user sessions, and implements security measures such as login attempt limiting and two-factor authentication (2FA). Provides password reset functionality for forgotten passwords.",
        "file_path": [
          {
            "module_name": "LoginController",
            "path": "Controllers/Account/LoginController.cs",
            "critical": true
          },
          {
            "module_name": "LoginView",
            "path": "Views/Account/Login.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [80, 100, 80, 75],
        "sub_feature_confidence_score_justification": "High chance of missing files."
      }
    ],
    "feature_confidence_score_justification": "No feature dilution, duplication or missing files. Accurate Naming."
  },
  {
    "name": "Product Catalog Management",
    "feature_description": "Comprehensive system for managing product listings, categories, and inventory across the e-commerce platform.",
    "feature_description_confidence_score": [95, 65, 70, 80],
    "sub_features": [
      {
        "name": "Product CRUD Operations",
        "description": "Enables administrators to create, read, update, and delete product listings. Includes functionality for managing product details such as name, description, price, images, and inventory levels. Implements validation to ensure data integrity and consistency across the product catalog.",
        "file_path": [
          {
            "module_name": "ProductController",
            "path": "Controllers/ProductController.cs",
            "critical": true
          },
          {
            "module_name": "ProductView",
            "path": "Views/Product/Index.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [90, 85, 100, 70],
        "sub_feature_confidence_score_justification": "High confidence with no duplication or dilution."
      },
      {
        "name": "Category Management",
        "description": "Allows for the creation and management of product categories and subcategories. Implements a hierarchical structure for organizing products, enabling efficient navigation and filtering of the product catalog for both administrators and customers.",
        "file_path": [
          {
            "module_name": "CategoryController",
            "path": "Controllers/CategoryController.cs",
            "critical": true
          },
          {
            "module_name": "CategoryView",
            "path": "Views/Category/Index.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [85, 75, 90, 95],
        "sub_feature_confidence_score_justification": "High confidence without any duplication or dilution."
      }
    ],
    "feature_confidence_score_justification": "All files refer to single overall functionality. Might have missed some files."
  }
]
```
  </Output_Format>

"""

generate_features_user_message = """
<Strictly Remember>
1. As input you will be given a batch of `file_path` and `file_summary` from a production codebase. Keep it in mind that it could be a file from a very large repository with lot of inter-dependencies.
2. Understand all the file description first, then try to determine the feature, sub-features and their description. For **each file** it should have a feature or sub-features whenever the conditions are met.
3. The response should contain all the fields given in the example output format. The response should be strictly in json format.
4. The description of features/subfeatures must be in the length of 2-3 lines. The response should be structured and well-formatted.
5. Don't generate any additional explanation or description. Provide the structured response in json only.
</Strictly Remember>
  
<Input file wise summary>
{file_summary}
</Input file wise summary>
<Response>
"""

merge_features_in_hierarchy_user_prompt = """You are a software feature analyzer. Given a list of related features that have been clustered together, create a merged feature that encompasses all the functionality.

Features to merge:
{feature_list}

Generate a JSON response that includes:
1. A name for the merged feature representing accurate feature name. Do not mention its merged or unified or anything as such. The feature name should accurately represent a major funcationality of a repository.
2. A detailed description that covers all functionality
3. A confidence score (0-100) for the merge
4. A justification for the confidence score

Respond with a JSON object in the following format:
```json
{{
    "name": "Merged feature name",
    "description": "Comprehensive description",
    "confidence_score": 85,
    "confidence_justification": "Reason for the confidence score"
}}
```
Give only JSON and nothing else. Do not include any explanations or additional text outside the JSON block. Make sure to start with ```json and end with ``` only.
"""

mapping_names_for_merged_features_user_prompt = """  <Role>
    You are a smart AI cassistant with strong expertise in Software Engineering. You can understand complex, production-grade codebases written in various programming languages and summarize them effectively.
  </Role>
  <Task>
  You will be given a brief description of  features of a large codebase and your task is to generate a relevant feature name, brief description, and priority level.
  <Important>
   1. The feature name should be brief, relevant and should represent the entire description provided.
   2. Generate a relevant description which is basically a overall summary of the description provided.
   3. Assign a priority level (high, medium, low) based on the significance, importance and complexity of the feature to the overall system. 
  </important>
  </Task>
  <Example output>
  ```json
    {
        "name": <feature_name>, //string
        "feature_description": <feature_description>, //string
        "priority": <priority> //string (high, medium, or low)
    }
    ```
  </Example output>
  <Strictly Remember>
1. The feature name should be relevant and at the same time interpretable, easy to understand.
2. The feature description should represnt the entire description given for summarisation, it should be simple and easy to understant.
3. The priority should be one of: high, medium, or low.
4. The response should be strictly in json format specified above.
5. Strictly make sure Feature Description is not more than 200 words.
  </Strictly Remember>

<code summary>
The code summary is given below:
"""


reducing_sub_features_user_prompt = """
    You are a software feature consolidation expert. Your task is to merge similar sub-features into one comprehensive sub-feature.

    Here are the sub-features that need to be merged:
    {sub_features_list}

    For each sub-feature, we have:
    - Name: The sub-feature name
    - Description: The sub-feature description (if available)
    - Confidence Score: The confidence score (if available)

    Your output should be a JSON object containing:
    1. A unified sub-feature name that encompasses all the input sub-features
    2. A comprehensive description that covers all aspects of the input sub-features
    3. A confidence score (use the highest available from input sub-features)
    4. A justification for the confidence score

    Return the output in JSON format starting with ```json and ending with ```.

    Example output format:
    ```json
    {{
        "name": "Unified Sub-Feature Name",
        "description": "Comprehensive description covering all aspects",
        "sub_feature_confidence_score": 95,
        "sub_feature_confidence_score_justification": "Merged from similar sub-features with high semantic similarity"
    }}
    ```
    """


post_processing_feature_name_description_system_prompt="""
  <Role>
    You are a smart AI assistant with strong expertise in Software Engineering. You can understand complex, production-grade codebases written in various programming languages and summarize them effectively.
  </Role>
  <Task>
  You will be given a brief description of modules or features of a large codebase and your task is to generate a relevant feature name and brief description.
  <Important>
   1. The feature name should be brief, relevant and should represent the entire description provided.
   2. Generate a relevant description which is basically a overall summary of the description provided.
   3. Also generate a confidence score in a scale of 0 - 100.
  </important>
  </Task>
  <Example output>
  ```json
    {
        "name": <feature_name>,
        "feature_description_confidence_score": <score 0 - 100>,
        "feature_description": <feature_description>
    }```
  </Example output>"""

post_processing_feature_name_description_user_prompt = """<Strictly Remember>
1. The feature name should be relevant and at the same time interpretable, easy to understant.
2. The confidence score should represent the ability to summarise the description.
3. The feature description should represnt the entire description given for summarisation, it should be simple and easy to understant.
4. The response should be strictly in json format specified above.
</Strictly Remember>
<code summary>
The code summary is given below: \n
{feature_description}
</code_summary>
<response>
Your response in json goes here:
"""

merge_similar_features_system_prompt = """You are a solution architect. Your task is to carefully review each feature and its description, and combine them into a single high-level feature.

The final high-level features should represent what an end user would perceive, e.g., Messenger, Google Chat, Messaging, Reels, etc.

Based on the generated features provided, identify which features can be merged into a single high-level feature. 
Strictly output them in the following format:
{{ 
  <High-Level Feature Name 1>: [<Merged Feature 1>, <Merged Feature 2>, <Merged Feature 3>, ...],
  <High-Level Feature Name 2>: [<Merged Feature 1>, <Merged Feature 2>, <Merged Feature 3>, ...],
  ...
}}

INPUT:
Feature names and descriptions are provided in the format: 
[1. Feature name: <feature name> 
Feature description: <feature description>, 
2. ...]

{feature_texts}

MVFS:
{total_MVFs}

Points to remember:
1. While merging features and naming high-level features, always prefer names from the user-defined MVFs provided. All relevant features can be grouped under these high-level features.
2. If certain features do not fit under the user-defined MVFs, choose a better name than the existing one for the new high-level feature if necessary.
3. The names of the features being merged must remain exactly as provided in the INPUT section; do not modify them. Do not consider Feature description in Feature Names.
4. Follow the output structure strictly: high-level feature names as dictionary keys and merged features as values in list format.
5. If a feature is already a high-level feature, you do not need to forcibly merge it. If a feature seems to be function-level/low-level  features, merge them into a High-level feature.
6. Merge similar features into a single high-level feature based on their names and descriptions, when applicable. Each final high-level feature should be independent of the others.
7. Do not assign the same feature to multiple high-level features.
8. If user-defined MVFs are empty, skip point 1 and begin with point 2.
9. Do **not** include any Feature descriptions in the final output."""


merging_description_user_prompt = """You are a Solution Architect. Your task is to summarize the multiple feature descriptions provided into a brief, coherent summary of **no more than two sentences**.

  The summary must:
  - Accurately capture all key components from the provided descriptions.
  - Align clearly with the given high-level feature name.
  - Serve as the final description of the high-level feature.

  Only the final summarized description should be included in the output â€” no additional commentary or formatting.

  INPUT:
  Multiple descriptions: {merging_feature_description}

  High-Level Feature Name: {high_level_feature}
  """


micro_sub_feature_prompt = """You are an expert system analyst specializing in decomposing SubFeatures into granular, logically independent components. You support **two levels** of splitting:

1. **Horizontal splitting**: Split a subfeature into multiple *same-level subfeatures* when it encompasses multiple independently meaningful functionalities. The subfeatures created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.
2. **Vertical splitting**: Further break each of those subfeatures into *microsubfeatures* (if applicable), ensuring each micro-sub-features/micro-user-story describes a single goal or operation. The micro-sub-features/micro-user-story created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.

---

### ðŸ”§ TASK OVERVIEW

Given a Macro-Feature, Subfeature, its description, associated module files and its summary:

- Decide if the subfeature should be split horizontally into multiple same-level subfeatures.
- For each resulting subfeature (or original if not split), analyze whether it can be split vertically into **microsubfeatures** (fine-grained user stories).
- Provide the confidence scores for the subfeature that is split, whether horizontally or vertically.
- Provide the files that are related to the sub_features too, not just the micro_sub_features.
- Each leaf user-story must have files assigned to them, else you should not create/split these subfeatures.
- Provide description of generated subfeature/sub-user-stories in 2-4 lines but only valid information. Do not assume or hallucinate to generate description.
Apply this recursively: if horizontal splitting occurs, then attempt vertical splitting for each. But remember, not to create any duplicates in the process. 

---

### SPLITTING DECISIONS

#### Horizontal Splitting (Same-level Subfeatures):
Split if:
- The subfeature covers multiple high-level functionalities
- Each function could be planned, developed, and deployed independently
- Each component has a clear boundary and responsibility

#### Vertical Splitting (Microsubfeatures):
Split further if:
- A subfeature contains multiple independent operations or logical stages
- These operations can be implemented, tested, or tracked separately
- Each micro-subfeature represents one atomic, non-overlapping functionality

---

### DO NOT SPLIT IF:
- sub-user-stories are tightly coupled in the Subfeature and cannot function independently.
- Do not split subfeatures into sub-user-stories that are hardly single line of code and cannot be considered as a proper functionality, but just a config/parameter.
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across actions are too complex to isolate.
- There are no files that can be mapped to the generated user-story.
- Do not split if the user-story is barely a functionality. The split user-stories must have independent functionality that contributes to the subfeature and feature and if not, do not split.
- Don not split ReadMe & .md files into sub-user-stories.
- Do not split horizontall for granullar subfeatures as they are not user stories but mid level features.
---

### FILE MAPPING RULES:
- For each subfeature or microsubfeature, cite only directly relevant files.
- Use only the provided input data to match files â€” no guessing.
- Avoid duplication unless a file is clearly shared between components.

Each `file_path` entry must include:
```json
{
  "module_name": "<Name>",
  "path": "<Path>",
  "critical": <true/false>,
  "git_url": "<Git URL>"
}

OUTPUT FORMAT
If the subfeature should NOT be split:
Return: "None"

If the subfeature should be split, return a list of Parent User Stories with subfeatures inside.
If a subfeature itself can be further split into microsubfeatures, nest them under micro_sub_features like so:

[
  {
    "name": "Parent User Story Title 1",
    "description": "Full description of the original or updated user story and its purpose.",
    "file_path": [...],
    "sub_feature_confidence_score":"confidence score of the subfeature with respect to the Feature, as a percentage (e.g., 80)"
    "micro_sub_features": [
      {
        "name": "Sub-User Story Title 1",
        "description": "Standalone description of a single functionality.",
        "file_path": [...],
        "micro_sub_feature_confidence_score":"confidence score of the micro_sub_feature with respect to the sub_feature, as a percentage (e.g., 90)"
        }
          ...
        ]
      },
      ...
    ]
  }
]
Each layer must preserve independence, clarity, and singular focus of each story.

VALIDATION CHECKLIST
- Each title must express one functionality only (no imperative phrasing)
- description must avoid assumptions and describe the real function. It must be as detailled as possible.
- Each story must make sense independently and fit in the broader feature flow
- if there are multiple user-story under the subfeature, it needs to be in sequence of business logic.
- File mappings must be relevant and scoped accurately
- Do no miss/skip any values in the output json. The output structure must be maintained strictly.
- All subfeature and sub-user-story names and descriptions must be strictly in a declarative tone, not imperative.

* Use generic or speculative statements
"""


db_micro_sub_feature_prompt = """
<Role>
You are an expert Database analyst specializing in decomposing SubFeatures into granular, logically independent components. You support **two levels** of splitting:
You shall ALWAYS process features from a Database perspective ONLY. 
There can be more than one Table in the DB context provided to you.
</Role>

1. **Horizontal splitting**: Split a subfeature into multiple *same-level subfeatures* when it encompasses multiple independently meaningful functionalities. The subfeatures created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.
2. **Vertical splitting**: Further break each of those subfeatures into *microsubfeatures* (if applicable), ensuring each micro-sub-features/micro-user-story describes a single goal or operation. The micro-sub-features/micro-user-story created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.

<Strict Constraints> 
- You are dealing with Database Information. 
- No matter what, STRICTLY use Database-Specific Language ALWAYS. 
- Use words like Columns / Fields / Schema / DataTypes / Constraints / Foreign Keys / Primary Keys etc.
- Strictly Do not start descriptions with or start with "this micro-feature" / or "this sub-feature".
- You shall do this regardless of the input context and nature.
Remember : Every "FILE" given to you is information of a table. Therefore in your response, ALWAYS refer to "Table" instead of "File".

</Strict Constraints> 


### ðŸ”§ TASK OVERVIEW

Given a Macro-Feature, Subfeature, its description, associated module files and its summary:

- Decide if the subfeature should be split horizontally into multiple same-level subfeatures.
- For each resulting subfeature (or original if not split), analyze whether it can be split vertically into **microsubfeatures** (fine-grained user stories).
- Provide the confidence scores for the subfeature that is split, whether horizontally or vertically.
- Provide the files that are related to the sub_features too, not just the micro_sub_features.
- Each leaf user-story must have files assigned to them, else you should not create/split these subfeatures.
- Provide description of generated subfeature/sub-user-stories in 2-4 lines but only valid information. Do not assume or hallucinate to generate description.
Apply this recursively: if horizontal splitting occurs, then attempt vertical splitting for each. But remember, not to create any duplicates in the process. 

---

### SPLITTING DECISIONS

#### Horizontal Splitting (Same-level Subfeatures):
Split if:
- The subfeature covers ONE / MORE THAN ONE high-level functionalities
- Each function could be planned and developed independently
- Each component has some clear boundaries and responsibilities

#### Vertical Splitting (Microsubfeatures):
Split further if:
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across actions are too complex to isolate.
- There are no tables that can be mapped to the generated user-story.
- The subfeature is too complex to be planned, developed, and deployed independently
- Each micro-subfeature represents one atomic, non-overlapping functionality
Note: Maintain at least 2 subfeatures unless the database has only one table.
- Prioritize brevity, consistency and no informaiton leakage across subfeatures.
- Ensure crisp segregation.
---

### DO NOT SPLIT IF:
- sub-user-stories are tightly coupled in the Subfeature and cannot function independently.
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across tables in two features are too complex to isolate.
- There are no tables that can be mapped to the generated user-story.
Note: Maintain at least 2 subfeatures and 1 or more microsubfeatures per subfeature, Unless the database has only one table.
Note : Maintain brevity during splitting at the same level. Do NOT overload the a single feature with too many subfeatures.
---


### FILE MAPPING RULES:
- For each subfeature or microsubfeature, cite only directly relevant tables.
- Use only the provided input data to match files â€” no guessing.
- Avoid duplication unless a file is clearly shared between components.

Each `file_path` entry must include:
```json
{
  "module_name": "<Name>",
  "path": "<Path>",
  "critical": <true/false>,
  "git_url": "<Git URL>"
}

OUTPUT FORMAT
If the subfeature should NOT be split:
Return: "None"

If the subfeature should be split, return a list of Parent User Stories with subfeatures inside.
If a subfeature itself can be further split into microsubfeatures, nest them under micro_sub_features like so:

[
  {
    "name": "Parent User Story Title 1",
    "description": "Full description of the original or updated user story and its purpose.",
    "file_path": [...],
    "sub_feature_confidence_score":"confidence score of the subfeature with respect to the Feature, as a percentage (e.g., 80)"
    "micro_sub_features": [
      {
        "name": "Sub-User Story Title 1",
        "description": "Standalone description of a single functionality.",
        "file_path": [...],
        "micro_sub_feature_confidence_score":"confidence score of the micro_sub_feature with respect to the sub_feature, as a percentage (e.g., 90)"
        }
          ...
        ]
      },
      ...
    ]
  }
]
Each layer must preserve independence, clarity, and singular focus of each story.

VALIDATION CHECKLIST
- Each title must express one functionality only (no imperative phrasing)
- description must avoid assumptions and describe the real function. It must be as detailled as possible.
- Each story must make sense independently and fit in the broader feature flow
- if there are multiple user-story under the subfeature, it needs to be in sequence of business logic.
- File mappings must be relevant and scoped accurately
- Do no miss/skip any values in the output json. The output structure must be maintained strictly.
- All subfeature and sub-user-story names and descriptions must be strictly in a declarative tone, not imperative.
- Use Database-specific schema only. Do not include words like "Attributes" / "Code Files" in your response. 
- Strictly Do not start descriptions with or start with "this micro-feature" / or "this sub-feature".
* Use generic or speculative statements

"""import os
from graphviz import Digraph
import re 
import json

def parse_ddl(ddl: str):
    """
    Parse the DDL to extract columns, primary keys, and foreign keys.
    """
    lines = ddl.splitlines()
    column_lines = []

    for line in lines:
        line = line.strip()
        if (
            line.upper().startswith("CREATE")
            or line.upper().startswith("PRIMARY")
            or line.upper().startswith("FOREIGN")
            or line.upper().startswith(")")
            or line == ""
        ):
            continue

        match = re.match(r'(\w+)\s+\w+', line)
        if match:
            column_lines.append(match.group(1))

    pk_match = re.search(r'PRIMARY KEY\s*\((.*?)\)', ddl)
    primary_keys = [key.strip() for key in pk_match.group(1).split(",")] if pk_match else []

    foreign_keys = []
    for match in re.finditer(r'FOREIGN KEY\s*\(([^)]+)\)\s+REFERENCES\s+`?[\w]+\.(\w+)`\(([^)]+)\)', ddl):
        fk_col = match.group(1).strip()
        ref_table = match.group(2).strip()
        ref_col = match.group(3).strip()
        foreign_keys.append((fk_col, ref_table, ref_col))

    return column_lines, primary_keys, foreign_keys


def generate_combined_graph(tables_data):
    """
    Generate a single combined graph from multiple tables.
    """
    dot = Digraph(comment='Combined Table Diagram')
    dot.attr(rankdir='LR')

    # Store individual table nodes
    for table in tables_data:
        table_name = table['table_name']
        columns = table['columns']
        primary_keys = table['primary_keys']
        
        label_lines = []
        for col in columns:
            if col in primary_keys:
                label_lines.append(f"{col} [PK]")
            else:
                label_lines.append(col)
        dot.node(table_name, shape='box', label=f'{table_name}\\n' + "\\n".join(label_lines))

    # Add relationships
    for table in tables_data:
        table_name = table['table_name']
        for fk_col, ref_table, ref_col in table['foreign_keys']:
            dot.edge(table_name, ref_table, label=f'{fk_col} â†’ {ref_col}')

    return dot

def folder_summary_generation_prompts(
        total_allocated_tokens, 
        file_list, folder_name, 
        folder_path,
        subfolder_list,
        formatted_file_summaries,
        formatted_file_services,
        formatted_subfolder_summaries,
        formatted_subfolder_services,
        formatted_subfolder_features
    ):
    
    system_prompt = f"""
        You are an expert code analyst specialized in creating detailed, informative summaries of software project folders. Your task is to thoroughly analyze files and subfolders to provide a comprehensive understanding of the application or project and provide combined summaries along with required details. These summaries must be detailled enough for further summarization.

        Follow these guidelines:
        1. Conduct a deep analysis of the features to identify its core purpose and functionality
        2. Provide detailed explanation of key implementations and technical approaches of the features
        3. Thoroughly examine the summaries based on files and folders to understand relationship between features and combined smaller features into larger high level application level features.
        4. Explain the features within the broader project architecture with specific connections
        5. Describe technical patterns, design decisions, and architectural choices evident in the code
        6. Include specific functions, classes, and methods that define the feature's behavior
        7. Note dependencies, imports, and external connections that shape the folder's functionality
        8. Identify potential architectural strengths and areas for improvement when evident
        9. Identify all services represented in this folder based on file and subfolder services information
        10. Identify and articulate high-level features or functionalities represented by the folder into the feature_details section, when consolidating multiple subfolders or lower-level files. Derive these insights from both file-level and subfolder-level summaries. Also under each feature, mention which file/folder was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
        11. Do not miss any features that could be formed based on these summaries as this information is required to understand the application's buisness logic.
        12. Gather insights from the summaries provided to generate a high level detailled executive summary that could be used by business stakeholders to understand the folder/project.
        13. When analyzing the root folder, both the executive summary and the features must be strictly formed in a high level business logic standpoint of an application.
        
        IMPORTANT: 
        - Your summary should be thorough and detailed({total_allocated_tokens}) while maintaining technical/business precision and depth. Focus on providing insights that would help both stakeholders and developers understand the application better.
        - feature_details must contain high level feature name and feature description(value of the files/folders) strictly in concise bullet points. The feature inforamtion must be in detail to capture the complete high level knowledge for that feature but not the function level details. Feature names cannot be programmatic function names like Dependency management, json handling etc. instead it should be inventory management, order processing etc. 
        - Your services list should be comprehensive and include all services represented in this folder.
        - is_reuasble_lib if a folder is used as reusable lib make it True otherwise False
        - lib_name if is_reusable_lib is True then provide the name of the reusable lib/component If is_reusable_lib False then add Not Applicable
        - category if is_reusable_lib is True then provide category only between 'Frontend' and 'Backend' If is_reusable_lib False then add Not Applicable
        - sub_category if is_reusable_lib is True then provide sub category only between 'UI Component','Custom Hooks', 'http_client', 'Utils', 'Others' In Frontend & 'Middleware', 'Error Handling', 'Auth', 'Utils', 'Others' In Backend If is_reusable_lib False then add Not Applicable
        - when_to_use if is_reusable_lib is True then provide where this reusable lib/component can be used If is_reusable_lib False then add Not Applicable 
        - associated_files if is_reusable_lib is True then provide the list of files associated(give complete path for the assosciated file) with this reusable lib/component If is_reusable_lib False then add Not Applicable
        - summary must not be technical and only explain the high level details of the folder/project. Understand the file and folder summaries provided to combine the knowledge to form the executive summary. Make it as detailled as possible.
        - Use clear and concise language, avoiding jargon where possible.
        
        - You must provide your response in this exact format:
        ```summary
        [Your detailled high-level executive summary for the folder for business stakeholders]
        ```
        ```feature_details
        [List of high-level features or functionalities represented in this folder]
        ```
        ```services_namess
        [Comma-separated list of all services represented in this folder]
        ```
        ```is_reuasble_lib
        Boolean Value
        ```
        ```lib_name
        [Name of the reusable library if applicable]
        ```
        ```category
        [Category of the reusable library if applicable]
        ```
        ```sub_category
            [Sub category of the reusable library if applicable]
        ```
        ```when_to_use
        [Your detailed use case where or when this reuasble_lib can be usefull]
        ```
        ```associated_files
            [Comma-separated list of associated files with the reusable library, Give the Complete file path as mentioned in the file list]
        ```
        ```example_usage
            [Example code snippet of how to use this reusable library]
        ```
    """

    user_prompt = f"""
        Generate a summary and services list for the folder: "{folder_name}" (Path: {folder_path})

        FOLDER CONTENTS:
        - Files ({len(file_list)}): {", ".join(file_list) if file_list else "None"}
        - Subfolders ({len(subfolder_list)}): {", ".join(subfolder_list) if subfolder_list else "None"}

        FILE SUMMARIES:
        {os.linesep.join(formatted_file_summaries) if formatted_file_summaries else "No file summaries available"}

        FILE SERVICES:
        {os.linesep.join(formatted_file_services) if formatted_file_services else "No file services available"}

        SUBFOLDER SUMMARIES:
        {os.linesep.join(formatted_subfolder_summaries) if formatted_subfolder_summaries else "No subfolder summaries available"}

        SUBFOLDER SERVICES:
        {os.linesep.join(formatted_subfolder_services) if formatted_subfolder_services else "No subfolder services available"}

        SUBFOLDER FEATURES:
        {os.linesep.join(formatted_subfolder_features) if formatted_subfolder_features else "No subfolder features available"}
        
        Based on these components:
        1. Provide a thorough technical summary explaining the folder's purpose, implementation details, and architectural significance
        2. Compile a comprehensive list of all services represented in this folder based on file and subfolder services information
        
        Follow the exact format specified in the system instructions for your response.
    """

    return system_prompt, user_prompt

def services_generation():
    system_prompt = """
        <Task>
        Create an architectural blueprint of the given repository by identifying and classifying both external services and third-party services with no overlap between categories.
        </Task>

        <Definitions>
        - External services: Company-provided services hosted outside the application (AWS S3, Google Cloud, Stripe, Twilio)
        - Third-party services: Libraries, frameworks, and SDKs that are part of the core application stack (Django, React, MongoDB, Redux)
        </Definitions>

        <Output_Format>
        {
        "external_services": [
            {
            "external_service_name": "string",
            "description": "string",
            "associated_files": ["string"],
            "service_class": "string",
            "used_in_files": ["string"]
            }
        ],
        "thirdparty_services": [
            {
            "thirdparty_service_name": "string",
            "description": "string",
            "associated_files": ["string"],
            "service_class": "string",
            "used_in_files": ["string"]
            }
        ]
        }
        </Output_Format>

        <Instructions>
        1. Conduct a thorough repository analysis to identify all services
        2. Classify each service into exactly ONE category:
        - External services: Cloud platforms, payment processors, authentication providers
        - Third-party services: Frameworks, libraries, SDKs integrated into the codebase
        3. For each service, provide:
        - Name: Exact service name
        - Description: Concise explanation of functionality and purpose
        - Associated files: All files directly importing or using the service
        - Service class: Category (e.g., "cloud storage", "web framework", "database")
        - Used in files: Complete paths of files utilizing the service
        4. Ensure ZERO overlap between categories
        5. Prioritize accuracy over comprehensiveness
        6. Validate that identified services are actively used in the project
        7. Include only services with clear evidence of implementation
        8. Do not create a lot of services which are redundant. Keep it to a maximum of 50 services only.
        </Instructions>

        <Examples>
        Good External Service Entry:
        {
        "external_service_name": "AWS S3",
        "description": "Cloud storage service used for storing user-uploaded files",
        "associated_files": ["src/services/storage.js", "src/config/aws.js"],
        "service_class": "cloud storage",
        "used_in_files": ["src/components/FileUpload.js", "src/pages/UserProfile.js"]
        }

        Good Third-Party Service Entry:
        {
        "thirdparty_service_name": "React",
        "description": "Frontend JavaScript library for building user interfaces",
        "associated_files": ["package.json", "src/index.js"],
        "service_class": "frontend framework",
        "used_in_files": ["src/App.js", "src/components/*.js"]
        }
        </Examples>

        Analyze the repository and provide the complete architectural blueprint in the specified format.
    """

    user_prompt = ""

    return system_prompt, user_prompt

def executive_summary_generation(combined_summary, user_mvf):
    system_prompt = """
    Your Role:
    You are an expert software architect tasked with understanding a codebase and creating an executive summary that clearly articulates the main purpose of this application,
    the core problem that the application is solving, and the prioritized list of the most valuable features, solely based on the provided folder wise summary. Do not hallucinate and create the most valuable features and its description on assumption. This needs to be based on facts.

    Task:
    1. Analyze provided folder wise summary and the services used and the user defined features (if provided).
    2. Understand component interactions and functions.
    3. Prioritize the User Defined Features (if provided) in the summary.
    4. Identify and prioritize the most valuable features based on their importance and relevance to the overall project, as evidenced in the code.
    5. Create a comprehensive executive summary.

    Steps:
    1. Review folder wise summary.
    2. Analyze folder wise summary:
    - Identify key components and their roles
    - Note data operations, design patterns, and architectural decisions
    3. Create summary:
    - Describe the specific problem the codebase solves, based on folder wise summary
    - Explain component interactions
    - Outline data workflow
    4. Identify and prioritize main features:
    - Determine which feature(s) address the core problem of the application, based on code implementation
    - Rank features based on their importance and relevance to solving the main problem, as evidenced in the code
    - The feature should be major components of the codebase and not minor functions like "Modular Architecture" or "Code Reusability", these are not features but design principles.

    Focus Areas:
    - Precised feature prioritization and importance
    - High-level functionality
    - Clear, concise technical language
    - Objective description
    - Capture entire workflow

    Guidelines:
    - Only use the folder wise summary provided
    - Use precise technical terms
    - Include user-defined features if provided and evidenced in the code
    - Prioritize features based on their importance to the core problem, as shown in the folder wise summary

    Feature Identification and Prioritization:
    - Carefully analyze the folder wise summary to identify features actually present in the folder wise summary
    - Do not assume or infer features that are not explicitly mentioned in the folder wise summary
    - Identify the top feature that solves the majority of the problem based on code evidence
    - Rank subsequent features in descending order of importance, ensuring they are present in the folder wise summary
    - Ensure the feature list reflects the codebase's focus and structure
    - Only include features that have substantial implementation in the codebase that is evident from folder wise summary

    Output Format - Adhering to this format is crucial
    ```json
    {
    "data": "generated_summary in string format adhering to the Expected Output Format for Generated Summary",
    "confidence_score": 90,
    "traceback": {
    "Feature 1 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 1 Title' is included, as the 'phrase' is an evidence that this feature is part of the codebase.",
    "Feature 2 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 2 Title' is included, as the 'phrase' is an evidence that this feature is part of the codebase.",
    ...
    }
    }
    ```

    Requirements:
    - Replace \n with \\n in JSON
    - Limit upto 5 main features (max 2 sub-features each) or 7500 tokens
    - If due to any reason such as codebase being small, you are unable to provide 5 features, then provide as many high-level features as possible between the range of 1 to 5.
    - Don't assume features or include minor features due to inability to provide 5 features, lesser number of features is acceptable.
    - Use specified JSON format only
    - Start with "```json" and end with "```"
    - Ensure the top feature in the prioritized list addresses the core problem and is present in the folder wise summary
    - Rank features in descending order of importance to the main problem, based on actual code implementation
    - Do NOT include features that are NOT evidenced in the provided folder wise summary
    - Evaluate the folder wise summary objectively, considering all conclusions on the actual code provided
    - Do NOT make any assumptions about organizational goals or intentions beyond what is explicitly shown in the code
    - Focus solely on the technical aspects and implemented functionality, avoiding speculation about business objectives or future plans
    - Both the keys data, confidence score, and traceback should be present in the output JSON
    - The generated summary should be in string format only and be contained inside the "data" key
    - The "traceback" key should contain a dictionary with feature names as keys and justifications for including these features based on exact phrases from the input
    - Do not include any feature that could potentially be part of the folder wise summary without explicit evidence
    - Every feature mentioned must be driven by clear evidence from the provided input
    """
    user_prompt = """
    Expected Output Format for Generated Summary:

  **Overview**
  <empty line>
  <A brief introduction to the codebase and its main purpose; in paragraph format only, not in points.
  This paragraph should provide a concise yet comprehensive overview of the codebase, its primary functionality, solution provided by the project and its intended use case.
  Aim for 3-5 sentences that capture the essence of the project.>
  <empty line>
  **Highlighted Features**
  <empty line>
  <
  List and briefly explain the key features that are significant components of the codebase and would serve as selling points.
  These features should be presented as follows:
  1. Use numbered points for each feature.
  2. Provide a brief explanation for each feature in 1-2 sentences, highlighting its importance and benefit to the end user.
  3. Focus on features that are central to the codebase's functionality and most important to the end user.
  4. Dont include generic features like "Modular Architecture" or "Code Reusability", these are not features but design principles.
  5. Do not include sub-points under any feature.
  6. Prioritize User Defined Features (if provided) at the beginning of the list.
  7. If User Defined Features are given, list them first before including any features identified through your analysis.
  8. Aim to provide upto of 1 to 5 key features, after each feature add an empty line for formatting purposes.
  9. Ensure that the features listed represent the core functionality and unique selling points based on the folder wise summary.
  10. Use clear, concise language that emphasizes the value proposition of each feature.
  11. Also under each feature, mention which file/folder was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
  12. Do not add features into Highlighted Features if they dont have value for buisness stakeholder about the application. Also do not repeat adding similar feature in this section.

  Output Structure:
  1. ***<Feature 1 Title>***: <Description of the feature in one to two sentences.\n
  2. ***<Feature 2 Title>***: <Description of the feature in one to two sentences.>\n
  >
  <empty line>
  **Key Benefits**
  <empty line>
  <Summarize the key benefits of the codebase in one to two sentences.
  This summary should encapsulate the overall value proposition of the codebase and its potential impact on users or the organization.>
  <empty line>
  <Highlight the most significant key benefits the codebase has to offer in bulleted points. The format should be:
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  Aim for 3-5 bullet points that capture the most compelling advantages of using this codebase, after each point add an empty line for formatting purposes.
  Each benefit should be distinct and provide a clear value proposition.>

  <Final Output Format>
  Output Format - Adhering to this format is crucial, the output should be in parsable JSON format:
  ```json
  {{
    "data": "<generated_summary in string format adhering to the Expected Output Format for Generated Summary>",
    "confidence_score": 90,
    "traceback": {{
      "Feature 1 Title": "Since it mentions about <exact phrase from the folder wise summary>, the 'Feature 1 Title' is included, as the "phrase" is an evidence that this feature is part of the folder wise summary.",
      "Feature 2 Title": "Since it mentions about <exact phrase from the folder wise summary>, the 'Feature 2 Title' is included, as the "phrase" is an evidence that this feature is part of the folder wise summary.",
      ...
    }}
  }}
  ```
  </Final Output Format>
  Note: If the traceback includes phrases that are not present in the folder wise summary then you would be penalized 10000 points.
  The output should be having data, confidence score, and traceback keys, and the entire content inside "```json" and "```" should be parsable by json.
  The "data" key should contain the generated summary and it should be in string format only, allowing the parsing of the entire json.
  If there are any inverted commas inside the generated summary, then escape them with a backslash.
  Do not change or skip the headings of each section in the generated json. The generated summary must have "Overview", "Highlighted Features", "Key Benefits" as section titles. Follow the above provided guidelines."""
    user_prompt += f"""Use the below folder wise summary to generate the summary in the above format: {combined_summary}""" + "User Defined Features : " + str(user_mvf)
    return system_prompt, user_prompt

def db_executive_summary_generation(combined_summary, user_mvf): 
    system_prompt = """
    Role:
    You are an expert Database Architect tasked with understanding the contents of all tables and schema of the database. 
    You shall Articulate a proper executive summary that clearly captures all the main & high-level features of this database.
    The core use-case that this database is intended for, and the prioritized list of the most valuable features, solely based on the provided Table-Level summaries. 
    Do not hallucinate. Do NOT create the most valuable features and its description on pure assumptions. This needs to be based on facts, with proper backing.

    Task:
    1. Analyze provided Table wise summaries.
    2. Understand component interactions and functions.
    3. Prioritize the User Defined Features (if provided) in the summary.
    4. Identify and prioritize the most valuable features based on their importance to the core use-case the Database is solving.
    5. Create a comprehensive executive summary.

    Steps:
    1. Review Table wise summary.
    2. Analyze Table wise summary:
      - Identify all tables. 
      - Take into consideration the foreign keys, primary keys, is-a, has-a, and many-to-many relationships.
      - Deeply understand the intended-use-case of each table.
      - Note data operations, design patterns, and architectural decisions
    3. Create summary:
      - Describe the specific problem the Database is solving, based on Table wise summary
      - Explain high-level interactions and dependencies
      - Outline data workflow
    4. Identify and prioritize main features:
      - Determine which feature(s) address the core problem of the Database, based on SQL implementation and Table wise summary
      - Rank features based on their importance and relevance to solving the main problem, as evidenced in the Database
      - The feature should be major components of the Database and not minor functions like Many-to-Many Relationships, or "Foreign Keys". 
        These are implementation concepts. Not core features.

    Focus Areas:
    - Precised feature prioritization and importance
    - High-level functionality of this Database
    - Clear, concise technical language with Database-specific Language
    - Objective description
    - Capture entire data workflow

    Guidelines:
    - Only use the Table wise summary provided
    - Use precise Database-relevant technical terms
    - Include user-defined features if provided and evidenced in the Table wise summary
    - Prioritize features based on their importance to the core problem, as shown in the Table wise summary

    Feature Identification and Prioritization:
    - Carefully analyze the Table wise summary to identify features actually present in the Table wise summary
    - Do not assume or infer features that are not explicitly mentioned in the Table wise summary
    - Identify the top feature that solves the majority of the problem based on Database and SQL evidence
    - Rank subsequent features in descending order of importance, ensuring they are present in the Table wise summary
    - Ensure the feature list reflects the Database's focus and structure
    - Only include features that have substantial implementation in the Database that is evident from Table wise summary

    Output Format - Adhering to this format is crucial
    ```json
    {
    "data": "generated_summary in string format adhering to the Expected Output Format for Generated Summary",
    "confidence_score": 90,
    "traceback": {
    "Feature 1 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 1 Title' is included, as the 'phrase' is an evidence that this feature is part of the Database.",
    "Feature 2 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 2 Title' is included, as the 'phrase' is an evidence that this feature is part of the Database.",
    ...
    }
    }
    ```

    Requirements:
    - Replace \n with \\n in JSON
    - Limit upto 5 main features (max 2 sub-features each) or 7500 tokens
    - If due to any reason such as Database being small, you are unable to provide 5 features, then provide as many high-level features as possible between the range of 1 to 5.
    - Don't assume features or include minor features due to inability to provide 5 features, lesser number of features is acceptable.
    - Use specified JSON format only
    - Start with "```json" and end with "```"
    - Ensure the top feature in the prioritized list addresses the core problem and is present in the Table wise summary
    - Rank features in descending order of importance to the main problem, based on actual Database and SQL implementation
    - Do NOT include features that are NOT evidenced in the provided Table wise summary
    - Evaluate the Table wise summary objectively, considering all conclusions on the actual Database and SQL provided
    - Do NOT make any assumptions about organizational goals or intentions beyond what is explicitly shown in the Database and SQL
    - Focus solely on the technical aspects and implemented functionality, avoiding speculation about business objectives or future plans
    - Both the keys data, confidence score, and traceback should be present in the output JSON
    - The generated summary should be in string format only and be contained inside the "data" key
    - The "traceback" key should contain a dictionary with feature names as keys and justifications for including these features based on exact phrases from the input
    - Do not include any feature that could potentially be part of the Table wise summary without explicit evidence
    - Every feature mentioned must be driven by clear evidence from the provided input.
    - Strictly use an assertive and objective tone in your response. 
    - Do not be unsure about anything.
    - Do not include the "Folder Name" in your response. Ignore "dbanalysis" folder. Provide Executive Summary of the Database-ONLY.
    """

    user_prompt = """
  Expected Output Format for Generated Summary:

  **Overview**
  <empty line>
  <A brief introduction to the Database and its main purpose; in paragraph format only, not in points.
  This paragraph should provide a concise yet comprehensive overview of the Database, its primary functionality, and its intended use case.
  Aim for 3-5 sentences that capture the essence of the Database.>
  <empty line>
  **Highlighted Features**
  <empty line>
  <
  List and briefly explain the key features that are significant components of the Database and would serve as selling points.
  These features should be presented as follows:
  1. Use numbered points for each feature.
  2. Provide a brief explanation for each feature in 1-2 sentences, highlighting its importance and benefit to the END USER.
  3. Focus on features that are central to the Database's functionality and most important to the END USER.
  4. Dont include generic features like  Many-to-Many Relationships, or "Foreign Keys", these are not features but Design Principles.
  5. Do not include sub-points under any feature.
  6. Prioritize User Defined Features (if provided) at the beginning of the list.
  7. If User Defined Features are given, list them first before including any features identified through your analysis.
  8. Aim to provide upto of 1 to 5 key features, after each feature add an empty line for formatting purposes.
  9. Ensure that the features listed represent the core functionality and unique selling points based on the Table wise summary.
  10. Use clear, concise language that emphasizes the value proposition of each feature.
  11. Also under each feature, mention which file/Table was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
  12. Do not add features into Highlighted Features if they dont have value for buisness stakeholder about the application. Also do not repeat adding similar feature in this section.

  Output Structure:
  1. ***<Feature 1 Title>***: <Description of the feature in one to two sentences.\n
  2. ***<Feature 2 Title>***: <Description of the feature in one to two sentences.>\n
  >
  <empty line>
  **Key Benefits**
  <empty line>
  <Summarize the key benefits of the Database in one to two sentences.
  This summary should encapsulate the overall value proposition of the Database and its potential impact on users or the organization.>
  <empty line>
  <Highlight the most significant key benefits the Database has to offer in bulleted points. The format should be:
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  Aim for 3-5 bullet points that capture the most compelling advantages of using this Database, after each point add an empty line for formatting purposes.
  Each benefit should be distinct and provide a clear value proposition.>

  <Final Output Format>
  Output Format - Adhering to this format is crucial, the output should be in parsable JSON format:
  ```json
  {{
    "data": "<generated_summary in string format adhering to the Expected Output Format for Generated Summary>",
    "confidence_score": 90,
    "traceback": {{
      "Feature 1 Title": "Since it mentions about <exact phrase from the Table wise summary>, the 'Feature 1 Title' is included, as the "phrase" is an evidence that this feature is part of the Table wise summary.",
      "Feature 2 Title": "Since it mentions about <exact phrase from the Table wise summary>, the 'Feature 2 Title' is included, as the "phrase" is an evidence that this feature is part of the Table wise summary.",
      ...
    }}
  }}
  ```
  </Final Output Format>
  Note: If the traceback includes phrases that are not present in the Table wise summary then you would be penalized 10000 points.
  The output should be having data, confidence score, and traceback keys, and the entire content inside "```json" and "```" should be parsable by json.
  The "data" key should contain the generated summary and it should be in string format only, allowing the parsing of the entire json.
  If there are any inverted commas inside the generated summary, then escape them with a backslash.
  Do not change or skip the headings of each section in the generated json. The generated summary must have "Overview", "Highlighted Features", "Key Benefits" as section titles. Follow the above provided guidelines.
    """

    user_prompt += f"""Use the below Table wise summary to generate the summary in the above format: {combined_summary}""" + "User Defined Features : " + str(user_mvf)

    return system_prompt, user_prompt


def architecture_diagram_generation(services_data, icons_metadata):
    user_prompt = f"""
    <Input>
    $services_data = {services_data}
    $icons_metadata
    </Input>

    <Role>
    You are an expert at understanding large projects based on their executive summary and the services being used in them. Create a JSON structure for a ReactFlow diagram based on the given service class JSON.
    </Role>

    <Output Structure>
    1. Create a JSON object with a "nodes" and "edges" array.
    2. Create nodes for each external and third-party service.
    3. "nodes": An array containing all node objects.
      - "id": A unique string identifier for the node.
      - "data":   
        - "label": The name of the node.
        - "description": Description of the service.
        - "associated_files": Associated file and used in files in the service node, defaulting to "No File Available" if not present.
        - "group": The logical group name (e.g., 'Backend', 'Frontend', 'Database',etc..).
        - "subgroup": The specific subgroup within the group (e.g., Frameworks, NoSQL Databases, State Management, etc.).
        - "service": The appropriate filename of the icon based on the $icons_metadata.
      - "position" : The x and y coordinates of the node.
      - "type" : "customNode" This should be fixed.
    4. "edges" : An array having id, source, target, label, and type should be customEdge always.
    4. Ensure all services and files from the input JSON are included.
    5. The output should be in the form of a dictionary containing a "nodes" and "edges" array.
    6. Present only the code inside delimiters "```reactflow [reactflow CODE]```" without any additional explanation.
    """

    system_prompt:str = """
    <Task>
      You are tasked with creating a JSON structure for a ReactFlow diagram based on the given executive summary and the service_class_json. The executive summary contains an overview of the entire project. This JSON includes information about external services and third-party services, along with their associated files. Your output should represent this information as a network of nodes and edges.
    </Task>
    
    <Icons Context>
      $icons_metadata = """ + str(icons_metadata) + """
    </Icons Context>

    <Instructions>
      You are a solution expert, specializing in problem and solution flows. You will be given the solution overview for a project, and your task is to create an interconnected single component of graph which is detailed, and intuitive and self explanatory for:

      Follow these guidelines:
      1. Create nodes for each unique service (both external and third-party).
      2. Do not create any group nodes.
      4. In the data key for each service node, include two additional fields called group and subgroup. The group field should contain the logical group name (e.g., Frontend, Backend, Databases, etc..), and the subgroup field should provide more specific categorization (e.g., Frameworks, NoSQL Databases, etc..). For example, for a service node representing React, the group would be Frontend and the subgroup would be Frameworks.
      5. For each node, check which icon will be the most suitable from the $icons_metadata in the <Icons Context>
      6. Ensure all information from the input is represented in the output.
      7. The position coordinates must be proper for all the nodes.
    </Instructions>

    <Rules>
      **Ensure all nodes in the generated graph are interconnected such that every node has at least one edge, forming a single connected component without any isolated or disjoint sections. (High Priority Requirement)**
      Important Rules to be followed:
      1. Give detailed technical architecture flow and the JSON object following the below output format.
      2. Make sure that the flow and order of new solution approach is explained well in the graph with appropriate edges. Use as many edges you want to describe the data and user flow properly.
      3. The whole user and data flow should be clear.
      4. Do not add unnecessary nodes and edges. Do not create duplicate nodes that perform same task.
      5. Make the Node descriptions detailed, breaking tasks into multiple sub-tasks if needed.
      6. Ensure your edges show the actual flow, and not just connections of what's related. The connections are meant to show the logical flow, and not the relatedness/similarity.
      7. The group name is meant to classify clusters of nodes within each graph. For instance, if we have multiple nodes in features, they would all have "feature" as group. In Architecture Flow, the "Group" should show the layer each node is in, for instance "Backend Layer", "Database Layer" etc.
      9. for a hierarchy of nodes A -> B -> C; ensure that there is not a connection between A -> C.
    </Rules>
    
    <output_format>
    The output should be in between the delimeters ```reactflow and ```. Only provide the json output. Don't give unnecesary explanation.
    ```reactflow
    {
      "nodes": [
        { 
          "id": "unique_node_identifier_string",
          "data" : {
            "label": "name_of_the_service",
            "description": "description of the service",
            "associated_files": ["file_path_1", "file_path_2", "file_path_3", etc.],  // (default: ["No File Available"] if not present)
            "group": "name_of_group",  // Add the logical group name (e.g., "Frontend", "Backend", etc..)
            "subgroup": "name_of_subgroup",  // Add a more specific subgroup name (e.g., "Frameworks", "NoSQL Databases", etc..)
            "service": "filename" //taken from the $icons_metadata,
          }
          "position":{ "x": "Xcoordinate", "y": "Ycoordinate" },
          "type" : "customNode" //this is hardcoded and will be constant
        }
      ],
      "edges": [
        {
          "id": "unique_egde_identifier_string",
          "source": "label A",
          "target": "label B",
          "label": "Showcase what comes from the source node, to the target node. Be concise and specific with labels, such as 'Ingested Data', 'Converted Text', 'User Query' etc. Use at max 5 words",
          "type" : "customEdge" //this is hardcoded and will be constant
        }
      ]
    }```
    </output_format>
    """
    return system_prompt, user_prompt
  

def erd_generation(services_data, icons_metadata):
  tables_metadata = []
  for entry in services_data:
      table_name = entry["table_name"]
      ddl = entry["ddl"]
      columns, primary_keys, foreign_keys = parse_ddl(ddl)
      tables_metadata.append({
          "table_name": table_name,
          "columns": columns,
          "primary_keys": primary_keys,
          "foreign_keys": foreign_keys
      })

  dot = generate_combined_graph(tables_metadata)

  system_prompt:str = """
    You are tasked with creating a JSON structure for a ReactFlow diagram based on the given database ER diagram and schema JSON. This JSON includes information about database columns and their relationships.Your output should represent this information as a network of nodes and edges.
    </Task>
    
    <Icons Context>
      $icons_metadata = """ + str(icons_metadata) + """
    </Icons Context>

    <Instructions>
      You are a solution expert, specializing in problem and solution flows. You will be given the database schema information of a database, and your task is to create an interconnected single component of graph which is detailed, and intuitive and self explanatory for:

      Follow these guidelines:
      1. Create nodes for each unique service (both external and third-party).
      2. Do not create any group nodes.
      4. In the data key for each service node, include two additional fields called group and subgroup. The group field should contain the logical group name (e.g.,Databases, etc..), and the subgroup field should provide more specific categorization (e.g., 'Transactional Tables', 'Reference Tables' etc..). For example, for a service node representing daily transactions, the group would be Database and the subgroup would be Transactional Tables.
      5. For each node, check which icon will be the most suitable from the $icons_metadata in the <Icons Context>
      6. Ensure all information from the input is represented in the output.
      7. The position coordinates must be proper for all the nodes.
    </Instructions>

    <Rules>
      Important Rules to be followed:
      1. Give detailed technical architecture flow and the JSON object following the below output format.
      2. Make sure that the flow and order of new solution approach is explained well in the graph with appropriate edges. Use as many edges you want to describe the data and user flow properly.
      3. The whole user and data flow should be clear.
      4. Do not add unnecessary nodes and edges. Do not create duplicate nodes that perform same task.
      5. Make the Node descriptions detailed, breaking tasks into multiple sub-tasks if needed.
      6. Ensure your edges show the actual flow, and not just connections of what's related. The connections are meant to show the logical flow, and not the relatedness/similarity.
      7. The group name is meant to classify clusters of nodes within each graph. For instance, if we have multiple nodes in features, they would all have "feature" as group. In Architecture Flow, the "Group" should show the layer each node is in, for instance "Database Layer" etc.
      9. for a hierarchy of nodes A -> B -> C; ensure that there is not a connection between A -> C.
    </Rules>
    
    <output_format>
    The output should be in between the delimeters ```reactflow and ```. Only provide the json output. Don't give unnecesary explanation.
    ```reactflow
    {
      "nodes": [
        { 
          "id": "unique_node_identifier_string",
          "data" : {
            "label": "name_of_the_table",
            "description": "description of the table",
  	    "columns": ["order_id [PK]", "product_sku [PK]", "quantity", "unit_price"]
            "group": "name_of_group",  // Add the logical group name (e.g., "Database", etc..)
            "subgroup": "name_of_subgroup",  // Add a more specific subgroup name (e.g., 'Transactional Tables', 'Reference Tables', etc..)
            "service": "filename" //taken from the $icons_metadata,
          }
          "position":{ "x": "Xcoordinate", "y": "Ycoordinate" },
          "type" : "customNode" //this is hardcoded and will be constant
        }
      ],
      "edges": [
        {
          "id": "unique_egde_identifier_string",
          "source": "label A",
          "target": "label B",
          "label": "Showcase what comes from the source node, to the target node. Be concise and specific with labels, such as 'Ingested Data', 'Converted Text', 'User Query' etc. Use at max 5 words",
          "type" : "customEdge" //this is hardcoded and will be constant
        }
      ]
    }```
    </output_format>
    """
    
  user_prompt:str = f"""
    <Input>
    $database_tables = {dot}
    $icons_metadata
    </Input>

    <Role>
    You are an expert at understanding database architecture based on ER diagrams and relational structures. Create a JSON structure for a ReactFlow diagram based on the given database schema.
    </Role>
    <Output Structure>
      1. Create a JSON object with a "nodes" and "edges" array.
      2. Create nodes for each table in the schema.
      3. "nodes": An array containing all node objects.
      - "id": A unique string identifier for the node.
      - "data":  
        - "label": The name of the table.
        - "description": A brief summary of the table's role or content.
        - "columns": List of column names (mark primary keys with [PK], foreign keys with [FK]).
        - "group": The logical group name (e.g., 'Database').
        - "subgroup": The specific subgroup within the group (e.g., 'Transactional Tables', 'Reference Tables').
        - "service": The appropriate filename of the icon based on the $icons_metadata.
      - "position" : The x and y coordinates of the node.
      - "type" : "customNode" This should be fixed.
      4. "edges" : An array having id, source, target, label, and type should be customEdge always.
      5. The label of the edge should describe the relationship, like "order_id â†’ order_id". 
      6. The output should be in the form of a dictionary containing a "nodes" and "edges" array.
      7. Present only the code inside delimiters "```reactflow [reactflow CODE]```" without any additional explanation.
    """
    
  return system_prompt, user_prompt
    

def feature_summary_generation(formatted_data, user_mvf, executive_summary):
    # if input_type is None:
    #     formatted_data = file_summary_list
    # elif input_type == "batch_summary":
    #     formatted_data = format_batchwise_summary_metadata_for_services(file_summary_list)
    # else:
    #     formatted_data = format_file_summaries(file_summary_list)

    user_prompt = """
    Role: You are an AI code analyst specializing in creating concise, feature-level summaries of codebases.

    Objective: Provide a comprehensive yet concise feature-level summary of a given codebase, highlighting key components, functionality, and the project's overall workflow.

    Input: You will receive information about a codebase, which may include an executive summary or other project details.

    Steps:
    1. Analyze the provided codebase information.
    2. Identify the main features (maximum 5) of the project from the executive summary (if provided in same order)
    3. Create a summary following the specified format, including:
        a. An overview of the project
        b. A list of key features with brief descriptions
        c. A closure statement
    4. Self-evaluate the generated summary and assign a confidence score.
    5. Format the output as specified in the instructions.

    Output Format:
    ```json
    {
        "data": "generated_summary in string format adhering to the Detailed Instructions for Output Format",
        "confidence_score": 90
    }
    ```

    Detailed Instructions for Output Format:

    **Overview**
    <empty line>
    < 
        Summarize all features in 2-3 sentences, introducing the project and its purpose.
        Provide a 2-3 sentence summary of key benefits, highlighting core architecture and value proposition.
    >
    <empty line>
    **Key Features**
    <empty line>
    <   
        List a maximum of 5 main features.
        For each feature, provide up to 2 sub-points describing its functionality.
        Ensure clear explanation of how features interact and contribute to the project's goals.
        1. ***<Key Feature Title>*** : 
        * <Sub point 1 description>
        * <Sub point 2 description>
        <empty line>
    >
    <empty line>
    < 
        Summarize the overall impact and value proposition of the project in one sentence as a conclusion statement.
    >
    <empty line>
    
    -> Self-Evaluation:
        - Score the summary out of 100 based on clarity, precision, detail, knowledge, accuracy, technical correctness, and understanding of the data.

    -> Formatting Requirements:
        - Replace all newline characters (\n) with \\n in the JSON output.
        - Ensure the complete JSON is less than 7500 tokens.
        - Start the output with "```json" and end with "```".
        - If an executive summary is provided, use only the highlighted features from it.

    Example Output Structure:
    ```json
    {
        "data": "**Overview**\\n\\n[Project overview]\\n\\n[Benefits summary]\\n\\n**Key Features**\\n\\n1. *Feature 1*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n2. *Feature 2*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n[...continue for up to 5 features...]\\n\\n[Closure statement]",
        "confidence_score": 90
    }
    ```

    Remember: Adhere strictly to the output format and instructions to maintain consistency and accuracy in your summary.
    """

    user_prompt += "User Defined Features : " + str(user_mvf)

    system_prompt = f"""
        <role>
        You are an assistant to a Senior Software Engineer. You are very capable in reading and understanding huge codebases.
        There is no edge-case, no mistake, no functionality no matter how small goes unnoticed by you.
        You will be given a large codebase and be asked queries regarding it.
        </role>

        <Task>
        You will be given relevant files from a production codebase. The Senior Engineer will consult you to clear his doubts and ask for critical code-level and functionality level analysis of the same.
        <Important>
        1. You will be clear. Feel free to be descriptive but Avoid Jargon
        2. You shall perform critical analysis on the code before responding.
        3. Note that the codebase will be quite complex and have dependencies everywhere, be mindful of them all.
        4. Enclose code in (triple backticks)``` code ```
        </Important>
        </Task>

        Files from Codebase goes here :
        <Repo Structure>
        {formatted_data}
        </Repo Structure>
    """

    start_index = executive_summary.find("Highlighted Features")
    end_index = executive_summary.find("Key Benefits")

    if start_index != -1 and end_index != -1:
        executive_summary = executive_summary[start_index:end_index].strip()

    user_prompt += "Executive Summary : " + str(executive_summary)

    return system_prompt, user_prompt

def feature_summary_generation_db(formatted_data, user_mvf, executive_summary):
    # if input_type is None:
    #     formatted_data = file_summary_list
    # elif input_type == "batch_summary":
    #     formatted_data = format_batchwise_summary_metadata_for_services(file_summary_list)
    # else:
    #     formatted_data = format_file_summaries(file_summary_list)

    user_prompt = """
    Role: You are an AI Database Analyst specializing in creating concise, feature-level summaries of complex database schemas and architectures.

    Objective: Provide a comprehensive yet concise feature-level summary of a given database schema information, highlighting key components, entities, relationships, and the overall data architecture workflow.

    Input: You will receive information about a database design, which may include an executive summary or other schema-level details.

    Steps:
    1. Analyze the provided database schema information.
    2. Identify the main features (maximum 5) of the database from the executive summary (if provided in same order)
    3. Create a summary following the specified format, including:
        a. An overview of the database
        b. A list of key features with brief descriptions
        c. A closure statement
    4. Self-evaluate the generated summary and assign a confidence score.
    5. Format the output as specified in the instructions.

    Output Format:
    ```json
    {
        "data": "generated_summary in string format adhering to the Detailed Instructions for Output Format",
        "confidence_score": 90
    }
    ```

    Detailed Instructions for Output Format:

    **Overview**
    <empty line>
    < 
        Summarize all features in 2-3 sentences, introducing the database and its purpose.
        Provide a 2-3 sentence summary of key benefits, highlighting schema structure, normalization or denormalization logic, and value proposition in handling data.
    >
    <empty line>
    **Key Features**
    <empty line>
    <   
        List a maximum of 5 main features.
        For each feature, provide up to 2 sub-points describing its data handling, relationships, or optimization logic.
        Ensure clear explanation of how features contribute to performance, consistency, and data integrity.
        1. ***<Key Feature Title>*** : 
        * <Sub point 1 description>
        * <Sub point 2 description>
        <empty line>
    >
    <empty line>
    < 
        Summarize the overall impact and value proposition of the database in one sentence as a conclusion statement.
    >
    <empty line>
    
    -> Self-Evaluation:
        - Score the summary out of 100 based on clarity, precision, detail, knowledge, accuracy, technical correctness, and understanding of the schema information.

    -> Formatting Requirements:
        - Replace all newline characters (\n) with \\n in the JSON output.
        - Ensure the complete JSON is less than 7500 tokens.
        - Start the output with "```json" and end with "```".
        - If an executive summary is provided, use only the highlighted features from it.

    Example Output Structure:
    ```json
    {
        "data": "**Overview**\\n\\n[Database overview]\\n\\n[Benefits summary]\\n\\n**Key Features**\\n\\n1. *Feature 1*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n2. *Feature 2*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n[...continue for up to 5 features...]\\n\\n[Closure statement]",
        "confidence_score": 90
    }
    ```

    Remember: Adhere strictly to the output format and instructions to maintain consistency and accuracy in your summary.
    """

    user_prompt += "User Defined Features : " + str(user_mvf)

    system_prompt = f"""
        <role>
        You are an assistant to a Senior Data Architect. You are very capable in reading, analyzing, and understanding complex database schemas and data models.
        No entity, constraint, relationship, or optimization logic goes unnoticed by you.
        You will be given a comprehensive database structure or schema information and will be asked to analyze, explain, and summarize it at a structural and functional level.
        </role>

        <Task>
        You will be given relevant database schema files or DDL definitions. The Senior Data Architect will consult you to clear doubts and ask for critical schema-level and data model-level analysis.
        <Important>
        1. You will be clear. Feel free to be descriptive but Avoid Jargon
        2. Perform a critical and deep analysis of the schema and the information given before responding.
        3. The schema will often involve multiple tables, foreign keys, views, procedures, and indexing strategies â€” be mindful of their dependencies and relationships.
        4. Enclose code or schema in (triple backticks)``` code ```
        </Important>
        </Task>

        Files from Database schema goes here :
        <Database Structure>
        {formatted_data}
        </Database Structure>
    """

    start_index = executive_summary.find("Highlighted Features")
    end_index = executive_summary.find("Key Benefits")

    if start_index != -1 and end_index != -1:
        executive_summary = executive_summary[start_index:end_index].strip()

    user_prompt += "Executive Summary : " + str(executive_summary)

    return system_prompt, user_prompt


#FEATURE HIERARCHY:
generate_features_system_prompt = """
  <Role>
    You are a Software Architect with expertise in analyzing large summaries from code files of an application. 
    You can comprehend summaries from code files that are complex, production-grade and are written in various programming languages to generate most important features, their description and the subfeatures with their description belonging to the most important features along with the other relevant information requested below.
    
    You will follow 2 Events before responding : 
    1. Generation of Feature Hierarchy as given in "Output_Format".
    2. Critical Evaluation of Every Confidence Score.  
  </Role> 

    <Task 1>
    You are provided with multiple relative file paths and file-wise code summaries from a application codebase.
    1. Analyze the file summaries carefully, leveraging your expertise to deduce the frameworks, functionality, and features.
    2. Perform a critical assessment of the code's functionality and interdependencies before responding.
    3. The codebase is complex and likely contains dependencies across various modules. Be mindful of these.
    4. Analyse every file summary and assign the features and sub-features based on the information provided.
    5. Respond strictly in the structured JSON format provided below.
    6. In each sub-feature's 'file_path' array:
        - Set 'critical: true' ONLY for files that are CORE & NON-REPLACEABLE to the sub-feature's main functionality.
        - Set 'critical: false' for ALL supporting, secondary, or replaceable files  
        - Each sub-feature should have both true and false entries.
        - If unsure, default to false (be EXTREMELY selective with 'true')
        - Make sure each sub-feature atleast have one file as true.

    Explanation of the Output terms:
    Feature - Features are most valuable and high level features extracted from the list of summaries that are provided to you. 
    Feature description - Description of the features explaining the high level value and impact that it creates for the project. Define the Feature. The description should be crisp, precise, well formatted and must be between 2-3 lines.
    Subfeature - Subfeatures are micro most valuable features that are extracted from the list of summaries and belong to the Most related and similar Features.
    Subfeature description - Description of the subfeatures explaining the specific value, technical and non-technical functionalites that it provided to the project. Define the subfeature and also explain how its related to the feature. The description should be crisp, precise, well formatted and must be between 2-3 lines.
    
    Points to Remember:
    1. Do not extract any feature or subfeature where there are no reference/citations from the application summaries.
    2. The description must be precise, valuable, well-formatted and must be between 2-3 lines.
    3. The Feature titles should be precise, specific, self explanaible, independent and not have similar feature titles. The Feature titles should not be highly generalized.
    4. The SubFeatures titles should be precise, self explanaible and not have similar subfeature titles. The SubFeature titles should not be highly generalized.
    5. SubFeatures should not be very low level that it explains code functions, code process like 'Json handling', 'Reading csv', readME etc.
    6. If similar subfeatures are present, then group them under one common Feature itself. Do not create multuple Features for similar subfeatures.
    6. If Unit testing related summaries are found, then create that as another Feature named 'Unit Testing' and assign the specific testing subfeatures under this feature.
    </Task 1>

  <Task 2>
  You shall now Assign and Justify Confidence Scores for each feature.

  <Critical Evaluation of Confidence Scores> 

  <Evaluation MODE>
  - You will now Forget everything that was done beforehand and act as an unbiased judge.
  - $Project-Summaries-&-Paths (INPUT).
  </Evaluation MODE>
  <Important>
  Critically analyze every "Feature" and "SubFeature" based on the following metrics. 
  You shall generate a confidence score between 0-100 for each of the following :
  1. Is the "Feature" & "SubFeature" name accurate to its functionality ? (Accuracy)
  2. Does the "Feature" & "SubFeature" include files with an unrelated function ? (Feature Dilution Rate)
  3. Important : Does this "Feature" & "SubFeature" make sense given the Overall Purpose of the Application ? (Consistency)
  4. Are all the files in "Feature" & "SubFeature" included ? (Completeness)

  <Strict>
  1. You will now generate a list of 4 confidence scores between 0-100 for above criteria under "confidence_score" key.
  2. Based on above criteria, you shall provide a VERY BRIEF logical explanation (10-20 words) for Confidence Score under "confidence_score_justification" key.
  3. Make sure to mention the entire filepath without omitting the prefix.
  4. Make sure all the filepaths are present.
  <Important> STRICTLY Don't Comment on Missing Files. Don't Overestimate. Don't Underestimate.</Important> 
  </Strict>

  </Important>

  </Critical Evaluation of Confidence Scores> 
  </Step 2>


      <Output_Format>
    Return a response in JSON format. Do not include any extra information or explanations. Strictly DON'T deviate from mentioned KEYS.
    Example:
```json
[
  {
    "name": "User Authentication and Management",
    "feature_description": "Comprehensive user account system with secure login, registration, profile management, and role-based access control.",
    "feature_description_confidence_score": [95, 70, 100, 70],
    "sub_features": [
      {
        "name": "User Registration",
        "description": "Allows new users to create accounts by providing necessary information such as username, email, and password. Implements email verification, password strength checks, and duplicate account prevention. Stores user data securely in the database with password hashing.",
        "file_path": [
          {
            "module_name": "RegistrationController",
            "path": "Controllers/Account/RegistrationController.cs",
            "critical": true
          },
          {
            "module_name": "RegisterView",
            "path": "Views/Account/Register.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [75, 80, 85, 65],
        "sub_feature_confidence_score_justification": "No feature dilution, might have missed some file."
      },
      {
        "name": "User Login",
        "description": "Authenticates users using their credentials, creates and manages user sessions, and implements security measures such as login attempt limiting and two-factor authentication (2FA). Provides password reset functionality for forgotten passwords.",
        "file_path": [
          {
            "module_name": "LoginController",
            "path": "Controllers/Account/LoginController.cs",
            "critical": true
          },
          {
            "module_name": "LoginView",
            "path": "Views/Account/Login.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [80, 100, 80, 75],
        "sub_feature_confidence_score_justification": "High chance of missing files."
      }
    ],
    "feature_confidence_score_justification": "No feature dilution, duplication or missing files. Accurate Naming."
  },
  {
    "name": "Product Catalog Management",
    "feature_description": "Comprehensive system for managing product listings, categories, and inventory across the e-commerce platform.",
    "feature_description_confidence_score": [95, 65, 70, 80],
    "sub_features": [
      {
        "name": "Product CRUD Operations",
        "description": "Enables administrators to create, read, update, and delete product listings. Includes functionality for managing product details such as name, description, price, images, and inventory levels. Implements validation to ensure data integrity and consistency across the product catalog.",
        "file_path": [
          {
            "module_name": "ProductController",
            "path": "Controllers/ProductController.cs",
            "critical": true
          },
          {
            "module_name": "ProductView",
            "path": "Views/Product/Index.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [90, 85, 100, 70],
        "sub_feature_confidence_score_justification": "High confidence with no duplication or dilution."
      },
      {
        "name": "Category Management",
        "description": "Allows for the creation and management of product categories and subcategories. Implements a hierarchical structure for organizing products, enabling efficient navigation and filtering of the product catalog for both administrators and customers.",
        "file_path": [
          {
            "module_name": "CategoryController",
            "path": "Controllers/CategoryController.cs",
            "critical": true
          },
          {
            "module_name": "CategoryView",
            "path": "Views/Category/Index.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [85, 75, 90, 95],
        "sub_feature_confidence_score_justification": "High confidence without any duplication or dilution."
      }
    ],
    "feature_confidence_score_justification": "All files refer to single overall functionality. Might have missed some files."
  }
]
```
  </Output_Format>

"""

generate_features_user_message = """
<Strictly Remember>
1. As input you will be given a batch of `file_path` and `file_summary` from a production codebase. Keep it in mind that it could be a file from a very large repository with lot of inter-dependencies.
2. Understand all the file description first, then try to determine the feature, sub-features and their description. For **each file** it should have a feature or sub-features whenever the conditions are met.
3. The response should contain all the fields given in the example output format. The response should be strictly in json format.
4. The description of features/subfeatures must be in the length of 2-3 lines. The response should be structured and well-formatted.
5. Don't generate any additional explanation or description. Provide the structured response in json only.
</Strictly Remember>
  
<Input file wise summary>
{file_summary}
</Input file wise summary>
<Response>
"""

merge_features_in_hierarchy_user_prompt = """You are a software feature analyzer. Given a list of related features that have been clustered together, create a merged feature that encompasses all the functionality.

Features to merge:
{feature_list}

Generate a JSON response that includes:
1. A name for the merged feature representing accurate feature name. Do not mention its merged or unified or anything as such. The feature name should accurately represent a major funcationality of a repository.
2. A detailed description that covers all functionality
3. A confidence score (0-100) for the merge
4. A justification for the confidence score

Respond with a JSON object in the following format:
```json
{{
    "name": "Merged feature name",
    "description": "Comprehensive description",
    "confidence_score": 85,
    "confidence_justification": "Reason for the confidence score"
}}
```
Give only JSON and nothing else. Do not include any explanations or additional text outside the JSON block. Make sure to start with ```json and end with ``` only.
"""

mapping_names_for_merged_features_user_prompt = """  <Role>
    You are a smart AI cassistant with strong expertise in Software Engineering. You can understand complex, production-grade codebases written in various programming languages and summarize them effectively.
  </Role>
  <Task>
  You will be given a brief description of  features of a large codebase and your task is to generate a relevant feature name, brief description, and priority level.
  <Important>
   1. The feature name should be brief, relevant and should represent the entire description provided.
   2. Generate a relevant description which is basically a overall summary of the description provided.
   3. Assign a priority level (high, medium, low) based on the significance, importance and complexity of the feature to the overall system. 
  </important>
  </Task>
  <Example output>
  ```json
    {
        "name": <feature_name>, //string
        "feature_description": <feature_description>, //string
        "priority": <priority> //string (high, medium, or low)
    }
    ```
  </Example output>
  <Strictly Remember>
1. The feature name should be relevant and at the same time interpretable, easy to understand.
2. The feature description should represnt the entire description given for summarisation, it should be simple and easy to understant.
3. The priority should be one of: high, medium, or low.
4. The response should be strictly in json format specified above.
5. Strictly make sure Feature Description is not more than 200 words.
  </Strictly Remember>

<code summary>
The code summary is given below:
"""


reducing_sub_features_user_prompt = """
    You are a software feature consolidation expert. Your task is to merge similar sub-features into one comprehensive sub-feature.

    Here are the sub-features that need to be merged:
    {sub_features_list}

    For each sub-feature, we have:
    - Name: The sub-feature name
    - Description: The sub-feature description (if available)
    - Confidence Score: The confidence score (if available)

    Your output should be a JSON object containing:
    1. A unified sub-feature name that encompasses all the input sub-features
    2. A comprehensive description that covers all aspects of the input sub-features
    3. A confidence score (use the highest available from input sub-features)
    4. A justification for the confidence score

    Return the output in JSON format starting with ```json and ending with ```.

    Example output format:
    ```json
    {{
        "name": "Unified Sub-Feature Name",
        "description": "Comprehensive description covering all aspects",
        "sub_feature_confidence_score": 95,
        "sub_feature_confidence_score_justification": "Merged from similar sub-features with high semantic similarity"
    }}
    ```
    """


post_processing_feature_name_description_system_prompt="""
  <Role>
    You are a smart AI assistant with strong expertise in Software Engineering. You can understand complex, production-grade codebases written in various programming languages and summarize them effectively.
  </Role>
  <Task>
  You will be given a brief description of modules or features of a large codebase and your task is to generate a relevant feature name and brief description.
  <Important>
   1. The feature name should be brief, relevant and should represent the entire description provided.
   2. Generate a relevant description which is basically a overall summary of the description provided.
   3. Also generate a confidence score in a scale of 0 - 100.
  </important>
  </Task>
  <Example output>
  ```json
    {
        "name": <feature_name>,
        "feature_description_confidence_score": <score 0 - 100>,
        "feature_description": <feature_description>
    }```
  </Example output>"""

post_processing_feature_name_description_user_prompt = """<Strictly Remember>
1. The feature name should be relevant and at the same time interpretable, easy to understant.
2. The confidence score should represent the ability to summarise the description.
3. The feature description should represnt the entire description given for summarisation, it should be simple and easy to understant.
4. The response should be strictly in json format specified above.
</Strictly Remember>
<code summary>
The code summary is given below: \n
{feature_description}
</code_summary>
<response>
Your response in json goes here:
"""

merge_similar_features_system_prompt = """You are a solution architect. Your task is to carefully review each feature and its description, and combine them into a single high-level feature.

The final high-level features should represent what an end user would perceive, e.g., Messenger, Google Chat, Messaging, Reels, etc.

Based on the generated features provided, identify which features can be merged into a single high-level feature. 
Strictly output them in the following format:
{{ 
  <High-Level Feature Name 1>: [<Merged Feature 1>, <Merged Feature 2>, <Merged Feature 3>, ...],
  <High-Level Feature Name 2>: [<Merged Feature 1>, <Merged Feature 2>, <Merged Feature 3>, ...],
  ...
}}

INPUT:
Feature names and descriptions are provided in the format: 
[1. Feature name: <feature name> 
Feature description: <feature description>, 
2. ...]

{feature_texts}

MVFS:
{total_MVFs}

Points to remember:
1. While merging features and naming high-level features, always prefer names from the user-defined MVFs provided. All relevant features can be grouped under these high-level features.
2. If certain features do not fit under the user-defined MVFs, choose a better name than the existing one for the new high-level feature if necessary.
3. The names of the features being merged must remain exactly as provided in the INPUT section; do not modify them. Do not consider Feature description in Feature Names.
4. Follow the output structure strictly: high-level feature names as dictionary keys and merged features as values in list format.
5. If a feature is already a high-level feature, you do not need to forcibly merge it. If a feature seems to be function-level/low-level  features, merge them into a High-level feature.
6. Merge similar features into a single high-level feature based on their names and descriptions, when applicable. Each final high-level feature should be independent of the others.
7. Do not assign the same feature to multiple high-level features.
8. If user-defined MVFs are empty, skip point 1 and begin with point 2.
9. Do **not** include any Feature descriptions in the final output."""


merging_description_user_prompt = """You are a Solution Architect. Your task is to summarize the multiple feature descriptions provided into a brief, coherent summary of **no more than two sentences**.

  The summary must:
  - Accurately capture all key components from the provided descriptions.
  - Align clearly with the given high-level feature name.
  - Serve as the final description of the high-level feature.

  Only the final summarized description should be included in the output â€” no additional commentary or formatting.

  INPUT:
  Multiple descriptions: {merging_feature_description}

  High-Level Feature Name: {high_level_feature}
  """


micro_sub_feature_prompt = """You are an expert system analyst specializing in decomposing SubFeatures into granular, logically independent components. You support **two levels** of splitting:

1. **Horizontal splitting**: Split a subfeature into multiple *same-level subfeatures* when it encompasses multiple independently meaningful functionalities. The subfeatures created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.
2. **Vertical splitting**: Further break each of those subfeatures into *microsubfeatures* (if applicable), ensuring each micro-sub-features/micro-user-story describes a single goal or operation. The micro-sub-features/micro-user-story created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.

---

### ðŸ”§ TASK OVERVIEW

Given a Macro-Feature, Subfeature, its description, associated module files and its summary:

- Decide if the subfeature should be split horizontally into multiple same-level subfeatures.
- For each resulting subfeature (or original if not split), analyze whether it can be split vertically into **microsubfeatures** (fine-grained user stories).
- Provide the confidence scores for the subfeature that is split, whether horizontally or vertically.
- Provide the files that are related to the sub_features too, not just the micro_sub_features.
- Each leaf user-story must have files assigned to them, else you should not create/split these subfeatures.
- Provide description of generated subfeature/sub-user-stories in 2-4 lines but only valid information. Do not assume or hallucinate to generate description.
Apply this recursively: if horizontal splitting occurs, then attempt vertical splitting for each. But remember, not to create any duplicates in the process. 

---

### SPLITTING DECISIONS

#### Horizontal Splitting (Same-level Subfeatures):
Split if:
- The subfeature covers multiple high-level functionalities
- Each function could be planned, developed, and deployed independently
- Each component has a clear boundary and responsibility

#### Vertical Splitting (Microsubfeatures):
Split further if:
- A subfeature contains multiple independent operations or logical stages
- These operations can be implemented, tested, or tracked separately
- Each micro-subfeature represents one atomic, non-overlapping functionality

---

### DO NOT SPLIT IF:
- sub-user-stories are tightly coupled in the Subfeature and cannot function independently.
- Do not split subfeatures into sub-user-stories that are hardly single line of code and cannot be considered as a proper functionality, but just a config/parameter.
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across actions are too complex to isolate.
- There are no files that can be mapped to the generated user-story.
- Do not split if the user-story is barely a functionality. The split user-stories must have independent functionality that contributes to the subfeature and feature and if not, do not split.
- Don not split ReadMe & .md files into sub-user-stories.
- Do not split horizontall for granullar subfeatures as they are not user stories but mid level features.
---

### FILE MAPPING RULES:
- For each subfeature or microsubfeature, cite only directly relevant files.
- Use only the provided input data to match files â€” no guessing.
- Avoid duplication unless a file is clearly shared between components.

Each `file_path` entry must include:
```json
{
  "module_name": "<Name>",
  "path": "<Path>",
  "critical": <true/false>,
  "git_url": "<Git URL>"
}

OUTPUT FORMAT
If the subfeature should NOT be split:
Return: "None"

If the subfeature should be split, return a list of Parent User Stories with subfeatures inside.
If a subfeature itself can be further split into microsubfeatures, nest them under micro_sub_features like so:

[
  {
    "name": "Parent User Story Title 1",
    "description": "Full description of the original or updated user story and its purpose.",
    "file_path": [...],
    "sub_feature_confidence_score":"confidence score of the subfeature with respect to the Feature, as a percentage (e.g., 80)"
    "micro_sub_features": [
      {
        "name": "Sub-User Story Title 1",
        "description": "Standalone description of a single functionality.",
        "file_path": [...],
        "micro_sub_feature_confidence_score":"confidence score of the micro_sub_feature with respect to the sub_feature, as a percentage (e.g., 90)"
        }
          ...
        ]
      },
      ...
    ]
  }
]
Each layer must preserve independence, clarity, and singular focus of each story.

VALIDATION CHECKLIST
- Each title must express one functionality only (no imperative phrasing)
- description must avoid assumptions and describe the real function. It must be as detailled as possible.
- Each story must make sense independently and fit in the broader feature flow
- if there are multiple user-story under the subfeature, it needs to be in sequence of business logic.
- File mappings must be relevant and scoped accurately
- Do no miss/skip any values in the output json. The output structure must be maintained strictly.
- All subfeature and sub-user-story names and descriptions must be strictly in a declarative tone, not imperative.

* Use generic or speculative statements
"""


db_micro_sub_feature_prompt = """
<Role>
You are an expert Database analyst specializing in decomposing SubFeatures into granular, logically independent components. You support **two levels** of splitting:
You shall ALWAYS process features from a Database perspective ONLY. 
There can be more than one Table in the DB context provided to you.
</Role>

1. **Horizontal splitting**: Split a subfeature into multiple *same-level subfeatures* when it encompasses multiple independently meaningful functionalities. The subfeatures created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.
2. **Vertical splitting**: Further break each of those subfeatures into *microsubfeatures* (if applicable), ensuring each micro-sub-features/micro-user-story describes a single goal or operation. The micro-sub-features/micro-user-story created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.

<Strict Constraints> 
- You are dealing with Database Information. 
- No matter what, STRICTLY use Database-Specific Language ALWAYS. 
- Use words like Columns / Fields / Schema / DataTypes / Constraints / Foreign Keys / Primary Keys etc.
- Strictly Do not start descriptions with or start with "this micro-feature" / or "this sub-feature".
- You shall do this regardless of the input context and nature.
Remember : Every "FILE" given to you is information of a table. Therefore in your response, ALWAYS refer to "Table" instead of "File".

</Strict Constraints> 


### ðŸ”§ TASK OVERVIEW

Given a Macro-Feature, Subfeature, its description, associated module files and its summary:

- Decide if the subfeature should be split horizontally into multiple same-level subfeatures.
- For each resulting subfeature (or original if not split), analyze whether it can be split vertically into **microsubfeatures** (fine-grained user stories).
- Provide the confidence scores for the subfeature that is split, whether horizontally or vertically.
- Provide the files that are related to the sub_features too, not just the micro_sub_features.
- Each leaf user-story must have files assigned to them, else you should not create/split these subfeatures.
- Provide description of generated subfeature/sub-user-stories in 2-4 lines but only valid information. Do not assume or hallucinate to generate description.
Apply this recursively: if horizontal splitting occurs, then attempt vertical splitting for each. But remember, not to create any duplicates in the process. 

---

### SPLITTING DECISIONS

#### Horizontal Splitting (Same-level Subfeatures):
Split if:
- The subfeature covers ONE / MORE THAN ONE high-level functionalities
- Each function could be planned and developed independently
- Each component has some clear boundaries and responsibilities

#### Vertical Splitting (Microsubfeatures):
Split further if:
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across actions are too complex to isolate.
- There are no tables that can be mapped to the generated user-story.
- The subfeature is too complex to be planned, developed, and deployed independently
- Each micro-subfeature represents one atomic, non-overlapping functionality
Note: Maintain at least 2 subfeatures unless the database has only one table.
- Prioritize brevity, consistency and no informaiton leakage across subfeatures.
- Ensure crisp segregation.
---

### DO NOT SPLIT IF:
- sub-user-stories are tightly coupled in the Subfeature and cannot function independently.
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across tables in two features are too complex to isolate.
- There are no tables that can be mapped to the generated user-story.
Note: Maintain at least 2 subfeatures and 1 or more microsubfeatures per subfeature, Unless the database has only one table.
Note : Maintain brevity during splitting at the same level. Do NOT overload the a single feature with too many subfeatures.
---


### FILE MAPPING RULES:
- For each subfeature or microsubfeature, cite only directly relevant tables.
- Use only the provided input data to match files â€” no guessing.
- Avoid duplication unless a file is clearly shared between components.

Each `file_path` entry must include:
```json
{
  "module_name": "<Name>",
  "path": "<Path>",
  "critical": <true/false>,
  "git_url": "<Git URL>"
}

OUTPUT FORMAT
If the subfeature should NOT be split:
Return: "None"

If the subfeature should be split, return a list of Parent User Stories with subfeatures inside.
If a subfeature itself can be further split into microsubfeatures, nest them under micro_sub_features like so:

[
  {
    "name": "Parent User Story Title 1",
    "description": "Full description of the original or updated user story and its purpose.",
    "file_path": [...],
    "sub_feature_confidence_score":"confidence score of the subfeature with respect to the Feature, as a percentage (e.g., 80)"
    "micro_sub_features": [
      {
        "name": "Sub-User Story Title 1",
        "description": "Standalone description of a single functionality.",
        "file_path": [...],
        "micro_sub_feature_confidence_score":"confidence score of the micro_sub_feature with respect to the sub_feature, as a percentage (e.g., 90)"
        }
          ...
        ]
      },
      ...
    ]
  }
]
Each layer must preserve independence, clarity, and singular focus of each story.

VALIDATION CHECKLIST
- Each title must express one functionality only (no imperative phrasing)
- description must avoid assumptions and describe the real function. It must be as detailled as possible.
- Each story must make sense independently and fit in the broader feature flow
- if there are multiple user-story under the subfeature, it needs to be in sequence of business logic.
- File mappings must be relevant and scoped accurately
- Do no miss/skip any values in the output json. The output structure must be maintained strictly.
- All subfeature and sub-user-story names and descriptions must be strictly in a declarative tone, not imperative.
- Use Database-specific schema only. Do not include words like "Attributes" / "Code Files" in your response. 
- Strictly Do not start descriptions with or start with "this micro-feature" / or "this sub-feature".
* Use generic or speculative statements

"""import os
from graphviz import Digraph
import re 
import json

def parse_ddl(ddl: str):
    """
    Parse the DDL to extract columns, primary keys, and foreign keys.
    """
    lines = ddl.splitlines()
    column_lines = []

    for line in lines:
        line = line.strip()
        if (
            line.upper().startswith("CREATE")
            or line.upper().startswith("PRIMARY")
            or line.upper().startswith("FOREIGN")
            or line.upper().startswith(")")
            or line == ""
        ):
            continue

        match = re.match(r'(\w+)\s+\w+', line)
        if match:
            column_lines.append(match.group(1))

    pk_match = re.search(r'PRIMARY KEY\s*\((.*?)\)', ddl)
    primary_keys = [key.strip() for key in pk_match.group(1).split(",")] if pk_match else []

    foreign_keys = []
    for match in re.finditer(r'FOREIGN KEY\s*\(([^)]+)\)\s+REFERENCES\s+`?[\w]+\.(\w+)`\(([^)]+)\)', ddl):
        fk_col = match.group(1).strip()
        ref_table = match.group(2).strip()
        ref_col = match.group(3).strip()
        foreign_keys.append((fk_col, ref_table, ref_col))

    return column_lines, primary_keys, foreign_keys


def generate_combined_graph(tables_data):
    """
    Generate a single combined graph from multiple tables.
    """
    dot = Digraph(comment='Combined Table Diagram')
    dot.attr(rankdir='LR')

    # Store individual table nodes
    for table in tables_data:
        table_name = table['table_name']
        columns = table['columns']
        primary_keys = table['primary_keys']
        
        label_lines = []
        for col in columns:
            if col in primary_keys:
                label_lines.append(f"{col} [PK]")
            else:
                label_lines.append(col)
        dot.node(table_name, shape='box', label=f'{table_name}\\n' + "\\n".join(label_lines))

    # Add relationships
    for table in tables_data:
        table_name = table['table_name']
        for fk_col, ref_table, ref_col in table['foreign_keys']:
            dot.edge(table_name, ref_table, label=f'{fk_col} â†’ {ref_col}')

    return dot

def folder_summary_generation_prompts(
        total_allocated_tokens, 
        file_list, folder_name, 
        folder_path,
        subfolder_list,
        formatted_file_summaries,
        formatted_file_services,
        formatted_subfolder_summaries,
        formatted_subfolder_services,
        formatted_subfolder_features
    ):
    
    system_prompt = f"""
        You are an expert code analyst specialized in creating detailed, informative summaries of software project folders. Your task is to thoroughly analyze files and subfolders to provide a comprehensive understanding of the application or project and provide combined summaries along with required details. These summaries must be detailled enough for further summarization.

        Follow these guidelines:
        1. Conduct a deep analysis of the features to identify its core purpose and functionality
        2. Provide detailed explanation of key implementations and technical approaches of the features
        3. Thoroughly examine the summaries based on files and folders to understand relationship between features and combined smaller features into larger high level application level features.
        4. Explain the features within the broader project architecture with specific connections
        5. Describe technical patterns, design decisions, and architectural choices evident in the code
        6. Include specific functions, classes, and methods that define the feature's behavior
        7. Note dependencies, imports, and external connections that shape the folder's functionality
        8. Identify potential architectural strengths and areas for improvement when evident
        9. Identify all services represented in this folder based on file and subfolder services information
        10. Identify and articulate high-level features or functionalities represented by the folder into the feature_details section, when consolidating multiple subfolders or lower-level files. Derive these insights from both file-level and subfolder-level summaries. Also under each feature, mention which file/folder was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
        11. Do not miss any features that could be formed based on these summaries as this information is required to understand the application's buisness logic.
        12. Gather insights from the summaries provided to generate a high level detailled executive summary that could be used by business stakeholders to understand the folder/project.
        13. When analyzing the root folder, both the executive summary and the features must be strictly formed in a high level business logic standpoint of an application.
        
        IMPORTANT: 
        - Your summary should be thorough and detailed({total_allocated_tokens}) while maintaining technical/business precision and depth. Focus on providing insights that would help both stakeholders and developers understand the application better.
        - feature_details must contain high level feature name and feature description(value of the files/folders) strictly in concise bullet points. The feature inforamtion must be in detail to capture the complete high level knowledge for that feature but not the function level details. Feature names cannot be programmatic function names like Dependency management, json handling etc. instead it should be inventory management, order processing etc. 
        - Your services list should be comprehensive and include all services represented in this folder.
        - is_reuasble_lib if a folder is used as reusable lib make it True otherwise False
        - lib_name if is_reusable_lib is True then provide the name of the reusable lib/component If is_reusable_lib False then add Not Applicable
        - category if is_reusable_lib is True then provide category only between 'Frontend' and 'Backend' If is_reusable_lib False then add Not Applicable
        - sub_category if is_reusable_lib is True then provide sub category only between 'UI Component','Custom Hooks', 'http_client', 'Utils', 'Others' In Frontend & 'Middleware', 'Error Handling', 'Auth', 'Utils', 'Others' In Backend If is_reusable_lib False then add Not Applicable
        - when_to_use if is_reusable_lib is True then provide where this reusable lib/component can be used If is_reusable_lib False then add Not Applicable 
        - associated_files if is_reusable_lib is True then provide the list of files associated(give complete path for the assosciated file) with this reusable lib/component If is_reusable_lib False then add Not Applicable
        - summary must not be technical and only explain the high level details of the folder/project. Understand the file and folder summaries provided to combine the knowledge to form the executive summary. Make it as detailled as possible.
        - Use clear and concise language, avoiding jargon where possible.
        
        - You must provide your response in this exact format:
        ```summary
        [Your detailled high-level executive summary for the folder for business stakeholders]
        ```
        ```feature_details
        [List of high-level features or functionalities represented in this folder]
        ```
        ```services_namess
        [Comma-separated list of all services represented in this folder]
        ```
        ```is_reuasble_lib
        Boolean Value
        ```
        ```lib_name
        [Name of the reusable library if applicable]
        ```
        ```category
        [Category of the reusable library if applicable]
        ```
        ```sub_category
            [Sub category of the reusable library if applicable]
        ```
        ```when_to_use
        [Your detailed use case where or when this reuasble_lib can be usefull]
        ```
        ```associated_files
            [Comma-separated list of associated files with the reusable library, Give the Complete file path as mentioned in the file list]
        ```
        ```example_usage
            [Example code snippet of how to use this reusable library]
        ```
    """

    user_prompt = f"""
        Generate a summary and services list for the folder: "{folder_name}" (Path: {folder_path})

        FOLDER CONTENTS:
        - Files ({len(file_list)}): {", ".join(file_list) if file_list else "None"}
        - Subfolders ({len(subfolder_list)}): {", ".join(subfolder_list) if subfolder_list else "None"}

        FILE SUMMARIES:
        {os.linesep.join(formatted_file_summaries) if formatted_file_summaries else "No file summaries available"}

        FILE SERVICES:
        {os.linesep.join(formatted_file_services) if formatted_file_services else "No file services available"}

        SUBFOLDER SUMMARIES:
        {os.linesep.join(formatted_subfolder_summaries) if formatted_subfolder_summaries else "No subfolder summaries available"}

        SUBFOLDER SERVICES:
        {os.linesep.join(formatted_subfolder_services) if formatted_subfolder_services else "No subfolder services available"}

        SUBFOLDER FEATURES:
        {os.linesep.join(formatted_subfolder_features) if formatted_subfolder_features else "No subfolder features available"}
        
        Based on these components:
        1. Provide a thorough technical summary explaining the folder's purpose, implementation details, and architectural significance
        2. Compile a comprehensive list of all services represented in this folder based on file and subfolder services information
        
        Follow the exact format specified in the system instructions for your response.
    """

    return system_prompt, user_prompt

def services_generation():
    system_prompt = """
        <Task>
        Create an architectural blueprint of the given repository by identifying and classifying both external services and third-party services with no overlap between categories.
        </Task>

        <Definitions>
        - External services: Company-provided services hosted outside the application (AWS S3, Google Cloud, Stripe, Twilio)
        - Third-party services: Libraries, frameworks, and SDKs that are part of the core application stack (Django, React, MongoDB, Redux)
        </Definitions>

        <Output_Format>
        {
        "external_services": [
            {
            "external_service_name": "string",
            "description": "string",
            "associated_files": ["string"],
            "service_class": "string",
            "used_in_files": ["string"]
            }
        ],
        "thirdparty_services": [
            {
            "thirdparty_service_name": "string",
            "description": "string",
            "associated_files": ["string"],
            "service_class": "string",
            "used_in_files": ["string"]
            }
        ]
        }
        </Output_Format>

        <Instructions>
        1. Conduct a thorough repository analysis to identify all services
        2. Classify each service into exactly ONE category:
        - External services: Cloud platforms, payment processors, authentication providers
        - Third-party services: Frameworks, libraries, SDKs integrated into the codebase
        3. For each service, provide:
        - Name: Exact service name
        - Description: Concise explanation of functionality and purpose
        - Associated files: All files directly importing or using the service
        - Service class: Category (e.g., "cloud storage", "web framework", "database")
        - Used in files: Complete paths of files utilizing the service
        4. Ensure ZERO overlap between categories
        5. Prioritize accuracy over comprehensiveness
        6. Validate that identified services are actively used in the project
        7. Include only services with clear evidence of implementation
        8. Do not create a lot of services which are redundant. Keep it to a maximum of 50 services only.
        </Instructions>

        <Examples>
        Good External Service Entry:
        {
        "external_service_name": "AWS S3",
        "description": "Cloud storage service used for storing user-uploaded files",
        "associated_files": ["src/services/storage.js", "src/config/aws.js"],
        "service_class": "cloud storage",
        "used_in_files": ["src/components/FileUpload.js", "src/pages/UserProfile.js"]
        }

        Good Third-Party Service Entry:
        {
        "thirdparty_service_name": "React",
        "description": "Frontend JavaScript library for building user interfaces",
        "associated_files": ["package.json", "src/index.js"],
        "service_class": "frontend framework",
        "used_in_files": ["src/App.js", "src/components/*.js"]
        }
        </Examples>

        Analyze the repository and provide the complete architectural blueprint in the specified format.
    """

    user_prompt = ""

    return system_prompt, user_prompt

def executive_summary_generation(combined_summary, user_mvf):
    system_prompt = """
    Your Role:
    You are an expert software architect tasked with understanding a codebase and creating an executive summary that clearly articulates the main purpose of this application,
    the core problem that the application is solving, and the prioritized list of the most valuable features, solely based on the provided folder wise summary. Do not hallucinate and create the most valuable features and its description on assumption. This needs to be based on facts.

    Task:
    1. Analyze provided folder wise summary and the services used and the user defined features (if provided).
    2. Understand component interactions and functions.
    3. Prioritize the User Defined Features (if provided) in the summary.
    4. Identify and prioritize the most valuable features based on their importance and relevance to the overall project, as evidenced in the code.
    5. Create a comprehensive executive summary.

    Steps:
    1. Review folder wise summary.
    2. Analyze folder wise summary:
    - Identify key components and their roles
    - Note data operations, design patterns, and architectural decisions
    3. Create summary:
    - Describe the specific problem the codebase solves, based on folder wise summary
    - Explain component interactions
    - Outline data workflow
    4. Identify and prioritize main features:
    - Determine which feature(s) address the core problem of the application, based on code implementation
    - Rank features based on their importance and relevance to solving the main problem, as evidenced in the code
    - The feature should be major components of the codebase and not minor functions like "Modular Architecture" or "Code Reusability", these are not features but design principles.

    Focus Areas:
    - Precised feature prioritization and importance
    - High-level functionality
    - Clear, concise technical language
    - Objective description
    - Capture entire workflow

    Guidelines:
    - Only use the folder wise summary provided
    - Use precise technical terms
    - Include user-defined features if provided and evidenced in the code
    - Prioritize features based on their importance to the core problem, as shown in the folder wise summary

    Feature Identification and Prioritization:
    - Carefully analyze the folder wise summary to identify features actually present in the folder wise summary
    - Do not assume or infer features that are not explicitly mentioned in the folder wise summary
    - Identify the top feature that solves the majority of the problem based on code evidence
    - Rank subsequent features in descending order of importance, ensuring they are present in the folder wise summary
    - Ensure the feature list reflects the codebase's focus and structure
    - Only include features that have substantial implementation in the codebase that is evident from folder wise summary

    Output Format - Adhering to this format is crucial
    ```json
    {
    "data": "generated_summary in string format adhering to the Expected Output Format for Generated Summary",
    "confidence_score": 90,
    "traceback": {
    "Feature 1 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 1 Title' is included, as the 'phrase' is an evidence that this feature is part of the codebase.",
    "Feature 2 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 2 Title' is included, as the 'phrase' is an evidence that this feature is part of the codebase.",
    ...
    }
    }
    ```

    Requirements:
    - Replace \n with \\n in JSON
    - Limit upto 5 main features (max 2 sub-features each) or 7500 tokens
    - If due to any reason such as codebase being small, you are unable to provide 5 features, then provide as many high-level features as possible between the range of 1 to 5.
    - Don't assume features or include minor features due to inability to provide 5 features, lesser number of features is acceptable.
    - Use specified JSON format only
    - Start with "```json" and end with "```"
    - Ensure the top feature in the prioritized list addresses the core problem and is present in the folder wise summary
    - Rank features in descending order of importance to the main problem, based on actual code implementation
    - Do NOT include features that are NOT evidenced in the provided folder wise summary
    - Evaluate the folder wise summary objectively, considering all conclusions on the actual code provided
    - Do NOT make any assumptions about organizational goals or intentions beyond what is explicitly shown in the code
    - Focus solely on the technical aspects and implemented functionality, avoiding speculation about business objectives or future plans
    - Both the keys data, confidence score, and traceback should be present in the output JSON
    - The generated summary should be in string format only and be contained inside the "data" key
    - The "traceback" key should contain a dictionary with feature names as keys and justifications for including these features based on exact phrases from the input
    - Do not include any feature that could potentially be part of the folder wise summary without explicit evidence
    - Every feature mentioned must be driven by clear evidence from the provided input
    """
    user_prompt = """
    Expected Output Format for Generated Summary:

  **Overview**
  <empty line>
  <A brief introduction to the codebase and its main purpose; in paragraph format only, not in points.
  This paragraph should provide a concise yet comprehensive overview of the codebase, its primary functionality, solution provided by the project and its intended use case.
  Aim for 3-5 sentences that capture the essence of the project.>
  <empty line>
  **Highlighted Features**
  <empty line>
  <
  List and briefly explain the key features that are significant components of the codebase and would serve as selling points.
  These features should be presented as follows:
  1. Use numbered points for each feature.
  2. Provide a brief explanation for each feature in 1-2 sentences, highlighting its importance and benefit to the end user.
  3. Focus on features that are central to the codebase's functionality and most important to the end user.
  4. Dont include generic features like "Modular Architecture" or "Code Reusability", these are not features but design principles.
  5. Do not include sub-points under any feature.
  6. Prioritize User Defined Features (if provided) at the beginning of the list.
  7. If User Defined Features are given, list them first before including any features identified through your analysis.
  8. Aim to provide upto of 1 to 5 key features, after each feature add an empty line for formatting purposes.
  9. Ensure that the features listed represent the core functionality and unique selling points based on the folder wise summary.
  10. Use clear, concise language that emphasizes the value proposition of each feature.
  11. Also under each feature, mention which file/folder was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
  12. Do not add features into Highlighted Features if they dont have value for buisness stakeholder about the application. Also do not repeat adding similar feature in this section.

  Output Structure:
  1. ***<Feature 1 Title>***: <Description of the feature in one to two sentences.\n
  2. ***<Feature 2 Title>***: <Description of the feature in one to two sentences.>\n
  >
  <empty line>
  **Key Benefits**
  <empty line>
  <Summarize the key benefits of the codebase in one to two sentences.
  This summary should encapsulate the overall value proposition of the codebase and its potential impact on users or the organization.>
  <empty line>
  <Highlight the most significant key benefits the codebase has to offer in bulleted points. The format should be:
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  Aim for 3-5 bullet points that capture the most compelling advantages of using this codebase, after each point add an empty line for formatting purposes.
  Each benefit should be distinct and provide a clear value proposition.>

  <Final Output Format>
  Output Format - Adhering to this format is crucial, the output should be in parsable JSON format:
  ```json
  {{
    "data": "<generated_summary in string format adhering to the Expected Output Format for Generated Summary>",
    "confidence_score": 90,
    "traceback": {{
      "Feature 1 Title": "Since it mentions about <exact phrase from the folder wise summary>, the 'Feature 1 Title' is included, as the "phrase" is an evidence that this feature is part of the folder wise summary.",
      "Feature 2 Title": "Since it mentions about <exact phrase from the folder wise summary>, the 'Feature 2 Title' is included, as the "phrase" is an evidence that this feature is part of the folder wise summary.",
      ...
    }}
  }}
  ```
  </Final Output Format>
  Note: If the traceback includes phrases that are not present in the folder wise summary then you would be penalized 10000 points.
  The output should be having data, confidence score, and traceback keys, and the entire content inside "```json" and "```" should be parsable by json.
  The "data" key should contain the generated summary and it should be in string format only, allowing the parsing of the entire json.
  If there are any inverted commas inside the generated summary, then escape them with a backslash.
  Do not change or skip the headings of each section in the generated json. The generated summary must have "Overview", "Highlighted Features", "Key Benefits" as section titles. Follow the above provided guidelines."""
    user_prompt += f"""Use the below folder wise summary to generate the summary in the above format: {combined_summary}""" + "User Defined Features : " + str(user_mvf)
    return system_prompt, user_prompt

def db_executive_summary_generation(combined_summary, user_mvf): 
    system_prompt = """
    Role:
    You are an expert Database Architect tasked with understanding the contents of all tables and schema of the database. 
    You shall Articulate a proper executive summary that clearly captures all the main & high-level features of this database.
    The core use-case that this database is intended for, and the prioritized list of the most valuable features, solely based on the provided Table-Level summaries. 
    Do not hallucinate. Do NOT create the most valuable features and its description on pure assumptions. This needs to be based on facts, with proper backing.

    Task:
    1. Analyze provided Table wise summaries.
    2. Understand component interactions and functions.
    3. Prioritize the User Defined Features (if provided) in the summary.
    4. Identify and prioritize the most valuable features based on their importance to the core use-case the Database is solving.
    5. Create a comprehensive executive summary.

    Steps:
    1. Review Table wise summary.
    2. Analyze Table wise summary:
      - Identify all tables. 
      - Take into consideration the foreign keys, primary keys, is-a, has-a, and many-to-many relationships.
      - Deeply understand the intended-use-case of each table.
      - Note data operations, design patterns, and architectural decisions
    3. Create summary:
      - Describe the specific problem the Database is solving, based on Table wise summary
      - Explain high-level interactions and dependencies
      - Outline data workflow
    4. Identify and prioritize main features:
      - Determine which feature(s) address the core problem of the Database, based on SQL implementation and Table wise summary
      - Rank features based on their importance and relevance to solving the main problem, as evidenced in the Database
      - The feature should be major components of the Database and not minor functions like Many-to-Many Relationships, or "Foreign Keys". 
        These are implementation concepts. Not core features.

    Focus Areas:
    - Precised feature prioritization and importance
    - High-level functionality of this Database
    - Clear, concise technical language with Database-specific Language
    - Objective description
    - Capture entire data workflow

    Guidelines:
    - Only use the Table wise summary provided
    - Use precise Database-relevant technical terms
    - Include user-defined features if provided and evidenced in the Table wise summary
    - Prioritize features based on their importance to the core problem, as shown in the Table wise summary

    Feature Identification and Prioritization:
    - Carefully analyze the Table wise summary to identify features actually present in the Table wise summary
    - Do not assume or infer features that are not explicitly mentioned in the Table wise summary
    - Identify the top feature that solves the majority of the problem based on Database and SQL evidence
    - Rank subsequent features in descending order of importance, ensuring they are present in the Table wise summary
    - Ensure the feature list reflects the Database's focus and structure
    - Only include features that have substantial implementation in the Database that is evident from Table wise summary

    Output Format - Adhering to this format is crucial
    ```json
    {
    "data": "generated_summary in string format adhering to the Expected Output Format for Generated Summary",
    "confidence_score": 90,
    "traceback": {
    "Feature 1 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 1 Title' is included, as the 'phrase' is an evidence that this feature is part of the Database.",
    "Feature 2 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 2 Title' is included, as the 'phrase' is an evidence that this feature is part of the Database.",
    ...
    }
    }
    ```

    Requirements:
    - Replace \n with \\n in JSON
    - Limit upto 5 main features (max 2 sub-features each) or 7500 tokens
    - If due to any reason such as Database being small, you are unable to provide 5 features, then provide as many high-level features as possible between the range of 1 to 5.
    - Don't assume features or include minor features due to inability to provide 5 features, lesser number of features is acceptable.
    - Use specified JSON format only
    - Start with "```json" and end with "```"
    - Ensure the top feature in the prioritized list addresses the core problem and is present in the Table wise summary
    - Rank features in descending order of importance to the main problem, based on actual Database and SQL implementation
    - Do NOT include features that are NOT evidenced in the provided Table wise summary
    - Evaluate the Table wise summary objectively, considering all conclusions on the actual Database and SQL provided
    - Do NOT make any assumptions about organizational goals or intentions beyond what is explicitly shown in the Database and SQL
    - Focus solely on the technical aspects and implemented functionality, avoiding speculation about business objectives or future plans
    - Both the keys data, confidence score, and traceback should be present in the output JSON
    - The generated summary should be in string format only and be contained inside the "data" key
    - The "traceback" key should contain a dictionary with feature names as keys and justifications for including these features based on exact phrases from the input
    - Do not include any feature that could potentially be part of the Table wise summary without explicit evidence
    - Every feature mentioned must be driven by clear evidence from the provided input.
    - Strictly use an assertive and objective tone in your response. 
    - Do not be unsure about anything.
    - Do not include the "Folder Name" in your response. Ignore "dbanalysis" folder. Provide Executive Summary of the Database-ONLY.
    """

    user_prompt = """
  Expected Output Format for Generated Summary:

  **Overview**
  <empty line>
  <A brief introduction to the Database and its main purpose; in paragraph format only, not in points.
  This paragraph should provide a concise yet comprehensive overview of the Database, its primary functionality, and its intended use case.
  Aim for 3-5 sentences that capture the essence of the Database.>
  <empty line>
  **Highlighted Features**
  <empty line>
  <
  List and briefly explain the key features that are significant components of the Database and would serve as selling points.
  These features should be presented as follows:
  1. Use numbered points for each feature.
  2. Provide a brief explanation for each feature in 1-2 sentences, highlighting its importance and benefit to the END USER.
  3. Focus on features that are central to the Database's functionality and most important to the END USER.
  4. Dont include generic features like  Many-to-Many Relationships, or "Foreign Keys", these are not features but Design Principles.
  5. Do not include sub-points under any feature.
  6. Prioritize User Defined Features (if provided) at the beginning of the list.
  7. If User Defined Features are given, list them first before including any features identified through your analysis.
  8. Aim to provide upto of 1 to 5 key features, after each feature add an empty line for formatting purposes.
  9. Ensure that the features listed represent the core functionality and unique selling points based on the Table wise summary.
  10. Use clear, concise language that emphasizes the value proposition of each feature.
  11. Also under each feature, mention which file/Table was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
  12. Do not add features into Highlighted Features if they dont have value for buisness stakeholder about the application. Also do not repeat adding similar feature in this section.

  Output Structure:
  1. ***<Feature 1 Title>***: <Description of the feature in one to two sentences.\n
  2. ***<Feature 2 Title>***: <Description of the feature in one to two sentences.>\n
  >
  <empty line>
  **Key Benefits**
  <empty line>
  <Summarize the key benefits of the Database in one to two sentences.
  This summary should encapsulate the overall value proposition of the Database and its potential impact on users or the organization.>
  <empty line>
  <Highlight the most significant key benefits the Database has to offer in bulleted points. The format should be:
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  Aim for 3-5 bullet points that capture the most compelling advantages of using this Database, after each point add an empty line for formatting purposes.
  Each benefit should be distinct and provide a clear value proposition.>

  <Final Output Format>
  Output Format - Adhering to this format is crucial, the output should be in parsable JSON format:
  ```json
  {{
    "data": "<generated_summary in string format adhering to the Expected Output Format for Generated Summary>",
    "confidence_score": 90,
    "traceback": {{
      "Feature 1 Title": "Since it mentions about <exact phrase from the Table wise summary>, the 'Feature 1 Title' is included, as the "phrase" is an evidence that this feature is part of the Table wise summary.",
      "Feature 2 Title": "Since it mentions about <exact phrase from the Table wise summary>, the 'Feature 2 Title' is included, as the "phrase" is an evidence that this feature is part of the Table wise summary.",
      ...
    }}
  }}
  ```
  </Final Output Format>
  Note: If the traceback includes phrases that are not present in the Table wise summary then you would be penalized 10000 points.
  The output should be having data, confidence score, and traceback keys, and the entire content inside "```json" and "```" should be parsable by json.
  The "data" key should contain the generated summary and it should be in string format only, allowing the parsing of the entire json.
  If there are any inverted commas inside the generated summary, then escape them with a backslash.
  Do not change or skip the headings of each section in the generated json. The generated summary must have "Overview", "Highlighted Features", "Key Benefits" as section titles. Follow the above provided guidelines.
    """

    user_prompt += f"""Use the below Table wise summary to generate the summary in the above format: {combined_summary}""" + "User Defined Features : " + str(user_mvf)

    return system_prompt, user_prompt


def architecture_diagram_generation(services_data, icons_metadata):
    user_prompt = f"""
    <Input>
    $services_data = {services_data}
    $icons_metadata
    </Input>

    <Role>
    You are an expert at understanding large projects based on their executive summary and the services being used in them. Create a JSON structure for a ReactFlow diagram based on the given service class JSON.
    </Role>

    <Output Structure>
    1. Create a JSON object with a "nodes" and "edges" array.
    2. Create nodes for each external and third-party service.
    3. "nodes": An array containing all node objects.
      - "id": A unique string identifier for the node.
      - "data":   
        - "label": The name of the node.
        - "description": Description of the service.
        - "associated_files": Associated file and used in files in the service node, defaulting to "No File Available" if not present.
        - "group": The logical group name (e.g., 'Backend', 'Frontend', 'Database',etc..).
        - "subgroup": The specific subgroup within the group (e.g., Frameworks, NoSQL Databases, State Management, etc.).
        - "service": The appropriate filename of the icon based on the $icons_metadata.
      - "position" : The x and y coordinates of the node.
      - "type" : "customNode" This should be fixed.
    4. "edges" : An array having id, source, target, label, and type should be customEdge always.
    4. Ensure all services and files from the input JSON are included.
    5. The output should be in the form of a dictionary containing a "nodes" and "edges" array.
    6. Present only the code inside delimiters "```reactflow [reactflow CODE]```" without any additional explanation.
    """

    system_prompt:str = """
    <Task>
      You are tasked with creating a JSON structure for a ReactFlow diagram based on the given executive summary and the service_class_json. The executive summary contains an overview of the entire project. This JSON includes information about external services and third-party services, along with their associated files. Your output should represent this information as a network of nodes and edges.
    </Task>
    
    <Icons Context>
      $icons_metadata = """ + str(icons_metadata) + """
    </Icons Context>

    <Instructions>
      You are a solution expert, specializing in problem and solution flows. You will be given the solution overview for a project, and your task is to create an interconnected single component of graph which is detailed, and intuitive and self explanatory for:

      Follow these guidelines:
      1. Create nodes for each unique service (both external and third-party).
      2. Do not create any group nodes.
      4. In the data key for each service node, include two additional fields called group and subgroup. The group field should contain the logical group name (e.g., Frontend, Backend, Databases, etc..), and the subgroup field should provide more specific categorization (e.g., Frameworks, NoSQL Databases, etc..). For example, for a service node representing React, the group would be Frontend and the subgroup would be Frameworks.
      5. For each node, check which icon will be the most suitable from the $icons_metadata in the <Icons Context>
      6. Ensure all information from the input is represented in the output.
      7. The position coordinates must be proper for all the nodes.
    </Instructions>

    <Rules>
      **Ensure all nodes in the generated graph are interconnected such that every node has at least one edge, forming a single connected component without any isolated or disjoint sections. (High Priority Requirement)**
      Important Rules to be followed:
      1. Give detailed technical architecture flow and the JSON object following the below output format.
      2. Make sure that the flow and order of new solution approach is explained well in the graph with appropriate edges. Use as many edges you want to describe the data and user flow properly.
      3. The whole user and data flow should be clear.
      4. Do not add unnecessary nodes and edges. Do not create duplicate nodes that perform same task.
      5. Make the Node descriptions detailed, breaking tasks into multiple sub-tasks if needed.
      6. Ensure your edges show the actual flow, and not just connections of what's related. The connections are meant to show the logical flow, and not the relatedness/similarity.
      7. The group name is meant to classify clusters of nodes within each graph. For instance, if we have multiple nodes in features, they would all have "feature" as group. In Architecture Flow, the "Group" should show the layer each node is in, for instance "Backend Layer", "Database Layer" etc.
      9. for a hierarchy of nodes A -> B -> C; ensure that there is not a connection between A -> C.
    </Rules>
    
    <output_format>
    The output should be in between the delimeters ```reactflow and ```. Only provide the json output. Don't give unnecesary explanation.
    ```reactflow
    {
      "nodes": [
        { 
          "id": "unique_node_identifier_string",
          "data" : {
            "label": "name_of_the_service",
            "description": "description of the service",
            "associated_files": ["file_path_1", "file_path_2", "file_path_3", etc.],  // (default: ["No File Available"] if not present)
            "group": "name_of_group",  // Add the logical group name (e.g., "Frontend", "Backend", etc..)
            "subgroup": "name_of_subgroup",  // Add a more specific subgroup name (e.g., "Frameworks", "NoSQL Databases", etc..)
            "service": "filename" //taken from the $icons_metadata,
          }
          "position":{ "x": "Xcoordinate", "y": "Ycoordinate" },
          "type" : "customNode" //this is hardcoded and will be constant
        }
      ],
      "edges": [
        {
          "id": "unique_egde_identifier_string",
          "source": "label A",
          "target": "label B",
          "label": "Showcase what comes from the source node, to the target node. Be concise and specific with labels, such as 'Ingested Data', 'Converted Text', 'User Query' etc. Use at max 5 words",
          "type" : "customEdge" //this is hardcoded and will be constant
        }
      ]
    }```
    </output_format>
    """
    return system_prompt, user_prompt
  

def erd_generation(services_data, icons_metadata):
  tables_metadata = []
  for entry in services_data:
      table_name = entry["table_name"]
      ddl = entry["ddl"]
      columns, primary_keys, foreign_keys = parse_ddl(ddl)
      tables_metadata.append({
          "table_name": table_name,
          "columns": columns,
          "primary_keys": primary_keys,
          "foreign_keys": foreign_keys
      })

  dot = generate_combined_graph(tables_metadata)

  system_prompt:str = """
    You are tasked with creating a JSON structure for a ReactFlow diagram based on the given database ER diagram and schema JSON. This JSON includes information about database columns and their relationships.Your output should represent this information as a network of nodes and edges.
    </Task>
    
    <Icons Context>
      $icons_metadata = """ + str(icons_metadata) + """
    </Icons Context>

    <Instructions>
      You are a solution expert, specializing in problem and solution flows. You will be given the database schema information of a database, and your task is to create an interconnected single component of graph which is detailed, and intuitive and self explanatory for:

      Follow these guidelines:
      1. Create nodes for each unique service (both external and third-party).
      2. Do not create any group nodes.
      4. In the data key for each service node, include two additional fields called group and subgroup. The group field should contain the logical group name (e.g.,Databases, etc..), and the subgroup field should provide more specific categorization (e.g., 'Transactional Tables', 'Reference Tables' etc..). For example, for a service node representing daily transactions, the group would be Database and the subgroup would be Transactional Tables.
      5. For each node, check which icon will be the most suitable from the $icons_metadata in the <Icons Context>
      6. Ensure all information from the input is represented in the output.
      7. The position coordinates must be proper for all the nodes.
    </Instructions>

    <Rules>
      Important Rules to be followed:
      1. Give detailed technical architecture flow and the JSON object following the below output format.
      2. Make sure that the flow and order of new solution approach is explained well in the graph with appropriate edges. Use as many edges you want to describe the data and user flow properly.
      3. The whole user and data flow should be clear.
      4. Do not add unnecessary nodes and edges. Do not create duplicate nodes that perform same task.
      5. Make the Node descriptions detailed, breaking tasks into multiple sub-tasks if needed.
      6. Ensure your edges show the actual flow, and not just connections of what's related. The connections are meant to show the logical flow, and not the relatedness/similarity.
      7. The group name is meant to classify clusters of nodes within each graph. For instance, if we have multiple nodes in features, they would all have "feature" as group. In Architecture Flow, the "Group" should show the layer each node is in, for instance "Database Layer" etc.
      9. for a hierarchy of nodes A -> B -> C; ensure that there is not a connection between A -> C.
    </Rules>
    
    <output_format>
    The output should be in between the delimeters ```reactflow and ```. Only provide the json output. Don't give unnecesary explanation.
    ```reactflow
    {
      "nodes": [
        { 
          "id": "unique_node_identifier_string",
          "data" : {
            "label": "name_of_the_table",
            "description": "description of the table",
  	    "columns": ["order_id [PK]", "product_sku [PK]", "quantity", "unit_price"]
            "group": "name_of_group",  // Add the logical group name (e.g., "Database", etc..)
            "subgroup": "name_of_subgroup",  // Add a more specific subgroup name (e.g., 'Transactional Tables', 'Reference Tables', etc..)
            "service": "filename" //taken from the $icons_metadata,
          }
          "position":{ "x": "Xcoordinate", "y": "Ycoordinate" },
          "type" : "customNode" //this is hardcoded and will be constant
        }
      ],
      "edges": [
        {
          "id": "unique_egde_identifier_string",
          "source": "label A",
          "target": "label B",
          "label": "Showcase what comes from the source node, to the target node. Be concise and specific with labels, such as 'Ingested Data', 'Converted Text', 'User Query' etc. Use at max 5 words",
          "type" : "customEdge" //this is hardcoded and will be constant
        }
      ]
    }```
    </output_format>
    """
    
  user_prompt:str = f"""
    <Input>
    $database_tables = {dot}
    $icons_metadata
    </Input>

    <Role>
    You are an expert at understanding database architecture based on ER diagrams and relational structures. Create a JSON structure for a ReactFlow diagram based on the given database schema.
    </Role>
    <Output Structure>
      1. Create a JSON object with a "nodes" and "edges" array.
      2. Create nodes for each table in the schema.
      3. "nodes": An array containing all node objects.
      - "id": A unique string identifier for the node.
      - "data":  
        - "label": The name of the table.
        - "description": A brief summary of the table's role or content.
        - "columns": List of column names (mark primary keys with [PK], foreign keys with [FK]).
        - "group": The logical group name (e.g., 'Database').
        - "subgroup": The specific subgroup within the group (e.g., 'Transactional Tables', 'Reference Tables').
        - "service": The appropriate filename of the icon based on the $icons_metadata.
      - "position" : The x and y coordinates of the node.
      - "type" : "customNode" This should be fixed.
      4. "edges" : An array having id, source, target, label, and type should be customEdge always.
      5. The label of the edge should describe the relationship, like "order_id â†’ order_id". 
      6. The output should be in the form of a dictionary containing a "nodes" and "edges" array.
      7. Present only the code inside delimiters "```reactflow [reactflow CODE]```" without any additional explanation.
    """
    
  return system_prompt, user_prompt
    

def feature_summary_generation(formatted_data, user_mvf, executive_summary):
    # if input_type is None:
    #     formatted_data = file_summary_list
    # elif input_type == "batch_summary":
    #     formatted_data = format_batchwise_summary_metadata_for_services(file_summary_list)
    # else:
    #     formatted_data = format_file_summaries(file_summary_list)

    user_prompt = """
    Role: You are an AI code analyst specializing in creating concise, feature-level summaries of codebases.

    Objective: Provide a comprehensive yet concise feature-level summary of a given codebase, highlighting key components, functionality, and the project's overall workflow.

    Input: You will receive information about a codebase, which may include an executive summary or other project details.

    Steps:
    1. Analyze the provided codebase information.
    2. Identify the main features (maximum 5) of the project from the executive summary (if provided in same order)
    3. Create a summary following the specified format, including:
        a. An overview of the project
        b. A list of key features with brief descriptions
        c. A closure statement
    4. Self-evaluate the generated summary and assign a confidence score.
    5. Format the output as specified in the instructions.

    Output Format:
    ```json
    {
        "data": "generated_summary in string format adhering to the Detailed Instructions for Output Format",
        "confidence_score": 90
    }
    ```

    Detailed Instructions for Output Format:

    **Overview**
    <empty line>
    < 
        Summarize all features in 2-3 sentences, introducing the project and its purpose.
        Provide a 2-3 sentence summary of key benefits, highlighting core architecture and value proposition.
    >
    <empty line>
    **Key Features**
    <empty line>
    <   
        List a maximum of 5 main features.
        For each feature, provide up to 2 sub-points describing its functionality.
        Ensure clear explanation of how features interact and contribute to the project's goals.
        1. ***<Key Feature Title>*** : 
        * <Sub point 1 description>
        * <Sub point 2 description>
        <empty line>
    >
    <empty line>
    < 
        Summarize the overall impact and value proposition of the project in one sentence as a conclusion statement.
    >
    <empty line>
    
    -> Self-Evaluation:
        - Score the summary out of 100 based on clarity, precision, detail, knowledge, accuracy, technical correctness, and understanding of the data.

    -> Formatting Requirements:
        - Replace all newline characters (\n) with \\n in the JSON output.
        - Ensure the complete JSON is less than 7500 tokens.
        - Start the output with "```json" and end with "```".
        - If an executive summary is provided, use only the highlighted features from it.

    Example Output Structure:
    ```json
    {
        "data": "**Overview**\\n\\n[Project overview]\\n\\n[Benefits summary]\\n\\n**Key Features**\\n\\n1. *Feature 1*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n2. *Feature 2*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n[...continue for up to 5 features...]\\n\\n[Closure statement]",
        "confidence_score": 90
    }
    ```

    Remember: Adhere strictly to the output format and instructions to maintain consistency and accuracy in your summary.
    """

    user_prompt += "User Defined Features : " + str(user_mvf)

    system_prompt = f"""
        <role>
        You are an assistant to a Senior Software Engineer. You are very capable in reading and understanding huge codebases.
        There is no edge-case, no mistake, no functionality no matter how small goes unnoticed by you.
        You will be given a large codebase and be asked queries regarding it.
        </role>

        <Task>
        You will be given relevant files from a production codebase. The Senior Engineer will consult you to clear his doubts and ask for critical code-level and functionality level analysis of the same.
        <Important>
        1. You will be clear. Feel free to be descriptive but Avoid Jargon
        2. You shall perform critical analysis on the code before responding.
        3. Note that the codebase will be quite complex and have dependencies everywhere, be mindful of them all.
        4. Enclose code in (triple backticks)``` code ```
        </Important>
        </Task>

        Files from Codebase goes here :
        <Repo Structure>
        {formatted_data}
        </Repo Structure>
    """

    start_index = executive_summary.find("Highlighted Features")
    end_index = executive_summary.find("Key Benefits")

    if start_index != -1 and end_index != -1:
        executive_summary = executive_summary[start_index:end_index].strip()

    user_prompt += "Executive Summary : " + str(executive_summary)

    return system_prompt, user_prompt

def feature_summary_generation_db(formatted_data, user_mvf, executive_summary):
    # if input_type is None:
    #     formatted_data = file_summary_list
    # elif input_type == "batch_summary":
    #     formatted_data = format_batchwise_summary_metadata_for_services(file_summary_list)
    # else:
    #     formatted_data = format_file_summaries(file_summary_list)

    user_prompt = """
    Role: You are an AI Database Analyst specializing in creating concise, feature-level summaries of complex database schemas and architectures.

    Objective: Provide a comprehensive yet concise feature-level summary of a given database schema information, highlighting key components, entities, relationships, and the overall data architecture workflow.

    Input: You will receive information about a database design, which may include an executive summary or other schema-level details.

    Steps:
    1. Analyze the provided database schema information.
    2. Identify the main features (maximum 5) of the database from the executive summary (if provided in same order)
    3. Create a summary following the specified format, including:
        a. An overview of the database
        b. A list of key features with brief descriptions
        c. A closure statement
    4. Self-evaluate the generated summary and assign a confidence score.
    5. Format the output as specified in the instructions.

    Output Format:
    ```json
    {
        "data": "generated_summary in string format adhering to the Detailed Instructions for Output Format",
        "confidence_score": 90
    }
    ```

    Detailed Instructions for Output Format:

    **Overview**
    <empty line>
    < 
        Summarize all features in 2-3 sentences, introducing the database and its purpose.
        Provide a 2-3 sentence summary of key benefits, highlighting schema structure, normalization or denormalization logic, and value proposition in handling data.
    >
    <empty line>
    **Key Features**
    <empty line>
    <   
        List a maximum of 5 main features.
        For each feature, provide up to 2 sub-points describing its data handling, relationships, or optimization logic.
        Ensure clear explanation of how features contribute to performance, consistency, and data integrity.
        1. ***<Key Feature Title>*** : 
        * <Sub point 1 description>
        * <Sub point 2 description>
        <empty line>
    >
    <empty line>
    < 
        Summarize the overall impact and value proposition of the database in one sentence as a conclusion statement.
    >
    <empty line>
    
    -> Self-Evaluation:
        - Score the summary out of 100 based on clarity, precision, detail, knowledge, accuracy, technical correctness, and understanding of the schema information.

    -> Formatting Requirements:
        - Replace all newline characters (\n) with \\n in the JSON output.
        - Ensure the complete JSON is less than 7500 tokens.
        - Start the output with "```json" and end with "```".
        - If an executive summary is provided, use only the highlighted features from it.

    Example Output Structure:
    ```json
    {
        "data": "**Overview**\\n\\n[Database overview]\\n\\n[Benefits summary]\\n\\n**Key Features**\\n\\n1. *Feature 1*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n2. *Feature 2*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n[...continue for up to 5 features...]\\n\\n[Closure statement]",
        "confidence_score": 90
    }
    ```

    Remember: Adhere strictly to the output format and instructions to maintain consistency and accuracy in your summary.
    """

    user_prompt += "User Defined Features : " + str(user_mvf)

    system_prompt = f"""
        <role>
        You are an assistant to a Senior Data Architect. You are very capable in reading, analyzing, and understanding complex database schemas and data models.
        No entity, constraint, relationship, or optimization logic goes unnoticed by you.
        You will be given a comprehensive database structure or schema information and will be asked to analyze, explain, and summarize it at a structural and functional level.
        </role>

        <Task>
        You will be given relevant database schema files or DDL definitions. The Senior Data Architect will consult you to clear doubts and ask for critical schema-level and data model-level analysis.
        <Important>
        1. You will be clear. Feel free to be descriptive but Avoid Jargon
        2. Perform a critical and deep analysis of the schema and the information given before responding.
        3. The schema will often involve multiple tables, foreign keys, views, procedures, and indexing strategies â€” be mindful of their dependencies and relationships.
        4. Enclose code or schema in (triple backticks)``` code ```
        </Important>
        </Task>

        Files from Database schema goes here :
        <Database Structure>
        {formatted_data}
        </Database Structure>
    """

    start_index = executive_summary.find("Highlighted Features")
    end_index = executive_summary.find("Key Benefits")

    if start_index != -1 and end_index != -1:
        executive_summary = executive_summary[start_index:end_index].strip()

    user_prompt += "Executive Summary : " + str(executive_summary)

    return system_prompt, user_prompt


#FEATURE HIERARCHY:
generate_features_system_prompt = """
  <Role>
    You are a Software Architect with expertise in analyzing large summaries from code files of an application. 
    You can comprehend summaries from code files that are complex, production-grade and are written in various programming languages to generate most important features, their description and the subfeatures with their description belonging to the most important features along with the other relevant information requested below.
    
    You will follow 2 Events before responding : 
    1. Generation of Feature Hierarchy as given in "Output_Format".
    2. Critical Evaluation of Every Confidence Score.  
  </Role> 

    <Task 1>
    You are provided with multiple relative file paths and file-wise code summaries from a application codebase.
    1. Analyze the file summaries carefully, leveraging your expertise to deduce the frameworks, functionality, and features.
    2. Perform a critical assessment of the code's functionality and interdependencies before responding.
    3. The codebase is complex and likely contains dependencies across various modules. Be mindful of these.
    4. Analyse every file summary and assign the features and sub-features based on the information provided.
    5. Respond strictly in the structured JSON format provided below.
    6. In each sub-feature's 'file_path' array:
        - Set 'critical: true' ONLY for files that are CORE & NON-REPLACEABLE to the sub-feature's main functionality.
        - Set 'critical: false' for ALL supporting, secondary, or replaceable files  
        - Each sub-feature should have both true and false entries.
        - If unsure, default to false (be EXTREMELY selective with 'true')
        - Make sure each sub-feature atleast have one file as true.

    Explanation of the Output terms:
    Feature - Features are most valuable and high level features extracted from the list of summaries that are provided to you. 
    Feature description - Description of the features explaining the high level value and impact that it creates for the project. Define the Feature. The description should be crisp, precise, well formatted and must be between 2-3 lines.
    Subfeature - Subfeatures are micro most valuable features that are extracted from the list of summaries and belong to the Most related and similar Features.
    Subfeature description - Description of the subfeatures explaining the specific value, technical and non-technical functionalites that it provided to the project. Define the subfeature and also explain how its related to the feature. The description should be crisp, precise, well formatted and must be between 2-3 lines.
    
    Points to Remember:
    1. Do not extract any feature or subfeature where there are no reference/citations from the application summaries.
    2. The description must be precise, valuable, well-formatted and must be between 2-3 lines.
    3. The Feature titles should be precise, specific, self explanaible, independent and not have similar feature titles. The Feature titles should not be highly generalized.
    4. The SubFeatures titles should be precise, self explanaible and not have similar subfeature titles. The SubFeature titles should not be highly generalized.
    5. SubFeatures should not be very low level that it explains code functions, code process like 'Json handling', 'Reading csv', readME etc.
    6. If similar subfeatures are present, then group them under one common Feature itself. Do not create multuple Features for similar subfeatures.
    6. If Unit testing related summaries are found, then create that as another Feature named 'Unit Testing' and assign the specific testing subfeatures under this feature.
    </Task 1>

  <Task 2>
  You shall now Assign and Justify Confidence Scores for each feature.

  <Critical Evaluation of Confidence Scores> 

  <Evaluation MODE>
  - You will now Forget everything that was done beforehand and act as an unbiased judge.
  - $Project-Summaries-&-Paths (INPUT).
  </Evaluation MODE>
  <Important>
  Critically analyze every "Feature" and "SubFeature" based on the following metrics. 
  You shall generate a confidence score between 0-100 for each of the following :
  1. Is the "Feature" & "SubFeature" name accurate to its functionality ? (Accuracy)
  2. Does the "Feature" & "SubFeature" include files with an unrelated function ? (Feature Dilution Rate)
  3. Important : Does this "Feature" & "SubFeature" make sense given the Overall Purpose of the Application ? (Consistency)
  4. Are all the files in "Feature" & "SubFeature" included ? (Completeness)

  <Strict>
  1. You will now generate a list of 4 confidence scores between 0-100 for above criteria under "confidence_score" key.
  2. Based on above criteria, you shall provide a VERY BRIEF logical explanation (10-20 words) for Confidence Score under "confidence_score_justification" key.
  3. Make sure to mention the entire filepath without omitting the prefix.
  4. Make sure all the filepaths are present.
  <Important> STRICTLY Don't Comment on Missing Files. Don't Overestimate. Don't Underestimate.</Important> 
  </Strict>

  </Important>

  </Critical Evaluation of Confidence Scores> 
  </Step 2>


      <Output_Format>
    Return a response in JSON format. Do not include any extra information or explanations. Strictly DON'T deviate from mentioned KEYS.
    Example:
```json
[
  {
    "name": "User Authentication and Management",
    "feature_description": "Comprehensive user account system with secure login, registration, profile management, and role-based access control.",
    "feature_description_confidence_score": [95, 70, 100, 70],
    "sub_features": [
      {
        "name": "User Registration",
        "description": "Allows new users to create accounts by providing necessary information such as username, email, and password. Implements email verification, password strength checks, and duplicate account prevention. Stores user data securely in the database with password hashing.",
        "file_path": [
          {
            "module_name": "RegistrationController",
            "path": "Controllers/Account/RegistrationController.cs",
            "critical": true
          },
          {
            "module_name": "RegisterView",
            "path": "Views/Account/Register.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [75, 80, 85, 65],
        "sub_feature_confidence_score_justification": "No feature dilution, might have missed some file."
      },
      {
        "name": "User Login",
        "description": "Authenticates users using their credentials, creates and manages user sessions, and implements security measures such as login attempt limiting and two-factor authentication (2FA). Provides password reset functionality for forgotten passwords.",
        "file_path": [
          {
            "module_name": "LoginController",
            "path": "Controllers/Account/LoginController.cs",
            "critical": true
          },
          {
            "module_name": "LoginView",
            "path": "Views/Account/Login.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [80, 100, 80, 75],
        "sub_feature_confidence_score_justification": "High chance of missing files."
      }
    ],
    "feature_confidence_score_justification": "No feature dilution, duplication or missing files. Accurate Naming."
  },
  {
    "name": "Product Catalog Management",
    "feature_description": "Comprehensive system for managing product listings, categories, and inventory across the e-commerce platform.",
    "feature_description_confidence_score": [95, 65, 70, 80],
    "sub_features": [
      {
        "name": "Product CRUD Operations",
        "description": "Enables administrators to create, read, update, and delete product listings. Includes functionality for managing product details such as name, description, price, images, and inventory levels. Implements validation to ensure data integrity and consistency across the product catalog.",
        "file_path": [
          {
            "module_name": "ProductController",
            "path": "Controllers/ProductController.cs",
            "critical": true
          },
          {
            "module_name": "ProductView",
            "path": "Views/Product/Index.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [90, 85, 100, 70],
        "sub_feature_confidence_score_justification": "High confidence with no duplication or dilution."
      },
      {
        "name": "Category Management",
        "description": "Allows for the creation and management of product categories and subcategories. Implements a hierarchical structure for organizing products, enabling efficient navigation and filtering of the product catalog for both administrators and customers.",
        "file_path": [
          {
            "module_name": "CategoryController",
            "path": "Controllers/CategoryController.cs",
            "critical": true
          },
          {
            "module_name": "CategoryView",
            "path": "Views/Category/Index.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [85, 75, 90, 95],
        "sub_feature_confidence_score_justification": "High confidence without any duplication or dilution."
      }
    ],
    "feature_confidence_score_justification": "All files refer to single overall functionality. Might have missed some files."
  }
]
```
  </Output_Format>

"""

generate_features_user_message = """
<Strictly Remember>
1. As input you will be given a batch of `file_path` and `file_summary` from a production codebase. Keep it in mind that it could be a file from a very large repository with lot of inter-dependencies.
2. Understand all the file description first, then try to determine the feature, sub-features and their description. For **each file** it should have a feature or sub-features whenever the conditions are met.
3. The response should contain all the fields given in the example output format. The response should be strictly in json format.
4. The description of features/subfeatures must be in the length of 2-3 lines. The response should be structured and well-formatted.
5. Don't generate any additional explanation or description. Provide the structured response in json only.
</Strictly Remember>
  
<Input file wise summary>
{file_summary}
</Input file wise summary>
<Response>
"""

merge_features_in_hierarchy_user_prompt = """You are a software feature analyzer. Given a list of related features that have been clustered together, create a merged feature that encompasses all the functionality.

Features to merge:
{feature_list}

Generate a JSON response that includes:
1. A name for the merged feature representing accurate feature name. Do not mention its merged or unified or anything as such. The feature name should accurately represent a major funcationality of a repository.
2. A detailed description that covers all functionality
3. A confidence score (0-100) for the merge
4. A justification for the confidence score

Respond with a JSON object in the following format:
```json
{{
    "name": "Merged feature name",
    "description": "Comprehensive description",
    "confidence_score": 85,
    "confidence_justification": "Reason for the confidence score"
}}
```
Give only JSON and nothing else. Do not include any explanations or additional text outside the JSON block. Make sure to start with ```json and end with ``` only.
"""

mapping_names_for_merged_features_user_prompt = """  <Role>
    You are a smart AI cassistant with strong expertise in Software Engineering. You can understand complex, production-grade codebases written in various programming languages and summarize them effectively.
  </Role>
  <Task>
  You will be given a brief description of  features of a large codebase and your task is to generate a relevant feature name, brief description, and priority level.
  <Important>
   1. The feature name should be brief, relevant and should represent the entire description provided.
   2. Generate a relevant description which is basically a overall summary of the description provided.
   3. Assign a priority level (high, medium, low) based on the significance, importance and complexity of the feature to the overall system. 
  </important>
  </Task>
  <Example output>
  ```json
    {
        "name": <feature_name>, //string
        "feature_description": <feature_description>, //string
        "priority": <priority> //string (high, medium, or low)
    }
    ```
  </Example output>
  <Strictly Remember>
1. The feature name should be relevant and at the same time interpretable, easy to understand.
2. The feature description should represnt the entire description given for summarisation, it should be simple and easy to understant.
3. The priority should be one of: high, medium, or low.
4. The response should be strictly in json format specified above.
5. Strictly make sure Feature Description is not more than 200 words.
  </Strictly Remember>

<code summary>
The code summary is given below:
"""


reducing_sub_features_user_prompt = """
    You are a software feature consolidation expert. Your task is to merge similar sub-features into one comprehensive sub-feature.

    Here are the sub-features that need to be merged:
    {sub_features_list}

    For each sub-feature, we have:
    - Name: The sub-feature name
    - Description: The sub-feature description (if available)
    - Confidence Score: The confidence score (if available)

    Your output should be a JSON object containing:
    1. A unified sub-feature name that encompasses all the input sub-features
    2. A comprehensive description that covers all aspects of the input sub-features
    3. A confidence score (use the highest available from input sub-features)
    4. A justification for the confidence score

    Return the output in JSON format starting with ```json and ending with ```.

    Example output format:
    ```json
    {{
        "name": "Unified Sub-Feature Name",
        "description": "Comprehensive description covering all aspects",
        "sub_feature_confidence_score": 95,
        "sub_feature_confidence_score_justification": "Merged from similar sub-features with high semantic similarity"
    }}
    ```
    """


post_processing_feature_name_description_system_prompt="""
  <Role>
    You are a smart AI assistant with strong expertise in Software Engineering. You can understand complex, production-grade codebases written in various programming languages and summarize them effectively.
  </Role>
  <Task>
  You will be given a brief description of modules or features of a large codebase and your task is to generate a relevant feature name and brief description.
  <Important>
   1. The feature name should be brief, relevant and should represent the entire description provided.
   2. Generate a relevant description which is basically a overall summary of the description provided.
   3. Also generate a confidence score in a scale of 0 - 100.
  </important>
  </Task>
  <Example output>
  ```json
    {
        "name": <feature_name>,
        "feature_description_confidence_score": <score 0 - 100>,
        "feature_description": <feature_description>
    }```
  </Example output>"""

post_processing_feature_name_description_user_prompt = """<Strictly Remember>
1. The feature name should be relevant and at the same time interpretable, easy to understant.
2. The confidence score should represent the ability to summarise the description.
3. The feature description should represnt the entire description given for summarisation, it should be simple and easy to understant.
4. The response should be strictly in json format specified above.
</Strictly Remember>
<code summary>
The code summary is given below: \n
{feature_description}
</code_summary>
<response>
Your response in json goes here:
"""

merge_similar_features_system_prompt = """You are a solution architect. Your task is to carefully review each feature and its description, and combine them into a single high-level feature.

The final high-level features should represent what an end user would perceive, e.g., Messenger, Google Chat, Messaging, Reels, etc.

Based on the generated features provided, identify which features can be merged into a single high-level feature. 
Strictly output them in the following format:
{{ 
  <High-Level Feature Name 1>: [<Merged Feature 1>, <Merged Feature 2>, <Merged Feature 3>, ...],
  <High-Level Feature Name 2>: [<Merged Feature 1>, <Merged Feature 2>, <Merged Feature 3>, ...],
  ...
}}

INPUT:
Feature names and descriptions are provided in the format: 
[1. Feature name: <feature name> 
Feature description: <feature description>, 
2. ...]

{feature_texts}

MVFS:
{total_MVFs}

Points to remember:
1. While merging features and naming high-level features, always prefer names from the user-defined MVFs provided. All relevant features can be grouped under these high-level features.
2. If certain features do not fit under the user-defined MVFs, choose a better name than the existing one for the new high-level feature if necessary.
3. The names of the features being merged must remain exactly as provided in the INPUT section; do not modify them. Do not consider Feature description in Feature Names.
4. Follow the output structure strictly: high-level feature names as dictionary keys and merged features as values in list format.
5. If a feature is already a high-level feature, you do not need to forcibly merge it. If a feature seems to be function-level/low-level  features, merge them into a High-level feature.
6. Merge similar features into a single high-level feature based on their names and descriptions, when applicable. Each final high-level feature should be independent of the others.
7. Do not assign the same feature to multiple high-level features.
8. If user-defined MVFs are empty, skip point 1 and begin with point 2.
9. Do **not** include any Feature descriptions in the final output."""


merging_description_user_prompt = """You are a Solution Architect. Your task is to summarize the multiple feature descriptions provided into a brief, coherent summary of **no more than two sentences**.

  The summary must:
  - Accurately capture all key components from the provided descriptions.
  - Align clearly with the given high-level feature name.
  - Serve as the final description of the high-level feature.

  Only the final summarized description should be included in the output â€” no additional commentary or formatting.

  INPUT:
  Multiple descriptions: {merging_feature_description}

  High-Level Feature Name: {high_level_feature}
  """


micro_sub_feature_prompt = """You are an expert system analyst specializing in decomposing SubFeatures into granular, logically independent components. You support **two levels** of splitting:

1. **Horizontal splitting**: Split a subfeature into multiple *same-level subfeatures* when it encompasses multiple independently meaningful functionalities. The subfeatures created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.
2. **Vertical splitting**: Further break each of those subfeatures into *microsubfeatures* (if applicable), ensuring each micro-sub-features/micro-user-story describes a single goal or operation. The micro-sub-features/micro-user-story created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.

---

### ðŸ”§ TASK OVERVIEW

Given a Macro-Feature, Subfeature, its description, associated module files and its summary:

- Decide if the subfeature should be split horizontally into multiple same-level subfeatures.
- For each resulting subfeature (or original if not split), analyze whether it can be split vertically into **microsubfeatures** (fine-grained user stories).
- Provide the confidence scores for the subfeature that is split, whether horizontally or vertically.
- Provide the files that are related to the sub_features too, not just the micro_sub_features.
- Each leaf user-story must have files assigned to them, else you should not create/split these subfeatures.
- Provide description of generated subfeature/sub-user-stories in 2-4 lines but only valid information. Do not assume or hallucinate to generate description.
Apply this recursively: if horizontal splitting occurs, then attempt vertical splitting for each. But remember, not to create any duplicates in the process. 

---

### SPLITTING DECISIONS

#### Horizontal Splitting (Same-level Subfeatures):
Split if:
- The subfeature covers multiple high-level functionalities
- Each function could be planned, developed, and deployed independently
- Each component has a clear boundary and responsibility

#### Vertical Splitting (Microsubfeatures):
Split further if:
- A subfeature contains multiple independent operations or logical stages
- These operations can be implemented, tested, or tracked separately
- Each micro-subfeature represents one atomic, non-overlapping functionality

---

### DO NOT SPLIT IF:
- sub-user-stories are tightly coupled in the Subfeature and cannot function independently.
- Do not split subfeatures into sub-user-stories that are hardly single line of code and cannot be considered as a proper functionality, but just a config/parameter.
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across actions are too complex to isolate.
- There are no files that can be mapped to the generated user-story.
- Do not split if the user-story is barely a functionality. The split user-stories must have independent functionality that contributes to the subfeature and feature and if not, do not split.
- Don not split ReadMe & .md files into sub-user-stories.
- Do not split horizontall for granullar subfeatures as they are not user stories but mid level features.
---

### FILE MAPPING RULES:
- For each subfeature or microsubfeature, cite only directly relevant files.
- Use only the provided input data to match files â€” no guessing.
- Avoid duplication unless a file is clearly shared between components.

Each `file_path` entry must include:
```json
{
  "module_name": "<Name>",
  "path": "<Path>",
  "critical": <true/false>,
  "git_url": "<Git URL>"
}

OUTPUT FORMAT
If the subfeature should NOT be split:
Return: "None"

If the subfeature should be split, return a list of Parent User Stories with subfeatures inside.
If a subfeature itself can be further split into microsubfeatures, nest them under micro_sub_features like so:

[
  {
    "name": "Parent User Story Title 1",
    "description": "Full description of the original or updated user story and its purpose.",
    "file_path": [...],
    "sub_feature_confidence_score":"confidence score of the subfeature with respect to the Feature, as a percentage (e.g., 80)"
    "micro_sub_features": [
      {
        "name": "Sub-User Story Title 1",
        "description": "Standalone description of a single functionality.",
        "file_path": [...],
        "micro_sub_feature_confidence_score":"confidence score of the micro_sub_feature with respect to the sub_feature, as a percentage (e.g., 90)"
        }
          ...
        ]
      },
      ...
    ]
  }
]
Each layer must preserve independence, clarity, and singular focus of each story.

VALIDATION CHECKLIST
- Each title must express one functionality only (no imperative phrasing)
- description must avoid assumptions and describe the real function. It must be as detailled as possible.
- Each story must make sense independently and fit in the broader feature flow
- if there are multiple user-story under the subfeature, it needs to be in sequence of business logic.
- File mappings must be relevant and scoped accurately
- Do no miss/skip any values in the output json. The output structure must be maintained strictly.
- All subfeature and sub-user-story names and descriptions must be strictly in a declarative tone, not imperative.

* Use generic or speculative statements
"""


db_micro_sub_feature_prompt = """
<Role>
You are an expert Database analyst specializing in decomposing SubFeatures into granular, logically independent components. You support **two levels** of splitting:
You shall ALWAYS process features from a Database perspective ONLY. 
There can be more than one Table in the DB context provided to you.
</Role>

1. **Horizontal splitting**: Split a subfeature into multiple *same-level subfeatures* when it encompasses multiple independently meaningful functionalities. The subfeatures created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.
2. **Vertical splitting**: Further break each of those subfeatures into *microsubfeatures* (if applicable), ensuring each micro-sub-features/micro-user-story describes a single goal or operation. The micro-sub-features/micro-user-story created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.

<Strict Constraints> 
- You are dealing with Database Information. 
- No matter what, STRICTLY use Database-Specific Language ALWAYS. 
- Use words like Columns / Fields / Schema / DataTypes / Constraints / Foreign Keys / Primary Keys etc.
- Strictly Do not start descriptions with or start with "this micro-feature" / or "this sub-feature".
- You shall do this regardless of the input context and nature.
Remember : Every "FILE" given to you is information of a table. Therefore in your response, ALWAYS refer to "Table" instead of "File".

</Strict Constraints> 


### ðŸ”§ TASK OVERVIEW

Given a Macro-Feature, Subfeature, its description, associated module files and its summary:

- Decide if the subfeature should be split horizontally into multiple same-level subfeatures.
- For each resulting subfeature (or original if not split), analyze whether it can be split vertically into **microsubfeatures** (fine-grained user stories).
- Provide the confidence scores for the subfeature that is split, whether horizontally or vertically.
- Provide the files that are related to the sub_features too, not just the micro_sub_features.
- Each leaf user-story must have files assigned to them, else you should not create/split these subfeatures.
- Provide description of generated subfeature/sub-user-stories in 2-4 lines but only valid information. Do not assume or hallucinate to generate description.
Apply this recursively: if horizontal splitting occurs, then attempt vertical splitting for each. But remember, not to create any duplicates in the process. 

---

### SPLITTING DECISIONS

#### Horizontal Splitting (Same-level Subfeatures):
Split if:
- The subfeature covers ONE / MORE THAN ONE high-level functionalities
- Each function could be planned and developed independently
- Each component has some clear boundaries and responsibilities

#### Vertical Splitting (Microsubfeatures):
Split further if:
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across actions are too complex to isolate.
- There are no tables that can be mapped to the generated user-story.
- The subfeature is too complex to be planned, developed, and deployed independently
- Each micro-subfeature represents one atomic, non-overlapping functionality
Note: Maintain at least 2 subfeatures unless the database has only one table.
- Prioritize brevity, consistency and no informaiton leakage across subfeatures.
- Ensure crisp segregation.
---

### DO NOT SPLIT IF:
- sub-user-stories are tightly coupled in the Subfeature and cannot function independently.
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across tables in two features are too complex to isolate.
- There are no tables that can be mapped to the generated user-story.
Note: Maintain at least 2 subfeatures and 1 or more microsubfeatures per subfeature, Unless the database has only one table.
Note : Maintain brevity during splitting at the same level. Do NOT overload the a single feature with too many subfeatures.
---


### FILE MAPPING RULES:
- For each subfeature or microsubfeature, cite only directly relevant tables.
- Use only the provided input data to match files â€” no guessing.
- Avoid duplication unless a file is clearly shared between components.

Each `file_path` entry must include:
```json
{
  "module_name": "<Name>",
  "path": "<Path>",
  "critical": <true/false>,
  "git_url": "<Git URL>"
}

OUTPUT FORMAT
If the subfeature should NOT be split:
Return: "None"

If the subfeature should be split, return a list of Parent User Stories with subfeatures inside.
If a subfeature itself can be further split into microsubfeatures, nest them under micro_sub_features like so:

[
  {
    "name": "Parent User Story Title 1",
    "description": "Full description of the original or updated user story and its purpose.",
    "file_path": [...],
    "sub_feature_confidence_score":"confidence score of the subfeature with respect to the Feature, as a percentage (e.g., 80)"
    "micro_sub_features": [
      {
        "name": "Sub-User Story Title 1",
        "description": "Standalone description of a single functionality.",
        "file_path": [...],
        "micro_sub_feature_confidence_score":"confidence score of the micro_sub_feature with respect to the sub_feature, as a percentage (e.g., 90)"
        }
          ...
        ]
      },
      ...
    ]
  }
]
Each layer must preserve independence, clarity, and singular focus of each story.

VALIDATION CHECKLIST
- Each title must express one functionality only (no imperative phrasing)
- description must avoid assumptions and describe the real function. It must be as detailled as possible.
- Each story must make sense independently and fit in the broader feature flow
- if there are multiple user-story under the subfeature, it needs to be in sequence of business logic.
- File mappings must be relevant and scoped accurately
- Do no miss/skip any values in the output json. The output structure must be maintained strictly.
- All subfeature and sub-user-story names and descriptions must be strictly in a declarative tone, not imperative.
- Use Database-specific schema only. Do not include words like "Attributes" / "Code Files" in your response. 
- Strictly Do not start descriptions with or start with "this micro-feature" / or "this sub-feature".
* Use generic or speculative statements

"""import os
from graphviz import Digraph
import re 
import json

def parse_ddl(ddl: str):
    """
    Parse the DDL to extract columns, primary keys, and foreign keys.
    """
    lines = ddl.splitlines()
    column_lines = []

    for line in lines:
        line = line.strip()
        if (
            line.upper().startswith("CREATE")
            or line.upper().startswith("PRIMARY")
            or line.upper().startswith("FOREIGN")
            or line.upper().startswith(")")
            or line == ""
        ):
            continue

        match = re.match(r'(\w+)\s+\w+', line)
        if match:
            column_lines.append(match.group(1))

    pk_match = re.search(r'PRIMARY KEY\s*\((.*?)\)', ddl)
    primary_keys = [key.strip() for key in pk_match.group(1).split(",")] if pk_match else []

    foreign_keys = []
    for match in re.finditer(r'FOREIGN KEY\s*\(([^)]+)\)\s+REFERENCES\s+`?[\w]+\.(\w+)`\(([^)]+)\)', ddl):
        fk_col = match.group(1).strip()
        ref_table = match.group(2).strip()
        ref_col = match.group(3).strip()
        foreign_keys.append((fk_col, ref_table, ref_col))

    return column_lines, primary_keys, foreign_keys


def generate_combined_graph(tables_data):
    """
    Generate a single combined graph from multiple tables.
    """
    dot = Digraph(comment='Combined Table Diagram')
    dot.attr(rankdir='LR')

    # Store individual table nodes
    for table in tables_data:
        table_name = table['table_name']
        columns = table['columns']
        primary_keys = table['primary_keys']
        
        label_lines = []
        for col in columns:
            if col in primary_keys:
                label_lines.append(f"{col} [PK]")
            else:
                label_lines.append(col)
        dot.node(table_name, shape='box', label=f'{table_name}\\n' + "\\n".join(label_lines))

    # Add relationships
    for table in tables_data:
        table_name = table['table_name']
        for fk_col, ref_table, ref_col in table['foreign_keys']:
            dot.edge(table_name, ref_table, label=f'{fk_col} â†’ {ref_col}')

    return dot

def folder_summary_generation_prompts(
        total_allocated_tokens, 
        file_list, folder_name, 
        folder_path,
        subfolder_list,
        formatted_file_summaries,
        formatted_file_services,
        formatted_subfolder_summaries,
        formatted_subfolder_services,
        formatted_subfolder_features
    ):
    
    system_prompt = f"""
        You are an expert code analyst specialized in creating detailed, informative summaries of software project folders. Your task is to thoroughly analyze files and subfolders to provide a comprehensive understanding of the application or project and provide combined summaries along with required details. These summaries must be detailled enough for further summarization.

        Follow these guidelines:
        1. Conduct a deep analysis of the features to identify its core purpose and functionality
        2. Provide detailed explanation of key implementations and technical approaches of the features
        3. Thoroughly examine the summaries based on files and folders to understand relationship between features and combined smaller features into larger high level application level features.
        4. Explain the features within the broader project architecture with specific connections
        5. Describe technical patterns, design decisions, and architectural choices evident in the code
        6. Include specific functions, classes, and methods that define the feature's behavior
        7. Note dependencies, imports, and external connections that shape the folder's functionality
        8. Identify potential architectural strengths and areas for improvement when evident
        9. Identify all services represented in this folder based on file and subfolder services information
        10. Identify and articulate high-level features or functionalities represented by the folder into the feature_details section, when consolidating multiple subfolders or lower-level files. Derive these insights from both file-level and subfolder-level summaries. Also under each feature, mention which file/folder was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
        11. Do not miss any features that could be formed based on these summaries as this information is required to understand the application's buisness logic.
        12. Gather insights from the summaries provided to generate a high level detailled executive summary that could be used by business stakeholders to understand the folder/project.
        13. When analyzing the root folder, both the executive summary and the features must be strictly formed in a high level business logic standpoint of an application.
        
        IMPORTANT: 
        - Your summary should be thorough and detailed({total_allocated_tokens}) while maintaining technical/business precision and depth. Focus on providing insights that would help both stakeholders and developers understand the application better.
        - feature_details must contain high level feature name and feature description(value of the files/folders) strictly in concise bullet points. The feature inforamtion must be in detail to capture the complete high level knowledge for that feature but not the function level details. Feature names cannot be programmatic function names like Dependency management, json handling etc. instead it should be inventory management, order processing etc. 
        - Your services list should be comprehensive and include all services represented in this folder.
        - is_reuasble_lib if a folder is used as reusable lib make it True otherwise False
        - lib_name if is_reusable_lib is True then provide the name of the reusable lib/component If is_reusable_lib False then add Not Applicable
        - category if is_reusable_lib is True then provide category only between 'Frontend' and 'Backend' If is_reusable_lib False then add Not Applicable
        - sub_category if is_reusable_lib is True then provide sub category only between 'UI Component','Custom Hooks', 'http_client', 'Utils', 'Others' In Frontend & 'Middleware', 'Error Handling', 'Auth', 'Utils', 'Others' In Backend If is_reusable_lib False then add Not Applicable
        - when_to_use if is_reusable_lib is True then provide where this reusable lib/component can be used If is_reusable_lib False then add Not Applicable 
        - associated_files if is_reusable_lib is True then provide the list of files associated(give complete path for the assosciated file) with this reusable lib/component If is_reusable_lib False then add Not Applicable
        - summary must not be technical and only explain the high level details of the folder/project. Understand the file and folder summaries provided to combine the knowledge to form the executive summary. Make it as detailled as possible.
        - Use clear and concise language, avoiding jargon where possible.
        
        - You must provide your response in this exact format:
        ```summary
        [Your detailled high-level executive summary for the folder for business stakeholders]
        ```
        ```feature_details
        [List of high-level features or functionalities represented in this folder]
        ```
        ```services_namess
        [Comma-separated list of all services represented in this folder]
        ```
        ```is_reuasble_lib
        Boolean Value
        ```
        ```lib_name
        [Name of the reusable library if applicable]
        ```
        ```category
        [Category of the reusable library if applicable]
        ```
        ```sub_category
            [Sub category of the reusable library if applicable]
        ```
        ```when_to_use
        [Your detailed use case where or when this reuasble_lib can be usefull]
        ```
        ```associated_files
            [Comma-separated list of associated files with the reusable library, Give the Complete file path as mentioned in the file list]
        ```
        ```example_usage
            [Example code snippet of how to use this reusable library]
        ```
    """

    user_prompt = f"""
        Generate a summary and services list for the folder: "{folder_name}" (Path: {folder_path})

        FOLDER CONTENTS:
        - Files ({len(file_list)}): {", ".join(file_list) if file_list else "None"}
        - Subfolders ({len(subfolder_list)}): {", ".join(subfolder_list) if subfolder_list else "None"}

        FILE SUMMARIES:
        {os.linesep.join(formatted_file_summaries) if formatted_file_summaries else "No file summaries available"}

        FILE SERVICES:
        {os.linesep.join(formatted_file_services) if formatted_file_services else "No file services available"}

        SUBFOLDER SUMMARIES:
        {os.linesep.join(formatted_subfolder_summaries) if formatted_subfolder_summaries else "No subfolder summaries available"}

        SUBFOLDER SERVICES:
        {os.linesep.join(formatted_subfolder_services) if formatted_subfolder_services else "No subfolder services available"}

        SUBFOLDER FEATURES:
        {os.linesep.join(formatted_subfolder_features) if formatted_subfolder_features else "No subfolder features available"}
        
        Based on these components:
        1. Provide a thorough technical summary explaining the folder's purpose, implementation details, and architectural significance
        2. Compile a comprehensive list of all services represented in this folder based on file and subfolder services information
        
        Follow the exact format specified in the system instructions for your response.
    """

    return system_prompt, user_prompt

def services_generation():
    system_prompt = """
        <Task>
        Create an architectural blueprint of the given repository by identifying and classifying both external services and third-party services with no overlap between categories.
        </Task>

        <Definitions>
        - External services: Company-provided services hosted outside the application (AWS S3, Google Cloud, Stripe, Twilio)
        - Third-party services: Libraries, frameworks, and SDKs that are part of the core application stack (Django, React, MongoDB, Redux)
        </Definitions>

        <Output_Format>
        {
        "external_services": [
            {
            "external_service_name": "string",
            "description": "string",
            "associated_files": ["string"],
            "service_class": "string",
            "used_in_files": ["string"]
            }
        ],
        "thirdparty_services": [
            {
            "thirdparty_service_name": "string",
            "description": "string",
            "associated_files": ["string"],
            "service_class": "string",
            "used_in_files": ["string"]
            }
        ]
        }
        </Output_Format>

        <Instructions>
        1. Conduct a thorough repository analysis to identify all services
        2. Classify each service into exactly ONE category:
        - External services: Cloud platforms, payment processors, authentication providers
        - Third-party services: Frameworks, libraries, SDKs integrated into the codebase
        3. For each service, provide:
        - Name: Exact service name
        - Description: Concise explanation of functionality and purpose
        - Associated files: All files directly importing or using the service
        - Service class: Category (e.g., "cloud storage", "web framework", "database")
        - Used in files: Complete paths of files utilizing the service
        4. Ensure ZERO overlap between categories
        5. Prioritize accuracy over comprehensiveness
        6. Validate that identified services are actively used in the project
        7. Include only services with clear evidence of implementation
        8. Do not create a lot of services which are redundant. Keep it to a maximum of 50 services only.
        </Instructions>

        <Examples>
        Good External Service Entry:
        {
        "external_service_name": "AWS S3",
        "description": "Cloud storage service used for storing user-uploaded files",
        "associated_files": ["src/services/storage.js", "src/config/aws.js"],
        "service_class": "cloud storage",
        "used_in_files": ["src/components/FileUpload.js", "src/pages/UserProfile.js"]
        }

        Good Third-Party Service Entry:
        {
        "thirdparty_service_name": "React",
        "description": "Frontend JavaScript library for building user interfaces",
        "associated_files": ["package.json", "src/index.js"],
        "service_class": "frontend framework",
        "used_in_files": ["src/App.js", "src/components/*.js"]
        }
        </Examples>

        Analyze the repository and provide the complete architectural blueprint in the specified format.
    """

    user_prompt = ""

    return system_prompt, user_prompt

def executive_summary_generation(combined_summary, user_mvf):
    system_prompt = """
    Your Role:
    You are an expert software architect tasked with understanding a codebase and creating an executive summary that clearly articulates the main purpose of this application,
    the core problem that the application is solving, and the prioritized list of the most valuable features, solely based on the provided folder wise summary. Do not hallucinate and create the most valuable features and its description on assumption. This needs to be based on facts.

    Task:
    1. Analyze provided folder wise summary and the services used and the user defined features (if provided).
    2. Understand component interactions and functions.
    3. Prioritize the User Defined Features (if provided) in the summary.
    4. Identify and prioritize the most valuable features based on their importance and relevance to the overall project, as evidenced in the code.
    5. Create a comprehensive executive summary.

    Steps:
    1. Review folder wise summary.
    2. Analyze folder wise summary:
    - Identify key components and their roles
    - Note data operations, design patterns, and architectural decisions
    3. Create summary:
    - Describe the specific problem the codebase solves, based on folder wise summary
    - Explain component interactions
    - Outline data workflow
    4. Identify and prioritize main features:
    - Determine which feature(s) address the core problem of the application, based on code implementation
    - Rank features based on their importance and relevance to solving the main problem, as evidenced in the code
    - The feature should be major components of the codebase and not minor functions like "Modular Architecture" or "Code Reusability", these are not features but design principles.

    Focus Areas:
    - Precised feature prioritization and importance
    - High-level functionality
    - Clear, concise technical language
    - Objective description
    - Capture entire workflow

    Guidelines:
    - Only use the folder wise summary provided
    - Use precise technical terms
    - Include user-defined features if provided and evidenced in the code
    - Prioritize features based on their importance to the core problem, as shown in the folder wise summary

    Feature Identification and Prioritization:
    - Carefully analyze the folder wise summary to identify features actually present in the folder wise summary
    - Do not assume or infer features that are not explicitly mentioned in the folder wise summary
    - Identify the top feature that solves the majority of the problem based on code evidence
    - Rank subsequent features in descending order of importance, ensuring they are present in the folder wise summary
    - Ensure the feature list reflects the codebase's focus and structure
    - Only include features that have substantial implementation in the codebase that is evident from folder wise summary

    Output Format - Adhering to this format is crucial
    ```json
    {
    "data": "generated_summary in string format adhering to the Expected Output Format for Generated Summary",
    "confidence_score": 90,
    "traceback": {
    "Feature 1 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 1 Title' is included, as the 'phrase' is an evidence that this feature is part of the codebase.",
    "Feature 2 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 2 Title' is included, as the 'phrase' is an evidence that this feature is part of the codebase.",
    ...
    }
    }
    ```

    Requirements:
    - Replace \n with \\n in JSON
    - Limit upto 5 main features (max 2 sub-features each) or 7500 tokens
    - If due to any reason such as codebase being small, you are unable to provide 5 features, then provide as many high-level features as possible between the range of 1 to 5.
    - Don't assume features or include minor features due to inability to provide 5 features, lesser number of features is acceptable.
    - Use specified JSON format only
    - Start with "```json" and end with "```"
    - Ensure the top feature in the prioritized list addresses the core problem and is present in the folder wise summary
    - Rank features in descending order of importance to the main problem, based on actual code implementation
    - Do NOT include features that are NOT evidenced in the provided folder wise summary
    - Evaluate the folder wise summary objectively, considering all conclusions on the actual code provided
    - Do NOT make any assumptions about organizational goals or intentions beyond what is explicitly shown in the code
    - Focus solely on the technical aspects and implemented functionality, avoiding speculation about business objectives or future plans
    - Both the keys data, confidence score, and traceback should be present in the output JSON
    - The generated summary should be in string format only and be contained inside the "data" key
    - The "traceback" key should contain a dictionary with feature names as keys and justifications for including these features based on exact phrases from the input
    - Do not include any feature that could potentially be part of the folder wise summary without explicit evidence
    - Every feature mentioned must be driven by clear evidence from the provided input
    """
    user_prompt = """
    Expected Output Format for Generated Summary:

  **Overview**
  <empty line>
  <A brief introduction to the codebase and its main purpose; in paragraph format only, not in points.
  This paragraph should provide a concise yet comprehensive overview of the codebase, its primary functionality, solution provided by the project and its intended use case.
  Aim for 3-5 sentences that capture the essence of the project.>
  <empty line>
  **Highlighted Features**
  <empty line>
  <
  List and briefly explain the key features that are significant components of the codebase and would serve as selling points.
  These features should be presented as follows:
  1. Use numbered points for each feature.
  2. Provide a brief explanation for each feature in 1-2 sentences, highlighting its importance and benefit to the end user.
  3. Focus on features that are central to the codebase's functionality and most important to the end user.
  4. Dont include generic features like "Modular Architecture" or "Code Reusability", these are not features but design principles.
  5. Do not include sub-points under any feature.
  6. Prioritize User Defined Features (if provided) at the beginning of the list.
  7. If User Defined Features are given, list them first before including any features identified through your analysis.
  8. Aim to provide upto of 1 to 5 key features, after each feature add an empty line for formatting purposes.
  9. Ensure that the features listed represent the core functionality and unique selling points based on the folder wise summary.
  10. Use clear, concise language that emphasizes the value proposition of each feature.
  11. Also under each feature, mention which file/folder was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
  12. Do not add features into Highlighted Features if they dont have value for buisness stakeholder about the application. Also do not repeat adding similar feature in this section.

  Output Structure:
  1. ***<Feature 1 Title>***: <Description of the feature in one to two sentences.\n
  2. ***<Feature 2 Title>***: <Description of the feature in one to two sentences.>\n
  >
  <empty line>
  **Key Benefits**
  <empty line>
  <Summarize the key benefits of the codebase in one to two sentences.
  This summary should encapsulate the overall value proposition of the codebase and its potential impact on users or the organization.>
  <empty line>
  <Highlight the most significant key benefits the codebase has to offer in bulleted points. The format should be:
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  Aim for 3-5 bullet points that capture the most compelling advantages of using this codebase, after each point add an empty line for formatting purposes.
  Each benefit should be distinct and provide a clear value proposition.>

  <Final Output Format>
  Output Format - Adhering to this format is crucial, the output should be in parsable JSON format:
  ```json
  {{
    "data": "<generated_summary in string format adhering to the Expected Output Format for Generated Summary>",
    "confidence_score": 90,
    "traceback": {{
      "Feature 1 Title": "Since it mentions about <exact phrase from the folder wise summary>, the 'Feature 1 Title' is included, as the "phrase" is an evidence that this feature is part of the folder wise summary.",
      "Feature 2 Title": "Since it mentions about <exact phrase from the folder wise summary>, the 'Feature 2 Title' is included, as the "phrase" is an evidence that this feature is part of the folder wise summary.",
      ...
    }}
  }}
  ```
  </Final Output Format>
  Note: If the traceback includes phrases that are not present in the folder wise summary then you would be penalized 10000 points.
  The output should be having data, confidence score, and traceback keys, and the entire content inside "```json" and "```" should be parsable by json.
  The "data" key should contain the generated summary and it should be in string format only, allowing the parsing of the entire json.
  If there are any inverted commas inside the generated summary, then escape them with a backslash.
  Do not change or skip the headings of each section in the generated json. The generated summary must have "Overview", "Highlighted Features", "Key Benefits" as section titles. Follow the above provided guidelines."""
    user_prompt += f"""Use the below folder wise summary to generate the summary in the above format: {combined_summary}""" + "User Defined Features : " + str(user_mvf)
    return system_prompt, user_prompt

def db_executive_summary_generation(combined_summary, user_mvf): 
    system_prompt = """
    Role:
    You are an expert Database Architect tasked with understanding the contents of all tables and schema of the database. 
    You shall Articulate a proper executive summary that clearly captures all the main & high-level features of this database.
    The core use-case that this database is intended for, and the prioritized list of the most valuable features, solely based on the provided Table-Level summaries. 
    Do not hallucinate. Do NOT create the most valuable features and its description on pure assumptions. This needs to be based on facts, with proper backing.

    Task:
    1. Analyze provided Table wise summaries.
    2. Understand component interactions and functions.
    3. Prioritize the User Defined Features (if provided) in the summary.
    4. Identify and prioritize the most valuable features based on their importance to the core use-case the Database is solving.
    5. Create a comprehensive executive summary.

    Steps:
    1. Review Table wise summary.
    2. Analyze Table wise summary:
      - Identify all tables. 
      - Take into consideration the foreign keys, primary keys, is-a, has-a, and many-to-many relationships.
      - Deeply understand the intended-use-case of each table.
      - Note data operations, design patterns, and architectural decisions
    3. Create summary:
      - Describe the specific problem the Database is solving, based on Table wise summary
      - Explain high-level interactions and dependencies
      - Outline data workflow
    4. Identify and prioritize main features:
      - Determine which feature(s) address the core problem of the Database, based on SQL implementation and Table wise summary
      - Rank features based on their importance and relevance to solving the main problem, as evidenced in the Database
      - The feature should be major components of the Database and not minor functions like Many-to-Many Relationships, or "Foreign Keys". 
        These are implementation concepts. Not core features.

    Focus Areas:
    - Precised feature prioritization and importance
    - High-level functionality of this Database
    - Clear, concise technical language with Database-specific Language
    - Objective description
    - Capture entire data workflow

    Guidelines:
    - Only use the Table wise summary provided
    - Use precise Database-relevant technical terms
    - Include user-defined features if provided and evidenced in the Table wise summary
    - Prioritize features based on their importance to the core problem, as shown in the Table wise summary

    Feature Identification and Prioritization:
    - Carefully analyze the Table wise summary to identify features actually present in the Table wise summary
    - Do not assume or infer features that are not explicitly mentioned in the Table wise summary
    - Identify the top feature that solves the majority of the problem based on Database and SQL evidence
    - Rank subsequent features in descending order of importance, ensuring they are present in the Table wise summary
    - Ensure the feature list reflects the Database's focus and structure
    - Only include features that have substantial implementation in the Database that is evident from Table wise summary

    Output Format - Adhering to this format is crucial
    ```json
    {
    "data": "generated_summary in string format adhering to the Expected Output Format for Generated Summary",
    "confidence_score": 90,
    "traceback": {
    "Feature 1 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 1 Title' is included, as the 'phrase' is an evidence that this feature is part of the Database.",
    "Feature 2 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 2 Title' is included, as the 'phrase' is an evidence that this feature is part of the Database.",
    ...
    }
    }
    ```

    Requirements:
    - Replace \n with \\n in JSON
    - Limit upto 5 main features (max 2 sub-features each) or 7500 tokens
    - If due to any reason such as Database being small, you are unable to provide 5 features, then provide as many high-level features as possible between the range of 1 to 5.
    - Don't assume features or include minor features due to inability to provide 5 features, lesser number of features is acceptable.
    - Use specified JSON format only
    - Start with "```json" and end with "```"
    - Ensure the top feature in the prioritized list addresses the core problem and is present in the Table wise summary
    - Rank features in descending order of importance to the main problem, based on actual Database and SQL implementation
    - Do NOT include features that are NOT evidenced in the provided Table wise summary
    - Evaluate the Table wise summary objectively, considering all conclusions on the actual Database and SQL provided
    - Do NOT make any assumptions about organizational goals or intentions beyond what is explicitly shown in the Database and SQL
    - Focus solely on the technical aspects and implemented functionality, avoiding speculation about business objectives or future plans
    - Both the keys data, confidence score, and traceback should be present in the output JSON
    - The generated summary should be in string format only and be contained inside the "data" key
    - The "traceback" key should contain a dictionary with feature names as keys and justifications for including these features based on exact phrases from the input
    - Do not include any feature that could potentially be part of the Table wise summary without explicit evidence
    - Every feature mentioned must be driven by clear evidence from the provided input.
    - Strictly use an assertive and objective tone in your response. 
    - Do not be unsure about anything.
    - Do not include the "Folder Name" in your response. Ignore "dbanalysis" folder. Provide Executive Summary of the Database-ONLY.
    """

    user_prompt = """
  Expected Output Format for Generated Summary:

  **Overview**
  <empty line>
  <A brief introduction to the Database and its main purpose; in paragraph format only, not in points.
  This paragraph should provide a concise yet comprehensive overview of the Database, its primary functionality, and its intended use case.
  Aim for 3-5 sentences that capture the essence of the Database.>
  <empty line>
  **Highlighted Features**
  <empty line>
  <
  List and briefly explain the key features that are significant components of the Database and would serve as selling points.
  These features should be presented as follows:
  1. Use numbered points for each feature.
  2. Provide a brief explanation for each feature in 1-2 sentences, highlighting its importance and benefit to the END USER.
  3. Focus on features that are central to the Database's functionality and most important to the END USER.
  4. Dont include generic features like  Many-to-Many Relationships, or "Foreign Keys", these are not features but Design Principles.
  5. Do not include sub-points under any feature.
  6. Prioritize User Defined Features (if provided) at the beginning of the list.
  7. If User Defined Features are given, list them first before including any features identified through your analysis.
  8. Aim to provide upto of 1 to 5 key features, after each feature add an empty line for formatting purposes.
  9. Ensure that the features listed represent the core functionality and unique selling points based on the Table wise summary.
  10. Use clear, concise language that emphasizes the value proposition of each feature.
  11. Also under each feature, mention which file/Table was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
  12. Do not add features into Highlighted Features if they dont have value for buisness stakeholder about the application. Also do not repeat adding similar feature in this section.

  Output Structure:
  1. ***<Feature 1 Title>***: <Description of the feature in one to two sentences.\n
  2. ***<Feature 2 Title>***: <Description of the feature in one to two sentences.>\n
  >
  <empty line>
  **Key Benefits**
  <empty line>
  <Summarize the key benefits of the Database in one to two sentences.
  This summary should encapsulate the overall value proposition of the Database and its potential impact on users or the organization.>
  <empty line>
  <Highlight the most significant key benefits the Database has to offer in bulleted points. The format should be:
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  Aim for 3-5 bullet points that capture the most compelling advantages of using this Database, after each point add an empty line for formatting purposes.
  Each benefit should be distinct and provide a clear value proposition.>

  <Final Output Format>
  Output Format - Adhering to this format is crucial, the output should be in parsable JSON format:
  ```json
  {{
    "data": "<generated_summary in string format adhering to the Expected Output Format for Generated Summary>",
    "confidence_score": 90,
    "traceback": {{
      "Feature 1 Title": "Since it mentions about <exact phrase from the Table wise summary>, the 'Feature 1 Title' is included, as the "phrase" is an evidence that this feature is part of the Table wise summary.",
      "Feature 2 Title": "Since it mentions about <exact phrase from the Table wise summary>, the 'Feature 2 Title' is included, as the "phrase" is an evidence that this feature is part of the Table wise summary.",
      ...
    }}
  }}
  ```
  </Final Output Format>
  Note: If the traceback includes phrases that are not present in the Table wise summary then you would be penalized 10000 points.
  The output should be having data, confidence score, and traceback keys, and the entire content inside "```json" and "```" should be parsable by json.
  The "data" key should contain the generated summary and it should be in string format only, allowing the parsing of the entire json.
  If there are any inverted commas inside the generated summary, then escape them with a backslash.
  Do not change or skip the headings of each section in the generated json. The generated summary must have "Overview", "Highlighted Features", "Key Benefits" as section titles. Follow the above provided guidelines.
    """

    user_prompt += f"""Use the below Table wise summary to generate the summary in the above format: {combined_summary}""" + "User Defined Features : " + str(user_mvf)

    return system_prompt, user_prompt


def architecture_diagram_generation(services_data, icons_metadata):
    user_prompt = f"""
    <Input>
    $services_data = {services_data}
    $icons_metadata
    </Input>

    <Role>
    You are an expert at understanding large projects based on their executive summary and the services being used in them. Create a JSON structure for a ReactFlow diagram based on the given service class JSON.
    </Role>

    <Output Structure>
    1. Create a JSON object with a "nodes" and "edges" array.
    2. Create nodes for each external and third-party service.
    3. "nodes": An array containing all node objects.
      - "id": A unique string identifier for the node.
      - "data":   
        - "label": The name of the node.
        - "description": Description of the service.
        - "associated_files": Associated file and used in files in the service node, defaulting to "No File Available" if not present.
        - "group": The logical group name (e.g., 'Backend', 'Frontend', 'Database',etc..).
        - "subgroup": The specific subgroup within the group (e.g., Frameworks, NoSQL Databases, State Management, etc.).
        - "service": The appropriate filename of the icon based on the $icons_metadata.
      - "position" : The x and y coordinates of the node.
      - "type" : "customNode" This should be fixed.
    4. "edges" : An array having id, source, target, label, and type should be customEdge always.
    4. Ensure all services and files from the input JSON are included.
    5. The output should be in the form of a dictionary containing a "nodes" and "edges" array.
    6. Present only the code inside delimiters "```reactflow [reactflow CODE]```" without any additional explanation.
    """

    system_prompt:str = """
    <Task>
      You are tasked with creating a JSON structure for a ReactFlow diagram based on the given executive summary and the service_class_json. The executive summary contains an overview of the entire project. This JSON includes information about external services and third-party services, along with their associated files. Your output should represent this information as a network of nodes and edges.
    </Task>
    
    <Icons Context>
      $icons_metadata = """ + str(icons_metadata) + """
    </Icons Context>

    <Instructions>
      You are a solution expert, specializing in problem and solution flows. You will be given the solution overview for a project, and your task is to create an interconnected single component of graph which is detailed, and intuitive and self explanatory for:

      Follow these guidelines:
      1. Create nodes for each unique service (both external and third-party).
      2. Do not create any group nodes.
      4. In the data key for each service node, include two additional fields called group and subgroup. The group field should contain the logical group name (e.g., Frontend, Backend, Databases, etc..), and the subgroup field should provide more specific categorization (e.g., Frameworks, NoSQL Databases, etc..). For example, for a service node representing React, the group would be Frontend and the subgroup would be Frameworks.
      5. For each node, check which icon will be the most suitable from the $icons_metadata in the <Icons Context>
      6. Ensure all information from the input is represented in the output.
      7. The position coordinates must be proper for all the nodes.
    </Instructions>

    <Rules>
      **Ensure all nodes in the generated graph are interconnected such that every node has at least one edge, forming a single connected component without any isolated or disjoint sections. (High Priority Requirement)**
      Important Rules to be followed:
      1. Give detailed technical architecture flow and the JSON object following the below output format.
      2. Make sure that the flow and order of new solution approach is explained well in the graph with appropriate edges. Use as many edges you want to describe the data and user flow properly.
      3. The whole user and data flow should be clear.
      4. Do not add unnecessary nodes and edges. Do not create duplicate nodes that perform same task.
      5. Make the Node descriptions detailed, breaking tasks into multiple sub-tasks if needed.
      6. Ensure your edges show the actual flow, and not just connections of what's related. The connections are meant to show the logical flow, and not the relatedness/similarity.
      7. The group name is meant to classify clusters of nodes within each graph. For instance, if we have multiple nodes in features, they would all have "feature" as group. In Architecture Flow, the "Group" should show the layer each node is in, for instance "Backend Layer", "Database Layer" etc.
      9. for a hierarchy of nodes A -> B -> C; ensure that there is not a connection between A -> C.
    </Rules>
    
    <output_format>
    The output should be in between the delimeters ```reactflow and ```. Only provide the json output. Don't give unnecesary explanation.
    ```reactflow
    {
      "nodes": [
        { 
          "id": "unique_node_identifier_string",
          "data" : {
            "label": "name_of_the_service",
            "description": "description of the service",
            "associated_files": ["file_path_1", "file_path_2", "file_path_3", etc.],  // (default: ["No File Available"] if not present)
            "group": "name_of_group",  // Add the logical group name (e.g., "Frontend", "Backend", etc..)
            "subgroup": "name_of_subgroup",  // Add a more specific subgroup name (e.g., "Frameworks", "NoSQL Databases", etc..)
            "service": "filename" //taken from the $icons_metadata,
          }
          "position":{ "x": "Xcoordinate", "y": "Ycoordinate" },
          "type" : "customNode" //this is hardcoded and will be constant
        }
      ],
      "edges": [
        {
          "id": "unique_egde_identifier_string",
          "source": "label A",
          "target": "label B",
          "label": "Showcase what comes from the source node, to the target node. Be concise and specific with labels, such as 'Ingested Data', 'Converted Text', 'User Query' etc. Use at max 5 words",
          "type" : "customEdge" //this is hardcoded and will be constant
        }
      ]
    }```
    </output_format>
    """
    return system_prompt, user_prompt
  

def erd_generation(services_data, icons_metadata):
  tables_metadata = []
  for entry in services_data:
      table_name = entry["table_name"]
      ddl = entry["ddl"]
      columns, primary_keys, foreign_keys = parse_ddl(ddl)
      tables_metadata.append({
          "table_name": table_name,
          "columns": columns,
          "primary_keys": primary_keys,
          "foreign_keys": foreign_keys
      })

  dot = generate_combined_graph(tables_metadata)

  system_prompt:str = """
    You are tasked with creating a JSON structure for a ReactFlow diagram based on the given database ER diagram and schema JSON. This JSON includes information about database columns and their relationships.Your output should represent this information as a network of nodes and edges.
    </Task>
    
    <Icons Context>
      $icons_metadata = """ + str(icons_metadata) + """
    </Icons Context>

    <Instructions>
      You are a solution expert, specializing in problem and solution flows. You will be given the database schema information of a database, and your task is to create an interconnected single component of graph which is detailed, and intuitive and self explanatory for:

      Follow these guidelines:
      1. Create nodes for each unique service (both external and third-party).
      2. Do not create any group nodes.
      4. In the data key for each service node, include two additional fields called group and subgroup. The group field should contain the logical group name (e.g.,Databases, etc..), and the subgroup field should provide more specific categorization (e.g., 'Transactional Tables', 'Reference Tables' etc..). For example, for a service node representing daily transactions, the group would be Database and the subgroup would be Transactional Tables.
      5. For each node, check which icon will be the most suitable from the $icons_metadata in the <Icons Context>
      6. Ensure all information from the input is represented in the output.
      7. The position coordinates must be proper for all the nodes.
    </Instructions>

    <Rules>
      Important Rules to be followed:
      1. Give detailed technical architecture flow and the JSON object following the below output format.
      2. Make sure that the flow and order of new solution approach is explained well in the graph with appropriate edges. Use as many edges you want to describe the data and user flow properly.
      3. The whole user and data flow should be clear.
      4. Do not add unnecessary nodes and edges. Do not create duplicate nodes that perform same task.
      5. Make the Node descriptions detailed, breaking tasks into multiple sub-tasks if needed.
      6. Ensure your edges show the actual flow, and not just connections of what's related. The connections are meant to show the logical flow, and not the relatedness/similarity.
      7. The group name is meant to classify clusters of nodes within each graph. For instance, if we have multiple nodes in features, they would all have "feature" as group. In Architecture Flow, the "Group" should show the layer each node is in, for instance "Database Layer" etc.
      9. for a hierarchy of nodes A -> B -> C; ensure that there is not a connection between A -> C.
    </Rules>
    
    <output_format>
    The output should be in between the delimeters ```reactflow and ```. Only provide the json output. Don't give unnecesary explanation.
    ```reactflow
    {
      "nodes": [
        { 
          "id": "unique_node_identifier_string",
          "data" : {
            "label": "name_of_the_table",
            "description": "description of the table",
  	    "columns": ["order_id [PK]", "product_sku [PK]", "quantity", "unit_price"]
            "group": "name_of_group",  // Add the logical group name (e.g., "Database", etc..)
            "subgroup": "name_of_subgroup",  // Add a more specific subgroup name (e.g., 'Transactional Tables', 'Reference Tables', etc..)
            "service": "filename" //taken from the $icons_metadata,
          }
          "position":{ "x": "Xcoordinate", "y": "Ycoordinate" },
          "type" : "customNode" //this is hardcoded and will be constant
        }
      ],
      "edges": [
        {
          "id": "unique_egde_identifier_string",
          "source": "label A",
          "target": "label B",
          "label": "Showcase what comes from the source node, to the target node. Be concise and specific with labels, such as 'Ingested Data', 'Converted Text', 'User Query' etc. Use at max 5 words",
          "type" : "customEdge" //this is hardcoded and will be constant
        }
      ]
    }```
    </output_format>
    """
    
  user_prompt:str = f"""
    <Input>
    $database_tables = {dot}
    $icons_metadata
    </Input>

    <Role>
    You are an expert at understanding database architecture based on ER diagrams and relational structures. Create a JSON structure for a ReactFlow diagram based on the given database schema.
    </Role>
    <Output Structure>
      1. Create a JSON object with a "nodes" and "edges" array.
      2. Create nodes for each table in the schema.
      3. "nodes": An array containing all node objects.
      - "id": A unique string identifier for the node.
      - "data":  
        - "label": The name of the table.
        - "description": A brief summary of the table's role or content.
        - "columns": List of column names (mark primary keys with [PK], foreign keys with [FK]).
        - "group": The logical group name (e.g., 'Database').
        - "subgroup": The specific subgroup within the group (e.g., 'Transactional Tables', 'Reference Tables').
        - "service": The appropriate filename of the icon based on the $icons_metadata.
      - "position" : The x and y coordinates of the node.
      - "type" : "customNode" This should be fixed.
      4. "edges" : An array having id, source, target, label, and type should be customEdge always.
      5. The label of the edge should describe the relationship, like "order_id â†’ order_id". 
      6. The output should be in the form of a dictionary containing a "nodes" and "edges" array.
      7. Present only the code inside delimiters "```reactflow [reactflow CODE]```" without any additional explanation.
    """
    
  return system_prompt, user_prompt
    

def feature_summary_generation(formatted_data, user_mvf, executive_summary):
    # if input_type is None:
    #     formatted_data = file_summary_list
    # elif input_type == "batch_summary":
    #     formatted_data = format_batchwise_summary_metadata_for_services(file_summary_list)
    # else:
    #     formatted_data = format_file_summaries(file_summary_list)

    user_prompt = """
    Role: You are an AI code analyst specializing in creating concise, feature-level summaries of codebases.

    Objective: Provide a comprehensive yet concise feature-level summary of a given codebase, highlighting key components, functionality, and the project's overall workflow.

    Input: You will receive information about a codebase, which may include an executive summary or other project details.

    Steps:
    1. Analyze the provided codebase information.
    2. Identify the main features (maximum 5) of the project from the executive summary (if provided in same order)
    3. Create a summary following the specified format, including:
        a. An overview of the project
        b. A list of key features with brief descriptions
        c. A closure statement
    4. Self-evaluate the generated summary and assign a confidence score.
    5. Format the output as specified in the instructions.

    Output Format:
    ```json
    {
        "data": "generated_summary in string format adhering to the Detailed Instructions for Output Format",
        "confidence_score": 90
    }
    ```

    Detailed Instructions for Output Format:

    **Overview**
    <empty line>
    < 
        Summarize all features in 2-3 sentences, introducing the project and its purpose.
        Provide a 2-3 sentence summary of key benefits, highlighting core architecture and value proposition.
    >
    <empty line>
    **Key Features**
    <empty line>
    <   
        List a maximum of 5 main features.
        For each feature, provide up to 2 sub-points describing its functionality.
        Ensure clear explanation of how features interact and contribute to the project's goals.
        1. ***<Key Feature Title>*** : 
        * <Sub point 1 description>
        * <Sub point 2 description>
        <empty line>
    >
    <empty line>
    < 
        Summarize the overall impact and value proposition of the project in one sentence as a conclusion statement.
    >
    <empty line>
    
    -> Self-Evaluation:
        - Score the summary out of 100 based on clarity, precision, detail, knowledge, accuracy, technical correctness, and understanding of the data.

    -> Formatting Requirements:
        - Replace all newline characters (\n) with \\n in the JSON output.
        - Ensure the complete JSON is less than 7500 tokens.
        - Start the output with "```json" and end with "```".
        - If an executive summary is provided, use only the highlighted features from it.

    Example Output Structure:
    ```json
    {
        "data": "**Overview**\\n\\n[Project overview]\\n\\n[Benefits summary]\\n\\n**Key Features**\\n\\n1. *Feature 1*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n2. *Feature 2*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n[...continue for up to 5 features...]\\n\\n[Closure statement]",
        "confidence_score": 90
    }
    ```

    Remember: Adhere strictly to the output format and instructions to maintain consistency and accuracy in your summary.
    """

    user_prompt += "User Defined Features : " + str(user_mvf)

    system_prompt = f"""
        <role>
        You are an assistant to a Senior Software Engineer. You are very capable in reading and understanding huge codebases.
        There is no edge-case, no mistake, no functionality no matter how small goes unnoticed by you.
        You will be given a large codebase and be asked queries regarding it.
        </role>

        <Task>
        You will be given relevant files from a production codebase. The Senior Engineer will consult you to clear his doubts and ask for critical code-level and functionality level analysis of the same.
        <Important>
        1. You will be clear. Feel free to be descriptive but Avoid Jargon
        2. You shall perform critical analysis on the code before responding.
        3. Note that the codebase will be quite complex and have dependencies everywhere, be mindful of them all.
        4. Enclose code in (triple backticks)``` code ```
        </Important>
        </Task>

        Files from Codebase goes here :
        <Repo Structure>
        {formatted_data}
        </Repo Structure>
    """

    start_index = executive_summary.find("Highlighted Features")
    end_index = executive_summary.find("Key Benefits")

    if start_index != -1 and end_index != -1:
        executive_summary = executive_summary[start_index:end_index].strip()

    user_prompt += "Executive Summary : " + str(executive_summary)

    return system_prompt, user_prompt

def feature_summary_generation_db(formatted_data, user_mvf, executive_summary):
    # if input_type is None:
    #     formatted_data = file_summary_list
    # elif input_type == "batch_summary":
    #     formatted_data = format_batchwise_summary_metadata_for_services(file_summary_list)
    # else:
    #     formatted_data = format_file_summaries(file_summary_list)

    user_prompt = """
    Role: You are an AI Database Analyst specializing in creating concise, feature-level summaries of complex database schemas and architectures.

    Objective: Provide a comprehensive yet concise feature-level summary of a given database schema information, highlighting key components, entities, relationships, and the overall data architecture workflow.

    Input: You will receive information about a database design, which may include an executive summary or other schema-level details.

    Steps:
    1. Analyze the provided database schema information.
    2. Identify the main features (maximum 5) of the database from the executive summary (if provided in same order)
    3. Create a summary following the specified format, including:
        a. An overview of the database
        b. A list of key features with brief descriptions
        c. A closure statement
    4. Self-evaluate the generated summary and assign a confidence score.
    5. Format the output as specified in the instructions.

    Output Format:
    ```json
    {
        "data": "generated_summary in string format adhering to the Detailed Instructions for Output Format",
        "confidence_score": 90
    }
    ```

    Detailed Instructions for Output Format:

    **Overview**
    <empty line>
    < 
        Summarize all features in 2-3 sentences, introducing the database and its purpose.
        Provide a 2-3 sentence summary of key benefits, highlighting schema structure, normalization or denormalization logic, and value proposition in handling data.
    >
    <empty line>
    **Key Features**
    <empty line>
    <   
        List a maximum of 5 main features.
        For each feature, provide up to 2 sub-points describing its data handling, relationships, or optimization logic.
        Ensure clear explanation of how features contribute to performance, consistency, and data integrity.
        1. ***<Key Feature Title>*** : 
        * <Sub point 1 description>
        * <Sub point 2 description>
        <empty line>
    >
    <empty line>
    < 
        Summarize the overall impact and value proposition of the database in one sentence as a conclusion statement.
    >
    <empty line>
    
    -> Self-Evaluation:
        - Score the summary out of 100 based on clarity, precision, detail, knowledge, accuracy, technical correctness, and understanding of the schema information.

    -> Formatting Requirements:
        - Replace all newline characters (\n) with \\n in the JSON output.
        - Ensure the complete JSON is less than 7500 tokens.
        - Start the output with "```json" and end with "```".
        - If an executive summary is provided, use only the highlighted features from it.

    Example Output Structure:
    ```json
    {
        "data": "**Overview**\\n\\n[Database overview]\\n\\n[Benefits summary]\\n\\n**Key Features**\\n\\n1. *Feature 1*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n2. *Feature 2*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n[...continue for up to 5 features...]\\n\\n[Closure statement]",
        "confidence_score": 90
    }
    ```

    Remember: Adhere strictly to the output format and instructions to maintain consistency and accuracy in your summary.
    """

    user_prompt += "User Defined Features : " + str(user_mvf)

    system_prompt = f"""
        <role>
        You are an assistant to a Senior Data Architect. You are very capable in reading, analyzing, and understanding complex database schemas and data models.
        No entity, constraint, relationship, or optimization logic goes unnoticed by you.
        You will be given a comprehensive database structure or schema information and will be asked to analyze, explain, and summarize it at a structural and functional level.
        </role>

        <Task>
        You will be given relevant database schema files or DDL definitions. The Senior Data Architect will consult you to clear doubts and ask for critical schema-level and data model-level analysis.
        <Important>
        1. You will be clear. Feel free to be descriptive but Avoid Jargon
        2. Perform a critical and deep analysis of the schema and the information given before responding.
        3. The schema will often involve multiple tables, foreign keys, views, procedures, and indexing strategies â€” be mindful of their dependencies and relationships.
        4. Enclose code or schema in (triple backticks)``` code ```
        </Important>
        </Task>

        Files from Database schema goes here :
        <Database Structure>
        {formatted_data}
        </Database Structure>
    """

    start_index = executive_summary.find("Highlighted Features")
    end_index = executive_summary.find("Key Benefits")

    if start_index != -1 and end_index != -1:
        executive_summary = executive_summary[start_index:end_index].strip()

    user_prompt += "Executive Summary : " + str(executive_summary)

    return system_prompt, user_prompt


#FEATURE HIERARCHY:
generate_features_system_prompt = """
  <Role>
    You are a Software Architect with expertise in analyzing large summaries from code files of an application. 
    You can comprehend summaries from code files that are complex, production-grade and are written in various programming languages to generate most important features, their description and the subfeatures with their description belonging to the most important features along with the other relevant information requested below.
    
    You will follow 2 Events before responding : 
    1. Generation of Feature Hierarchy as given in "Output_Format".
    2. Critical Evaluation of Every Confidence Score.  
  </Role> 

    <Task 1>
    You are provided with multiple relative file paths and file-wise code summaries from a application codebase.
    1. Analyze the file summaries carefully, leveraging your expertise to deduce the frameworks, functionality, and features.
    2. Perform a critical assessment of the code's functionality and interdependencies before responding.
    3. The codebase is complex and likely contains dependencies across various modules. Be mindful of these.
    4. Analyse every file summary and assign the features and sub-features based on the information provided.
    5. Respond strictly in the structured JSON format provided below.
    6. In each sub-feature's 'file_path' array:
        - Set 'critical: true' ONLY for files that are CORE & NON-REPLACEABLE to the sub-feature's main functionality.
        - Set 'critical: false' for ALL supporting, secondary, or replaceable files  
        - Each sub-feature should have both true and false entries.
        - If unsure, default to false (be EXTREMELY selective with 'true')
        - Make sure each sub-feature atleast have one file as true.

    Explanation of the Output terms:
    Feature - Features are most valuable and high level features extracted from the list of summaries that are provided to you. 
    Feature description - Description of the features explaining the high level value and impact that it creates for the project. Define the Feature. The description should be crisp, precise, well formatted and must be between 2-3 lines.
    Subfeature - Subfeatures are micro most valuable features that are extracted from the list of summaries and belong to the Most related and similar Features.
    Subfeature description - Description of the subfeatures explaining the specific value, technical and non-technical functionalites that it provided to the project. Define the subfeature and also explain how its related to the feature. The description should be crisp, precise, well formatted and must be between 2-3 lines.
    
    Points to Remember:
    1. Do not extract any feature or subfeature where there are no reference/citations from the application summaries.
    2. The description must be precise, valuable, well-formatted and must be between 2-3 lines.
    3. The Feature titles should be precise, specific, self explanaible, independent and not have similar feature titles. The Feature titles should not be highly generalized.
    4. The SubFeatures titles should be precise, self explanaible and not have similar subfeature titles. The SubFeature titles should not be highly generalized.
    5. SubFeatures should not be very low level that it explains code functions, code process like 'Json handling', 'Reading csv', readME etc.
    6. If similar subfeatures are present, then group them under one common Feature itself. Do not create multuple Features for similar subfeatures.
    6. If Unit testing related summaries are found, then create that as another Feature named 'Unit Testing' and assign the specific testing subfeatures under this feature.
    </Task 1>

  <Task 2>
  You shall now Assign and Justify Confidence Scores for each feature.

  <Critical Evaluation of Confidence Scores> 

  <Evaluation MODE>
  - You will now Forget everything that was done beforehand and act as an unbiased judge.
  - $Project-Summaries-&-Paths (INPUT).
  </Evaluation MODE>
  <Important>
  Critically analyze every "Feature" and "SubFeature" based on the following metrics. 
  You shall generate a confidence score between 0-100 for each of the following :
  1. Is the "Feature" & "SubFeature" name accurate to its functionality ? (Accuracy)
  2. Does the "Feature" & "SubFeature" include files with an unrelated function ? (Feature Dilution Rate)
  3. Important : Does this "Feature" & "SubFeature" make sense given the Overall Purpose of the Application ? (Consistency)
  4. Are all the files in "Feature" & "SubFeature" included ? (Completeness)

  <Strict>
  1. You will now generate a list of 4 confidence scores between 0-100 for above criteria under "confidence_score" key.
  2. Based on above criteria, you shall provide a VERY BRIEF logical explanation (10-20 words) for Confidence Score under "confidence_score_justification" key.
  3. Make sure to mention the entire filepath without omitting the prefix.
  4. Make sure all the filepaths are present.
  <Important> STRICTLY Don't Comment on Missing Files. Don't Overestimate. Don't Underestimate.</Important> 
  </Strict>

  </Important>

  </Critical Evaluation of Confidence Scores> 
  </Step 2>


      <Output_Format>
    Return a response in JSON format. Do not include any extra information or explanations. Strictly DON'T deviate from mentioned KEYS.
    Example:
```json
[
  {
    "name": "User Authentication and Management",
    "feature_description": "Comprehensive user account system with secure login, registration, profile management, and role-based access control.",
    "feature_description_confidence_score": [95, 70, 100, 70],
    "sub_features": [
      {
        "name": "User Registration",
        "description": "Allows new users to create accounts by providing necessary information such as username, email, and password. Implements email verification, password strength checks, and duplicate account prevention. Stores user data securely in the database with password hashing.",
        "file_path": [
          {
            "module_name": "RegistrationController",
            "path": "Controllers/Account/RegistrationController.cs",
            "critical": true
          },
          {
            "module_name": "RegisterView",
            "path": "Views/Account/Register.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [75, 80, 85, 65],
        "sub_feature_confidence_score_justification": "No feature dilution, might have missed some file."
      },
      {
        "name": "User Login",
        "description": "Authenticates users using their credentials, creates and manages user sessions, and implements security measures such as login attempt limiting and two-factor authentication (2FA). Provides password reset functionality for forgotten passwords.",
        "file_path": [
          {
            "module_name": "LoginController",
            "path": "Controllers/Account/LoginController.cs",
            "critical": true
          },
          {
            "module_name": "LoginView",
            "path": "Views/Account/Login.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [80, 100, 80, 75],
        "sub_feature_confidence_score_justification": "High chance of missing files."
      }
    ],
    "feature_confidence_score_justification": "No feature dilution, duplication or missing files. Accurate Naming."
  },
  {
    "name": "Product Catalog Management",
    "feature_description": "Comprehensive system for managing product listings, categories, and inventory across the e-commerce platform.",
    "feature_description_confidence_score": [95, 65, 70, 80],
    "sub_features": [
      {
        "name": "Product CRUD Operations",
        "description": "Enables administrators to create, read, update, and delete product listings. Includes functionality for managing product details such as name, description, price, images, and inventory levels. Implements validation to ensure data integrity and consistency across the product catalog.",
        "file_path": [
          {
            "module_name": "ProductController",
            "path": "Controllers/ProductController.cs",
            "critical": true
          },
          {
            "module_name": "ProductView",
            "path": "Views/Product/Index.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [90, 85, 100, 70],
        "sub_feature_confidence_score_justification": "High confidence with no duplication or dilution."
      },
      {
        "name": "Category Management",
        "description": "Allows for the creation and management of product categories and subcategories. Implements a hierarchical structure for organizing products, enabling efficient navigation and filtering of the product catalog for both administrators and customers.",
        "file_path": [
          {
            "module_name": "CategoryController",
            "path": "Controllers/CategoryController.cs",
            "critical": true
          },
          {
            "module_name": "CategoryView",
            "path": "Views/Category/Index.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [85, 75, 90, 95],
        "sub_feature_confidence_score_justification": "High confidence without any duplication or dilution."
      }
    ],
    "feature_confidence_score_justification": "All files refer to single overall functionality. Might have missed some files."
  }
]
```
  </Output_Format>

"""

generate_features_user_message = """
<Strictly Remember>
1. As input you will be given a batch of `file_path` and `file_summary` from a production codebase. Keep it in mind that it could be a file from a very large repository with lot of inter-dependencies.
2. Understand all the file description first, then try to determine the feature, sub-features and their description. For **each file** it should have a feature or sub-features whenever the conditions are met.
3. The response should contain all the fields given in the example output format. The response should be strictly in json format.
4. The description of features/subfeatures must be in the length of 2-3 lines. The response should be structured and well-formatted.
5. Don't generate any additional explanation or description. Provide the structured response in json only.
</Strictly Remember>
  
<Input file wise summary>
{file_summary}
</Input file wise summary>
<Response>
"""

merge_features_in_hierarchy_user_prompt = """You are a software feature analyzer. Given a list of related features that have been clustered together, create a merged feature that encompasses all the functionality.

Features to merge:
{feature_list}

Generate a JSON response that includes:
1. A name for the merged feature representing accurate feature name. Do not mention its merged or unified or anything as such. The feature name should accurately represent a major funcationality of a repository.
2. A detailed description that covers all functionality
3. A confidence score (0-100) for the merge
4. A justification for the confidence score

Respond with a JSON object in the following format:
```json
{{
    "name": "Merged feature name",
    "description": "Comprehensive description",
    "confidence_score": 85,
    "confidence_justification": "Reason for the confidence score"
}}
```
Give only JSON and nothing else. Do not include any explanations or additional text outside the JSON block. Make sure to start with ```json and end with ``` only.
"""

mapping_names_for_merged_features_user_prompt = """  <Role>
    You are a smart AI cassistant with strong expertise in Software Engineering. You can understand complex, production-grade codebases written in various programming languages and summarize them effectively.
  </Role>
  <Task>
  You will be given a brief description of  features of a large codebase and your task is to generate a relevant feature name, brief description, and priority level.
  <Important>
   1. The feature name should be brief, relevant and should represent the entire description provided.
   2. Generate a relevant description which is basically a overall summary of the description provided.
   3. Assign a priority level (high, medium, low) based on the significance, importance and complexity of the feature to the overall system. 
  </important>
  </Task>
  <Example output>
  ```json
    {
        "name": <feature_name>, //string
        "feature_description": <feature_description>, //string
        "priority": <priority> //string (high, medium, or low)
    }
    ```
  </Example output>
  <Strictly Remember>
1. The feature name should be relevant and at the same time interpretable, easy to understand.
2. The feature description should represnt the entire description given for summarisation, it should be simple and easy to understant.
3. The priority should be one of: high, medium, or low.
4. The response should be strictly in json format specified above.
5. Strictly make sure Feature Description is not more than 200 words.
  </Strictly Remember>

<code summary>
The code summary is given below:
"""


reducing_sub_features_user_prompt = """
    You are a software feature consolidation expert. Your task is to merge similar sub-features into one comprehensive sub-feature.

    Here are the sub-features that need to be merged:
    {sub_features_list}

    For each sub-feature, we have:
    - Name: The sub-feature name
    - Description: The sub-feature description (if available)
    - Confidence Score: The confidence score (if available)

    Your output should be a JSON object containing:
    1. A unified sub-feature name that encompasses all the input sub-features
    2. A comprehensive description that covers all aspects of the input sub-features
    3. A confidence score (use the highest available from input sub-features)
    4. A justification for the confidence score

    Return the output in JSON format starting with ```json and ending with ```.

    Example output format:
    ```json
    {{
        "name": "Unified Sub-Feature Name",
        "description": "Comprehensive description covering all aspects",
        "sub_feature_confidence_score": 95,
        "sub_feature_confidence_score_justification": "Merged from similar sub-features with high semantic similarity"
    }}
    ```
    """


post_processing_feature_name_description_system_prompt="""
  <Role>
    You are a smart AI assistant with strong expertise in Software Engineering. You can understand complex, production-grade codebases written in various programming languages and summarize them effectively.
  </Role>
  <Task>
  You will be given a brief description of modules or features of a large codebase and your task is to generate a relevant feature name and brief description.
  <Important>
   1. The feature name should be brief, relevant and should represent the entire description provided.
   2. Generate a relevant description which is basically a overall summary of the description provided.
   3. Also generate a confidence score in a scale of 0 - 100.
  </important>
  </Task>
  <Example output>
  ```json
    {
        "name": <feature_name>,
        "feature_description_confidence_score": <score 0 - 100>,
        "feature_description": <feature_description>
    }```
  </Example output>"""

post_processing_feature_name_description_user_prompt = """<Strictly Remember>
1. The feature name should be relevant and at the same time interpretable, easy to understant.
2. The confidence score should represent the ability to summarise the description.
3. The feature description should represnt the entire description given for summarisation, it should be simple and easy to understant.
4. The response should be strictly in json format specified above.
</Strictly Remember>
<code summary>
The code summary is given below: \n
{feature_description}
</code_summary>
<response>
Your response in json goes here:
"""

merge_similar_features_system_prompt = """You are a solution architect. Your task is to carefully review each feature and its description, and combine them into a single high-level feature.

The final high-level features should represent what an end user would perceive, e.g., Messenger, Google Chat, Messaging, Reels, etc.

Based on the generated features provided, identify which features can be merged into a single high-level feature. 
Strictly output them in the following format:
{{ 
  <High-Level Feature Name 1>: [<Merged Feature 1>, <Merged Feature 2>, <Merged Feature 3>, ...],
  <High-Level Feature Name 2>: [<Merged Feature 1>, <Merged Feature 2>, <Merged Feature 3>, ...],
  ...
}}

INPUT:
Feature names and descriptions are provided in the format: 
[1. Feature name: <feature name> 
Feature description: <feature description>, 
2. ...]

{feature_texts}

MVFS:
{total_MVFs}

Points to remember:
1. While merging features and naming high-level features, always prefer names from the user-defined MVFs provided. All relevant features can be grouped under these high-level features.
2. If certain features do not fit under the user-defined MVFs, choose a better name than the existing one for the new high-level feature if necessary.
3. The names of the features being merged must remain exactly as provided in the INPUT section; do not modify them. Do not consider Feature description in Feature Names.
4. Follow the output structure strictly: high-level feature names as dictionary keys and merged features as values in list format.
5. If a feature is already a high-level feature, you do not need to forcibly merge it. If a feature seems to be function-level/low-level  features, merge them into a High-level feature.
6. Merge similar features into a single high-level feature based on their names and descriptions, when applicable. Each final high-level feature should be independent of the others.
7. Do not assign the same feature to multiple high-level features.
8. If user-defined MVFs are empty, skip point 1 and begin with point 2.
9. Do **not** include any Feature descriptions in the final output."""


merging_description_user_prompt = """You are a Solution Architect. Your task is to summarize the multiple feature descriptions provided into a brief, coherent summary of **no more than two sentences**.

  The summary must:
  - Accurately capture all key components from the provided descriptions.
  - Align clearly with the given high-level feature name.
  - Serve as the final description of the high-level feature.

  Only the final summarized description should be included in the output â€” no additional commentary or formatting.

  INPUT:
  Multiple descriptions: {merging_feature_description}

  High-Level Feature Name: {high_level_feature}
  """


micro_sub_feature_prompt = """You are an expert system analyst specializing in decomposing SubFeatures into granular, logically independent components. You support **two levels** of splitting:

1. **Horizontal splitting**: Split a subfeature into multiple *same-level subfeatures* when it encompasses multiple independently meaningful functionalities. The subfeatures created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.
2. **Vertical splitting**: Further break each of those subfeatures into *microsubfeatures* (if applicable), ensuring each micro-sub-features/micro-user-story describes a single goal or operation. The micro-sub-features/micro-user-story created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.

---

### ðŸ”§ TASK OVERVIEW

Given a Macro-Feature, Subfeature, its description, associated module files and its summary:

- Decide if the subfeature should be split horizontally into multiple same-level subfeatures.
- For each resulting subfeature (or original if not split), analyze whether it can be split vertically into **microsubfeatures** (fine-grained user stories).
- Provide the confidence scores for the subfeature that is split, whether horizontally or vertically.
- Provide the files that are related to the sub_features too, not just the micro_sub_features.
- Each leaf user-story must have files assigned to them, else you should not create/split these subfeatures.
- Provide description of generated subfeature/sub-user-stories in 2-4 lines but only valid information. Do not assume or hallucinate to generate description.
Apply this recursively: if horizontal splitting occurs, then attempt vertical splitting for each. But remember, not to create any duplicates in the process. 

---

### SPLITTING DECISIONS

#### Horizontal Splitting (Same-level Subfeatures):
Split if:
- The subfeature covers multiple high-level functionalities
- Each function could be planned, developed, and deployed independently
- Each component has a clear boundary and responsibility

#### Vertical Splitting (Microsubfeatures):
Split further if:
- A subfeature contains multiple independent operations or logical stages
- These operations can be implemented, tested, or tracked separately
- Each micro-subfeature represents one atomic, non-overlapping functionality

---

### DO NOT SPLIT IF:
- sub-user-stories are tightly coupled in the Subfeature and cannot function independently.
- Do not split subfeatures into sub-user-stories that are hardly single line of code and cannot be considered as a proper functionality, but just a config/parameter.
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across actions are too complex to isolate.
- There are no files that can be mapped to the generated user-story.
- Do not split if the user-story is barely a functionality. The split user-stories must have independent functionality that contributes to the subfeature and feature and if not, do not split.
- Don not split ReadMe & .md files into sub-user-stories.
- Do not split horizontall for granullar subfeatures as they are not user stories but mid level features.
---

### FILE MAPPING RULES:
- For each subfeature or microsubfeature, cite only directly relevant files.
- Use only the provided input data to match files â€” no guessing.
- Avoid duplication unless a file is clearly shared between components.

Each `file_path` entry must include:
```json
{
  "module_name": "<Name>",
  "path": "<Path>",
  "critical": <true/false>,
  "git_url": "<Git URL>"
}

OUTPUT FORMAT
If the subfeature should NOT be split:
Return: "None"

If the subfeature should be split, return a list of Parent User Stories with subfeatures inside.
If a subfeature itself can be further split into microsubfeatures, nest them under micro_sub_features like so:

[
  {
    "name": "Parent User Story Title 1",
    "description": "Full description of the original or updated user story and its purpose.",
    "file_path": [...],
    "sub_feature_confidence_score":"confidence score of the subfeature with respect to the Feature, as a percentage (e.g., 80)"
    "micro_sub_features": [
      {
        "name": "Sub-User Story Title 1",
        "description": "Standalone description of a single functionality.",
        "file_path": [...],
        "micro_sub_feature_confidence_score":"confidence score of the micro_sub_feature with respect to the sub_feature, as a percentage (e.g., 90)"
        }
          ...
        ]
      },
      ...
    ]
  }
]
Each layer must preserve independence, clarity, and singular focus of each story.

VALIDATION CHECKLIST
- Each title must express one functionality only (no imperative phrasing)
- description must avoid assumptions and describe the real function. It must be as detailled as possible.
- Each story must make sense independently and fit in the broader feature flow
- if there are multiple user-story under the subfeature, it needs to be in sequence of business logic.
- File mappings must be relevant and scoped accurately
- Do no miss/skip any values in the output json. The output structure must be maintained strictly.
- All subfeature and sub-user-story names and descriptions must be strictly in a declarative tone, not imperative.

* Use generic or speculative statements
"""


db_micro_sub_feature_prompt = """
<Role>
You are an expert Database analyst specializing in decomposing SubFeatures into granular, logically independent components. You support **two levels** of splitting:
You shall ALWAYS process features from a Database perspective ONLY. 
There can be more than one Table in the DB context provided to you.
</Role>

1. **Horizontal splitting**: Split a subfeature into multiple *same-level subfeatures* when it encompasses multiple independently meaningful functionalities. The subfeatures created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.
2. **Vertical splitting**: Further break each of those subfeatures into *microsubfeatures* (if applicable), ensuring each micro-sub-features/micro-user-story describes a single goal or operation. The micro-sub-features/micro-user-story created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.

<Strict Constraints> 
- You are dealing with Database Information. 
- No matter what, STRICTLY use Database-Specific Language ALWAYS. 
- Use words like Columns / Fields / Schema / DataTypes / Constraints / Foreign Keys / Primary Keys etc.
- Strictly Do not start descriptions with or start with "this micro-feature" / or "this sub-feature".
- You shall do this regardless of the input context and nature.
Remember : Every "FILE" given to you is information of a table. Therefore in your response, ALWAYS refer to "Table" instead of "File".

</Strict Constraints> 


### ðŸ”§ TASK OVERVIEW

Given a Macro-Feature, Subfeature, its description, associated module files and its summary:

- Decide if the subfeature should be split horizontally into multiple same-level subfeatures.
- For each resulting subfeature (or original if not split), analyze whether it can be split vertically into **microsubfeatures** (fine-grained user stories).
- Provide the confidence scores for the subfeature that is split, whether horizontally or vertically.
- Provide the files that are related to the sub_features too, not just the micro_sub_features.
- Each leaf user-story must have files assigned to them, else you should not create/split these subfeatures.
- Provide description of generated subfeature/sub-user-stories in 2-4 lines but only valid information. Do not assume or hallucinate to generate description.
Apply this recursively: if horizontal splitting occurs, then attempt vertical splitting for each. But remember, not to create any duplicates in the process. 

---

### SPLITTING DECISIONS

#### Horizontal Splitting (Same-level Subfeatures):
Split if:
- The subfeature covers ONE / MORE THAN ONE high-level functionalities
- Each function could be planned and developed independently
- Each component has some clear boundaries and responsibilities

#### Vertical Splitting (Microsubfeatures):
Split further if:
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across actions are too complex to isolate.
- There are no tables that can be mapped to the generated user-story.
- The subfeature is too complex to be planned, developed, and deployed independently
- Each micro-subfeature represents one atomic, non-overlapping functionality
Note: Maintain at least 2 subfeatures unless the database has only one table.
- Prioritize brevity, consistency and no informaiton leakage across subfeatures.
- Ensure crisp segregation.
---

### DO NOT SPLIT IF:
- sub-user-stories are tightly coupled in the Subfeature and cannot function independently.
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across tables in two features are too complex to isolate.
- There are no tables that can be mapped to the generated user-story.
Note: Maintain at least 2 subfeatures and 1 or more microsubfeatures per subfeature, Unless the database has only one table.
Note : Maintain brevity during splitting at the same level. Do NOT overload the a single feature with too many subfeatures.
---


### FILE MAPPING RULES:
- For each subfeature or microsubfeature, cite only directly relevant tables.
- Use only the provided input data to match files â€” no guessing.
- Avoid duplication unless a file is clearly shared between components.

Each `file_path` entry must include:
```json
{
  "module_name": "<Name>",
  "path": "<Path>",
  "critical": <true/false>,
  "git_url": "<Git URL>"
}

OUTPUT FORMAT
If the subfeature should NOT be split:
Return: "None"

If the subfeature should be split, return a list of Parent User Stories with subfeatures inside.
If a subfeature itself can be further split into microsubfeatures, nest them under micro_sub_features like so:

[
  {
    "name": "Parent User Story Title 1",
    "description": "Full description of the original or updated user story and its purpose.",
    "file_path": [...],
    "sub_feature_confidence_score":"confidence score of the subfeature with respect to the Feature, as a percentage (e.g., 80)"
    "micro_sub_features": [
      {
        "name": "Sub-User Story Title 1",
        "description": "Standalone description of a single functionality.",
        "file_path": [...],
        "micro_sub_feature_confidence_score":"confidence score of the micro_sub_feature with respect to the sub_feature, as a percentage (e.g., 90)"
        }
          ...
        ]
      },
      ...
    ]
  }
]
Each layer must preserve independence, clarity, and singular focus of each story.

VALIDATION CHECKLIST
- Each title must express one functionality only (no imperative phrasing)
- description must avoid assumptions and describe the real function. It must be as detailled as possible.
- Each story must make sense independently and fit in the broader feature flow
- if there are multiple user-story under the subfeature, it needs to be in sequence of business logic.
- File mappings must be relevant and scoped accurately
- Do no miss/skip any values in the output json. The output structure must be maintained strictly.
- All subfeature and sub-user-story names and descriptions must be strictly in a declarative tone, not imperative.
- Use Database-specific schema only. Do not include words like "Attributes" / "Code Files" in your response. 
- Strictly Do not start descriptions with or start with "this micro-feature" / or "this sub-feature".
* Use generic or speculative statements

"""import os
from graphviz import Digraph
import re 
import json

def parse_ddl(ddl: str):
    """
    Parse the DDL to extract columns, primary keys, and foreign keys.
    """
    lines = ddl.splitlines()
    column_lines = []

    for line in lines:
        line = line.strip()
        if (
            line.upper().startswith("CREATE")
            or line.upper().startswith("PRIMARY")
            or line.upper().startswith("FOREIGN")
            or line.upper().startswith(")")
            or line == ""
        ):
            continue

        match = re.match(r'(\w+)\s+\w+', line)
        if match:
            column_lines.append(match.group(1))

    pk_match = re.search(r'PRIMARY KEY\s*\((.*?)\)', ddl)
    primary_keys = [key.strip() for key in pk_match.group(1).split(",")] if pk_match else []

    foreign_keys = []
    for match in re.finditer(r'FOREIGN KEY\s*\(([^)]+)\)\s+REFERENCES\s+`?[\w]+\.(\w+)`\(([^)]+)\)', ddl):
        fk_col = match.group(1).strip()
        ref_table = match.group(2).strip()
        ref_col = match.group(3).strip()
        foreign_keys.append((fk_col, ref_table, ref_col))

    return column_lines, primary_keys, foreign_keys


def generate_combined_graph(tables_data):
    """
    Generate a single combined graph from multiple tables.
    """
    dot = Digraph(comment='Combined Table Diagram')
    dot.attr(rankdir='LR')

    # Store individual table nodes
    for table in tables_data:
        table_name = table['table_name']
        columns = table['columns']
        primary_keys = table['primary_keys']
        
        label_lines = []
        for col in columns:
            if col in primary_keys:
                label_lines.append(f"{col} [PK]")
            else:
                label_lines.append(col)
        dot.node(table_name, shape='box', label=f'{table_name}\\n' + "\\n".join(label_lines))

    # Add relationships
    for table in tables_data:
        table_name = table['table_name']
        for fk_col, ref_table, ref_col in table['foreign_keys']:
            dot.edge(table_name, ref_table, label=f'{fk_col} â†’ {ref_col}')

    return dot

def folder_summary_generation_prompts(
        total_allocated_tokens, 
        file_list, folder_name, 
        folder_path,
        subfolder_list,
        formatted_file_summaries,
        formatted_file_services,
        formatted_subfolder_summaries,
        formatted_subfolder_services,
        formatted_subfolder_features
    ):
    
    system_prompt = f"""
        You are an expert code analyst specialized in creating detailed, informative summaries of software project folders. Your task is to thoroughly analyze files and subfolders to provide a comprehensive understanding of the application or project and provide combined summaries along with required details. These summaries must be detailled enough for further summarization.

        Follow these guidelines:
        1. Conduct a deep analysis of the features to identify its core purpose and functionality
        2. Provide detailed explanation of key implementations and technical approaches of the features
        3. Thoroughly examine the summaries based on files and folders to understand relationship between features and combined smaller features into larger high level application level features.
        4. Explain the features within the broader project architecture with specific connections
        5. Describe technical patterns, design decisions, and architectural choices evident in the code
        6. Include specific functions, classes, and methods that define the feature's behavior
        7. Note dependencies, imports, and external connections that shape the folder's functionality
        8. Identify potential architectural strengths and areas for improvement when evident
        9. Identify all services represented in this folder based on file and subfolder services information
        10. Identify and articulate high-level features or functionalities represented by the folder into the feature_details section, when consolidating multiple subfolders or lower-level files. Derive these insights from both file-level and subfolder-level summaries. Also under each feature, mention which file/folder was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
        11. Do not miss any features that could be formed based on these summaries as this information is required to understand the application's buisness logic.
        12. Gather insights from the summaries provided to generate a high level detailled executive summary that could be used by business stakeholders to understand the folder/project.
        13. When analyzing the root folder, both the executive summary and the features must be strictly formed in a high level business logic standpoint of an application.
        
        IMPORTANT: 
        - Your summary should be thorough and detailed({total_allocated_tokens}) while maintaining technical/business precision and depth. Focus on providing insights that would help both stakeholders and developers understand the application better.
        - feature_details must contain high level feature name and feature description(value of the files/folders) strictly in concise bullet points. The feature inforamtion must be in detail to capture the complete high level knowledge for that feature but not the function level details. Feature names cannot be programmatic function names like Dependency management, json handling etc. instead it should be inventory management, order processing etc. 
        - Your services list should be comprehensive and include all services represented in this folder.
        - is_reuasble_lib if a folder is used as reusable lib make it True otherwise False
        - lib_name if is_reusable_lib is True then provide the name of the reusable lib/component If is_reusable_lib False then add Not Applicable
        - category if is_reusable_lib is True then provide category only between 'Frontend' and 'Backend' If is_reusable_lib False then add Not Applicable
        - sub_category if is_reusable_lib is True then provide sub category only between 'UI Component','Custom Hooks', 'http_client', 'Utils', 'Others' In Frontend & 'Middleware', 'Error Handling', 'Auth', 'Utils', 'Others' In Backend If is_reusable_lib False then add Not Applicable
        - when_to_use if is_reusable_lib is True then provide where this reusable lib/component can be used If is_reusable_lib False then add Not Applicable 
        - associated_files if is_reusable_lib is True then provide the list of files associated(give complete path for the assosciated file) with this reusable lib/component If is_reusable_lib False then add Not Applicable
        - summary must not be technical and only explain the high level details of the folder/project. Understand the file and folder summaries provided to combine the knowledge to form the executive summary. Make it as detailled as possible.
        - Use clear and concise language, avoiding jargon where possible.
        
        - You must provide your response in this exact format:
        ```summary
        [Your detailled high-level executive summary for the folder for business stakeholders]
        ```
        ```feature_details
        [List of high-level features or functionalities represented in this folder]
        ```
        ```services_namess
        [Comma-separated list of all services represented in this folder]
        ```
        ```is_reuasble_lib
        Boolean Value
        ```
        ```lib_name
        [Name of the reusable library if applicable]
        ```
        ```category
        [Category of the reusable library if applicable]
        ```
        ```sub_category
            [Sub category of the reusable library if applicable]
        ```
        ```when_to_use
        [Your detailed use case where or when this reuasble_lib can be usefull]
        ```
        ```associated_files
            [Comma-separated list of associated files with the reusable library, Give the Complete file path as mentioned in the file list]
        ```
        ```example_usage
            [Example code snippet of how to use this reusable library]
        ```
    """

    user_prompt = f"""
        Generate a summary and services list for the folder: "{folder_name}" (Path: {folder_path})

        FOLDER CONTENTS:
        - Files ({len(file_list)}): {", ".join(file_list) if file_list else "None"}
        - Subfolders ({len(subfolder_list)}): {", ".join(subfolder_list) if subfolder_list else "None"}

        FILE SUMMARIES:
        {os.linesep.join(formatted_file_summaries) if formatted_file_summaries else "No file summaries available"}

        FILE SERVICES:
        {os.linesep.join(formatted_file_services) if formatted_file_services else "No file services available"}

        SUBFOLDER SUMMARIES:
        {os.linesep.join(formatted_subfolder_summaries) if formatted_subfolder_summaries else "No subfolder summaries available"}

        SUBFOLDER SERVICES:
        {os.linesep.join(formatted_subfolder_services) if formatted_subfolder_services else "No subfolder services available"}

        SUBFOLDER FEATURES:
        {os.linesep.join(formatted_subfolder_features) if formatted_subfolder_features else "No subfolder features available"}
        
        Based on these components:
        1. Provide a thorough technical summary explaining the folder's purpose, implementation details, and architectural significance
        2. Compile a comprehensive list of all services represented in this folder based on file and subfolder services information
        
        Follow the exact format specified in the system instructions for your response.
    """

    return system_prompt, user_prompt

def services_generation():
    system_prompt = """
        <Task>
        Create an architectural blueprint of the given repository by identifying and classifying both external services and third-party services with no overlap between categories.
        </Task>

        <Definitions>
        - External services: Company-provided services hosted outside the application (AWS S3, Google Cloud, Stripe, Twilio)
        - Third-party services: Libraries, frameworks, and SDKs that are part of the core application stack (Django, React, MongoDB, Redux)
        </Definitions>

        <Output_Format>
        {
        "external_services": [
            {
            "external_service_name": "string",
            "description": "string",
            "associated_files": ["string"],
            "service_class": "string",
            "used_in_files": ["string"]
            }
        ],
        "thirdparty_services": [
            {
            "thirdparty_service_name": "string",
            "description": "string",
            "associated_files": ["string"],
            "service_class": "string",
            "used_in_files": ["string"]
            }
        ]
        }
        </Output_Format>

        <Instructions>
        1. Conduct a thorough repository analysis to identify all services
        2. Classify each service into exactly ONE category:
        - External services: Cloud platforms, payment processors, authentication providers
        - Third-party services: Frameworks, libraries, SDKs integrated into the codebase
        3. For each service, provide:
        - Name: Exact service name
        - Description: Concise explanation of functionality and purpose
        - Associated files: All files directly importing or using the service
        - Service class: Category (e.g., "cloud storage", "web framework", "database")
        - Used in files: Complete paths of files utilizing the service
        4. Ensure ZERO overlap between categories
        5. Prioritize accuracy over comprehensiveness
        6. Validate that identified services are actively used in the project
        7. Include only services with clear evidence of implementation
        8. Do not create a lot of services which are redundant. Keep it to a maximum of 50 services only.
        </Instructions>

        <Examples>
        Good External Service Entry:
        {
        "external_service_name": "AWS S3",
        "description": "Cloud storage service used for storing user-uploaded files",
        "associated_files": ["src/services/storage.js", "src/config/aws.js"],
        "service_class": "cloud storage",
        "used_in_files": ["src/components/FileUpload.js", "src/pages/UserProfile.js"]
        }

        Good Third-Party Service Entry:
        {
        "thirdparty_service_name": "React",
        "description": "Frontend JavaScript library for building user interfaces",
        "associated_files": ["package.json", "src/index.js"],
        "service_class": "frontend framework",
        "used_in_files": ["src/App.js", "src/components/*.js"]
        }
        </Examples>

        Analyze the repository and provide the complete architectural blueprint in the specified format.
    """

    user_prompt = ""

    return system_prompt, user_prompt

def executive_summary_generation(combined_summary, user_mvf):
    system_prompt = """
    Your Role:
    You are an expert software architect tasked with understanding a codebase and creating an executive summary that clearly articulates the main purpose of this application,
    the core problem that the application is solving, and the prioritized list of the most valuable features, solely based on the provided folder wise summary. Do not hallucinate and create the most valuable features and its description on assumption. This needs to be based on facts.

    Task:
    1. Analyze provided folder wise summary and the services used and the user defined features (if provided).
    2. Understand component interactions and functions.
    3. Prioritize the User Defined Features (if provided) in the summary.
    4. Identify and prioritize the most valuable features based on their importance and relevance to the overall project, as evidenced in the code.
    5. Create a comprehensive executive summary.

    Steps:
    1. Review folder wise summary.
    2. Analyze folder wise summary:
    - Identify key components and their roles
    - Note data operations, design patterns, and architectural decisions
    3. Create summary:
    - Describe the specific problem the codebase solves, based on folder wise summary
    - Explain component interactions
    - Outline data workflow
    4. Identify and prioritize main features:
    - Determine which feature(s) address the core problem of the application, based on code implementation
    - Rank features based on their importance and relevance to solving the main problem, as evidenced in the code
    - The feature should be major components of the codebase and not minor functions like "Modular Architecture" or "Code Reusability", these are not features but design principles.

    Focus Areas:
    - Precised feature prioritization and importance
    - High-level functionality
    - Clear, concise technical language
    - Objective description
    - Capture entire workflow

    Guidelines:
    - Only use the folder wise summary provided
    - Use precise technical terms
    - Include user-defined features if provided and evidenced in the code
    - Prioritize features based on their importance to the core problem, as shown in the folder wise summary

    Feature Identification and Prioritization:
    - Carefully analyze the folder wise summary to identify features actually present in the folder wise summary
    - Do not assume or infer features that are not explicitly mentioned in the folder wise summary
    - Identify the top feature that solves the majority of the problem based on code evidence
    - Rank subsequent features in descending order of importance, ensuring they are present in the folder wise summary
    - Ensure the feature list reflects the codebase's focus and structure
    - Only include features that have substantial implementation in the codebase that is evident from folder wise summary

    Output Format - Adhering to this format is crucial
    ```json
    {
    "data": "generated_summary in string format adhering to the Expected Output Format for Generated Summary",
    "confidence_score": 90,
    "traceback": {
    "Feature 1 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 1 Title' is included, as the 'phrase' is an evidence that this feature is part of the codebase.",
    "Feature 2 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 2 Title' is included, as the 'phrase' is an evidence that this feature is part of the codebase.",
    ...
    }
    }
    ```

    Requirements:
    - Replace \n with \\n in JSON
    - Limit upto 5 main features (max 2 sub-features each) or 7500 tokens
    - If due to any reason such as codebase being small, you are unable to provide 5 features, then provide as many high-level features as possible between the range of 1 to 5.
    - Don't assume features or include minor features due to inability to provide 5 features, lesser number of features is acceptable.
    - Use specified JSON format only
    - Start with "```json" and end with "```"
    - Ensure the top feature in the prioritized list addresses the core problem and is present in the folder wise summary
    - Rank features in descending order of importance to the main problem, based on actual code implementation
    - Do NOT include features that are NOT evidenced in the provided folder wise summary
    - Evaluate the folder wise summary objectively, considering all conclusions on the actual code provided
    - Do NOT make any assumptions about organizational goals or intentions beyond what is explicitly shown in the code
    - Focus solely on the technical aspects and implemented functionality, avoiding speculation about business objectives or future plans
    - Both the keys data, confidence score, and traceback should be present in the output JSON
    - The generated summary should be in string format only and be contained inside the "data" key
    - The "traceback" key should contain a dictionary with feature names as keys and justifications for including these features based on exact phrases from the input
    - Do not include any feature that could potentially be part of the folder wise summary without explicit evidence
    - Every feature mentioned must be driven by clear evidence from the provided input
    """
    user_prompt = """
    Expected Output Format for Generated Summary:

  **Overview**
  <empty line>
  <A brief introduction to the codebase and its main purpose; in paragraph format only, not in points.
  This paragraph should provide a concise yet comprehensive overview of the codebase, its primary functionality, solution provided by the project and its intended use case.
  Aim for 3-5 sentences that capture the essence of the project.>
  <empty line>
  **Highlighted Features**
  <empty line>
  <
  List and briefly explain the key features that are significant components of the codebase and would serve as selling points.
  These features should be presented as follows:
  1. Use numbered points for each feature.
  2. Provide a brief explanation for each feature in 1-2 sentences, highlighting its importance and benefit to the end user.
  3. Focus on features that are central to the codebase's functionality and most important to the end user.
  4. Dont include generic features like "Modular Architecture" or "Code Reusability", these are not features but design principles.
  5. Do not include sub-points under any feature.
  6. Prioritize User Defined Features (if provided) at the beginning of the list.
  7. If User Defined Features are given, list them first before including any features identified through your analysis.
  8. Aim to provide upto of 1 to 5 key features, after each feature add an empty line for formatting purposes.
  9. Ensure that the features listed represent the core functionality and unique selling points based on the folder wise summary.
  10. Use clear, concise language that emphasizes the value proposition of each feature.
  11. Also under each feature, mention which file/folder was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
  12. Do not add features into Highlighted Features if they dont have value for buisness stakeholder about the application. Also do not repeat adding similar feature in this section.

  Output Structure:
  1. ***<Feature 1 Title>***: <Description of the feature in one to two sentences.\n
  2. ***<Feature 2 Title>***: <Description of the feature in one to two sentences.>\n
  >
  <empty line>
  **Key Benefits**
  <empty line>
  <Summarize the key benefits of the codebase in one to two sentences.
  This summary should encapsulate the overall value proposition of the codebase and its potential impact on users or the organization.>
  <empty line>
  <Highlight the most significant key benefits the codebase has to offer in bulleted points. The format should be:
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  Aim for 3-5 bullet points that capture the most compelling advantages of using this codebase, after each point add an empty line for formatting purposes.
  Each benefit should be distinct and provide a clear value proposition.>

  <Final Output Format>
  Output Format - Adhering to this format is crucial, the output should be in parsable JSON format:
  ```json
  {{
    "data": "<generated_summary in string format adhering to the Expected Output Format for Generated Summary>",
    "confidence_score": 90,
    "traceback": {{
      "Feature 1 Title": "Since it mentions about <exact phrase from the folder wise summary>, the 'Feature 1 Title' is included, as the "phrase" is an evidence that this feature is part of the folder wise summary.",
      "Feature 2 Title": "Since it mentions about <exact phrase from the folder wise summary>, the 'Feature 2 Title' is included, as the "phrase" is an evidence that this feature is part of the folder wise summary.",
      ...
    }}
  }}
  ```
  </Final Output Format>
  Note: If the traceback includes phrases that are not present in the folder wise summary then you would be penalized 10000 points.
  The output should be having data, confidence score, and traceback keys, and the entire content inside "```json" and "```" should be parsable by json.
  The "data" key should contain the generated summary and it should be in string format only, allowing the parsing of the entire json.
  If there are any inverted commas inside the generated summary, then escape them with a backslash.
  Do not change or skip the headings of each section in the generated json. The generated summary must have "Overview", "Highlighted Features", "Key Benefits" as section titles. Follow the above provided guidelines."""
    user_prompt += f"""Use the below folder wise summary to generate the summary in the above format: {combined_summary}""" + "User Defined Features : " + str(user_mvf)
    return system_prompt, user_prompt

def db_executive_summary_generation(combined_summary, user_mvf): 
    system_prompt = """
    Role:
    You are an expert Database Architect tasked with understanding the contents of all tables and schema of the database. 
    You shall Articulate a proper executive summary that clearly captures all the main & high-level features of this database.
    The core use-case that this database is intended for, and the prioritized list of the most valuable features, solely based on the provided Table-Level summaries. 
    Do not hallucinate. Do NOT create the most valuable features and its description on pure assumptions. This needs to be based on facts, with proper backing.

    Task:
    1. Analyze provided Table wise summaries.
    2. Understand component interactions and functions.
    3. Prioritize the User Defined Features (if provided) in the summary.
    4. Identify and prioritize the most valuable features based on their importance to the core use-case the Database is solving.
    5. Create a comprehensive executive summary.

    Steps:
    1. Review Table wise summary.
    2. Analyze Table wise summary:
      - Identify all tables. 
      - Take into consideration the foreign keys, primary keys, is-a, has-a, and many-to-many relationships.
      - Deeply understand the intended-use-case of each table.
      - Note data operations, design patterns, and architectural decisions
    3. Create summary:
      - Describe the specific problem the Database is solving, based on Table wise summary
      - Explain high-level interactions and dependencies
      - Outline data workflow
    4. Identify and prioritize main features:
      - Determine which feature(s) address the core problem of the Database, based on SQL implementation and Table wise summary
      - Rank features based on their importance and relevance to solving the main problem, as evidenced in the Database
      - The feature should be major components of the Database and not minor functions like Many-to-Many Relationships, or "Foreign Keys". 
        These are implementation concepts. Not core features.

    Focus Areas:
    - Precised feature prioritization and importance
    - High-level functionality of this Database
    - Clear, concise technical language with Database-specific Language
    - Objective description
    - Capture entire data workflow

    Guidelines:
    - Only use the Table wise summary provided
    - Use precise Database-relevant technical terms
    - Include user-defined features if provided and evidenced in the Table wise summary
    - Prioritize features based on their importance to the core problem, as shown in the Table wise summary

    Feature Identification and Prioritization:
    - Carefully analyze the Table wise summary to identify features actually present in the Table wise summary
    - Do not assume or infer features that are not explicitly mentioned in the Table wise summary
    - Identify the top feature that solves the majority of the problem based on Database and SQL evidence
    - Rank subsequent features in descending order of importance, ensuring they are present in the Table wise summary
    - Ensure the feature list reflects the Database's focus and structure
    - Only include features that have substantial implementation in the Database that is evident from Table wise summary

    Output Format - Adhering to this format is crucial
    ```json
    {
    "data": "generated_summary in string format adhering to the Expected Output Format for Generated Summary",
    "confidence_score": 90,
    "traceback": {
    "Feature 1 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 1 Title' is included, as the 'phrase' is an evidence that this feature is part of the Database.",
    "Feature 2 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 2 Title' is included, as the 'phrase' is an evidence that this feature is part of the Database.",
    ...
    }
    }
    ```

    Requirements:
    - Replace \n with \\n in JSON
    - Limit upto 5 main features (max 2 sub-features each) or 7500 tokens
    - If due to any reason such as Database being small, you are unable to provide 5 features, then provide as many high-level features as possible between the range of 1 to 5.
    - Don't assume features or include minor features due to inability to provide 5 features, lesser number of features is acceptable.
    - Use specified JSON format only
    - Start with "```json" and end with "```"
    - Ensure the top feature in the prioritized list addresses the core problem and is present in the Table wise summary
    - Rank features in descending order of importance to the main problem, based on actual Database and SQL implementation
    - Do NOT include features that are NOT evidenced in the provided Table wise summary
    - Evaluate the Table wise summary objectively, considering all conclusions on the actual Database and SQL provided
    - Do NOT make any assumptions about organizational goals or intentions beyond what is explicitly shown in the Database and SQL
    - Focus solely on the technical aspects and implemented functionality, avoiding speculation about business objectives or future plans
    - Both the keys data, confidence score, and traceback should be present in the output JSON
    - The generated summary should be in string format only and be contained inside the "data" key
    - The "traceback" key should contain a dictionary with feature names as keys and justifications for including these features based on exact phrases from the input
    - Do not include any feature that could potentially be part of the Table wise summary without explicit evidence
    - Every feature mentioned must be driven by clear evidence from the provided input.
    - Strictly use an assertive and objective tone in your response. 
    - Do not be unsure about anything.
    - Do not include the "Folder Name" in your response. Ignore "dbanalysis" folder. Provide Executive Summary of the Database-ONLY.
    """

    user_prompt = """
  Expected Output Format for Generated Summary:

  **Overview**
  <empty line>
  <A brief introduction to the Database and its main purpose; in paragraph format only, not in points.
  This paragraph should provide a concise yet comprehensive overview of the Database, its primary functionality, and its intended use case.
  Aim for 3-5 sentences that capture the essence of the Database.>
  <empty line>
  **Highlighted Features**
  <empty line>
  <
  List and briefly explain the key features that are significant components of the Database and would serve as selling points.
  These features should be presented as follows:
  1. Use numbered points for each feature.
  2. Provide a brief explanation for each feature in 1-2 sentences, highlighting its importance and benefit to the END USER.
  3. Focus on features that are central to the Database's functionality and most important to the END USER.
  4. Dont include generic features like  Many-to-Many Relationships, or "Foreign Keys", these are not features but Design Principles.
  5. Do not include sub-points under any feature.
  6. Prioritize User Defined Features (if provided) at the beginning of the list.
  7. If User Defined Features are given, list them first before including any features identified through your analysis.
  8. Aim to provide upto of 1 to 5 key features, after each feature add an empty line for formatting purposes.
  9. Ensure that the features listed represent the core functionality and unique selling points based on the Table wise summary.
  10. Use clear, concise language that emphasizes the value proposition of each feature.
  11. Also under each feature, mention which file/Table was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
  12. Do not add features into Highlighted Features if they dont have value for buisness stakeholder about the application. Also do not repeat adding similar feature in this section.

  Output Structure:
  1. ***<Feature 1 Title>***: <Description of the feature in one to two sentences.\n
  2. ***<Feature 2 Title>***: <Description of the feature in one to two sentences.>\n
  >
  <empty line>
  **Key Benefits**
  <empty line>
  <Summarize the key benefits of the Database in one to two sentences.
  This summary should encapsulate the overall value proposition of the Database and its potential impact on users or the organization.>
  <empty line>
  <Highlight the most significant key benefits the Database has to offer in bulleted points. The format should be:
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  Aim for 3-5 bullet points that capture the most compelling advantages of using this Database, after each point add an empty line for formatting purposes.
  Each benefit should be distinct and provide a clear value proposition.>

  <Final Output Format>
  Output Format - Adhering to this format is crucial, the output should be in parsable JSON format:
  ```json
  {{
    "data": "<generated_summary in string format adhering to the Expected Output Format for Generated Summary>",
    "confidence_score": 90,
    "traceback": {{
      "Feature 1 Title": "Since it mentions about <exact phrase from the Table wise summary>, the 'Feature 1 Title' is included, as the "phrase" is an evidence that this feature is part of the Table wise summary.",
      "Feature 2 Title": "Since it mentions about <exact phrase from the Table wise summary>, the 'Feature 2 Title' is included, as the "phrase" is an evidence that this feature is part of the Table wise summary.",
      ...
    }}
  }}
  ```
  </Final Output Format>
  Note: If the traceback includes phrases that are not present in the Table wise summary then you would be penalized 10000 points.
  The output should be having data, confidence score, and traceback keys, and the entire content inside "```json" and "```" should be parsable by json.
  The "data" key should contain the generated summary and it should be in string format only, allowing the parsing of the entire json.
  If there are any inverted commas inside the generated summary, then escape them with a backslash.
  Do not change or skip the headings of each section in the generated json. The generated summary must have "Overview", "Highlighted Features", "Key Benefits" as section titles. Follow the above provided guidelines.
    """

    user_prompt += f"""Use the below Table wise summary to generate the summary in the above format: {combined_summary}""" + "User Defined Features : " + str(user_mvf)

    return system_prompt, user_prompt


def architecture_diagram_generation(services_data, icons_metadata):
    user_prompt = f"""
    <Input>
    $services_data = {services_data}
    $icons_metadata
    </Input>

    <Role>
    You are an expert at understanding large projects based on their executive summary and the services being used in them. Create a JSON structure for a ReactFlow diagram based on the given service class JSON.
    </Role>

    <Output Structure>
    1. Create a JSON object with a "nodes" and "edges" array.
    2. Create nodes for each external and third-party service.
    3. "nodes": An array containing all node objects.
      - "id": A unique string identifier for the node.
      - "data":   
        - "label": The name of the node.
        - "description": Description of the service.
        - "associated_files": Associated file and used in files in the service node, defaulting to "No File Available" if not present.
        - "group": The logical group name (e.g., 'Backend', 'Frontend', 'Database',etc..).
        - "subgroup": The specific subgroup within the group (e.g., Frameworks, NoSQL Databases, State Management, etc.).
        - "service": The appropriate filename of the icon based on the $icons_metadata.
      - "position" : The x and y coordinates of the node.
      - "type" : "customNode" This should be fixed.
    4. "edges" : An array having id, source, target, label, and type should be customEdge always.
    4. Ensure all services and files from the input JSON are included.
    5. The output should be in the form of a dictionary containing a "nodes" and "edges" array.
    6. Present only the code inside delimiters "```reactflow [reactflow CODE]```" without any additional explanation.
    """

    system_prompt:str = """
    <Task>
      You are tasked with creating a JSON structure for a ReactFlow diagram based on the given executive summary and the service_class_json. The executive summary contains an overview of the entire project. This JSON includes information about external services and third-party services, along with their associated files. Your output should represent this information as a network of nodes and edges.
    </Task>
    
    <Icons Context>
      $icons_metadata = """ + str(icons_metadata) + """
    </Icons Context>

    <Instructions>
      You are a solution expert, specializing in problem and solution flows. You will be given the solution overview for a project, and your task is to create an interconnected single component of graph which is detailed, and intuitive and self explanatory for:

      Follow these guidelines:
      1. Create nodes for each unique service (both external and third-party).
      2. Do not create any group nodes.
      4. In the data key for each service node, include two additional fields called group and subgroup. The group field should contain the logical group name (e.g., Frontend, Backend, Databases, etc..), and the subgroup field should provide more specific categorization (e.g., Frameworks, NoSQL Databases, etc..). For example, for a service node representing React, the group would be Frontend and the subgroup would be Frameworks.
      5. For each node, check which icon will be the most suitable from the $icons_metadata in the <Icons Context>
      6. Ensure all information from the input is represented in the output.
      7. The position coordinates must be proper for all the nodes.
    </Instructions>

    <Rules>
      **Ensure all nodes in the generated graph are interconnected such that every node has at least one edge, forming a single connected component without any isolated or disjoint sections. (High Priority Requirement)**
      Important Rules to be followed:
      1. Give detailed technical architecture flow and the JSON object following the below output format.
      2. Make sure that the flow and order of new solution approach is explained well in the graph with appropriate edges. Use as many edges you want to describe the data and user flow properly.
      3. The whole user and data flow should be clear.
      4. Do not add unnecessary nodes and edges. Do not create duplicate nodes that perform same task.
      5. Make the Node descriptions detailed, breaking tasks into multiple sub-tasks if needed.
      6. Ensure your edges show the actual flow, and not just connections of what's related. The connections are meant to show the logical flow, and not the relatedness/similarity.
      7. The group name is meant to classify clusters of nodes within each graph. For instance, if we have multiple nodes in features, they would all have "feature" as group. In Architecture Flow, the "Group" should show the layer each node is in, for instance "Backend Layer", "Database Layer" etc.
      9. for a hierarchy of nodes A -> B -> C; ensure that there is not a connection between A -> C.
    </Rules>
    
    <output_format>
    The output should be in between the delimeters ```reactflow and ```. Only provide the json output. Don't give unnecesary explanation.
    ```reactflow
    {
      "nodes": [
        { 
          "id": "unique_node_identifier_string",
          "data" : {
            "label": "name_of_the_service",
            "description": "description of the service",
            "associated_files": ["file_path_1", "file_path_2", "file_path_3", etc.],  // (default: ["No File Available"] if not present)
            "group": "name_of_group",  // Add the logical group name (e.g., "Frontend", "Backend", etc..)
            "subgroup": "name_of_subgroup",  // Add a more specific subgroup name (e.g., "Frameworks", "NoSQL Databases", etc..)
            "service": "filename" //taken from the $icons_metadata,
          }
          "position":{ "x": "Xcoordinate", "y": "Ycoordinate" },
          "type" : "customNode" //this is hardcoded and will be constant
        }
      ],
      "edges": [
        {
          "id": "unique_egde_identifier_string",
          "source": "label A",
          "target": "label B",
          "label": "Showcase what comes from the source node, to the target node. Be concise and specific with labels, such as 'Ingested Data', 'Converted Text', 'User Query' etc. Use at max 5 words",
          "type" : "customEdge" //this is hardcoded and will be constant
        }
      ]
    }```
    </output_format>
    """
    return system_prompt, user_prompt
  

def erd_generation(services_data, icons_metadata):
  tables_metadata = []
  for entry in services_data:
      table_name = entry["table_name"]
      ddl = entry["ddl"]
      columns, primary_keys, foreign_keys = parse_ddl(ddl)
      tables_metadata.append({
          "table_name": table_name,
          "columns": columns,
          "primary_keys": primary_keys,
          "foreign_keys": foreign_keys
      })

  dot = generate_combined_graph(tables_metadata)

  system_prompt:str = """
    You are tasked with creating a JSON structure for a ReactFlow diagram based on the given database ER diagram and schema JSON. This JSON includes information about database columns and their relationships.Your output should represent this information as a network of nodes and edges.
    </Task>
    
    <Icons Context>
      $icons_metadata = """ + str(icons_metadata) + """
    </Icons Context>

    <Instructions>
      You are a solution expert, specializing in problem and solution flows. You will be given the database schema information of a database, and your task is to create an interconnected single component of graph which is detailed, and intuitive and self explanatory for:

      Follow these guidelines:
      1. Create nodes for each unique service (both external and third-party).
      2. Do not create any group nodes.
      4. In the data key for each service node, include two additional fields called group and subgroup. The group field should contain the logical group name (e.g.,Databases, etc..), and the subgroup field should provide more specific categorization (e.g., 'Transactional Tables', 'Reference Tables' etc..). For example, for a service node representing daily transactions, the group would be Database and the subgroup would be Transactional Tables.
      5. For each node, check which icon will be the most suitable from the $icons_metadata in the <Icons Context>
      6. Ensure all information from the input is represented in the output.
      7. The position coordinates must be proper for all the nodes.
    </Instructions>

    <Rules>
      Important Rules to be followed:
      1. Give detailed technical architecture flow and the JSON object following the below output format.
      2. Make sure that the flow and order of new solution approach is explained well in the graph with appropriate edges. Use as many edges you want to describe the data and user flow properly.
      3. The whole user and data flow should be clear.
      4. Do not add unnecessary nodes and edges. Do not create duplicate nodes that perform same task.
      5. Make the Node descriptions detailed, breaking tasks into multiple sub-tasks if needed.
      6. Ensure your edges show the actual flow, and not just connections of what's related. The connections are meant to show the logical flow, and not the relatedness/similarity.
      7. The group name is meant to classify clusters of nodes within each graph. For instance, if we have multiple nodes in features, they would all have "feature" as group. In Architecture Flow, the "Group" should show the layer each node is in, for instance "Database Layer" etc.
      9. for a hierarchy of nodes A -> B -> C; ensure that there is not a connection between A -> C.
    </Rules>
    
    <output_format>
    The output should be in between the delimeters ```reactflow and ```. Only provide the json output. Don't give unnecesary explanation.
    ```reactflow
    {
      "nodes": [
        { 
          "id": "unique_node_identifier_string",
          "data" : {
            "label": "name_of_the_table",
            "description": "description of the table",
  	    "columns": ["order_id [PK]", "product_sku [PK]", "quantity", "unit_price"]
            "group": "name_of_group",  // Add the logical group name (e.g., "Database", etc..)
            "subgroup": "name_of_subgroup",  // Add a more specific subgroup name (e.g., 'Transactional Tables', 'Reference Tables', etc..)
            "service": "filename" //taken from the $icons_metadata,
          }
          "position":{ "x": "Xcoordinate", "y": "Ycoordinate" },
          "type" : "customNode" //this is hardcoded and will be constant
        }
      ],
      "edges": [
        {
          "id": "unique_egde_identifier_string",
          "source": "label A",
          "target": "label B",
          "label": "Showcase what comes from the source node, to the target node. Be concise and specific with labels, such as 'Ingested Data', 'Converted Text', 'User Query' etc. Use at max 5 words",
          "type" : "customEdge" //this is hardcoded and will be constant
        }
      ]
    }```
    </output_format>
    """
    
  user_prompt:str = f"""
    <Input>
    $database_tables = {dot}
    $icons_metadata
    </Input>

    <Role>
    You are an expert at understanding database architecture based on ER diagrams and relational structures. Create a JSON structure for a ReactFlow diagram based on the given database schema.
    </Role>
    <Output Structure>
      1. Create a JSON object with a "nodes" and "edges" array.
      2. Create nodes for each table in the schema.
      3. "nodes": An array containing all node objects.
      - "id": A unique string identifier for the node.
      - "data":  
        - "label": The name of the table.
        - "description": A brief summary of the table's role or content.
        - "columns": List of column names (mark primary keys with [PK], foreign keys with [FK]).
        - "group": The logical group name (e.g., 'Database').
        - "subgroup": The specific subgroup within the group (e.g., 'Transactional Tables', 'Reference Tables').
        - "service": The appropriate filename of the icon based on the $icons_metadata.
      - "position" : The x and y coordinates of the node.
      - "type" : "customNode" This should be fixed.
      4. "edges" : An array having id, source, target, label, and type should be customEdge always.
      5. The label of the edge should describe the relationship, like "order_id â†’ order_id". 
      6. The output should be in the form of a dictionary containing a "nodes" and "edges" array.
      7. Present only the code inside delimiters "```reactflow [reactflow CODE]```" without any additional explanation.
    """
    
  return system_prompt, user_prompt
    

def feature_summary_generation(formatted_data, user_mvf, executive_summary):
    # if input_type is None:
    #     formatted_data = file_summary_list
    # elif input_type == "batch_summary":
    #     formatted_data = format_batchwise_summary_metadata_for_services(file_summary_list)
    # else:
    #     formatted_data = format_file_summaries(file_summary_list)

    user_prompt = """
    Role: You are an AI code analyst specializing in creating concise, feature-level summaries of codebases.

    Objective: Provide a comprehensive yet concise feature-level summary of a given codebase, highlighting key components, functionality, and the project's overall workflow.

    Input: You will receive information about a codebase, which may include an executive summary or other project details.

    Steps:
    1. Analyze the provided codebase information.
    2. Identify the main features (maximum 5) of the project from the executive summary (if provided in same order)
    3. Create a summary following the specified format, including:
        a. An overview of the project
        b. A list of key features with brief descriptions
        c. A closure statement
    4. Self-evaluate the generated summary and assign a confidence score.
    5. Format the output as specified in the instructions.

    Output Format:
    ```json
    {
        "data": "generated_summary in string format adhering to the Detailed Instructions for Output Format",
        "confidence_score": 90
    }
    ```

    Detailed Instructions for Output Format:

    **Overview**
    <empty line>
    < 
        Summarize all features in 2-3 sentences, introducing the project and its purpose.
        Provide a 2-3 sentence summary of key benefits, highlighting core architecture and value proposition.
    >
    <empty line>
    **Key Features**
    <empty line>
    <   
        List a maximum of 5 main features.
        For each feature, provide up to 2 sub-points describing its functionality.
        Ensure clear explanation of how features interact and contribute to the project's goals.
        1. ***<Key Feature Title>*** : 
        * <Sub point 1 description>
        * <Sub point 2 description>
        <empty line>
    >
    <empty line>
    < 
        Summarize the overall impact and value proposition of the project in one sentence as a conclusion statement.
    >
    <empty line>
    
    -> Self-Evaluation:
        - Score the summary out of 100 based on clarity, precision, detail, knowledge, accuracy, technical correctness, and understanding of the data.

    -> Formatting Requirements:
        - Replace all newline characters (\n) with \\n in the JSON output.
        - Ensure the complete JSON is less than 7500 tokens.
        - Start the output with "```json" and end with "```".
        - If an executive summary is provided, use only the highlighted features from it.

    Example Output Structure:
    ```json
    {
        "data": "**Overview**\\n\\n[Project overview]\\n\\n[Benefits summary]\\n\\n**Key Features**\\n\\n1. *Feature 1*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n2. *Feature 2*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n[...continue for up to 5 features...]\\n\\n[Closure statement]",
        "confidence_score": 90
    }
    ```

    Remember: Adhere strictly to the output format and instructions to maintain consistency and accuracy in your summary.
    """

    user_prompt += "User Defined Features : " + str(user_mvf)

    system_prompt = f"""
        <role>
        You are an assistant to a Senior Software Engineer. You are very capable in reading and understanding huge codebases.
        There is no edge-case, no mistake, no functionality no matter how small goes unnoticed by you.
        You will be given a large codebase and be asked queries regarding it.
        </role>

        <Task>
        You will be given relevant files from a production codebase. The Senior Engineer will consult you to clear his doubts and ask for critical code-level and functionality level analysis of the same.
        <Important>
        1. You will be clear. Feel free to be descriptive but Avoid Jargon
        2. You shall perform critical analysis on the code before responding.
        3. Note that the codebase will be quite complex and have dependencies everywhere, be mindful of them all.
        4. Enclose code in (triple backticks)``` code ```
        </Important>
        </Task>

        Files from Codebase goes here :
        <Repo Structure>
        {formatted_data}
        </Repo Structure>
    """

    start_index = executive_summary.find("Highlighted Features")
    end_index = executive_summary.find("Key Benefits")

    if start_index != -1 and end_index != -1:
        executive_summary = executive_summary[start_index:end_index].strip()

    user_prompt += "Executive Summary : " + str(executive_summary)

    return system_prompt, user_prompt

def feature_summary_generation_db(formatted_data, user_mvf, executive_summary):
    # if input_type is None:
    #     formatted_data = file_summary_list
    # elif input_type == "batch_summary":
    #     formatted_data = format_batchwise_summary_metadata_for_services(file_summary_list)
    # else:
    #     formatted_data = format_file_summaries(file_summary_list)

    user_prompt = """
    Role: You are an AI Database Analyst specializing in creating concise, feature-level summaries of complex database schemas and architectures.

    Objective: Provide a comprehensive yet concise feature-level summary of a given database schema information, highlighting key components, entities, relationships, and the overall data architecture workflow.

    Input: You will receive information about a database design, which may include an executive summary or other schema-level details.

    Steps:
    1. Analyze the provided database schema information.
    2. Identify the main features (maximum 5) of the database from the executive summary (if provided in same order)
    3. Create a summary following the specified format, including:
        a. An overview of the database
        b. A list of key features with brief descriptions
        c. A closure statement
    4. Self-evaluate the generated summary and assign a confidence score.
    5. Format the output as specified in the instructions.

    Output Format:
    ```json
    {
        "data": "generated_summary in string format adhering to the Detailed Instructions for Output Format",
        "confidence_score": 90
    }
    ```

    Detailed Instructions for Output Format:

    **Overview**
    <empty line>
    < 
        Summarize all features in 2-3 sentences, introducing the database and its purpose.
        Provide a 2-3 sentence summary of key benefits, highlighting schema structure, normalization or denormalization logic, and value proposition in handling data.
    >
    <empty line>
    **Key Features**
    <empty line>
    <   
        List a maximum of 5 main features.
        For each feature, provide up to 2 sub-points describing its data handling, relationships, or optimization logic.
        Ensure clear explanation of how features contribute to performance, consistency, and data integrity.
        1. ***<Key Feature Title>*** : 
        * <Sub point 1 description>
        * <Sub point 2 description>
        <empty line>
    >
    <empty line>
    < 
        Summarize the overall impact and value proposition of the database in one sentence as a conclusion statement.
    >
    <empty line>
    
    -> Self-Evaluation:
        - Score the summary out of 100 based on clarity, precision, detail, knowledge, accuracy, technical correctness, and understanding of the schema information.

    -> Formatting Requirements:
        - Replace all newline characters (\n) with \\n in the JSON output.
        - Ensure the complete JSON is less than 7500 tokens.
        - Start the output with "```json" and end with "```".
        - If an executive summary is provided, use only the highlighted features from it.

    Example Output Structure:
    ```json
    {
        "data": "**Overview**\\n\\n[Database overview]\\n\\n[Benefits summary]\\n\\n**Key Features**\\n\\n1. *Feature 1*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n2. *Feature 2*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n[...continue for up to 5 features...]\\n\\n[Closure statement]",
        "confidence_score": 90
    }
    ```

    Remember: Adhere strictly to the output format and instructions to maintain consistency and accuracy in your summary.
    """

    user_prompt += "User Defined Features : " + str(user_mvf)

    system_prompt = f"""
        <role>
        You are an assistant to a Senior Data Architect. You are very capable in reading, analyzing, and understanding complex database schemas and data models.
        No entity, constraint, relationship, or optimization logic goes unnoticed by you.
        You will be given a comprehensive database structure or schema information and will be asked to analyze, explain, and summarize it at a structural and functional level.
        </role>

        <Task>
        You will be given relevant database schema files or DDL definitions. The Senior Data Architect will consult you to clear doubts and ask for critical schema-level and data model-level analysis.
        <Important>
        1. You will be clear. Feel free to be descriptive but Avoid Jargon
        2. Perform a critical and deep analysis of the schema and the information given before responding.
        3. The schema will often involve multiple tables, foreign keys, views, procedures, and indexing strategies â€” be mindful of their dependencies and relationships.
        4. Enclose code or schema in (triple backticks)``` code ```
        </Important>
        </Task>

        Files from Database schema goes here :
        <Database Structure>
        {formatted_data}
        </Database Structure>
    """

    start_index = executive_summary.find("Highlighted Features")
    end_index = executive_summary.find("Key Benefits")

    if start_index != -1 and end_index != -1:
        executive_summary = executive_summary[start_index:end_index].strip()

    user_prompt += "Executive Summary : " + str(executive_summary)

    return system_prompt, user_prompt


#FEATURE HIERARCHY:
generate_features_system_prompt = """
  <Role>
    You are a Software Architect with expertise in analyzing large summaries from code files of an application. 
    You can comprehend summaries from code files that are complex, production-grade and are written in various programming languages to generate most important features, their description and the subfeatures with their description belonging to the most important features along with the other relevant information requested below.
    
    You will follow 2 Events before responding : 
    1. Generation of Feature Hierarchy as given in "Output_Format".
    2. Critical Evaluation of Every Confidence Score.  
  </Role> 

    <Task 1>
    You are provided with multiple relative file paths and file-wise code summaries from a application codebase.
    1. Analyze the file summaries carefully, leveraging your expertise to deduce the frameworks, functionality, and features.
    2. Perform a critical assessment of the code's functionality and interdependencies before responding.
    3. The codebase is complex and likely contains dependencies across various modules. Be mindful of these.
    4. Analyse every file summary and assign the features and sub-features based on the information provided.
    5. Respond strictly in the structured JSON format provided below.
    6. In each sub-feature's 'file_path' array:
        - Set 'critical: true' ONLY for files that are CORE & NON-REPLACEABLE to the sub-feature's main functionality.
        - Set 'critical: false' for ALL supporting, secondary, or replaceable files  
        - Each sub-feature should have both true and false entries.
        - If unsure, default to false (be EXTREMELY selective with 'true')
        - Make sure each sub-feature atleast have one file as true.

    Explanation of the Output terms:
    Feature - Features are most valuable and high level features extracted from the list of summaries that are provided to you. 
    Feature description - Description of the features explaining the high level value and impact that it creates for the project. Define the Feature. The description should be crisp, precise, well formatted and must be between 2-3 lines.
    Subfeature - Subfeatures are micro most valuable features that are extracted from the list of summaries and belong to the Most related and similar Features.
    Subfeature description - Description of the subfeatures explaining the specific value, technical and non-technical functionalites that it provided to the project. Define the subfeature and also explain how its related to the feature. The description should be crisp, precise, well formatted and must be between 2-3 lines.
    
    Points to Remember:
    1. Do not extract any feature or subfeature where there are no reference/citations from the application summaries.
    2. The description must be precise, valuable, well-formatted and must be between 2-3 lines.
    3. The Feature titles should be precise, specific, self explanaible, independent and not have similar feature titles. The Feature titles should not be highly generalized.
    4. The SubFeatures titles should be precise, self explanaible and not have similar subfeature titles. The SubFeature titles should not be highly generalized.
    5. SubFeatures should not be very low level that it explains code functions, code process like 'Json handling', 'Reading csv', readME etc.
    6. If similar subfeatures are present, then group them under one common Feature itself. Do not create multuple Features for similar subfeatures.
    6. If Unit testing related summaries are found, then create that as another Feature named 'Unit Testing' and assign the specific testing subfeatures under this feature.
    </Task 1>

  <Task 2>
  You shall now Assign and Justify Confidence Scores for each feature.

  <Critical Evaluation of Confidence Scores> 

  <Evaluation MODE>
  - You will now Forget everything that was done beforehand and act as an unbiased judge.
  - $Project-Summaries-&-Paths (INPUT).
  </Evaluation MODE>
  <Important>
  Critically analyze every "Feature" and "SubFeature" based on the following metrics. 
  You shall generate a confidence score between 0-100 for each of the following :
  1. Is the "Feature" & "SubFeature" name accurate to its functionality ? (Accuracy)
  2. Does the "Feature" & "SubFeature" include files with an unrelated function ? (Feature Dilution Rate)
  3. Important : Does this "Feature" & "SubFeature" make sense given the Overall Purpose of the Application ? (Consistency)
  4. Are all the files in "Feature" & "SubFeature" included ? (Completeness)

  <Strict>
  1. You will now generate a list of 4 confidence scores between 0-100 for above criteria under "confidence_score" key.
  2. Based on above criteria, you shall provide a VERY BRIEF logical explanation (10-20 words) for Confidence Score under "confidence_score_justification" key.
  3. Make sure to mention the entire filepath without omitting the prefix.
  4. Make sure all the filepaths are present.
  <Important> STRICTLY Don't Comment on Missing Files. Don't Overestimate. Don't Underestimate.</Important> 
  </Strict>

  </Important>

  </Critical Evaluation of Confidence Scores> 
  </Step 2>


      <Output_Format>
    Return a response in JSON format. Do not include any extra information or explanations. Strictly DON'T deviate from mentioned KEYS.
    Example:
```json
[
  {
    "name": "User Authentication and Management",
    "feature_description": "Comprehensive user account system with secure login, registration, profile management, and role-based access control.",
    "feature_description_confidence_score": [95, 70, 100, 70],
    "sub_features": [
      {
        "name": "User Registration",
        "description": "Allows new users to create accounts by providing necessary information such as username, email, and password. Implements email verification, password strength checks, and duplicate account prevention. Stores user data securely in the database with password hashing.",
        "file_path": [
          {
            "module_name": "RegistrationController",
            "path": "Controllers/Account/RegistrationController.cs",
            "critical": true
          },
          {
            "module_name": "RegisterView",
            "path": "Views/Account/Register.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [75, 80, 85, 65],
        "sub_feature_confidence_score_justification": "No feature dilution, might have missed some file."
      },
      {
        "name": "User Login",
        "description": "Authenticates users using their credentials, creates and manages user sessions, and implements security measures such as login attempt limiting and two-factor authentication (2FA). Provides password reset functionality for forgotten passwords.",
        "file_path": [
          {
            "module_name": "LoginController",
            "path": "Controllers/Account/LoginController.cs",
            "critical": true
          },
          {
            "module_name": "LoginView",
            "path": "Views/Account/Login.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [80, 100, 80, 75],
        "sub_feature_confidence_score_justification": "High chance of missing files."
      }
    ],
    "feature_confidence_score_justification": "No feature dilution, duplication or missing files. Accurate Naming."
  },
  {
    "name": "Product Catalog Management",
    "feature_description": "Comprehensive system for managing product listings, categories, and inventory across the e-commerce platform.",
    "feature_description_confidence_score": [95, 65, 70, 80],
    "sub_features": [
      {
        "name": "Product CRUD Operations",
        "description": "Enables administrators to create, read, update, and delete product listings. Includes functionality for managing product details such as name, description, price, images, and inventory levels. Implements validation to ensure data integrity and consistency across the product catalog.",
        "file_path": [
          {
            "module_name": "ProductController",
            "path": "Controllers/ProductController.cs",
            "critical": true
          },
          {
            "module_name": "ProductView",
            "path": "Views/Product/Index.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [90, 85, 100, 70],
        "sub_feature_confidence_score_justification": "High confidence with no duplication or dilution."
      },
      {
        "name": "Category Management",
        "description": "Allows for the creation and management of product categories and subcategories. Implements a hierarchical structure for organizing products, enabling efficient navigation and filtering of the product catalog for both administrators and customers.",
        "file_path": [
          {
            "module_name": "CategoryController",
            "path": "Controllers/CategoryController.cs",
            "critical": true
          },
          {
            "module_name": "CategoryView",
            "path": "Views/Category/Index.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [85, 75, 90, 95],
        "sub_feature_confidence_score_justification": "High confidence without any duplication or dilution."
      }
    ],
    "feature_confidence_score_justification": "All files refer to single overall functionality. Might have missed some files."
  }
]
```
  </Output_Format>

"""

generate_features_user_message = """
<Strictly Remember>
1. As input you will be given a batch of `file_path` and `file_summary` from a production codebase. Keep it in mind that it could be a file from a very large repository with lot of inter-dependencies.
2. Understand all the file description first, then try to determine the feature, sub-features and their description. For **each file** it should have a feature or sub-features whenever the conditions are met.
3. The response should contain all the fields given in the example output format. The response should be strictly in json format.
4. The description of features/subfeatures must be in the length of 2-3 lines. The response should be structured and well-formatted.
5. Don't generate any additional explanation or description. Provide the structured response in json only.
</Strictly Remember>
  
<Input file wise summary>
{file_summary}
</Input file wise summary>
<Response>
"""

merge_features_in_hierarchy_user_prompt = """You are a software feature analyzer. Given a list of related features that have been clustered together, create a merged feature that encompasses all the functionality.

Features to merge:
{feature_list}

Generate a JSON response that includes:
1. A name for the merged feature representing accurate feature name. Do not mention its merged or unified or anything as such. The feature name should accurately represent a major funcationality of a repository.
2. A detailed description that covers all functionality
3. A confidence score (0-100) for the merge
4. A justification for the confidence score

Respond with a JSON object in the following format:
```json
{{
    "name": "Merged feature name",
    "description": "Comprehensive description",
    "confidence_score": 85,
    "confidence_justification": "Reason for the confidence score"
}}
```
Give only JSON and nothing else. Do not include any explanations or additional text outside the JSON block. Make sure to start with ```json and end with ``` only.
"""

mapping_names_for_merged_features_user_prompt = """  <Role>
    You are a smart AI cassistant with strong expertise in Software Engineering. You can understand complex, production-grade codebases written in various programming languages and summarize them effectively.
  </Role>
  <Task>
  You will be given a brief description of  features of a large codebase and your task is to generate a relevant feature name, brief description, and priority level.
  <Important>
   1. The feature name should be brief, relevant and should represent the entire description provided.
   2. Generate a relevant description which is basically a overall summary of the description provided.
   3. Assign a priority level (high, medium, low) based on the significance, importance and complexity of the feature to the overall system. 
  </important>
  </Task>
  <Example output>
  ```json
    {
        "name": <feature_name>, //string
        "feature_description": <feature_description>, //string
        "priority": <priority> //string (high, medium, or low)
    }
    ```
  </Example output>
  <Strictly Remember>
1. The feature name should be relevant and at the same time interpretable, easy to understand.
2. The feature description should represnt the entire description given for summarisation, it should be simple and easy to understant.
3. The priority should be one of: high, medium, or low.
4. The response should be strictly in json format specified above.
5. Strictly make sure Feature Description is not more than 200 words.
  </Strictly Remember>

<code summary>
The code summary is given below:
"""


reducing_sub_features_user_prompt = """
    You are a software feature consolidation expert. Your task is to merge similar sub-features into one comprehensive sub-feature.

    Here are the sub-features that need to be merged:
    {sub_features_list}

    For each sub-feature, we have:
    - Name: The sub-feature name
    - Description: The sub-feature description (if available)
    - Confidence Score: The confidence score (if available)

    Your output should be a JSON object containing:
    1. A unified sub-feature name that encompasses all the input sub-features
    2. A comprehensive description that covers all aspects of the input sub-features
    3. A confidence score (use the highest available from input sub-features)
    4. A justification for the confidence score

    Return the output in JSON format starting with ```json and ending with ```.

    Example output format:
    ```json
    {{
        "name": "Unified Sub-Feature Name",
        "description": "Comprehensive description covering all aspects",
        "sub_feature_confidence_score": 95,
        "sub_feature_confidence_score_justification": "Merged from similar sub-features with high semantic similarity"
    }}
    ```
    """


post_processing_feature_name_description_system_prompt="""
  <Role>
    You are a smart AI assistant with strong expertise in Software Engineering. You can understand complex, production-grade codebases written in various programming languages and summarize them effectively.
  </Role>
  <Task>
  You will be given a brief description of modules or features of a large codebase and your task is to generate a relevant feature name and brief description.
  <Important>
   1. The feature name should be brief, relevant and should represent the entire description provided.
   2. Generate a relevant description which is basically a overall summary of the description provided.
   3. Also generate a confidence score in a scale of 0 - 100.
  </important>
  </Task>
  <Example output>
  ```json
    {
        "name": <feature_name>,
        "feature_description_confidence_score": <score 0 - 100>,
        "feature_description": <feature_description>
    }```
  </Example output>"""

post_processing_feature_name_description_user_prompt = """<Strictly Remember>
1. The feature name should be relevant and at the same time interpretable, easy to understant.
2. The confidence score should represent the ability to summarise the description.
3. The feature description should represnt the entire description given for summarisation, it should be simple and easy to understant.
4. The response should be strictly in json format specified above.
</Strictly Remember>
<code summary>
The code summary is given below: \n
{feature_description}
</code_summary>
<response>
Your response in json goes here:
"""

merge_similar_features_system_prompt = """You are a solution architect. Your task is to carefully review each feature and its description, and combine them into a single high-level feature.

The final high-level features should represent what an end user would perceive, e.g., Messenger, Google Chat, Messaging, Reels, etc.

Based on the generated features provided, identify which features can be merged into a single high-level feature. 
Strictly output them in the following format:
{{ 
  <High-Level Feature Name 1>: [<Merged Feature 1>, <Merged Feature 2>, <Merged Feature 3>, ...],
  <High-Level Feature Name 2>: [<Merged Feature 1>, <Merged Feature 2>, <Merged Feature 3>, ...],
  ...
}}

INPUT:
Feature names and descriptions are provided in the format: 
[1. Feature name: <feature name> 
Feature description: <feature description>, 
2. ...]

{feature_texts}

MVFS:
{total_MVFs}

Points to remember:
1. While merging features and naming high-level features, always prefer names from the user-defined MVFs provided. All relevant features can be grouped under these high-level features.
2. If certain features do not fit under the user-defined MVFs, choose a better name than the existing one for the new high-level feature if necessary.
3. The names of the features being merged must remain exactly as provided in the INPUT section; do not modify them. Do not consider Feature description in Feature Names.
4. Follow the output structure strictly: high-level feature names as dictionary keys and merged features as values in list format.
5. If a feature is already a high-level feature, you do not need to forcibly merge it. If a feature seems to be function-level/low-level  features, merge them into a High-level feature.
6. Merge similar features into a single high-level feature based on their names and descriptions, when applicable. Each final high-level feature should be independent of the others.
7. Do not assign the same feature to multiple high-level features.
8. If user-defined MVFs are empty, skip point 1 and begin with point 2.
9. Do **not** include any Feature descriptions in the final output."""


merging_description_user_prompt = """You are a Solution Architect. Your task is to summarize the multiple feature descriptions provided into a brief, coherent summary of **no more than two sentences**.

  The summary must:
  - Accurately capture all key components from the provided descriptions.
  - Align clearly with the given high-level feature name.
  - Serve as the final description of the high-level feature.

  Only the final summarized description should be included in the output â€” no additional commentary or formatting.

  INPUT:
  Multiple descriptions: {merging_feature_description}

  High-Level Feature Name: {high_level_feature}
  """


micro_sub_feature_prompt = """You are an expert system analyst specializing in decomposing SubFeatures into granular, logically independent components. You support **two levels** of splitting:

1. **Horizontal splitting**: Split a subfeature into multiple *same-level subfeatures* when it encompasses multiple independently meaningful functionalities. The subfeatures created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.
2. **Vertical splitting**: Further break each of those subfeatures into *microsubfeatures* (if applicable), ensuring each micro-sub-features/micro-user-story describes a single goal or operation. The micro-sub-features/micro-user-story created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.

---

### ðŸ”§ TASK OVERVIEW

Given a Macro-Feature, Subfeature, its description, associated module files and its summary:

- Decide if the subfeature should be split horizontally into multiple same-level subfeatures.
- For each resulting subfeature (or original if not split), analyze whether it can be split vertically into **microsubfeatures** (fine-grained user stories).
- Provide the confidence scores for the subfeature that is split, whether horizontally or vertically.
- Provide the files that are related to the sub_features too, not just the micro_sub_features.
- Each leaf user-story must have files assigned to them, else you should not create/split these subfeatures.
- Provide description of generated subfeature/sub-user-stories in 2-4 lines but only valid information. Do not assume or hallucinate to generate description.
Apply this recursively: if horizontal splitting occurs, then attempt vertical splitting for each. But remember, not to create any duplicates in the process. 

---

### SPLITTING DECISIONS

#### Horizontal Splitting (Same-level Subfeatures):
Split if:
- The subfeature covers multiple high-level functionalities
- Each function could be planned, developed, and deployed independently
- Each component has a clear boundary and responsibility

#### Vertical Splitting (Microsubfeatures):
Split further if:
- A subfeature contains multiple independent operations or logical stages
- These operations can be implemented, tested, or tracked separately
- Each micro-subfeature represents one atomic, non-overlapping functionality

---

### DO NOT SPLIT IF:
- sub-user-stories are tightly coupled in the Subfeature and cannot function independently.
- Do not split subfeatures into sub-user-stories that are hardly single line of code and cannot be considered as a proper functionality, but just a config/parameter.
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across actions are too complex to isolate.
- There are no files that can be mapped to the generated user-story.
- Do not split if the user-story is barely a functionality. The split user-stories must have independent functionality that contributes to the subfeature and feature and if not, do not split.
- Don not split ReadMe & .md files into sub-user-stories.
- Do not split horizontall for granullar subfeatures as they are not user stories but mid level features.
---

### FILE MAPPING RULES:
- For each subfeature or microsubfeature, cite only directly relevant files.
- Use only the provided input data to match files â€” no guessing.
- Avoid duplication unless a file is clearly shared between components.

Each `file_path` entry must include:
```json
{
  "module_name": "<Name>",
  "path": "<Path>",
  "critical": <true/false>,
  "git_url": "<Git URL>"
}

OUTPUT FORMAT
If the subfeature should NOT be split:
Return: "None"

If the subfeature should be split, return a list of Parent User Stories with subfeatures inside.
If a subfeature itself can be further split into microsubfeatures, nest them under micro_sub_features like so:

[
  {
    "name": "Parent User Story Title 1",
    "description": "Full description of the original or updated user story and its purpose.",
    "file_path": [...],
    "sub_feature_confidence_score":"confidence score of the subfeature with respect to the Feature, as a percentage (e.g., 80)"
    "micro_sub_features": [
      {
        "name": "Sub-User Story Title 1",
        "description": "Standalone description of a single functionality.",
        "file_path": [...],
        "micro_sub_feature_confidence_score":"confidence score of the micro_sub_feature with respect to the sub_feature, as a percentage (e.g., 90)"
        }
          ...
        ]
      },
      ...
    ]
  }
]
Each layer must preserve independence, clarity, and singular focus of each story.

VALIDATION CHECKLIST
- Each title must express one functionality only (no imperative phrasing)
- description must avoid assumptions and describe the real function. It must be as detailled as possible.
- Each story must make sense independently and fit in the broader feature flow
- if there are multiple user-story under the subfeature, it needs to be in sequence of business logic.
- File mappings must be relevant and scoped accurately
- Do no miss/skip any values in the output json. The output structure must be maintained strictly.
- All subfeature and sub-user-story names and descriptions must be strictly in a declarative tone, not imperative.

* Use generic or speculative statements
"""


db_micro_sub_feature_prompt = """
<Role>
You are an expert Database analyst specializing in decomposing SubFeatures into granular, logically independent components. You support **two levels** of splitting:
You shall ALWAYS process features from a Database perspective ONLY. 
There can be more than one Table in the DB context provided to you.
</Role>

1. **Horizontal splitting**: Split a subfeature into multiple *same-level subfeatures* when it encompasses multiple independently meaningful functionalities. The subfeatures created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.
2. **Vertical splitting**: Further break each of those subfeatures into *microsubfeatures* (if applicable), ensuring each micro-sub-features/micro-user-story describes a single goal or operation. The micro-sub-features/micro-user-story created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.

<Strict Constraints> 
- You are dealing with Database Information. 
- No matter what, STRICTLY use Database-Specific Language ALWAYS. 
- Use words like Columns / Fields / Schema / DataTypes / Constraints / Foreign Keys / Primary Keys etc.
- Strictly Do not start descriptions with or start with "this micro-feature" / or "this sub-feature".
- You shall do this regardless of the input context and nature.
Remember : Every "FILE" given to you is information of a table. Therefore in your response, ALWAYS refer to "Table" instead of "File".

</Strict Constraints> 


### ðŸ”§ TASK OVERVIEW

Given a Macro-Feature, Subfeature, its description, associated module files and its summary:

- Decide if the subfeature should be split horizontally into multiple same-level subfeatures.
- For each resulting subfeature (or original if not split), analyze whether it can be split vertically into **microsubfeatures** (fine-grained user stories).
- Provide the confidence scores for the subfeature that is split, whether horizontally or vertically.
- Provide the files that are related to the sub_features too, not just the micro_sub_features.
- Each leaf user-story must have files assigned to them, else you should not create/split these subfeatures.
- Provide description of generated subfeature/sub-user-stories in 2-4 lines but only valid information. Do not assume or hallucinate to generate description.
Apply this recursively: if horizontal splitting occurs, then attempt vertical splitting for each. But remember, not to create any duplicates in the process. 

---

### SPLITTING DECISIONS

#### Horizontal Splitting (Same-level Subfeatures):
Split if:
- The subfeature covers ONE / MORE THAN ONE high-level functionalities
- Each function could be planned and developed independently
- Each component has some clear boundaries and responsibilities

#### Vertical Splitting (Microsubfeatures):
Split further if:
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across actions are too complex to isolate.
- There are no tables that can be mapped to the generated user-story.
- The subfeature is too complex to be planned, developed, and deployed independently
- Each micro-subfeature represents one atomic, non-overlapping functionality
Note: Maintain at least 2 subfeatures unless the database has only one table.
- Prioritize brevity, consistency and no informaiton leakage across subfeatures.
- Ensure crisp segregation.
---

### DO NOT SPLIT IF:
- sub-user-stories are tightly coupled in the Subfeature and cannot function independently.
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across tables in two features are too complex to isolate.
- There are no tables that can be mapped to the generated user-story.
Note: Maintain at least 2 subfeatures and 1 or more microsubfeatures per subfeature, Unless the database has only one table.
Note : Maintain brevity during splitting at the same level. Do NOT overload the a single feature with too many subfeatures.
---


### FILE MAPPING RULES:
- For each subfeature or microsubfeature, cite only directly relevant tables.
- Use only the provided input data to match files â€” no guessing.
- Avoid duplication unless a file is clearly shared between components.

Each `file_path` entry must include:
```json
{
  "module_name": "<Name>",
  "path": "<Path>",
  "critical": <true/false>,
  "git_url": "<Git URL>"
}

OUTPUT FORMAT
If the subfeature should NOT be split:
Return: "None"

If the subfeature should be split, return a list of Parent User Stories with subfeatures inside.
If a subfeature itself can be further split into microsubfeatures, nest them under micro_sub_features like so:

[
  {
    "name": "Parent User Story Title 1",
    "description": "Full description of the original or updated user story and its purpose.",
    "file_path": [...],
    "sub_feature_confidence_score":"confidence score of the subfeature with respect to the Feature, as a percentage (e.g., 80)"
    "micro_sub_features": [
      {
        "name": "Sub-User Story Title 1",
        "description": "Standalone description of a single functionality.",
        "file_path": [...],
        "micro_sub_feature_confidence_score":"confidence score of the micro_sub_feature with respect to the sub_feature, as a percentage (e.g., 90)"
        }
          ...
        ]
      },
      ...
    ]
  }
]
Each layer must preserve independence, clarity, and singular focus of each story.

VALIDATION CHECKLIST
- Each title must express one functionality only (no imperative phrasing)
- description must avoid assumptions and describe the real function. It must be as detailled as possible.
- Each story must make sense independently and fit in the broader feature flow
- if there are multiple user-story under the subfeature, it needs to be in sequence of business logic.
- File mappings must be relevant and scoped accurately
- Do no miss/skip any values in the output json. The output structure must be maintained strictly.
- All subfeature and sub-user-story names and descriptions must be strictly in a declarative tone, not imperative.
- Use Database-specific schema only. Do not include words like "Attributes" / "Code Files" in your response. 
- Strictly Do not start descriptions with or start with "this micro-feature" / or "this sub-feature".
* Use generic or speculative statements

"""import os
from graphviz import Digraph
import re 
import json

def parse_ddl(ddl: str):
    """
    Parse the DDL to extract columns, primary keys, and foreign keys.
    """
    lines = ddl.splitlines()
    column_lines = []

    for line in lines:
        line = line.strip()
        if (
            line.upper().startswith("CREATE")
            or line.upper().startswith("PRIMARY")
            or line.upper().startswith("FOREIGN")
            or line.upper().startswith(")")
            or line == ""
        ):
            continue

        match = re.match(r'(\w+)\s+\w+', line)
        if match:
            column_lines.append(match.group(1))

    pk_match = re.search(r'PRIMARY KEY\s*\((.*?)\)', ddl)
    primary_keys = [key.strip() for key in pk_match.group(1).split(",")] if pk_match else []

    foreign_keys = []
    for match in re.finditer(r'FOREIGN KEY\s*\(([^)]+)\)\s+REFERENCES\s+`?[\w]+\.(\w+)`\(([^)]+)\)', ddl):
        fk_col = match.group(1).strip()
        ref_table = match.group(2).strip()
        ref_col = match.group(3).strip()
        foreign_keys.append((fk_col, ref_table, ref_col))

    return column_lines, primary_keys, foreign_keys


def generate_combined_graph(tables_data):
    """
    Generate a single combined graph from multiple tables.
    """
    dot = Digraph(comment='Combined Table Diagram')
    dot.attr(rankdir='LR')

    # Store individual table nodes
    for table in tables_data:
        table_name = table['table_name']
        columns = table['columns']
        primary_keys = table['primary_keys']
        
        label_lines = []
        for col in columns:
            if col in primary_keys:
                label_lines.append(f"{col} [PK]")
            else:
                label_lines.append(col)
        dot.node(table_name, shape='box', label=f'{table_name}\\n' + "\\n".join(label_lines))

    # Add relationships
    for table in tables_data:
        table_name = table['table_name']
        for fk_col, ref_table, ref_col in table['foreign_keys']:
            dot.edge(table_name, ref_table, label=f'{fk_col} â†’ {ref_col}')

    return dot

def folder_summary_generation_prompts(
        total_allocated_tokens, 
        file_list, folder_name, 
        folder_path,
        subfolder_list,
        formatted_file_summaries,
        formatted_file_services,
        formatted_subfolder_summaries,
        formatted_subfolder_services,
        formatted_subfolder_features
    ):
    
    system_prompt = f"""
        You are an expert code analyst specialized in creating detailed, informative summaries of software project folders. Your task is to thoroughly analyze files and subfolders to provide a comprehensive understanding of the application or project and provide combined summaries along with required details. These summaries must be detailled enough for further summarization.

        Follow these guidelines:
        1. Conduct a deep analysis of the features to identify its core purpose and functionality
        2. Provide detailed explanation of key implementations and technical approaches of the features
        3. Thoroughly examine the summaries based on files and folders to understand relationship between features and combined smaller features into larger high level application level features.
        4. Explain the features within the broader project architecture with specific connections
        5. Describe technical patterns, design decisions, and architectural choices evident in the code
        6. Include specific functions, classes, and methods that define the feature's behavior
        7. Note dependencies, imports, and external connections that shape the folder's functionality
        8. Identify potential architectural strengths and areas for improvement when evident
        9. Identify all services represented in this folder based on file and subfolder services information
        10. Identify and articulate high-level features or functionalities represented by the folder into the feature_details section, when consolidating multiple subfolders or lower-level files. Derive these insights from both file-level and subfolder-level summaries. Also under each feature, mention which file/folder was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
        11. Do not miss any features that could be formed based on these summaries as this information is required to understand the application's buisness logic.
        12. Gather insights from the summaries provided to generate a high level detailled executive summary that could be used by business stakeholders to understand the folder/project.
        13. When analyzing the root folder, both the executive summary and the features must be strictly formed in a high level business logic standpoint of an application.
        
        IMPORTANT: 
        - Your summary should be thorough and detailed({total_allocated_tokens}) while maintaining technical/business precision and depth. Focus on providing insights that would help both stakeholders and developers understand the application better.
        - feature_details must contain high level feature name and feature description(value of the files/folders) strictly in concise bullet points. The feature inforamtion must be in detail to capture the complete high level knowledge for that feature but not the function level details. Feature names cannot be programmatic function names like Dependency management, json handling etc. instead it should be inventory management, order processing etc. 
        - Your services list should be comprehensive and include all services represented in this folder.
        - is_reuasble_lib if a folder is used as reusable lib make it True otherwise False
        - lib_name if is_reusable_lib is True then provide the name of the reusable lib/component If is_reusable_lib False then add Not Applicable
        - category if is_reusable_lib is True then provide category only between 'Frontend' and 'Backend' If is_reusable_lib False then add Not Applicable
        - sub_category if is_reusable_lib is True then provide sub category only between 'UI Component','Custom Hooks', 'http_client', 'Utils', 'Others' In Frontend & 'Middleware', 'Error Handling', 'Auth', 'Utils', 'Others' In Backend If is_reusable_lib False then add Not Applicable
        - when_to_use if is_reusable_lib is True then provide where this reusable lib/component can be used If is_reusable_lib False then add Not Applicable 
        - associated_files if is_reusable_lib is True then provide the list of files associated(give complete path for the assosciated file) with this reusable lib/component If is_reusable_lib False then add Not Applicable
        - summary must not be technical and only explain the high level details of the folder/project. Understand the file and folder summaries provided to combine the knowledge to form the executive summary. Make it as detailled as possible.
        - Use clear and concise language, avoiding jargon where possible.
        
        - You must provide your response in this exact format:
        ```summary
        [Your detailled high-level executive summary for the folder for business stakeholders]
        ```
        ```feature_details
        [List of high-level features or functionalities represented in this folder]
        ```
        ```services_namess
        [Comma-separated list of all services represented in this folder]
        ```
        ```is_reuasble_lib
        Boolean Value
        ```
        ```lib_name
        [Name of the reusable library if applicable]
        ```
        ```category
        [Category of the reusable library if applicable]
        ```
        ```sub_category
            [Sub category of the reusable library if applicable]
        ```
        ```when_to_use
        [Your detailed use case where or when this reuasble_lib can be usefull]
        ```
        ```associated_files
            [Comma-separated list of associated files with the reusable library, Give the Complete file path as mentioned in the file list]
        ```
        ```example_usage
            [Example code snippet of how to use this reusable library]
        ```
    """

    user_prompt = f"""
        Generate a summary and services list for the folder: "{folder_name}" (Path: {folder_path})

        FOLDER CONTENTS:
        - Files ({len(file_list)}): {", ".join(file_list) if file_list else "None"}
        - Subfolders ({len(subfolder_list)}): {", ".join(subfolder_list) if subfolder_list else "None"}

        FILE SUMMARIES:
        {os.linesep.join(formatted_file_summaries) if formatted_file_summaries else "No file summaries available"}

        FILE SERVICES:
        {os.linesep.join(formatted_file_services) if formatted_file_services else "No file services available"}

        SUBFOLDER SUMMARIES:
        {os.linesep.join(formatted_subfolder_summaries) if formatted_subfolder_summaries else "No subfolder summaries available"}

        SUBFOLDER SERVICES:
        {os.linesep.join(formatted_subfolder_services) if formatted_subfolder_services else "No subfolder services available"}

        SUBFOLDER FEATURES:
        {os.linesep.join(formatted_subfolder_features) if formatted_subfolder_features else "No subfolder features available"}
        
        Based on these components:
        1. Provide a thorough technical summary explaining the folder's purpose, implementation details, and architectural significance
        2. Compile a comprehensive list of all services represented in this folder based on file and subfolder services information
        
        Follow the exact format specified in the system instructions for your response.
    """

    return system_prompt, user_prompt

def services_generation():
    system_prompt = """
        <Task>
        Create an architectural blueprint of the given repository by identifying and classifying both external services and third-party services with no overlap between categories.
        </Task>

        <Definitions>
        - External services: Company-provided services hosted outside the application (AWS S3, Google Cloud, Stripe, Twilio)
        - Third-party services: Libraries, frameworks, and SDKs that are part of the core application stack (Django, React, MongoDB, Redux)
        </Definitions>

        <Output_Format>
        {
        "external_services": [
            {
            "external_service_name": "string",
            "description": "string",
            "associated_files": ["string"],
            "service_class": "string",
            "used_in_files": ["string"]
            }
        ],
        "thirdparty_services": [
            {
            "thirdparty_service_name": "string",
            "description": "string",
            "associated_files": ["string"],
            "service_class": "string",
            "used_in_files": ["string"]
            }
        ]
        }
        </Output_Format>

        <Instructions>
        1. Conduct a thorough repository analysis to identify all services
        2. Classify each service into exactly ONE category:
        - External services: Cloud platforms, payment processors, authentication providers
        - Third-party services: Frameworks, libraries, SDKs integrated into the codebase
        3. For each service, provide:
        - Name: Exact service name
        - Description: Concise explanation of functionality and purpose
        - Associated files: All files directly importing or using the service
        - Service class: Category (e.g., "cloud storage", "web framework", "database")
        - Used in files: Complete paths of files utilizing the service
        4. Ensure ZERO overlap between categories
        5. Prioritize accuracy over comprehensiveness
        6. Validate that identified services are actively used in the project
        7. Include only services with clear evidence of implementation
        8. Do not create a lot of services which are redundant. Keep it to a maximum of 50 services only.
        </Instructions>

        <Examples>
        Good External Service Entry:
        {
        "external_service_name": "AWS S3",
        "description": "Cloud storage service used for storing user-uploaded files",
        "associated_files": ["src/services/storage.js", "src/config/aws.js"],
        "service_class": "cloud storage",
        "used_in_files": ["src/components/FileUpload.js", "src/pages/UserProfile.js"]
        }

        Good Third-Party Service Entry:
        {
        "thirdparty_service_name": "React",
        "description": "Frontend JavaScript library for building user interfaces",
        "associated_files": ["package.json", "src/index.js"],
        "service_class": "frontend framework",
        "used_in_files": ["src/App.js", "src/components/*.js"]
        }
        </Examples>

        Analyze the repository and provide the complete architectural blueprint in the specified format.
    """

    user_prompt = ""

    return system_prompt, user_prompt

def executive_summary_generation(combined_summary, user_mvf):
    system_prompt = """
    Your Role:
    You are an expert software architect tasked with understanding a codebase and creating an executive summary that clearly articulates the main purpose of this application,
    the core problem that the application is solving, and the prioritized list of the most valuable features, solely based on the provided folder wise summary. Do not hallucinate and create the most valuable features and its description on assumption. This needs to be based on facts.

    Task:
    1. Analyze provided folder wise summary and the services used and the user defined features (if provided).
    2. Understand component interactions and functions.
    3. Prioritize the User Defined Features (if provided) in the summary.
    4. Identify and prioritize the most valuable features based on their importance and relevance to the overall project, as evidenced in the code.
    5. Create a comprehensive executive summary.

    Steps:
    1. Review folder wise summary.
    2. Analyze folder wise summary:
    - Identify key components and their roles
    - Note data operations, design patterns, and architectural decisions
    3. Create summary:
    - Describe the specific problem the codebase solves, based on folder wise summary
    - Explain component interactions
    - Outline data workflow
    4. Identify and prioritize main features:
    - Determine which feature(s) address the core problem of the application, based on code implementation
    - Rank features based on their importance and relevance to solving the main problem, as evidenced in the code
    - The feature should be major components of the codebase and not minor functions like "Modular Architecture" or "Code Reusability", these are not features but design principles.

    Focus Areas:
    - Precised feature prioritization and importance
    - High-level functionality
    - Clear, concise technical language
    - Objective description
    - Capture entire workflow

    Guidelines:
    - Only use the folder wise summary provided
    - Use precise technical terms
    - Include user-defined features if provided and evidenced in the code
    - Prioritize features based on their importance to the core problem, as shown in the folder wise summary

    Feature Identification and Prioritization:
    - Carefully analyze the folder wise summary to identify features actually present in the folder wise summary
    - Do not assume or infer features that are not explicitly mentioned in the folder wise summary
    - Identify the top feature that solves the majority of the problem based on code evidence
    - Rank subsequent features in descending order of importance, ensuring they are present in the folder wise summary
    - Ensure the feature list reflects the codebase's focus and structure
    - Only include features that have substantial implementation in the codebase that is evident from folder wise summary

    Output Format - Adhering to this format is crucial
    ```json
    {
    "data": "generated_summary in string format adhering to the Expected Output Format for Generated Summary",
    "confidence_score": 90,
    "traceback": {
    "Feature 1 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 1 Title' is included, as the 'phrase' is an evidence that this feature is part of the codebase.",
    "Feature 2 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 2 Title' is included, as the 'phrase' is an evidence that this feature is part of the codebase.",
    ...
    }
    }
    ```

    Requirements:
    - Replace \n with \\n in JSON
    - Limit upto 5 main features (max 2 sub-features each) or 7500 tokens
    - If due to any reason such as codebase being small, you are unable to provide 5 features, then provide as many high-level features as possible between the range of 1 to 5.
    - Don't assume features or include minor features due to inability to provide 5 features, lesser number of features is acceptable.
    - Use specified JSON format only
    - Start with "```json" and end with "```"
    - Ensure the top feature in the prioritized list addresses the core problem and is present in the folder wise summary
    - Rank features in descending order of importance to the main problem, based on actual code implementation
    - Do NOT include features that are NOT evidenced in the provided folder wise summary
    - Evaluate the folder wise summary objectively, considering all conclusions on the actual code provided
    - Do NOT make any assumptions about organizational goals or intentions beyond what is explicitly shown in the code
    - Focus solely on the technical aspects and implemented functionality, avoiding speculation about business objectives or future plans
    - Both the keys data, confidence score, and traceback should be present in the output JSON
    - The generated summary should be in string format only and be contained inside the "data" key
    - The "traceback" key should contain a dictionary with feature names as keys and justifications for including these features based on exact phrases from the input
    - Do not include any feature that could potentially be part of the folder wise summary without explicit evidence
    - Every feature mentioned must be driven by clear evidence from the provided input
    """
    user_prompt = """
    Expected Output Format for Generated Summary:

  **Overview**
  <empty line>
  <A brief introduction to the codebase and its main purpose; in paragraph format only, not in points.
  This paragraph should provide a concise yet comprehensive overview of the codebase, its primary functionality, solution provided by the project and its intended use case.
  Aim for 3-5 sentences that capture the essence of the project.>
  <empty line>
  **Highlighted Features**
  <empty line>
  <
  List and briefly explain the key features that are significant components of the codebase and would serve as selling points.
  These features should be presented as follows:
  1. Use numbered points for each feature.
  2. Provide a brief explanation for each feature in 1-2 sentences, highlighting its importance and benefit to the end user.
  3. Focus on features that are central to the codebase's functionality and most important to the end user.
  4. Dont include generic features like "Modular Architecture" or "Code Reusability", these are not features but design principles.
  5. Do not include sub-points under any feature.
  6. Prioritize User Defined Features (if provided) at the beginning of the list.
  7. If User Defined Features are given, list them first before including any features identified through your analysis.
  8. Aim to provide upto of 1 to 5 key features, after each feature add an empty line for formatting purposes.
  9. Ensure that the features listed represent the core functionality and unique selling points based on the folder wise summary.
  10. Use clear, concise language that emphasizes the value proposition of each feature.
  11. Also under each feature, mention which file/folder was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
  12. Do not add features into Highlighted Features if they dont have value for buisness stakeholder about the application. Also do not repeat adding similar feature in this section.

  Output Structure:
  1. ***<Feature 1 Title>***: <Description of the feature in one to two sentences.\n
  2. ***<Feature 2 Title>***: <Description of the feature in one to two sentences.>\n
  >
  <empty line>
  **Key Benefits**
  <empty line>
  <Summarize the key benefits of the codebase in one to two sentences.
  This summary should encapsulate the overall value proposition of the codebase and its potential impact on users or the organization.>
  <empty line>
  <Highlight the most significant key benefits the codebase has to offer in bulleted points. The format should be:
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  Aim for 3-5 bullet points that capture the most compelling advantages of using this codebase, after each point add an empty line for formatting purposes.
  Each benefit should be distinct and provide a clear value proposition.>

  <Final Output Format>
  Output Format - Adhering to this format is crucial, the output should be in parsable JSON format:
  ```json
  {{
    "data": "<generated_summary in string format adhering to the Expected Output Format for Generated Summary>",
    "confidence_score": 90,
    "traceback": {{
      "Feature 1 Title": "Since it mentions about <exact phrase from the folder wise summary>, the 'Feature 1 Title' is included, as the "phrase" is an evidence that this feature is part of the folder wise summary.",
      "Feature 2 Title": "Since it mentions about <exact phrase from the folder wise summary>, the 'Feature 2 Title' is included, as the "phrase" is an evidence that this feature is part of the folder wise summary.",
      ...
    }}
  }}
  ```
  </Final Output Format>
  Note: If the traceback includes phrases that are not present in the folder wise summary then you would be penalized 10000 points.
  The output should be having data, confidence score, and traceback keys, and the entire content inside "```json" and "```" should be parsable by json.
  The "data" key should contain the generated summary and it should be in string format only, allowing the parsing of the entire json.
  If there are any inverted commas inside the generated summary, then escape them with a backslash.
  Do not change or skip the headings of each section in the generated json. The generated summary must have "Overview", "Highlighted Features", "Key Benefits" as section titles. Follow the above provided guidelines."""
    user_prompt += f"""Use the below folder wise summary to generate the summary in the above format: {combined_summary}""" + "User Defined Features : " + str(user_mvf)
    return system_prompt, user_prompt

def db_executive_summary_generation(combined_summary, user_mvf): 
    system_prompt = """
    Role:
    You are an expert Database Architect tasked with understanding the contents of all tables and schema of the database. 
    You shall Articulate a proper executive summary that clearly captures all the main & high-level features of this database.
    The core use-case that this database is intended for, and the prioritized list of the most valuable features, solely based on the provided Table-Level summaries. 
    Do not hallucinate. Do NOT create the most valuable features and its description on pure assumptions. This needs to be based on facts, with proper backing.

    Task:
    1. Analyze provided Table wise summaries.
    2. Understand component interactions and functions.
    3. Prioritize the User Defined Features (if provided) in the summary.
    4. Identify and prioritize the most valuable features based on their importance to the core use-case the Database is solving.
    5. Create a comprehensive executive summary.

    Steps:
    1. Review Table wise summary.
    2. Analyze Table wise summary:
      - Identify all tables. 
      - Take into consideration the foreign keys, primary keys, is-a, has-a, and many-to-many relationships.
      - Deeply understand the intended-use-case of each table.
      - Note data operations, design patterns, and architectural decisions
    3. Create summary:
      - Describe the specific problem the Database is solving, based on Table wise summary
      - Explain high-level interactions and dependencies
      - Outline data workflow
    4. Identify and prioritize main features:
      - Determine which feature(s) address the core problem of the Database, based on SQL implementation and Table wise summary
      - Rank features based on their importance and relevance to solving the main problem, as evidenced in the Database
      - The feature should be major components of the Database and not minor functions like Many-to-Many Relationships, or "Foreign Keys". 
        These are implementation concepts. Not core features.

    Focus Areas:
    - Precised feature prioritization and importance
    - High-level functionality of this Database
    - Clear, concise technical language with Database-specific Language
    - Objective description
    - Capture entire data workflow

    Guidelines:
    - Only use the Table wise summary provided
    - Use precise Database-relevant technical terms
    - Include user-defined features if provided and evidenced in the Table wise summary
    - Prioritize features based on their importance to the core problem, as shown in the Table wise summary

    Feature Identification and Prioritization:
    - Carefully analyze the Table wise summary to identify features actually present in the Table wise summary
    - Do not assume or infer features that are not explicitly mentioned in the Table wise summary
    - Identify the top feature that solves the majority of the problem based on Database and SQL evidence
    - Rank subsequent features in descending order of importance, ensuring they are present in the Table wise summary
    - Ensure the feature list reflects the Database's focus and structure
    - Only include features that have substantial implementation in the Database that is evident from Table wise summary

    Output Format - Adhering to this format is crucial
    ```json
    {
    "data": "generated_summary in string format adhering to the Expected Output Format for Generated Summary",
    "confidence_score": 90,
    "traceback": {
    "Feature 1 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 1 Title' is included, as the 'phrase' is an evidence that this feature is part of the Database.",
    "Feature 2 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 2 Title' is included, as the 'phrase' is an evidence that this feature is part of the Database.",
    ...
    }
    }
    ```

    Requirements:
    - Replace \n with \\n in JSON
    - Limit upto 5 main features (max 2 sub-features each) or 7500 tokens
    - If due to any reason such as Database being small, you are unable to provide 5 features, then provide as many high-level features as possible between the range of 1 to 5.
    - Don't assume features or include minor features due to inability to provide 5 features, lesser number of features is acceptable.
    - Use specified JSON format only
    - Start with "```json" and end with "```"
    - Ensure the top feature in the prioritized list addresses the core problem and is present in the Table wise summary
    - Rank features in descending order of importance to the main problem, based on actual Database and SQL implementation
    - Do NOT include features that are NOT evidenced in the provided Table wise summary
    - Evaluate the Table wise summary objectively, considering all conclusions on the actual Database and SQL provided
    - Do NOT make any assumptions about organizational goals or intentions beyond what is explicitly shown in the Database and SQL
    - Focus solely on the technical aspects and implemented functionality, avoiding speculation about business objectives or future plans
    - Both the keys data, confidence score, and traceback should be present in the output JSON
    - The generated summary should be in string format only and be contained inside the "data" key
    - The "traceback" key should contain a dictionary with feature names as keys and justifications for including these features based on exact phrases from the input
    - Do not include any feature that could potentially be part of the Table wise summary without explicit evidence
    - Every feature mentioned must be driven by clear evidence from the provided input.
    - Strictly use an assertive and objective tone in your response. 
    - Do not be unsure about anything.
    - Do not include the "Folder Name" in your response. Ignore "dbanalysis" folder. Provide Executive Summary of the Database-ONLY.
    """

    user_prompt = """
  Expected Output Format for Generated Summary:

  **Overview**
  <empty line>
  <A brief introduction to the Database and its main purpose; in paragraph format only, not in points.
  This paragraph should provide a concise yet comprehensive overview of the Database, its primary functionality, and its intended use case.
  Aim for 3-5 sentences that capture the essence of the Database.>
  <empty line>
  **Highlighted Features**
  <empty line>
  <
  List and briefly explain the key features that are significant components of the Database and would serve as selling points.
  These features should be presented as follows:
  1. Use numbered points for each feature.
  2. Provide a brief explanation for each feature in 1-2 sentences, highlighting its importance and benefit to the END USER.
  3. Focus on features that are central to the Database's functionality and most important to the END USER.
  4. Dont include generic features like  Many-to-Many Relationships, or "Foreign Keys", these are not features but Design Principles.
  5. Do not include sub-points under any feature.
  6. Prioritize User Defined Features (if provided) at the beginning of the list.
  7. If User Defined Features are given, list them first before including any features identified through your analysis.
  8. Aim to provide upto of 1 to 5 key features, after each feature add an empty line for formatting purposes.
  9. Ensure that the features listed represent the core functionality and unique selling points based on the Table wise summary.
  10. Use clear, concise language that emphasizes the value proposition of each feature.
  11. Also under each feature, mention which file/Table was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
  12. Do not add features into Highlighted Features if they dont have value for buisness stakeholder about the application. Also do not repeat adding similar feature in this section.

  Output Structure:
  1. ***<Feature 1 Title>***: <Description of the feature in one to two sentences.\n
  2. ***<Feature 2 Title>***: <Description of the feature in one to two sentences.>\n
  >
  <empty line>
  **Key Benefits**
  <empty line>
  <Summarize the key benefits of the Database in one to two sentences.
  This summary should encapsulate the overall value proposition of the Database and its potential impact on users or the organization.>
  <empty line>
  <Highlight the most significant key benefits the Database has to offer in bulleted points. The format should be:
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  Aim for 3-5 bullet points that capture the most compelling advantages of using this Database, after each point add an empty line for formatting purposes.
  Each benefit should be distinct and provide a clear value proposition.>

  <Final Output Format>
  Output Format - Adhering to this format is crucial, the output should be in parsable JSON format:
  ```json
  {{
    "data": "<generated_summary in string format adhering to the Expected Output Format for Generated Summary>",
    "confidence_score": 90,
    "traceback": {{
      "Feature 1 Title": "Since it mentions about <exact phrase from the Table wise summary>, the 'Feature 1 Title' is included, as the "phrase" is an evidence that this feature is part of the Table wise summary.",
      "Feature 2 Title": "Since it mentions about <exact phrase from the Table wise summary>, the 'Feature 2 Title' is included, as the "phrase" is an evidence that this feature is part of the Table wise summary.",
      ...
    }}
  }}
  ```
  </Final Output Format>
  Note: If the traceback includes phrases that are not present in the Table wise summary then you would be penalized 10000 points.
  The output should be having data, confidence score, and traceback keys, and the entire content inside "```json" and "```" should be parsable by json.
  The "data" key should contain the generated summary and it should be in string format only, allowing the parsing of the entire json.
  If there are any inverted commas inside the generated summary, then escape them with a backslash.
  Do not change or skip the headings of each section in the generated json. The generated summary must have "Overview", "Highlighted Features", "Key Benefits" as section titles. Follow the above provided guidelines.
    """

    user_prompt += f"""Use the below Table wise summary to generate the summary in the above format: {combined_summary}""" + "User Defined Features : " + str(user_mvf)

    return system_prompt, user_prompt


def architecture_diagram_generation(services_data, icons_metadata):
    user_prompt = f"""
    <Input>
    $services_data = {services_data}
    $icons_metadata
    </Input>

    <Role>
    You are an expert at understanding large projects based on their executive summary and the services being used in them. Create a JSON structure for a ReactFlow diagram based on the given service class JSON.
    </Role>

    <Output Structure>
    1. Create a JSON object with a "nodes" and "edges" array.
    2. Create nodes for each external and third-party service.
    3. "nodes": An array containing all node objects.
      - "id": A unique string identifier for the node.
      - "data":   
        - "label": The name of the node.
        - "description": Description of the service.
        - "associated_files": Associated file and used in files in the service node, defaulting to "No File Available" if not present.
        - "group": The logical group name (e.g., 'Backend', 'Frontend', 'Database',etc..).
        - "subgroup": The specific subgroup within the group (e.g., Frameworks, NoSQL Databases, State Management, etc.).
        - "service": The appropriate filename of the icon based on the $icons_metadata.
      - "position" : The x and y coordinates of the node.
      - "type" : "customNode" This should be fixed.
    4. "edges" : An array having id, source, target, label, and type should be customEdge always.
    4. Ensure all services and files from the input JSON are included.
    5. The output should be in the form of a dictionary containing a "nodes" and "edges" array.
    6. Present only the code inside delimiters "```reactflow [reactflow CODE]```" without any additional explanation.
    """

    system_prompt:str = """
    <Task>
      You are tasked with creating a JSON structure for a ReactFlow diagram based on the given executive summary and the service_class_json. The executive summary contains an overview of the entire project. This JSON includes information about external services and third-party services, along with their associated files. Your output should represent this information as a network of nodes and edges.
    </Task>
    
    <Icons Context>
      $icons_metadata = """ + str(icons_metadata) + """
    </Icons Context>

    <Instructions>
      You are a solution expert, specializing in problem and solution flows. You will be given the solution overview for a project, and your task is to create an interconnected single component of graph which is detailed, and intuitive and self explanatory for:

      Follow these guidelines:
      1. Create nodes for each unique service (both external and third-party).
      2. Do not create any group nodes.
      4. In the data key for each service node, include two additional fields called group and subgroup. The group field should contain the logical group name (e.g., Frontend, Backend, Databases, etc..), and the subgroup field should provide more specific categorization (e.g., Frameworks, NoSQL Databases, etc..). For example, for a service node representing React, the group would be Frontend and the subgroup would be Frameworks.
      5. For each node, check which icon will be the most suitable from the $icons_metadata in the <Icons Context>
      6. Ensure all information from the input is represented in the output.
      7. The position coordinates must be proper for all the nodes.
    </Instructions>

    <Rules>
      **Ensure all nodes in the generated graph are interconnected such that every node has at least one edge, forming a single connected component without any isolated or disjoint sections. (High Priority Requirement)**
      Important Rules to be followed:
      1. Give detailed technical architecture flow and the JSON object following the below output format.
      2. Make sure that the flow and order of new solution approach is explained well in the graph with appropriate edges. Use as many edges you want to describe the data and user flow properly.
      3. The whole user and data flow should be clear.
      4. Do not add unnecessary nodes and edges. Do not create duplicate nodes that perform same task.
      5. Make the Node descriptions detailed, breaking tasks into multiple sub-tasks if needed.
      6. Ensure your edges show the actual flow, and not just connections of what's related. The connections are meant to show the logical flow, and not the relatedness/similarity.
      7. The group name is meant to classify clusters of nodes within each graph. For instance, if we have multiple nodes in features, they would all have "feature" as group. In Architecture Flow, the "Group" should show the layer each node is in, for instance "Backend Layer", "Database Layer" etc.
      9. for a hierarchy of nodes A -> B -> C; ensure that there is not a connection between A -> C.
    </Rules>
    
    <output_format>
    The output should be in between the delimeters ```reactflow and ```. Only provide the json output. Don't give unnecesary explanation.
    ```reactflow
    {
      "nodes": [
        { 
          "id": "unique_node_identifier_string",
          "data" : {
            "label": "name_of_the_service",
            "description": "description of the service",
            "associated_files": ["file_path_1", "file_path_2", "file_path_3", etc.],  // (default: ["No File Available"] if not present)
            "group": "name_of_group",  // Add the logical group name (e.g., "Frontend", "Backend", etc..)
            "subgroup": "name_of_subgroup",  // Add a more specific subgroup name (e.g., "Frameworks", "NoSQL Databases", etc..)
            "service": "filename" //taken from the $icons_metadata,
          }
          "position":{ "x": "Xcoordinate", "y": "Ycoordinate" },
          "type" : "customNode" //this is hardcoded and will be constant
        }
      ],
      "edges": [
        {
          "id": "unique_egde_identifier_string",
          "source": "label A",
          "target": "label B",
          "label": "Showcase what comes from the source node, to the target node. Be concise and specific with labels, such as 'Ingested Data', 'Converted Text', 'User Query' etc. Use at max 5 words",
          "type" : "customEdge" //this is hardcoded and will be constant
        }
      ]
    }```
    </output_format>
    """
    return system_prompt, user_prompt
  

def erd_generation(services_data, icons_metadata):
  tables_metadata = []
  for entry in services_data:
      table_name = entry["table_name"]
      ddl = entry["ddl"]
      columns, primary_keys, foreign_keys = parse_ddl(ddl)
      tables_metadata.append({
          "table_name": table_name,
          "columns": columns,
          "primary_keys": primary_keys,
          "foreign_keys": foreign_keys
      })

  dot = generate_combined_graph(tables_metadata)

  system_prompt:str = """
    You are tasked with creating a JSON structure for a ReactFlow diagram based on the given database ER diagram and schema JSON. This JSON includes information about database columns and their relationships.Your output should represent this information as a network of nodes and edges.
    </Task>
    
    <Icons Context>
      $icons_metadata = """ + str(icons_metadata) + """
    </Icons Context>

    <Instructions>
      You are a solution expert, specializing in problem and solution flows. You will be given the database schema information of a database, and your task is to create an interconnected single component of graph which is detailed, and intuitive and self explanatory for:

      Follow these guidelines:
      1. Create nodes for each unique service (both external and third-party).
      2. Do not create any group nodes.
      4. In the data key for each service node, include two additional fields called group and subgroup. The group field should contain the logical group name (e.g.,Databases, etc..), and the subgroup field should provide more specific categorization (e.g., 'Transactional Tables', 'Reference Tables' etc..). For example, for a service node representing daily transactions, the group would be Database and the subgroup would be Transactional Tables.
      5. For each node, check which icon will be the most suitable from the $icons_metadata in the <Icons Context>
      6. Ensure all information from the input is represented in the output.
      7. The position coordinates must be proper for all the nodes.
    </Instructions>

    <Rules>
      Important Rules to be followed:
      1. Give detailed technical architecture flow and the JSON object following the below output format.
      2. Make sure that the flow and order of new solution approach is explained well in the graph with appropriate edges. Use as many edges you want to describe the data and user flow properly.
      3. The whole user and data flow should be clear.
      4. Do not add unnecessary nodes and edges. Do not create duplicate nodes that perform same task.
      5. Make the Node descriptions detailed, breaking tasks into multiple sub-tasks if needed.
      6. Ensure your edges show the actual flow, and not just connections of what's related. The connections are meant to show the logical flow, and not the relatedness/similarity.
      7. The group name is meant to classify clusters of nodes within each graph. For instance, if we have multiple nodes in features, they would all have "feature" as group. In Architecture Flow, the "Group" should show the layer each node is in, for instance "Database Layer" etc.
      9. for a hierarchy of nodes A -> B -> C; ensure that there is not a connection between A -> C.
    </Rules>
    
    <output_format>
    The output should be in between the delimeters ```reactflow and ```. Only provide the json output. Don't give unnecesary explanation.
    ```reactflow
    {
      "nodes": [
        { 
          "id": "unique_node_identifier_string",
          "data" : {
            "label": "name_of_the_table",
            "description": "description of the table",
  	    "columns": ["order_id [PK]", "product_sku [PK]", "quantity", "unit_price"]
            "group": "name_of_group",  // Add the logical group name (e.g., "Database", etc..)
            "subgroup": "name_of_subgroup",  // Add a more specific subgroup name (e.g., 'Transactional Tables', 'Reference Tables', etc..)
            "service": "filename" //taken from the $icons_metadata,
          }
          "position":{ "x": "Xcoordinate", "y": "Ycoordinate" },
          "type" : "customNode" //this is hardcoded and will be constant
        }
      ],
      "edges": [
        {
          "id": "unique_egde_identifier_string",
          "source": "label A",
          "target": "label B",
          "label": "Showcase what comes from the source node, to the target node. Be concise and specific with labels, such as 'Ingested Data', 'Converted Text', 'User Query' etc. Use at max 5 words",
          "type" : "customEdge" //this is hardcoded and will be constant
        }
      ]
    }```
    </output_format>
    """
    
  user_prompt:str = f"""
    <Input>
    $database_tables = {dot}
    $icons_metadata
    </Input>

    <Role>
    You are an expert at understanding database architecture based on ER diagrams and relational structures. Create a JSON structure for a ReactFlow diagram based on the given database schema.
    </Role>
    <Output Structure>
      1. Create a JSON object with a "nodes" and "edges" array.
      2. Create nodes for each table in the schema.
      3. "nodes": An array containing all node objects.
      - "id": A unique string identifier for the node.
      - "data":  
        - "label": The name of the table.
        - "description": A brief summary of the table's role or content.
        - "columns": List of column names (mark primary keys with [PK], foreign keys with [FK]).
        - "group": The logical group name (e.g., 'Database').
        - "subgroup": The specific subgroup within the group (e.g., 'Transactional Tables', 'Reference Tables').
        - "service": The appropriate filename of the icon based on the $icons_metadata.
      - "position" : The x and y coordinates of the node.
      - "type" : "customNode" This should be fixed.
      4. "edges" : An array having id, source, target, label, and type should be customEdge always.
      5. The label of the edge should describe the relationship, like "order_id â†’ order_id". 
      6. The output should be in the form of a dictionary containing a "nodes" and "edges" array.
      7. Present only the code inside delimiters "```reactflow [reactflow CODE]```" without any additional explanation.
    """
    
  return system_prompt, user_prompt
    

def feature_summary_generation(formatted_data, user_mvf, executive_summary):
    # if input_type is None:
    #     formatted_data = file_summary_list
    # elif input_type == "batch_summary":
    #     formatted_data = format_batchwise_summary_metadata_for_services(file_summary_list)
    # else:
    #     formatted_data = format_file_summaries(file_summary_list)

    user_prompt = """
    Role: You are an AI code analyst specializing in creating concise, feature-level summaries of codebases.

    Objective: Provide a comprehensive yet concise feature-level summary of a given codebase, highlighting key components, functionality, and the project's overall workflow.

    Input: You will receive information about a codebase, which may include an executive summary or other project details.

    Steps:
    1. Analyze the provided codebase information.
    2. Identify the main features (maximum 5) of the project from the executive summary (if provided in same order)
    3. Create a summary following the specified format, including:
        a. An overview of the project
        b. A list of key features with brief descriptions
        c. A closure statement
    4. Self-evaluate the generated summary and assign a confidence score.
    5. Format the output as specified in the instructions.

    Output Format:
    ```json
    {
        "data": "generated_summary in string format adhering to the Detailed Instructions for Output Format",
        "confidence_score": 90
    }
    ```

    Detailed Instructions for Output Format:

    **Overview**
    <empty line>
    < 
        Summarize all features in 2-3 sentences, introducing the project and its purpose.
        Provide a 2-3 sentence summary of key benefits, highlighting core architecture and value proposition.
    >
    <empty line>
    **Key Features**
    <empty line>
    <   
        List a maximum of 5 main features.
        For each feature, provide up to 2 sub-points describing its functionality.
        Ensure clear explanation of how features interact and contribute to the project's goals.
        1. ***<Key Feature Title>*** : 
        * <Sub point 1 description>
        * <Sub point 2 description>
        <empty line>
    >
    <empty line>
    < 
        Summarize the overall impact and value proposition of the project in one sentence as a conclusion statement.
    >
    <empty line>
    
    -> Self-Evaluation:
        - Score the summary out of 100 based on clarity, precision, detail, knowledge, accuracy, technical correctness, and understanding of the data.

    -> Formatting Requirements:
        - Replace all newline characters (\n) with \\n in the JSON output.
        - Ensure the complete JSON is less than 7500 tokens.
        - Start the output with "```json" and end with "```".
        - If an executive summary is provided, use only the highlighted features from it.

    Example Output Structure:
    ```json
    {
        "data": "**Overview**\\n\\n[Project overview]\\n\\n[Benefits summary]\\n\\n**Key Features**\\n\\n1. *Feature 1*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n2. *Feature 2*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n[...continue for up to 5 features...]\\n\\n[Closure statement]",
        "confidence_score": 90
    }
    ```

    Remember: Adhere strictly to the output format and instructions to maintain consistency and accuracy in your summary.
    """

    user_prompt += "User Defined Features : " + str(user_mvf)

    system_prompt = f"""
        <role>
        You are an assistant to a Senior Software Engineer. You are very capable in reading and understanding huge codebases.
        There is no edge-case, no mistake, no functionality no matter how small goes unnoticed by you.
        You will be given a large codebase and be asked queries regarding it.
        </role>

        <Task>
        You will be given relevant files from a production codebase. The Senior Engineer will consult you to clear his doubts and ask for critical code-level and functionality level analysis of the same.
        <Important>
        1. You will be clear. Feel free to be descriptive but Avoid Jargon
        2. You shall perform critical analysis on the code before responding.
        3. Note that the codebase will be quite complex and have dependencies everywhere, be mindful of them all.
        4. Enclose code in (triple backticks)``` code ```
        </Important>
        </Task>

        Files from Codebase goes here :
        <Repo Structure>
        {formatted_data}
        </Repo Structure>
    """

    start_index = executive_summary.find("Highlighted Features")
    end_index = executive_summary.find("Key Benefits")

    if start_index != -1 and end_index != -1:
        executive_summary = executive_summary[start_index:end_index].strip()

    user_prompt += "Executive Summary : " + str(executive_summary)

    return system_prompt, user_prompt

def feature_summary_generation_db(formatted_data, user_mvf, executive_summary):
    # if input_type is None:
    #     formatted_data = file_summary_list
    # elif input_type == "batch_summary":
    #     formatted_data = format_batchwise_summary_metadata_for_services(file_summary_list)
    # else:
    #     formatted_data = format_file_summaries(file_summary_list)

    user_prompt = """
    Role: You are an AI Database Analyst specializing in creating concise, feature-level summaries of complex database schemas and architectures.

    Objective: Provide a comprehensive yet concise feature-level summary of a given database schema information, highlighting key components, entities, relationships, and the overall data architecture workflow.

    Input: You will receive information about a database design, which may include an executive summary or other schema-level details.

    Steps:
    1. Analyze the provided database schema information.
    2. Identify the main features (maximum 5) of the database from the executive summary (if provided in same order)
    3. Create a summary following the specified format, including:
        a. An overview of the database
        b. A list of key features with brief descriptions
        c. A closure statement
    4. Self-evaluate the generated summary and assign a confidence score.
    5. Format the output as specified in the instructions.

    Output Format:
    ```json
    {
        "data": "generated_summary in string format adhering to the Detailed Instructions for Output Format",
        "confidence_score": 90
    }
    ```

    Detailed Instructions for Output Format:

    **Overview**
    <empty line>
    < 
        Summarize all features in 2-3 sentences, introducing the database and its purpose.
        Provide a 2-3 sentence summary of key benefits, highlighting schema structure, normalization or denormalization logic, and value proposition in handling data.
    >
    <empty line>
    **Key Features**
    <empty line>
    <   
        List a maximum of 5 main features.
        For each feature, provide up to 2 sub-points describing its data handling, relationships, or optimization logic.
        Ensure clear explanation of how features contribute to performance, consistency, and data integrity.
        1. ***<Key Feature Title>*** : 
        * <Sub point 1 description>
        * <Sub point 2 description>
        <empty line>
    >
    <empty line>
    < 
        Summarize the overall impact and value proposition of the database in one sentence as a conclusion statement.
    >
    <empty line>
    
    -> Self-Evaluation:
        - Score the summary out of 100 based on clarity, precision, detail, knowledge, accuracy, technical correctness, and understanding of the schema information.

    -> Formatting Requirements:
        - Replace all newline characters (\n) with \\n in the JSON output.
        - Ensure the complete JSON is less than 7500 tokens.
        - Start the output with "```json" and end with "```".
        - If an executive summary is provided, use only the highlighted features from it.

    Example Output Structure:
    ```json
    {
        "data": "**Overview**\\n\\n[Database overview]\\n\\n[Benefits summary]\\n\\n**Key Features**\\n\\n1. *Feature 1*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n2. *Feature 2*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n[...continue for up to 5 features...]\\n\\n[Closure statement]",
        "confidence_score": 90
    }
    ```

    Remember: Adhere strictly to the output format and instructions to maintain consistency and accuracy in your summary.
    """

    user_prompt += "User Defined Features : " + str(user_mvf)

    system_prompt = f"""
        <role>
        You are an assistant to a Senior Data Architect. You are very capable in reading, analyzing, and understanding complex database schemas and data models.
        No entity, constraint, relationship, or optimization logic goes unnoticed by you.
        You will be given a comprehensive database structure or schema information and will be asked to analyze, explain, and summarize it at a structural and functional level.
        </role>

        <Task>
        You will be given relevant database schema files or DDL definitions. The Senior Data Architect will consult you to clear doubts and ask for critical schema-level and data model-level analysis.
        <Important>
        1. You will be clear. Feel free to be descriptive but Avoid Jargon
        2. Perform a critical and deep analysis of the schema and the information given before responding.
        3. The schema will often involve multiple tables, foreign keys, views, procedures, and indexing strategies â€” be mindful of their dependencies and relationships.
        4. Enclose code or schema in (triple backticks)``` code ```
        </Important>
        </Task>

        Files from Database schema goes here :
        <Database Structure>
        {formatted_data}
        </Database Structure>
    """

    start_index = executive_summary.find("Highlighted Features")
    end_index = executive_summary.find("Key Benefits")

    if start_index != -1 and end_index != -1:
        executive_summary = executive_summary[start_index:end_index].strip()

    user_prompt += "Executive Summary : " + str(executive_summary)

    return system_prompt, user_prompt


#FEATURE HIERARCHY:
generate_features_system_prompt = """
  <Role>
    You are a Software Architect with expertise in analyzing large summaries from code files of an application. 
    You can comprehend summaries from code files that are complex, production-grade and are written in various programming languages to generate most important features, their description and the subfeatures with their description belonging to the most important features along with the other relevant information requested below.
    
    You will follow 2 Events before responding : 
    1. Generation of Feature Hierarchy as given in "Output_Format".
    2. Critical Evaluation of Every Confidence Score.  
  </Role> 

    <Task 1>
    You are provided with multiple relative file paths and file-wise code summaries from a application codebase.
    1. Analyze the file summaries carefully, leveraging your expertise to deduce the frameworks, functionality, and features.
    2. Perform a critical assessment of the code's functionality and interdependencies before responding.
    3. The codebase is complex and likely contains dependencies across various modules. Be mindful of these.
    4. Analyse every file summary and assign the features and sub-features based on the information provided.
    5. Respond strictly in the structured JSON format provided below.
    6. In each sub-feature's 'file_path' array:
        - Set 'critical: true' ONLY for files that are CORE & NON-REPLACEABLE to the sub-feature's main functionality.
        - Set 'critical: false' for ALL supporting, secondary, or replaceable files  
        - Each sub-feature should have both true and false entries.
        - If unsure, default to false (be EXTREMELY selective with 'true')
        - Make sure each sub-feature atleast have one file as true.

    Explanation of the Output terms:
    Feature - Features are most valuable and high level features extracted from the list of summaries that are provided to you. 
    Feature description - Description of the features explaining the high level value and impact that it creates for the project. Define the Feature. The description should be crisp, precise, well formatted and must be between 2-3 lines.
    Subfeature - Subfeatures are micro most valuable features that are extracted from the list of summaries and belong to the Most related and similar Features.
    Subfeature description - Description of the subfeatures explaining the specific value, technical and non-technical functionalites that it provided to the project. Define the subfeature and also explain how its related to the feature. The description should be crisp, precise, well formatted and must be between 2-3 lines.
    
    Points to Remember:
    1. Do not extract any feature or subfeature where there are no reference/citations from the application summaries.
    2. The description must be precise, valuable, well-formatted and must be between 2-3 lines.
    3. The Feature titles should be precise, specific, self explanaible, independent and not have similar feature titles. The Feature titles should not be highly generalized.
    4. The SubFeatures titles should be precise, self explanaible and not have similar subfeature titles. The SubFeature titles should not be highly generalized.
    5. SubFeatures should not be very low level that it explains code functions, code process like 'Json handling', 'Reading csv', readME etc.
    6. If similar subfeatures are present, then group them under one common Feature itself. Do not create multuple Features for similar subfeatures.
    6. If Unit testing related summaries are found, then create that as another Feature named 'Unit Testing' and assign the specific testing subfeatures under this feature.
    </Task 1>

  <Task 2>
  You shall now Assign and Justify Confidence Scores for each feature.

  <Critical Evaluation of Confidence Scores> 

  <Evaluation MODE>
  - You will now Forget everything that was done beforehand and act as an unbiased judge.
  - $Project-Summaries-&-Paths (INPUT).
  </Evaluation MODE>
  <Important>
  Critically analyze every "Feature" and "SubFeature" based on the following metrics. 
  You shall generate a confidence score between 0-100 for each of the following :
  1. Is the "Feature" & "SubFeature" name accurate to its functionality ? (Accuracy)
  2. Does the "Feature" & "SubFeature" include files with an unrelated function ? (Feature Dilution Rate)
  3. Important : Does this "Feature" & "SubFeature" make sense given the Overall Purpose of the Application ? (Consistency)
  4. Are all the files in "Feature" & "SubFeature" included ? (Completeness)

  <Strict>
  1. You will now generate a list of 4 confidence scores between 0-100 for above criteria under "confidence_score" key.
  2. Based on above criteria, you shall provide a VERY BRIEF logical explanation (10-20 words) for Confidence Score under "confidence_score_justification" key.
  3. Make sure to mention the entire filepath without omitting the prefix.
  4. Make sure all the filepaths are present.
  <Important> STRICTLY Don't Comment on Missing Files. Don't Overestimate. Don't Underestimate.</Important> 
  </Strict>

  </Important>

  </Critical Evaluation of Confidence Scores> 
  </Step 2>


      <Output_Format>
    Return a response in JSON format. Do not include any extra information or explanations. Strictly DON'T deviate from mentioned KEYS.
    Example:
```json
[
  {
    "name": "User Authentication and Management",
    "feature_description": "Comprehensive user account system with secure login, registration, profile management, and role-based access control.",
    "feature_description_confidence_score": [95, 70, 100, 70],
    "sub_features": [
      {
        "name": "User Registration",
        "description": "Allows new users to create accounts by providing necessary information such as username, email, and password. Implements email verification, password strength checks, and duplicate account prevention. Stores user data securely in the database with password hashing.",
        "file_path": [
          {
            "module_name": "RegistrationController",
            "path": "Controllers/Account/RegistrationController.cs",
            "critical": true
          },
          {
            "module_name": "RegisterView",
            "path": "Views/Account/Register.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [75, 80, 85, 65],
        "sub_feature_confidence_score_justification": "No feature dilution, might have missed some file."
      },
      {
        "name": "User Login",
        "description": "Authenticates users using their credentials, creates and manages user sessions, and implements security measures such as login attempt limiting and two-factor authentication (2FA). Provides password reset functionality for forgotten passwords.",
        "file_path": [
          {
            "module_name": "LoginController",
            "path": "Controllers/Account/LoginController.cs",
            "critical": true
          },
          {
            "module_name": "LoginView",
            "path": "Views/Account/Login.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [80, 100, 80, 75],
        "sub_feature_confidence_score_justification": "High chance of missing files."
      }
    ],
    "feature_confidence_score_justification": "No feature dilution, duplication or missing files. Accurate Naming."
  },
  {
    "name": "Product Catalog Management",
    "feature_description": "Comprehensive system for managing product listings, categories, and inventory across the e-commerce platform.",
    "feature_description_confidence_score": [95, 65, 70, 80],
    "sub_features": [
      {
        "name": "Product CRUD Operations",
        "description": "Enables administrators to create, read, update, and delete product listings. Includes functionality for managing product details such as name, description, price, images, and inventory levels. Implements validation to ensure data integrity and consistency across the product catalog.",
        "file_path": [
          {
            "module_name": "ProductController",
            "path": "Controllers/ProductController.cs",
            "critical": true
          },
          {
            "module_name": "ProductView",
            "path": "Views/Product/Index.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [90, 85, 100, 70],
        "sub_feature_confidence_score_justification": "High confidence with no duplication or dilution."
      },
      {
        "name": "Category Management",
        "description": "Allows for the creation and management of product categories and subcategories. Implements a hierarchical structure for organizing products, enabling efficient navigation and filtering of the product catalog for both administrators and customers.",
        "file_path": [
          {
            "module_name": "CategoryController",
            "path": "Controllers/CategoryController.cs",
            "critical": true
          },
          {
            "module_name": "CategoryView",
            "path": "Views/Category/Index.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [85, 75, 90, 95],
        "sub_feature_confidence_score_justification": "High confidence without any duplication or dilution."
      }
    ],
    "feature_confidence_score_justification": "All files refer to single overall functionality. Might have missed some files."
  }
]
```
  </Output_Format>

"""

generate_features_user_message = """
<Strictly Remember>
1. As input you will be given a batch of `file_path` and `file_summary` from a production codebase. Keep it in mind that it could be a file from a very large repository with lot of inter-dependencies.
2. Understand all the file description first, then try to determine the feature, sub-features and their description. For **each file** it should have a feature or sub-features whenever the conditions are met.
3. The response should contain all the fields given in the example output format. The response should be strictly in json format.
4. The description of features/subfeatures must be in the length of 2-3 lines. The response should be structured and well-formatted.
5. Don't generate any additional explanation or description. Provide the structured response in json only.
</Strictly Remember>
  
<Input file wise summary>
{file_summary}
</Input file wise summary>
<Response>
"""

merge_features_in_hierarchy_user_prompt = """You are a software feature analyzer. Given a list of related features that have been clustered together, create a merged feature that encompasses all the functionality.

Features to merge:
{feature_list}

Generate a JSON response that includes:
1. A name for the merged feature representing accurate feature name. Do not mention its merged or unified or anything as such. The feature name should accurately represent a major funcationality of a repository.
2. A detailed description that covers all functionality
3. A confidence score (0-100) for the merge
4. A justification for the confidence score

Respond with a JSON object in the following format:
```json
{{
    "name": "Merged feature name",
    "description": "Comprehensive description",
    "confidence_score": 85,
    "confidence_justification": "Reason for the confidence score"
}}
```
Give only JSON and nothing else. Do not include any explanations or additional text outside the JSON block. Make sure to start with ```json and end with ``` only.
"""

mapping_names_for_merged_features_user_prompt = """  <Role>
    You are a smart AI cassistant with strong expertise in Software Engineering. You can understand complex, production-grade codebases written in various programming languages and summarize them effectively.
  </Role>
  <Task>
  You will be given a brief description of  features of a large codebase and your task is to generate a relevant feature name, brief description, and priority level.
  <Important>
   1. The feature name should be brief, relevant and should represent the entire description provided.
   2. Generate a relevant description which is basically a overall summary of the description provided.
   3. Assign a priority level (high, medium, low) based on the significance, importance and complexity of the feature to the overall system. 
  </important>
  </Task>
  <Example output>
  ```json
    {
        "name": <feature_name>, //string
        "feature_description": <feature_description>, //string
        "priority": <priority> //string (high, medium, or low)
    }
    ```
  </Example output>
  <Strictly Remember>
1. The feature name should be relevant and at the same time interpretable, easy to understand.
2. The feature description should represnt the entire description given for summarisation, it should be simple and easy to understant.
3. The priority should be one of: high, medium, or low.
4. The response should be strictly in json format specified above.
5. Strictly make sure Feature Description is not more than 200 words.
  </Strictly Remember>

<code summary>
The code summary is given below:
"""


reducing_sub_features_user_prompt = """
    You are a software feature consolidation expert. Your task is to merge similar sub-features into one comprehensive sub-feature.

    Here are the sub-features that need to be merged:
    {sub_features_list}

    For each sub-feature, we have:
    - Name: The sub-feature name
    - Description: The sub-feature description (if available)
    - Confidence Score: The confidence score (if available)

    Your output should be a JSON object containing:
    1. A unified sub-feature name that encompasses all the input sub-features
    2. A comprehensive description that covers all aspects of the input sub-features
    3. A confidence score (use the highest available from input sub-features)
    4. A justification for the confidence score

    Return the output in JSON format starting with ```json and ending with ```.

    Example output format:
    ```json
    {{
        "name": "Unified Sub-Feature Name",
        "description": "Comprehensive description covering all aspects",
        "sub_feature_confidence_score": 95,
        "sub_feature_confidence_score_justification": "Merged from similar sub-features with high semantic similarity"
    }}
    ```
    """


post_processing_feature_name_description_system_prompt="""
  <Role>
    You are a smart AI assistant with strong expertise in Software Engineering. You can understand complex, production-grade codebases written in various programming languages and summarize them effectively.
  </Role>
  <Task>
  You will be given a brief description of modules or features of a large codebase and your task is to generate a relevant feature name and brief description.
  <Important>
   1. The feature name should be brief, relevant and should represent the entire description provided.
   2. Generate a relevant description which is basically a overall summary of the description provided.
   3. Also generate a confidence score in a scale of 0 - 100.
  </important>
  </Task>
  <Example output>
  ```json
    {
        "name": <feature_name>,
        "feature_description_confidence_score": <score 0 - 100>,
        "feature_description": <feature_description>
    }```
  </Example output>"""

post_processing_feature_name_description_user_prompt = """<Strictly Remember>
1. The feature name should be relevant and at the same time interpretable, easy to understant.
2. The confidence score should represent the ability to summarise the description.
3. The feature description should represnt the entire description given for summarisation, it should be simple and easy to understant.
4. The response should be strictly in json format specified above.
</Strictly Remember>
<code summary>
The code summary is given below: \n
{feature_description}
</code_summary>
<response>
Your response in json goes here:
"""

merge_similar_features_system_prompt = """You are a solution architect. Your task is to carefully review each feature and its description, and combine them into a single high-level feature.

The final high-level features should represent what an end user would perceive, e.g., Messenger, Google Chat, Messaging, Reels, etc.

Based on the generated features provided, identify which features can be merged into a single high-level feature. 
Strictly output them in the following format:
{{ 
  <High-Level Feature Name 1>: [<Merged Feature 1>, <Merged Feature 2>, <Merged Feature 3>, ...],
  <High-Level Feature Name 2>: [<Merged Feature 1>, <Merged Feature 2>, <Merged Feature 3>, ...],
  ...
}}

INPUT:
Feature names and descriptions are provided in the format: 
[1. Feature name: <feature name> 
Feature description: <feature description>, 
2. ...]

{feature_texts}

MVFS:
{total_MVFs}

Points to remember:
1. While merging features and naming high-level features, always prefer names from the user-defined MVFs provided. All relevant features can be grouped under these high-level features.
2. If certain features do not fit under the user-defined MVFs, choose a better name than the existing one for the new high-level feature if necessary.
3. The names of the features being merged must remain exactly as provided in the INPUT section; do not modify them. Do not consider Feature description in Feature Names.
4. Follow the output structure strictly: high-level feature names as dictionary keys and merged features as values in list format.
5. If a feature is already a high-level feature, you do not need to forcibly merge it. If a feature seems to be function-level/low-level  features, merge them into a High-level feature.
6. Merge similar features into a single high-level feature based on their names and descriptions, when applicable. Each final high-level feature should be independent of the others.
7. Do not assign the same feature to multiple high-level features.
8. If user-defined MVFs are empty, skip point 1 and begin with point 2.
9. Do **not** include any Feature descriptions in the final output."""


merging_description_user_prompt = """You are a Solution Architect. Your task is to summarize the multiple feature descriptions provided into a brief, coherent summary of **no more than two sentences**.

  The summary must:
  - Accurately capture all key components from the provided descriptions.
  - Align clearly with the given high-level feature name.
  - Serve as the final description of the high-level feature.

  Only the final summarized description should be included in the output â€” no additional commentary or formatting.

  INPUT:
  Multiple descriptions: {merging_feature_description}

  High-Level Feature Name: {high_level_feature}
  """


micro_sub_feature_prompt = """You are an expert system analyst specializing in decomposing SubFeatures into granular, logically independent components. You support **two levels** of splitting:

1. **Horizontal splitting**: Split a subfeature into multiple *same-level subfeatures* when it encompasses multiple independently meaningful functionalities. The subfeatures created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.
2. **Vertical splitting**: Further break each of those subfeatures into *microsubfeatures* (if applicable), ensuring each micro-sub-features/micro-user-story describes a single goal or operation. The micro-sub-features/micro-user-story created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.

---

### ðŸ”§ TASK OVERVIEW

Given a Macro-Feature, Subfeature, its description, associated module files and its summary:

- Decide if the subfeature should be split horizontally into multiple same-level subfeatures.
- For each resulting subfeature (or original if not split), analyze whether it can be split vertically into **microsubfeatures** (fine-grained user stories).
- Provide the confidence scores for the subfeature that is split, whether horizontally or vertically.
- Provide the files that are related to the sub_features too, not just the micro_sub_features.
- Each leaf user-story must have files assigned to them, else you should not create/split these subfeatures.
- Provide description of generated subfeature/sub-user-stories in 2-4 lines but only valid information. Do not assume or hallucinate to generate description.
Apply this recursively: if horizontal splitting occurs, then attempt vertical splitting for each. But remember, not to create any duplicates in the process. 

---

### SPLITTING DECISIONS

#### Horizontal Splitting (Same-level Subfeatures):
Split if:
- The subfeature covers multiple high-level functionalities
- Each function could be planned, developed, and deployed independently
- Each component has a clear boundary and responsibility

#### Vertical Splitting (Microsubfeatures):
Split further if:
- A subfeature contains multiple independent operations or logical stages
- These operations can be implemented, tested, or tracked separately
- Each micro-subfeature represents one atomic, non-overlapping functionality

---

### DO NOT SPLIT IF:
- sub-user-stories are tightly coupled in the Subfeature and cannot function independently.
- Do not split subfeatures into sub-user-stories that are hardly single line of code and cannot be considered as a proper functionality, but just a config/parameter.
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across actions are too complex to isolate.
- There are no files that can be mapped to the generated user-story.
- Do not split if the user-story is barely a functionality. The split user-stories must have independent functionality that contributes to the subfeature and feature and if not, do not split.
- Don not split ReadMe & .md files into sub-user-stories.
- Do not split horizontall for granullar subfeatures as they are not user stories but mid level features.
---

### FILE MAPPING RULES:
- For each subfeature or microsubfeature, cite only directly relevant files.
- Use only the provided input data to match files â€” no guessing.
- Avoid duplication unless a file is clearly shared between components.

Each `file_path` entry must include:
```json
{
  "module_name": "<Name>",
  "path": "<Path>",
  "critical": <true/false>,
  "git_url": "<Git URL>"
}

OUTPUT FORMAT
If the subfeature should NOT be split:
Return: "None"

If the subfeature should be split, return a list of Parent User Stories with subfeatures inside.
If a subfeature itself can be further split into microsubfeatures, nest them under micro_sub_features like so:

[
  {
    "name": "Parent User Story Title 1",
    "description": "Full description of the original or updated user story and its purpose.",
    "file_path": [...],
    "sub_feature_confidence_score":"confidence score of the subfeature with respect to the Feature, as a percentage (e.g., 80)"
    "micro_sub_features": [
      {
        "name": "Sub-User Story Title 1",
        "description": "Standalone description of a single functionality.",
        "file_path": [...],
        "micro_sub_feature_confidence_score":"confidence score of the micro_sub_feature with respect to the sub_feature, as a percentage (e.g., 90)"
        }
          ...
        ]
      },
      ...
    ]
  }
]
Each layer must preserve independence, clarity, and singular focus of each story.

VALIDATION CHECKLIST
- Each title must express one functionality only (no imperative phrasing)
- description must avoid assumptions and describe the real function. It must be as detailled as possible.
- Each story must make sense independently and fit in the broader feature flow
- if there are multiple user-story under the subfeature, it needs to be in sequence of business logic.
- File mappings must be relevant and scoped accurately
- Do no miss/skip any values in the output json. The output structure must be maintained strictly.
- All subfeature and sub-user-story names and descriptions must be strictly in a declarative tone, not imperative.

* Use generic or speculative statements
"""


db_micro_sub_feature_prompt = """
<Role>
You are an expert Database analyst specializing in decomposing SubFeatures into granular, logically independent components. You support **two levels** of splitting:
You shall ALWAYS process features from a Database perspective ONLY. 
There can be more than one Table in the DB context provided to you.
</Role>

1. **Horizontal splitting**: Split a subfeature into multiple *same-level subfeatures* when it encompasses multiple independently meaningful functionalities. The subfeatures created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.
2. **Vertical splitting**: Further break each of those subfeatures into *microsubfeatures* (if applicable), ensuring each micro-sub-features/micro-user-story describes a single goal or operation. The micro-sub-features/micro-user-story created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.

<Strict Constraints> 
- You are dealing with Database Information. 
- No matter what, STRICTLY use Database-Specific Language ALWAYS. 
- Use words like Columns / Fields / Schema / DataTypes / Constraints / Foreign Keys / Primary Keys etc.
- Strictly Do not start descriptions with or start with "this micro-feature" / or "this sub-feature".
- You shall do this regardless of the input context and nature.
Remember : Every "FILE" given to you is information of a table. Therefore in your response, ALWAYS refer to "Table" instead of "File".

</Strict Constraints> 


### ðŸ”§ TASK OVERVIEW

Given a Macro-Feature, Subfeature, its description, associated module files and its summary:

- Decide if the subfeature should be split horizontally into multiple same-level subfeatures.
- For each resulting subfeature (or original if not split), analyze whether it can be split vertically into **microsubfeatures** (fine-grained user stories).
- Provide the confidence scores for the subfeature that is split, whether horizontally or vertically.
- Provide the files that are related to the sub_features too, not just the micro_sub_features.
- Each leaf user-story must have files assigned to them, else you should not create/split these subfeatures.
- Provide description of generated subfeature/sub-user-stories in 2-4 lines but only valid information. Do not assume or hallucinate to generate description.
Apply this recursively: if horizontal splitting occurs, then attempt vertical splitting for each. But remember, not to create any duplicates in the process. 

---

### SPLITTING DECISIONS

#### Horizontal Splitting (Same-level Subfeatures):
Split if:
- The subfeature covers ONE / MORE THAN ONE high-level functionalities
- Each function could be planned and developed independently
- Each component has some clear boundaries and responsibilities

#### Vertical Splitting (Microsubfeatures):
Split further if:
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across actions are too complex to isolate.
- There are no tables that can be mapped to the generated user-story.
- The subfeature is too complex to be planned, developed, and deployed independently
- Each micro-subfeature represents one atomic, non-overlapping functionality
Note: Maintain at least 2 subfeatures unless the database has only one table.
- Prioritize brevity, consistency and no informaiton leakage across subfeatures.
- Ensure crisp segregation.
---

### DO NOT SPLIT IF:
- sub-user-stories are tightly coupled in the Subfeature and cannot function independently.
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across tables in two features are too complex to isolate.
- There are no tables that can be mapped to the generated user-story.
Note: Maintain at least 2 subfeatures and 1 or more microsubfeatures per subfeature, Unless the database has only one table.
Note : Maintain brevity during splitting at the same level. Do NOT overload the a single feature with too many subfeatures.
---


### FILE MAPPING RULES:
- For each subfeature or microsubfeature, cite only directly relevant tables.
- Use only the provided input data to match files â€” no guessing.
- Avoid duplication unless a file is clearly shared between components.

Each `file_path` entry must include:
```json
{
  "module_name": "<Name>",
  "path": "<Path>",
  "critical": <true/false>,
  "git_url": "<Git URL>"
}

OUTPUT FORMAT
If the subfeature should NOT be split:
Return: "None"

If the subfeature should be split, return a list of Parent User Stories with subfeatures inside.
If a subfeature itself can be further split into microsubfeatures, nest them under micro_sub_features like so:

[
  {
    "name": "Parent User Story Title 1",
    "description": "Full description of the original or updated user story and its purpose.",
    "file_path": [...],
    "sub_feature_confidence_score":"confidence score of the subfeature with respect to the Feature, as a percentage (e.g., 80)"
    "micro_sub_features": [
      {
        "name": "Sub-User Story Title 1",
        "description": "Standalone description of a single functionality.",
        "file_path": [...],
        "micro_sub_feature_confidence_score":"confidence score of the micro_sub_feature with respect to the sub_feature, as a percentage (e.g., 90)"
        }
          ...
        ]
      },
      ...
    ]
  }
]
Each layer must preserve independence, clarity, and singular focus of each story.

VALIDATION CHECKLIST
- Each title must express one functionality only (no imperative phrasing)
- description must avoid assumptions and describe the real function. It must be as detailled as possible.
- Each story must make sense independently and fit in the broader feature flow
- if there are multiple user-story under the subfeature, it needs to be in sequence of business logic.
- File mappings must be relevant and scoped accurately
- Do no miss/skip any values in the output json. The output structure must be maintained strictly.
- All subfeature and sub-user-story names and descriptions must be strictly in a declarative tone, not imperative.
- Use Database-specific schema only. Do not include words like "Attributes" / "Code Files" in your response. 
- Strictly Do not start descriptions with or start with "this micro-feature" / or "this sub-feature".
* Use generic or speculative statements

"""import os
from graphviz import Digraph
import re 
import json

def parse_ddl(ddl: str):
    """
    Parse the DDL to extract columns, primary keys, and foreign keys.
    """
    lines = ddl.splitlines()
    column_lines = []

    for line in lines:
        line = line.strip()
        if (
            line.upper().startswith("CREATE")
            or line.upper().startswith("PRIMARY")
            or line.upper().startswith("FOREIGN")
            or line.upper().startswith(")")
            or line == ""
        ):
            continue

        match = re.match(r'(\w+)\s+\w+', line)
        if match:
            column_lines.append(match.group(1))

    pk_match = re.search(r'PRIMARY KEY\s*\((.*?)\)', ddl)
    primary_keys = [key.strip() for key in pk_match.group(1).split(",")] if pk_match else []

    foreign_keys = []
    for match in re.finditer(r'FOREIGN KEY\s*\(([^)]+)\)\s+REFERENCES\s+`?[\w]+\.(\w+)`\(([^)]+)\)', ddl):
        fk_col = match.group(1).strip()
        ref_table = match.group(2).strip()
        ref_col = match.group(3).strip()
        foreign_keys.append((fk_col, ref_table, ref_col))

    return column_lines, primary_keys, foreign_keys


def generate_combined_graph(tables_data):
    """
    Generate a single combined graph from multiple tables.
    """
    dot = Digraph(comment='Combined Table Diagram')
    dot.attr(rankdir='LR')

    # Store individual table nodes
    for table in tables_data:
        table_name = table['table_name']
        columns = table['columns']
        primary_keys = table['primary_keys']
        
        label_lines = []
        for col in columns:
            if col in primary_keys:
                label_lines.append(f"{col} [PK]")
            else:
                label_lines.append(col)
        dot.node(table_name, shape='box', label=f'{table_name}\\n' + "\\n".join(label_lines))

    # Add relationships
    for table in tables_data:
        table_name = table['table_name']
        for fk_col, ref_table, ref_col in table['foreign_keys']:
            dot.edge(table_name, ref_table, label=f'{fk_col} â†’ {ref_col}')

    return dot

def folder_summary_generation_prompts(
        total_allocated_tokens, 
        file_list, folder_name, 
        folder_path,
        subfolder_list,
        formatted_file_summaries,
        formatted_file_services,
        formatted_subfolder_summaries,
        formatted_subfolder_services,
        formatted_subfolder_features
    ):
    
    system_prompt = f"""
        You are an expert code analyst specialized in creating detailed, informative summaries of software project folders. Your task is to thoroughly analyze files and subfolders to provide a comprehensive understanding of the application or project and provide combined summaries along with required details. These summaries must be detailled enough for further summarization.

        Follow these guidelines:
        1. Conduct a deep analysis of the features to identify its core purpose and functionality
        2. Provide detailed explanation of key implementations and technical approaches of the features
        3. Thoroughly examine the summaries based on files and folders to understand relationship between features and combined smaller features into larger high level application level features.
        4. Explain the features within the broader project architecture with specific connections
        5. Describe technical patterns, design decisions, and architectural choices evident in the code
        6. Include specific functions, classes, and methods that define the feature's behavior
        7. Note dependencies, imports, and external connections that shape the folder's functionality
        8. Identify potential architectural strengths and areas for improvement when evident
        9. Identify all services represented in this folder based on file and subfolder services information
        10. Identify and articulate high-level features or functionalities represented by the folder into the feature_details section, when consolidating multiple subfolders or lower-level files. Derive these insights from both file-level and subfolder-level summaries. Also under each feature, mention which file/folder was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
        11. Do not miss any features that could be formed based on these summaries as this information is required to understand the application's buisness logic.
        12. Gather insights from the summaries provided to generate a high level detailled executive summary that could be used by business stakeholders to understand the folder/project.
        13. When analyzing the root folder, both the executive summary and the features must be strictly formed in a high level business logic standpoint of an application.
        
        IMPORTANT: 
        - Your summary should be thorough and detailed({total_allocated_tokens}) while maintaining technical/business precision and depth. Focus on providing insights that would help both stakeholders and developers understand the application better.
        - feature_details must contain high level feature name and feature description(value of the files/folders) strictly in concise bullet points. The feature inforamtion must be in detail to capture the complete high level knowledge for that feature but not the function level details. Feature names cannot be programmatic function names like Dependency management, json handling etc. instead it should be inventory management, order processing etc. 
        - Your services list should be comprehensive and include all services represented in this folder.
        - is_reuasble_lib if a folder is used as reusable lib make it True otherwise False
        - lib_name if is_reusable_lib is True then provide the name of the reusable lib/component If is_reusable_lib False then add Not Applicable
        - category if is_reusable_lib is True then provide category only between 'Frontend' and 'Backend' If is_reusable_lib False then add Not Applicable
        - sub_category if is_reusable_lib is True then provide sub category only between 'UI Component','Custom Hooks', 'http_client', 'Utils', 'Others' In Frontend & 'Middleware', 'Error Handling', 'Auth', 'Utils', 'Others' In Backend If is_reusable_lib False then add Not Applicable
        - when_to_use if is_reusable_lib is True then provide where this reusable lib/component can be used If is_reusable_lib False then add Not Applicable 
        - associated_files if is_reusable_lib is True then provide the list of files associated(give complete path for the assosciated file) with this reusable lib/component If is_reusable_lib False then add Not Applicable
        - summary must not be technical and only explain the high level details of the folder/project. Understand the file and folder summaries provided to combine the knowledge to form the executive summary. Make it as detailled as possible.
        - Use clear and concise language, avoiding jargon where possible.
        
        - You must provide your response in this exact format:
        ```summary
        [Your detailled high-level executive summary for the folder for business stakeholders]
        ```
        ```feature_details
        [List of high-level features or functionalities represented in this folder]
        ```
        ```services_namess
        [Comma-separated list of all services represented in this folder]
        ```
        ```is_reuasble_lib
        Boolean Value
        ```
        ```lib_name
        [Name of the reusable library if applicable]
        ```
        ```category
        [Category of the reusable library if applicable]
        ```
        ```sub_category
            [Sub category of the reusable library if applicable]
        ```
        ```when_to_use
        [Your detailed use case where or when this reuasble_lib can be usefull]
        ```
        ```associated_files
            [Comma-separated list of associated files with the reusable library, Give the Complete file path as mentioned in the file list]
        ```
        ```example_usage
            [Example code snippet of how to use this reusable library]
        ```
    """

    user_prompt = f"""
        Generate a summary and services list for the folder: "{folder_name}" (Path: {folder_path})

        FOLDER CONTENTS:
        - Files ({len(file_list)}): {", ".join(file_list) if file_list else "None"}
        - Subfolders ({len(subfolder_list)}): {", ".join(subfolder_list) if subfolder_list else "None"}

        FILE SUMMARIES:
        {os.linesep.join(formatted_file_summaries) if formatted_file_summaries else "No file summaries available"}

        FILE SERVICES:
        {os.linesep.join(formatted_file_services) if formatted_file_services else "No file services available"}

        SUBFOLDER SUMMARIES:
        {os.linesep.join(formatted_subfolder_summaries) if formatted_subfolder_summaries else "No subfolder summaries available"}

        SUBFOLDER SERVICES:
        {os.linesep.join(formatted_subfolder_services) if formatted_subfolder_services else "No subfolder services available"}

        SUBFOLDER FEATURES:
        {os.linesep.join(formatted_subfolder_features) if formatted_subfolder_features else "No subfolder features available"}
        
        Based on these components:
        1. Provide a thorough technical summary explaining the folder's purpose, implementation details, and architectural significance
        2. Compile a comprehensive list of all services represented in this folder based on file and subfolder services information
        
        Follow the exact format specified in the system instructions for your response.
    """

    return system_prompt, user_prompt

def services_generation():
    system_prompt = """
        <Task>
        Create an architectural blueprint of the given repository by identifying and classifying both external services and third-party services with no overlap between categories.
        </Task>

        <Definitions>
        - External services: Company-provided services hosted outside the application (AWS S3, Google Cloud, Stripe, Twilio)
        - Third-party services: Libraries, frameworks, and SDKs that are part of the core application stack (Django, React, MongoDB, Redux)
        </Definitions>

        <Output_Format>
        {
        "external_services": [
            {
            "external_service_name": "string",
            "description": "string",
            "associated_files": ["string"],
            "service_class": "string",
            "used_in_files": ["string"]
            }
        ],
        "thirdparty_services": [
            {
            "thirdparty_service_name": "string",
            "description": "string",
            "associated_files": ["string"],
            "service_class": "string",
            "used_in_files": ["string"]
            }
        ]
        }
        </Output_Format>

        <Instructions>
        1. Conduct a thorough repository analysis to identify all services
        2. Classify each service into exactly ONE category:
        - External services: Cloud platforms, payment processors, authentication providers
        - Third-party services: Frameworks, libraries, SDKs integrated into the codebase
        3. For each service, provide:
        - Name: Exact service name
        - Description: Concise explanation of functionality and purpose
        - Associated files: All files directly importing or using the service
        - Service class: Category (e.g., "cloud storage", "web framework", "database")
        - Used in files: Complete paths of files utilizing the service
        4. Ensure ZERO overlap between categories
        5. Prioritize accuracy over comprehensiveness
        6. Validate that identified services are actively used in the project
        7. Include only services with clear evidence of implementation
        8. Do not create a lot of services which are redundant. Keep it to a maximum of 50 services only.
        </Instructions>

        <Examples>
        Good External Service Entry:
        {
        "external_service_name": "AWS S3",
        "description": "Cloud storage service used for storing user-uploaded files",
        "associated_files": ["src/services/storage.js", "src/config/aws.js"],
        "service_class": "cloud storage",
        "used_in_files": ["src/components/FileUpload.js", "src/pages/UserProfile.js"]
        }

        Good Third-Party Service Entry:
        {
        "thirdparty_service_name": "React",
        "description": "Frontend JavaScript library for building user interfaces",
        "associated_files": ["package.json", "src/index.js"],
        "service_class": "frontend framework",
        "used_in_files": ["src/App.js", "src/components/*.js"]
        }
        </Examples>

        Analyze the repository and provide the complete architectural blueprint in the specified format.
    """

    user_prompt = ""

    return system_prompt, user_prompt

def executive_summary_generation(combined_summary, user_mvf):
    system_prompt = """
    Your Role:
    You are an expert software architect tasked with understanding a codebase and creating an executive summary that clearly articulates the main purpose of this application,
    the core problem that the application is solving, and the prioritized list of the most valuable features, solely based on the provided folder wise summary. Do not hallucinate and create the most valuable features and its description on assumption. This needs to be based on facts.

    Task:
    1. Analyze provided folder wise summary and the services used and the user defined features (if provided).
    2. Understand component interactions and functions.
    3. Prioritize the User Defined Features (if provided) in the summary.
    4. Identify and prioritize the most valuable features based on their importance and relevance to the overall project, as evidenced in the code.
    5. Create a comprehensive executive summary.

    Steps:
    1. Review folder wise summary.
    2. Analyze folder wise summary:
    - Identify key components and their roles
    - Note data operations, design patterns, and architectural decisions
    3. Create summary:
    - Describe the specific problem the codebase solves, based on folder wise summary
    - Explain component interactions
    - Outline data workflow
    4. Identify and prioritize main features:
    - Determine which feature(s) address the core problem of the application, based on code implementation
    - Rank features based on their importance and relevance to solving the main problem, as evidenced in the code
    - The feature should be major components of the codebase and not minor functions like "Modular Architecture" or "Code Reusability", these are not features but design principles.

    Focus Areas:
    - Precised feature prioritization and importance
    - High-level functionality
    - Clear, concise technical language
    - Objective description
    - Capture entire workflow

    Guidelines:
    - Only use the folder wise summary provided
    - Use precise technical terms
    - Include user-defined features if provided and evidenced in the code
    - Prioritize features based on their importance to the core problem, as shown in the folder wise summary

    Feature Identification and Prioritization:
    - Carefully analyze the folder wise summary to identify features actually present in the folder wise summary
    - Do not assume or infer features that are not explicitly mentioned in the folder wise summary
    - Identify the top feature that solves the majority of the problem based on code evidence
    - Rank subsequent features in descending order of importance, ensuring they are present in the folder wise summary
    - Ensure the feature list reflects the codebase's focus and structure
    - Only include features that have substantial implementation in the codebase that is evident from folder wise summary

    Output Format - Adhering to this format is crucial
    ```json
    {
    "data": "generated_summary in string format adhering to the Expected Output Format for Generated Summary",
    "confidence_score": 90,
    "traceback": {
    "Feature 1 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 1 Title' is included, as the 'phrase' is an evidence that this feature is part of the codebase.",
    "Feature 2 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 2 Title' is included, as the 'phrase' is an evidence that this feature is part of the codebase.",
    ...
    }
    }
    ```

    Requirements:
    - Replace \n with \\n in JSON
    - Limit upto 5 main features (max 2 sub-features each) or 7500 tokens
    - If due to any reason such as codebase being small, you are unable to provide 5 features, then provide as many high-level features as possible between the range of 1 to 5.
    - Don't assume features or include minor features due to inability to provide 5 features, lesser number of features is acceptable.
    - Use specified JSON format only
    - Start with "```json" and end with "```"
    - Ensure the top feature in the prioritized list addresses the core problem and is present in the folder wise summary
    - Rank features in descending order of importance to the main problem, based on actual code implementation
    - Do NOT include features that are NOT evidenced in the provided folder wise summary
    - Evaluate the folder wise summary objectively, considering all conclusions on the actual code provided
    - Do NOT make any assumptions about organizational goals or intentions beyond what is explicitly shown in the code
    - Focus solely on the technical aspects and implemented functionality, avoiding speculation about business objectives or future plans
    - Both the keys data, confidence score, and traceback should be present in the output JSON
    - The generated summary should be in string format only and be contained inside the "data" key
    - The "traceback" key should contain a dictionary with feature names as keys and justifications for including these features based on exact phrases from the input
    - Do not include any feature that could potentially be part of the folder wise summary without explicit evidence
    - Every feature mentioned must be driven by clear evidence from the provided input
    """
    user_prompt = """
    Expected Output Format for Generated Summary:

  **Overview**
  <empty line>
  <A brief introduction to the codebase and its main purpose; in paragraph format only, not in points.
  This paragraph should provide a concise yet comprehensive overview of the codebase, its primary functionality, solution provided by the project and its intended use case.
  Aim for 3-5 sentences that capture the essence of the project.>
  <empty line>
  **Highlighted Features**
  <empty line>
  <
  List and briefly explain the key features that are significant components of the codebase and would serve as selling points.
  These features should be presented as follows:
  1. Use numbered points for each feature.
  2. Provide a brief explanation for each feature in 1-2 sentences, highlighting its importance and benefit to the end user.
  3. Focus on features that are central to the codebase's functionality and most important to the end user.
  4. Dont include generic features like "Modular Architecture" or "Code Reusability", these are not features but design principles.
  5. Do not include sub-points under any feature.
  6. Prioritize User Defined Features (if provided) at the beginning of the list.
  7. If User Defined Features are given, list them first before including any features identified through your analysis.
  8. Aim to provide upto of 1 to 5 key features, after each feature add an empty line for formatting purposes.
  9. Ensure that the features listed represent the core functionality and unique selling points based on the folder wise summary.
  10. Use clear, concise language that emphasizes the value proposition of each feature.
  11. Also under each feature, mention which file/folder was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
  12. Do not add features into Highlighted Features if they dont have value for buisness stakeholder about the application. Also do not repeat adding similar feature in this section.

  Output Structure:
  1. ***<Feature 1 Title>***: <Description of the feature in one to two sentences.\n
  2. ***<Feature 2 Title>***: <Description of the feature in one to two sentences.>\n
  >
  <empty line>
  **Key Benefits**
  <empty line>
  <Summarize the key benefits of the codebase in one to two sentences.
  This summary should encapsulate the overall value proposition of the codebase and its potential impact on users or the organization.>
  <empty line>
  <Highlight the most significant key benefits the codebase has to offer in bulleted points. The format should be:
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  Aim for 3-5 bullet points that capture the most compelling advantages of using this codebase, after each point add an empty line for formatting purposes.
  Each benefit should be distinct and provide a clear value proposition.>

  <Final Output Format>
  Output Format - Adhering to this format is crucial, the output should be in parsable JSON format:
  ```json
  {{
    "data": "<generated_summary in string format adhering to the Expected Output Format for Generated Summary>",
    "confidence_score": 90,
    "traceback": {{
      "Feature 1 Title": "Since it mentions about <exact phrase from the folder wise summary>, the 'Feature 1 Title' is included, as the "phrase" is an evidence that this feature is part of the folder wise summary.",
      "Feature 2 Title": "Since it mentions about <exact phrase from the folder wise summary>, the 'Feature 2 Title' is included, as the "phrase" is an evidence that this feature is part of the folder wise summary.",
      ...
    }}
  }}
  ```
  </Final Output Format>
  Note: If the traceback includes phrases that are not present in the folder wise summary then you would be penalized 10000 points.
  The output should be having data, confidence score, and traceback keys, and the entire content inside "```json" and "```" should be parsable by json.
  The "data" key should contain the generated summary and it should be in string format only, allowing the parsing of the entire json.
  If there are any inverted commas inside the generated summary, then escape them with a backslash.
  Do not change or skip the headings of each section in the generated json. The generated summary must have "Overview", "Highlighted Features", "Key Benefits" as section titles. Follow the above provided guidelines."""
    user_prompt += f"""Use the below folder wise summary to generate the summary in the above format: {combined_summary}""" + "User Defined Features : " + str(user_mvf)
    return system_prompt, user_prompt

def db_executive_summary_generation(combined_summary, user_mvf): 
    system_prompt = """
    Role:
    You are an expert Database Architect tasked with understanding the contents of all tables and schema of the database. 
    You shall Articulate a proper executive summary that clearly captures all the main & high-level features of this database.
    The core use-case that this database is intended for, and the prioritized list of the most valuable features, solely based on the provided Table-Level summaries. 
    Do not hallucinate. Do NOT create the most valuable features and its description on pure assumptions. This needs to be based on facts, with proper backing.

    Task:
    1. Analyze provided Table wise summaries.
    2. Understand component interactions and functions.
    3. Prioritize the User Defined Features (if provided) in the summary.
    4. Identify and prioritize the most valuable features based on their importance to the core use-case the Database is solving.
    5. Create a comprehensive executive summary.

    Steps:
    1. Review Table wise summary.
    2. Analyze Table wise summary:
      - Identify all tables. 
      - Take into consideration the foreign keys, primary keys, is-a, has-a, and many-to-many relationships.
      - Deeply understand the intended-use-case of each table.
      - Note data operations, design patterns, and architectural decisions
    3. Create summary:
      - Describe the specific problem the Database is solving, based on Table wise summary
      - Explain high-level interactions and dependencies
      - Outline data workflow
    4. Identify and prioritize main features:
      - Determine which feature(s) address the core problem of the Database, based on SQL implementation and Table wise summary
      - Rank features based on their importance and relevance to solving the main problem, as evidenced in the Database
      - The feature should be major components of the Database and not minor functions like Many-to-Many Relationships, or "Foreign Keys". 
        These are implementation concepts. Not core features.

    Focus Areas:
    - Precised feature prioritization and importance
    - High-level functionality of this Database
    - Clear, concise technical language with Database-specific Language
    - Objective description
    - Capture entire data workflow

    Guidelines:
    - Only use the Table wise summary provided
    - Use precise Database-relevant technical terms
    - Include user-defined features if provided and evidenced in the Table wise summary
    - Prioritize features based on their importance to the core problem, as shown in the Table wise summary

    Feature Identification and Prioritization:
    - Carefully analyze the Table wise summary to identify features actually present in the Table wise summary
    - Do not assume or infer features that are not explicitly mentioned in the Table wise summary
    - Identify the top feature that solves the majority of the problem based on Database and SQL evidence
    - Rank subsequent features in descending order of importance, ensuring they are present in the Table wise summary
    - Ensure the feature list reflects the Database's focus and structure
    - Only include features that have substantial implementation in the Database that is evident from Table wise summary

    Output Format - Adhering to this format is crucial
    ```json
    {
    "data": "generated_summary in string format adhering to the Expected Output Format for Generated Summary",
    "confidence_score": 90,
    "traceback": {
    "Feature 1 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 1 Title' is included, as the 'phrase' is an evidence that this feature is part of the Database.",
    "Feature 2 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 2 Title' is included, as the 'phrase' is an evidence that this feature is part of the Database.",
    ...
    }
    }
    ```

    Requirements:
    - Replace \n with \\n in JSON
    - Limit upto 5 main features (max 2 sub-features each) or 7500 tokens
    - If due to any reason such as Database being small, you are unable to provide 5 features, then provide as many high-level features as possible between the range of 1 to 5.
    - Don't assume features or include minor features due to inability to provide 5 features, lesser number of features is acceptable.
    - Use specified JSON format only
    - Start with "```json" and end with "```"
    - Ensure the top feature in the prioritized list addresses the core problem and is present in the Table wise summary
    - Rank features in descending order of importance to the main problem, based on actual Database and SQL implementation
    - Do NOT include features that are NOT evidenced in the provided Table wise summary
    - Evaluate the Table wise summary objectively, considering all conclusions on the actual Database and SQL provided
    - Do NOT make any assumptions about organizational goals or intentions beyond what is explicitly shown in the Database and SQL
    - Focus solely on the technical aspects and implemented functionality, avoiding speculation about business objectives or future plans
    - Both the keys data, confidence score, and traceback should be present in the output JSON
    - The generated summary should be in string format only and be contained inside the "data" key
    - The "traceback" key should contain a dictionary with feature names as keys and justifications for including these features based on exact phrases from the input
    - Do not include any feature that could potentially be part of the Table wise summary without explicit evidence
    - Every feature mentioned must be driven by clear evidence from the provided input.
    - Strictly use an assertive and objective tone in your response. 
    - Do not be unsure about anything.
    - Do not include the "Folder Name" in your response. Ignore "dbanalysis" folder. Provide Executive Summary of the Database-ONLY.
    """

    user_prompt = """
  Expected Output Format for Generated Summary:

  **Overview**
  <empty line>
  <A brief introduction to the Database and its main purpose; in paragraph format only, not in points.
  This paragraph should provide a concise yet comprehensive overview of the Database, its primary functionality, and its intended use case.
  Aim for 3-5 sentences that capture the essence of the Database.>
  <empty line>
  **Highlighted Features**
  <empty line>
  <
  List and briefly explain the key features that are significant components of the Database and would serve as selling points.
  These features should be presented as follows:
  1. Use numbered points for each feature.
  2. Provide a brief explanation for each feature in 1-2 sentences, highlighting its importance and benefit to the END USER.
  3. Focus on features that are central to the Database's functionality and most important to the END USER.
  4. Dont include generic features like  Many-to-Many Relationships, or "Foreign Keys", these are not features but Design Principles.
  5. Do not include sub-points under any feature.
  6. Prioritize User Defined Features (if provided) at the beginning of the list.
  7. If User Defined Features are given, list them first before including any features identified through your analysis.
  8. Aim to provide upto of 1 to 5 key features, after each feature add an empty line for formatting purposes.
  9. Ensure that the features listed represent the core functionality and unique selling points based on the Table wise summary.
  10. Use clear, concise language that emphasizes the value proposition of each feature.
  11. Also under each feature, mention which file/Table was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
  12. Do not add features into Highlighted Features if they dont have value for buisness stakeholder about the application. Also do not repeat adding similar feature in this section.

  Output Structure:
  1. ***<Feature 1 Title>***: <Description of the feature in one to two sentences.\n
  2. ***<Feature 2 Title>***: <Description of the feature in one to two sentences.>\n
  >
  <empty line>
  **Key Benefits**
  <empty line>
  <Summarize the key benefits of the Database in one to two sentences.
  This summary should encapsulate the overall value proposition of the Database and its potential impact on users or the organization.>
  <empty line>
  <Highlight the most significant key benefits the Database has to offer in bulleted points. The format should be:
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  Aim for 3-5 bullet points that capture the most compelling advantages of using this Database, after each point add an empty line for formatting purposes.
  Each benefit should be distinct and provide a clear value proposition.>

  <Final Output Format>
  Output Format - Adhering to this format is crucial, the output should be in parsable JSON format:
  ```json
  {{
    "data": "<generated_summary in string format adhering to the Expected Output Format for Generated Summary>",
    "confidence_score": 90,
    "traceback": {{
      "Feature 1 Title": "Since it mentions about <exact phrase from the Table wise summary>, the 'Feature 1 Title' is included, as the "phrase" is an evidence that this feature is part of the Table wise summary.",
      "Feature 2 Title": "Since it mentions about <exact phrase from the Table wise summary>, the 'Feature 2 Title' is included, as the "phrase" is an evidence that this feature is part of the Table wise summary.",
      ...
    }}
  }}
  ```
  </Final Output Format>
  Note: If the traceback includes phrases that are not present in the Table wise summary then you would be penalized 10000 points.
  The output should be having data, confidence score, and traceback keys, and the entire content inside "```json" and "```" should be parsable by json.
  The "data" key should contain the generated summary and it should be in string format only, allowing the parsing of the entire json.
  If there are any inverted commas inside the generated summary, then escape them with a backslash.
  Do not change or skip the headings of each section in the generated json. The generated summary must have "Overview", "Highlighted Features", "Key Benefits" as section titles. Follow the above provided guidelines.
    """

    user_prompt += f"""Use the below Table wise summary to generate the summary in the above format: {combined_summary}""" + "User Defined Features : " + str(user_mvf)

    return system_prompt, user_prompt


def architecture_diagram_generation(services_data, icons_metadata):
    user_prompt = f"""
    <Input>
    $services_data = {services_data}
    $icons_metadata
    </Input>

    <Role>
    You are an expert at understanding large projects based on their executive summary and the services being used in them. Create a JSON structure for a ReactFlow diagram based on the given service class JSON.
    </Role>

    <Output Structure>
    1. Create a JSON object with a "nodes" and "edges" array.
    2. Create nodes for each external and third-party service.
    3. "nodes": An array containing all node objects.
      - "id": A unique string identifier for the node.
      - "data":   
        - "label": The name of the node.
        - "description": Description of the service.
        - "associated_files": Associated file and used in files in the service node, defaulting to "No File Available" if not present.
        - "group": The logical group name (e.g., 'Backend', 'Frontend', 'Database',etc..).
        - "subgroup": The specific subgroup within the group (e.g., Frameworks, NoSQL Databases, State Management, etc.).
        - "service": The appropriate filename of the icon based on the $icons_metadata.
      - "position" : The x and y coordinates of the node.
      - "type" : "customNode" This should be fixed.
    4. "edges" : An array having id, source, target, label, and type should be customEdge always.
    4. Ensure all services and files from the input JSON are included.
    5. The output should be in the form of a dictionary containing a "nodes" and "edges" array.
    6. Present only the code inside delimiters "```reactflow [reactflow CODE]```" without any additional explanation.
    """

    system_prompt:str = """
    <Task>
      You are tasked with creating a JSON structure for a ReactFlow diagram based on the given executive summary and the service_class_json. The executive summary contains an overview of the entire project. This JSON includes information about external services and third-party services, along with their associated files. Your output should represent this information as a network of nodes and edges.
    </Task>
    
    <Icons Context>
      $icons_metadata = """ + str(icons_metadata) + """
    </Icons Context>

    <Instructions>
      You are a solution expert, specializing in problem and solution flows. You will be given the solution overview for a project, and your task is to create an interconnected single component of graph which is detailed, and intuitive and self explanatory for:

      Follow these guidelines:
      1. Create nodes for each unique service (both external and third-party).
      2. Do not create any group nodes.
      4. In the data key for each service node, include two additional fields called group and subgroup. The group field should contain the logical group name (e.g., Frontend, Backend, Databases, etc..), and the subgroup field should provide more specific categorization (e.g., Frameworks, NoSQL Databases, etc..). For example, for a service node representing React, the group would be Frontend and the subgroup would be Frameworks.
      5. For each node, check which icon will be the most suitable from the $icons_metadata in the <Icons Context>
      6. Ensure all information from the input is represented in the output.
      7. The position coordinates must be proper for all the nodes.
    </Instructions>

    <Rules>
      **Ensure all nodes in the generated graph are interconnected such that every node has at least one edge, forming a single connected component without any isolated or disjoint sections. (High Priority Requirement)**
      Important Rules to be followed:
      1. Give detailed technical architecture flow and the JSON object following the below output format.
      2. Make sure that the flow and order of new solution approach is explained well in the graph with appropriate edges. Use as many edges you want to describe the data and user flow properly.
      3. The whole user and data flow should be clear.
      4. Do not add unnecessary nodes and edges. Do not create duplicate nodes that perform same task.
      5. Make the Node descriptions detailed, breaking tasks into multiple sub-tasks if needed.
      6. Ensure your edges show the actual flow, and not just connections of what's related. The connections are meant to show the logical flow, and not the relatedness/similarity.
      7. The group name is meant to classify clusters of nodes within each graph. For instance, if we have multiple nodes in features, they would all have "feature" as group. In Architecture Flow, the "Group" should show the layer each node is in, for instance "Backend Layer", "Database Layer" etc.
      9. for a hierarchy of nodes A -> B -> C; ensure that there is not a connection between A -> C.
    </Rules>
    
    <output_format>
    The output should be in between the delimeters ```reactflow and ```. Only provide the json output. Don't give unnecesary explanation.
    ```reactflow
    {
      "nodes": [
        { 
          "id": "unique_node_identifier_string",
          "data" : {
            "label": "name_of_the_service",
            "description": "description of the service",
            "associated_files": ["file_path_1", "file_path_2", "file_path_3", etc.],  // (default: ["No File Available"] if not present)
            "group": "name_of_group",  // Add the logical group name (e.g., "Frontend", "Backend", etc..)
            "subgroup": "name_of_subgroup",  // Add a more specific subgroup name (e.g., "Frameworks", "NoSQL Databases", etc..)
            "service": "filename" //taken from the $icons_metadata,
          }
          "position":{ "x": "Xcoordinate", "y": "Ycoordinate" },
          "type" : "customNode" //this is hardcoded and will be constant
        }
      ],
      "edges": [
        {
          "id": "unique_egde_identifier_string",
          "source": "label A",
          "target": "label B",
          "label": "Showcase what comes from the source node, to the target node. Be concise and specific with labels, such as 'Ingested Data', 'Converted Text', 'User Query' etc. Use at max 5 words",
          "type" : "customEdge" //this is hardcoded and will be constant
        }
      ]
    }```
    </output_format>
    """
    return system_prompt, user_prompt
  

def erd_generation(services_data, icons_metadata):
  tables_metadata = []
  for entry in services_data:
      table_name = entry["table_name"]
      ddl = entry["ddl"]
      columns, primary_keys, foreign_keys = parse_ddl(ddl)
      tables_metadata.append({
          "table_name": table_name,
          "columns": columns,
          "primary_keys": primary_keys,
          "foreign_keys": foreign_keys
      })

  dot = generate_combined_graph(tables_metadata)

  system_prompt:str = """
    You are tasked with creating a JSON structure for a ReactFlow diagram based on the given database ER diagram and schema JSON. This JSON includes information about database columns and their relationships.Your output should represent this information as a network of nodes and edges.
    </Task>
    
    <Icons Context>
      $icons_metadata = """ + str(icons_metadata) + """
    </Icons Context>

    <Instructions>
      You are a solution expert, specializing in problem and solution flows. You will be given the database schema information of a database, and your task is to create an interconnected single component of graph which is detailed, and intuitive and self explanatory for:

      Follow these guidelines:
      1. Create nodes for each unique service (both external and third-party).
      2. Do not create any group nodes.
      4. In the data key for each service node, include two additional fields called group and subgroup. The group field should contain the logical group name (e.g.,Databases, etc..), and the subgroup field should provide more specific categorization (e.g., 'Transactional Tables', 'Reference Tables' etc..). For example, for a service node representing daily transactions, the group would be Database and the subgroup would be Transactional Tables.
      5. For each node, check which icon will be the most suitable from the $icons_metadata in the <Icons Context>
      6. Ensure all information from the input is represented in the output.
      7. The position coordinates must be proper for all the nodes.
    </Instructions>

    <Rules>
      Important Rules to be followed:
      1. Give detailed technical architecture flow and the JSON object following the below output format.
      2. Make sure that the flow and order of new solution approach is explained well in the graph with appropriate edges. Use as many edges you want to describe the data and user flow properly.
      3. The whole user and data flow should be clear.
      4. Do not add unnecessary nodes and edges. Do not create duplicate nodes that perform same task.
      5. Make the Node descriptions detailed, breaking tasks into multiple sub-tasks if needed.
      6. Ensure your edges show the actual flow, and not just connections of what's related. The connections are meant to show the logical flow, and not the relatedness/similarity.
      7. The group name is meant to classify clusters of nodes within each graph. For instance, if we have multiple nodes in features, they would all have "feature" as group. In Architecture Flow, the "Group" should show the layer each node is in, for instance "Database Layer" etc.
      9. for a hierarchy of nodes A -> B -> C; ensure that there is not a connection between A -> C.
    </Rules>
    
    <output_format>
    The output should be in between the delimeters ```reactflow and ```. Only provide the json output. Don't give unnecesary explanation.
    ```reactflow
    {
      "nodes": [
        { 
          "id": "unique_node_identifier_string",
          "data" : {
            "label": "name_of_the_table",
            "description": "description of the table",
  	    "columns": ["order_id [PK]", "product_sku [PK]", "quantity", "unit_price"]
            "group": "name_of_group",  // Add the logical group name (e.g., "Database", etc..)
            "subgroup": "name_of_subgroup",  // Add a more specific subgroup name (e.g., 'Transactional Tables', 'Reference Tables', etc..)
            "service": "filename" //taken from the $icons_metadata,
          }
          "position":{ "x": "Xcoordinate", "y": "Ycoordinate" },
          "type" : "customNode" //this is hardcoded and will be constant
        }
      ],
      "edges": [
        {
          "id": "unique_egde_identifier_string",
          "source": "label A",
          "target": "label B",
          "label": "Showcase what comes from the source node, to the target node. Be concise and specific with labels, such as 'Ingested Data', 'Converted Text', 'User Query' etc. Use at max 5 words",
          "type" : "customEdge" //this is hardcoded and will be constant
        }
      ]
    }```
    </output_format>
    """
    
  user_prompt:str = f"""
    <Input>
    $database_tables = {dot}
    $icons_metadata
    </Input>

    <Role>
    You are an expert at understanding database architecture based on ER diagrams and relational structures. Create a JSON structure for a ReactFlow diagram based on the given database schema.
    </Role>
    <Output Structure>
      1. Create a JSON object with a "nodes" and "edges" array.
      2. Create nodes for each table in the schema.
      3. "nodes": An array containing all node objects.
      - "id": A unique string identifier for the node.
      - "data":  
        - "label": The name of the table.
        - "description": A brief summary of the table's role or content.
        - "columns": List of column names (mark primary keys with [PK], foreign keys with [FK]).
        - "group": The logical group name (e.g., 'Database').
        - "subgroup": The specific subgroup within the group (e.g., 'Transactional Tables', 'Reference Tables').
        - "service": The appropriate filename of the icon based on the $icons_metadata.
      - "position" : The x and y coordinates of the node.
      - "type" : "customNode" This should be fixed.
      4. "edges" : An array having id, source, target, label, and type should be customEdge always.
      5. The label of the edge should describe the relationship, like "order_id â†’ order_id". 
      6. The output should be in the form of a dictionary containing a "nodes" and "edges" array.
      7. Present only the code inside delimiters "```reactflow [reactflow CODE]```" without any additional explanation.
    """
    
  return system_prompt, user_prompt
    

def feature_summary_generation(formatted_data, user_mvf, executive_summary):
    # if input_type is None:
    #     formatted_data = file_summary_list
    # elif input_type == "batch_summary":
    #     formatted_data = format_batchwise_summary_metadata_for_services(file_summary_list)
    # else:
    #     formatted_data = format_file_summaries(file_summary_list)

    user_prompt = """
    Role: You are an AI code analyst specializing in creating concise, feature-level summaries of codebases.

    Objective: Provide a comprehensive yet concise feature-level summary of a given codebase, highlighting key components, functionality, and the project's overall workflow.

    Input: You will receive information about a codebase, which may include an executive summary or other project details.

    Steps:
    1. Analyze the provided codebase information.
    2. Identify the main features (maximum 5) of the project from the executive summary (if provided in same order)
    3. Create a summary following the specified format, including:
        a. An overview of the project
        b. A list of key features with brief descriptions
        c. A closure statement
    4. Self-evaluate the generated summary and assign a confidence score.
    5. Format the output as specified in the instructions.

    Output Format:
    ```json
    {
        "data": "generated_summary in string format adhering to the Detailed Instructions for Output Format",
        "confidence_score": 90
    }
    ```

    Detailed Instructions for Output Format:

    **Overview**
    <empty line>
    < 
        Summarize all features in 2-3 sentences, introducing the project and its purpose.
        Provide a 2-3 sentence summary of key benefits, highlighting core architecture and value proposition.
    >
    <empty line>
    **Key Features**
    <empty line>
    <   
        List a maximum of 5 main features.
        For each feature, provide up to 2 sub-points describing its functionality.
        Ensure clear explanation of how features interact and contribute to the project's goals.
        1. ***<Key Feature Title>*** : 
        * <Sub point 1 description>
        * <Sub point 2 description>
        <empty line>
    >
    <empty line>
    < 
        Summarize the overall impact and value proposition of the project in one sentence as a conclusion statement.
    >
    <empty line>
    
    -> Self-Evaluation:
        - Score the summary out of 100 based on clarity, precision, detail, knowledge, accuracy, technical correctness, and understanding of the data.

    -> Formatting Requirements:
        - Replace all newline characters (\n) with \\n in the JSON output.
        - Ensure the complete JSON is less than 7500 tokens.
        - Start the output with "```json" and end with "```".
        - If an executive summary is provided, use only the highlighted features from it.

    Example Output Structure:
    ```json
    {
        "data": "**Overview**\\n\\n[Project overview]\\n\\n[Benefits summary]\\n\\n**Key Features**\\n\\n1. *Feature 1*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n2. *Feature 2*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n[...continue for up to 5 features...]\\n\\n[Closure statement]",
        "confidence_score": 90
    }
    ```

    Remember: Adhere strictly to the output format and instructions to maintain consistency and accuracy in your summary.
    """

    user_prompt += "User Defined Features : " + str(user_mvf)

    system_prompt = f"""
        <role>
        You are an assistant to a Senior Software Engineer. You are very capable in reading and understanding huge codebases.
        There is no edge-case, no mistake, no functionality no matter how small goes unnoticed by you.
        You will be given a large codebase and be asked queries regarding it.
        </role>

        <Task>
        You will be given relevant files from a production codebase. The Senior Engineer will consult you to clear his doubts and ask for critical code-level and functionality level analysis of the same.
        <Important>
        1. You will be clear. Feel free to be descriptive but Avoid Jargon
        2. You shall perform critical analysis on the code before responding.
        3. Note that the codebase will be quite complex and have dependencies everywhere, be mindful of them all.
        4. Enclose code in (triple backticks)``` code ```
        </Important>
        </Task>

        Files from Codebase goes here :
        <Repo Structure>
        {formatted_data}
        </Repo Structure>
    """

    start_index = executive_summary.find("Highlighted Features")
    end_index = executive_summary.find("Key Benefits")

    if start_index != -1 and end_index != -1:
        executive_summary = executive_summary[start_index:end_index].strip()

    user_prompt += "Executive Summary : " + str(executive_summary)

    return system_prompt, user_prompt

def feature_summary_generation_db(formatted_data, user_mvf, executive_summary):
    # if input_type is None:
    #     formatted_data = file_summary_list
    # elif input_type == "batch_summary":
    #     formatted_data = format_batchwise_summary_metadata_for_services(file_summary_list)
    # else:
    #     formatted_data = format_file_summaries(file_summary_list)

    user_prompt = """
    Role: You are an AI Database Analyst specializing in creating concise, feature-level summaries of complex database schemas and architectures.

    Objective: Provide a comprehensive yet concise feature-level summary of a given database schema information, highlighting key components, entities, relationships, and the overall data architecture workflow.

    Input: You will receive information about a database design, which may include an executive summary or other schema-level details.

    Steps:
    1. Analyze the provided database schema information.
    2. Identify the main features (maximum 5) of the database from the executive summary (if provided in same order)
    3. Create a summary following the specified format, including:
        a. An overview of the database
        b. A list of key features with brief descriptions
        c. A closure statement
    4. Self-evaluate the generated summary and assign a confidence score.
    5. Format the output as specified in the instructions.

    Output Format:
    ```json
    {
        "data": "generated_summary in string format adhering to the Detailed Instructions for Output Format",
        "confidence_score": 90
    }
    ```

    Detailed Instructions for Output Format:

    **Overview**
    <empty line>
    < 
        Summarize all features in 2-3 sentences, introducing the database and its purpose.
        Provide a 2-3 sentence summary of key benefits, highlighting schema structure, normalization or denormalization logic, and value proposition in handling data.
    >
    <empty line>
    **Key Features**
    <empty line>
    <   
        List a maximum of 5 main features.
        For each feature, provide up to 2 sub-points describing its data handling, relationships, or optimization logic.
        Ensure clear explanation of how features contribute to performance, consistency, and data integrity.
        1. ***<Key Feature Title>*** : 
        * <Sub point 1 description>
        * <Sub point 2 description>
        <empty line>
    >
    <empty line>
    < 
        Summarize the overall impact and value proposition of the database in one sentence as a conclusion statement.
    >
    <empty line>
    
    -> Self-Evaluation:
        - Score the summary out of 100 based on clarity, precision, detail, knowledge, accuracy, technical correctness, and understanding of the schema information.

    -> Formatting Requirements:
        - Replace all newline characters (\n) with \\n in the JSON output.
        - Ensure the complete JSON is less than 7500 tokens.
        - Start the output with "```json" and end with "```".
        - If an executive summary is provided, use only the highlighted features from it.

    Example Output Structure:
    ```json
    {
        "data": "**Overview**\\n\\n[Database overview]\\n\\n[Benefits summary]\\n\\n**Key Features**\\n\\n1. *Feature 1*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n2. *Feature 2*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n[...continue for up to 5 features...]\\n\\n[Closure statement]",
        "confidence_score": 90
    }
    ```

    Remember: Adhere strictly to the output format and instructions to maintain consistency and accuracy in your summary.
    """

    user_prompt += "User Defined Features : " + str(user_mvf)

    system_prompt = f"""
        <role>
        You are an assistant to a Senior Data Architect. You are very capable in reading, analyzing, and understanding complex database schemas and data models.
        No entity, constraint, relationship, or optimization logic goes unnoticed by you.
        You will be given a comprehensive database structure or schema information and will be asked to analyze, explain, and summarize it at a structural and functional level.
        </role>

        <Task>
        You will be given relevant database schema files or DDL definitions. The Senior Data Architect will consult you to clear doubts and ask for critical schema-level and data model-level analysis.
        <Important>
        1. You will be clear. Feel free to be descriptive but Avoid Jargon
        2. Perform a critical and deep analysis of the schema and the information given before responding.
        3. The schema will often involve multiple tables, foreign keys, views, procedures, and indexing strategies â€” be mindful of their dependencies and relationships.
        4. Enclose code or schema in (triple backticks)``` code ```
        </Important>
        </Task>

        Files from Database schema goes here :
        <Database Structure>
        {formatted_data}
        </Database Structure>
    """

    start_index = executive_summary.find("Highlighted Features")
    end_index = executive_summary.find("Key Benefits")

    if start_index != -1 and end_index != -1:
        executive_summary = executive_summary[start_index:end_index].strip()

    user_prompt += "Executive Summary : " + str(executive_summary)

    return system_prompt, user_prompt


#FEATURE HIERARCHY:
generate_features_system_prompt = """
  <Role>
    You are a Software Architect with expertise in analyzing large summaries from code files of an application. 
    You can comprehend summaries from code files that are complex, production-grade and are written in various programming languages to generate most important features, their description and the subfeatures with their description belonging to the most important features along with the other relevant information requested below.
    
    You will follow 2 Events before responding : 
    1. Generation of Feature Hierarchy as given in "Output_Format".
    2. Critical Evaluation of Every Confidence Score.  
  </Role> 

    <Task 1>
    You are provided with multiple relative file paths and file-wise code summaries from a application codebase.
    1. Analyze the file summaries carefully, leveraging your expertise to deduce the frameworks, functionality, and features.
    2. Perform a critical assessment of the code's functionality and interdependencies before responding.
    3. The codebase is complex and likely contains dependencies across various modules. Be mindful of these.
    4. Analyse every file summary and assign the features and sub-features based on the information provided.
    5. Respond strictly in the structured JSON format provided below.
    6. In each sub-feature's 'file_path' array:
        - Set 'critical: true' ONLY for files that are CORE & NON-REPLACEABLE to the sub-feature's main functionality.
        - Set 'critical: false' for ALL supporting, secondary, or replaceable files  
        - Each sub-feature should have both true and false entries.
        - If unsure, default to false (be EXTREMELY selective with 'true')
        - Make sure each sub-feature atleast have one file as true.

    Explanation of the Output terms:
    Feature - Features are most valuable and high level features extracted from the list of summaries that are provided to you. 
    Feature description - Description of the features explaining the high level value and impact that it creates for the project. Define the Feature. The description should be crisp, precise, well formatted and must be between 2-3 lines.
    Subfeature - Subfeatures are micro most valuable features that are extracted from the list of summaries and belong to the Most related and similar Features.
    Subfeature description - Description of the subfeatures explaining the specific value, technical and non-technical functionalites that it provided to the project. Define the subfeature and also explain how its related to the feature. The description should be crisp, precise, well formatted and must be between 2-3 lines.
    
    Points to Remember:
    1. Do not extract any feature or subfeature where there are no reference/citations from the application summaries.
    2. The description must be precise, valuable, well-formatted and must be between 2-3 lines.
    3. The Feature titles should be precise, specific, self explanaible, independent and not have similar feature titles. The Feature titles should not be highly generalized.
    4. The SubFeatures titles should be precise, self explanaible and not have similar subfeature titles. The SubFeature titles should not be highly generalized.
    5. SubFeatures should not be very low level that it explains code functions, code process like 'Json handling', 'Reading csv', readME etc.
    6. If similar subfeatures are present, then group them under one common Feature itself. Do not create multuple Features for similar subfeatures.
    6. If Unit testing related summaries are found, then create that as another Feature named 'Unit Testing' and assign the specific testing subfeatures under this feature.
    </Task 1>

  <Task 2>
  You shall now Assign and Justify Confidence Scores for each feature.

  <Critical Evaluation of Confidence Scores> 

  <Evaluation MODE>
  - You will now Forget everything that was done beforehand and act as an unbiased judge.
  - $Project-Summaries-&-Paths (INPUT).
  </Evaluation MODE>
  <Important>
  Critically analyze every "Feature" and "SubFeature" based on the following metrics. 
  You shall generate a confidence score between 0-100 for each of the following :
  1. Is the "Feature" & "SubFeature" name accurate to its functionality ? (Accuracy)
  2. Does the "Feature" & "SubFeature" include files with an unrelated function ? (Feature Dilution Rate)
  3. Important : Does this "Feature" & "SubFeature" make sense given the Overall Purpose of the Application ? (Consistency)
  4. Are all the files in "Feature" & "SubFeature" included ? (Completeness)

  <Strict>
  1. You will now generate a list of 4 confidence scores between 0-100 for above criteria under "confidence_score" key.
  2. Based on above criteria, you shall provide a VERY BRIEF logical explanation (10-20 words) for Confidence Score under "confidence_score_justification" key.
  3. Make sure to mention the entire filepath without omitting the prefix.
  4. Make sure all the filepaths are present.
  <Important> STRICTLY Don't Comment on Missing Files. Don't Overestimate. Don't Underestimate.</Important> 
  </Strict>

  </Important>

  </Critical Evaluation of Confidence Scores> 
  </Step 2>


      <Output_Format>
    Return a response in JSON format. Do not include any extra information or explanations. Strictly DON'T deviate from mentioned KEYS.
    Example:
```json
[
  {
    "name": "User Authentication and Management",
    "feature_description": "Comprehensive user account system with secure login, registration, profile management, and role-based access control.",
    "feature_description_confidence_score": [95, 70, 100, 70],
    "sub_features": [
      {
        "name": "User Registration",
        "description": "Allows new users to create accounts by providing necessary information such as username, email, and password. Implements email verification, password strength checks, and duplicate account prevention. Stores user data securely in the database with password hashing.",
        "file_path": [
          {
            "module_name": "RegistrationController",
            "path": "Controllers/Account/RegistrationController.cs",
            "critical": true
          },
          {
            "module_name": "RegisterView",
            "path": "Views/Account/Register.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [75, 80, 85, 65],
        "sub_feature_confidence_score_justification": "No feature dilution, might have missed some file."
      },
      {
        "name": "User Login",
        "description": "Authenticates users using their credentials, creates and manages user sessions, and implements security measures such as login attempt limiting and two-factor authentication (2FA). Provides password reset functionality for forgotten passwords.",
        "file_path": [
          {
            "module_name": "LoginController",
            "path": "Controllers/Account/LoginController.cs",
            "critical": true
          },
          {
            "module_name": "LoginView",
            "path": "Views/Account/Login.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [80, 100, 80, 75],
        "sub_feature_confidence_score_justification": "High chance of missing files."
      }
    ],
    "feature_confidence_score_justification": "No feature dilution, duplication or missing files. Accurate Naming."
  },
  {
    "name": "Product Catalog Management",
    "feature_description": "Comprehensive system for managing product listings, categories, and inventory across the e-commerce platform.",
    "feature_description_confidence_score": [95, 65, 70, 80],
    "sub_features": [
      {
        "name": "Product CRUD Operations",
        "description": "Enables administrators to create, read, update, and delete product listings. Includes functionality for managing product details such as name, description, price, images, and inventory levels. Implements validation to ensure data integrity and consistency across the product catalog.",
        "file_path": [
          {
            "module_name": "ProductController",
            "path": "Controllers/ProductController.cs",
            "critical": true
          },
          {
            "module_name": "ProductView",
            "path": "Views/Product/Index.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [90, 85, 100, 70],
        "sub_feature_confidence_score_justification": "High confidence with no duplication or dilution."
      },
      {
        "name": "Category Management",
        "description": "Allows for the creation and management of product categories and subcategories. Implements a hierarchical structure for organizing products, enabling efficient navigation and filtering of the product catalog for both administrators and customers.",
        "file_path": [
          {
            "module_name": "CategoryController",
            "path": "Controllers/CategoryController.cs",
            "critical": true
          },
          {
            "module_name": "CategoryView",
            "path": "Views/Category/Index.asp",
            "critical": false
          }
        ],
        "sub_feature_confidence_score": [85, 75, 90, 95],
        "sub_feature_confidence_score_justification": "High confidence without any duplication or dilution."
      }
    ],
    "feature_confidence_score_justification": "All files refer to single overall functionality. Might have missed some files."
  }
]
```
  </Output_Format>

"""

generate_features_user_message = """
<Strictly Remember>
1. As input you will be given a batch of `file_path` and `file_summary` from a production codebase. Keep it in mind that it could be a file from a very large repository with lot of inter-dependencies.
2. Understand all the file description first, then try to determine the feature, sub-features and their description. For **each file** it should have a feature or sub-features whenever the conditions are met.
3. The response should contain all the fields given in the example output format. The response should be strictly in json format.
4. The description of features/subfeatures must be in the length of 2-3 lines. The response should be structured and well-formatted.
5. Don't generate any additional explanation or description. Provide the structured response in json only.
</Strictly Remember>
  
<Input file wise summary>
{file_summary}
</Input file wise summary>
<Response>
"""

merge_features_in_hierarchy_user_prompt = """You are a software feature analyzer. Given a list of related features that have been clustered together, create a merged feature that encompasses all the functionality.

Features to merge:
{feature_list}

Generate a JSON response that includes:
1. A name for the merged feature representing accurate feature name. Do not mention its merged or unified or anything as such. The feature name should accurately represent a major funcationality of a repository.
2. A detailed description that covers all functionality
3. A confidence score (0-100) for the merge
4. A justification for the confidence score

Respond with a JSON object in the following format:
```json
{{
    "name": "Merged feature name",
    "description": "Comprehensive description",
    "confidence_score": 85,
    "confidence_justification": "Reason for the confidence score"
}}
```
Give only JSON and nothing else. Do not include any explanations or additional text outside the JSON block. Make sure to start with ```json and end with ``` only.
"""

mapping_names_for_merged_features_user_prompt = """  <Role>
    You are a smart AI cassistant with strong expertise in Software Engineering. You can understand complex, production-grade codebases written in various programming languages and summarize them effectively.
  </Role>
  <Task>
  You will be given a brief description of  features of a large codebase and your task is to generate a relevant feature name, brief description, and priority level.
  <Important>
   1. The feature name should be brief, relevant and should represent the entire description provided.
   2. Generate a relevant description which is basically a overall summary of the description provided.
   3. Assign a priority level (high, medium, low) based on the significance, importance and complexity of the feature to the overall system. 
  </important>
  </Task>
  <Example output>
  ```json
    {
        "name": <feature_name>, //string
        "feature_description": <feature_description>, //string
        "priority": <priority> //string (high, medium, or low)
    }
    ```
  </Example output>
  <Strictly Remember>
1. The feature name should be relevant and at the same time interpretable, easy to understand.
2. The feature description should represnt the entire description given for summarisation, it should be simple and easy to understant.
3. The priority should be one of: high, medium, or low.
4. The response should be strictly in json format specified above.
5. Strictly make sure Feature Description is not more than 200 words.
  </Strictly Remember>

<code summary>
The code summary is given below:
"""


reducing_sub_features_user_prompt = """
    You are a software feature consolidation expert. Your task is to merge similar sub-features into one comprehensive sub-feature.

    Here are the sub-features that need to be merged:
    {sub_features_list}

    For each sub-feature, we have:
    - Name: The sub-feature name
    - Description: The sub-feature description (if available)
    - Confidence Score: The confidence score (if available)

    Your output should be a JSON object containing:
    1. A unified sub-feature name that encompasses all the input sub-features
    2. A comprehensive description that covers all aspects of the input sub-features
    3. A confidence score (use the highest available from input sub-features)
    4. A justification for the confidence score

    Return the output in JSON format starting with ```json and ending with ```.

    Example output format:
    ```json
    {{
        "name": "Unified Sub-Feature Name",
        "description": "Comprehensive description covering all aspects",
        "sub_feature_confidence_score": 95,
        "sub_feature_confidence_score_justification": "Merged from similar sub-features with high semantic similarity"
    }}
    ```
    """


post_processing_feature_name_description_system_prompt="""
  <Role>
    You are a smart AI assistant with strong expertise in Software Engineering. You can understand complex, production-grade codebases written in various programming languages and summarize them effectively.
  </Role>
  <Task>
  You will be given a brief description of modules or features of a large codebase and your task is to generate a relevant feature name and brief description.
  <Important>
   1. The feature name should be brief, relevant and should represent the entire description provided.
   2. Generate a relevant description which is basically a overall summary of the description provided.
   3. Also generate a confidence score in a scale of 0 - 100.
  </important>
  </Task>
  <Example output>
  ```json
    {
        "name": <feature_name>,
        "feature_description_confidence_score": <score 0 - 100>,
        "feature_description": <feature_description>
    }```
  </Example output>"""

post_processing_feature_name_description_user_prompt = """<Strictly Remember>
1. The feature name should be relevant and at the same time interpretable, easy to understant.
2. The confidence score should represent the ability to summarise the description.
3. The feature description should represnt the entire description given for summarisation, it should be simple and easy to understant.
4. The response should be strictly in json format specified above.
</Strictly Remember>
<code summary>
The code summary is given below: \n
{feature_description}
</code_summary>
<response>
Your response in json goes here:
"""

merge_similar_features_system_prompt = """You are a solution architect. Your task is to carefully review each feature and its description, and combine them into a single high-level feature.

The final high-level features should represent what an end user would perceive, e.g., Messenger, Google Chat, Messaging, Reels, etc.

Based on the generated features provided, identify which features can be merged into a single high-level feature. 
Strictly output them in the following format:
{{ 
  <High-Level Feature Name 1>: [<Merged Feature 1>, <Merged Feature 2>, <Merged Feature 3>, ...],
  <High-Level Feature Name 2>: [<Merged Feature 1>, <Merged Feature 2>, <Merged Feature 3>, ...],
  ...
}}

INPUT:
Feature names and descriptions are provided in the format: 
[1. Feature name: <feature name> 
Feature description: <feature description>, 
2. ...]

{feature_texts}

MVFS:
{total_MVFs}

Points to remember:
1. While merging features and naming high-level features, always prefer names from the user-defined MVFs provided. All relevant features can be grouped under these high-level features.
2. If certain features do not fit under the user-defined MVFs, choose a better name than the existing one for the new high-level feature if necessary.
3. The names of the features being merged must remain exactly as provided in the INPUT section; do not modify them. Do not consider Feature description in Feature Names.
4. Follow the output structure strictly: high-level feature names as dictionary keys and merged features as values in list format.
5. If a feature is already a high-level feature, you do not need to forcibly merge it. If a feature seems to be function-level/low-level  features, merge them into a High-level feature.
6. Merge similar features into a single high-level feature based on their names and descriptions, when applicable. Each final high-level feature should be independent of the others.
7. Do not assign the same feature to multiple high-level features.
8. If user-defined MVFs are empty, skip point 1 and begin with point 2.
9. Do **not** include any Feature descriptions in the final output."""


merging_description_user_prompt = """You are a Solution Architect. Your task is to summarize the multiple feature descriptions provided into a brief, coherent summary of **no more than two sentences**.

  The summary must:
  - Accurately capture all key components from the provided descriptions.
  - Align clearly with the given high-level feature name.
  - Serve as the final description of the high-level feature.

  Only the final summarized description should be included in the output â€” no additional commentary or formatting.

  INPUT:
  Multiple descriptions: {merging_feature_description}

  High-Level Feature Name: {high_level_feature}
  """


micro_sub_feature_prompt = """You are an expert system analyst specializing in decomposing SubFeatures into granular, logically independent components. You support **two levels** of splitting:

1. **Horizontal splitting**: Split a subfeature into multiple *same-level subfeatures* when it encompasses multiple independently meaningful functionalities. The subfeatures created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.
2. **Vertical splitting**: Further break each of those subfeatures into *microsubfeatures* (if applicable), ensuring each micro-sub-features/micro-user-story describes a single goal or operation. The micro-sub-features/micro-user-story created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.

---

### ðŸ”§ TASK OVERVIEW

Given a Macro-Feature, Subfeature, its description, associated module files and its summary:

- Decide if the subfeature should be split horizontally into multiple same-level subfeatures.
- For each resulting subfeature (or original if not split), analyze whether it can be split vertically into **microsubfeatures** (fine-grained user stories).
- Provide the confidence scores for the subfeature that is split, whether horizontally or vertically.
- Provide the files that are related to the sub_features too, not just the micro_sub_features.
- Each leaf user-story must have files assigned to them, else you should not create/split these subfeatures.
- Provide description of generated subfeature/sub-user-stories in 2-4 lines but only valid information. Do not assume or hallucinate to generate description.
Apply this recursively: if horizontal splitting occurs, then attempt vertical splitting for each. But remember, not to create any duplicates in the process. 

---

### SPLITTING DECISIONS

#### Horizontal Splitting (Same-level Subfeatures):
Split if:
- The subfeature covers multiple high-level functionalities
- Each function could be planned, developed, and deployed independently
- Each component has a clear boundary and responsibility

#### Vertical Splitting (Microsubfeatures):
Split further if:
- A subfeature contains multiple independent operations or logical stages
- These operations can be implemented, tested, or tracked separately
- Each micro-subfeature represents one atomic, non-overlapping functionality

---

### DO NOT SPLIT IF:
- sub-user-stories are tightly coupled in the Subfeature and cannot function independently.
- Do not split subfeatures into sub-user-stories that are hardly single line of code and cannot be considered as a proper functionality, but just a config/parameter.
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across actions are too complex to isolate.
- There are no files that can be mapped to the generated user-story.
- Do not split if the user-story is barely a functionality. The split user-stories must have independent functionality that contributes to the subfeature and feature and if not, do not split.
- Don not split ReadMe & .md files into sub-user-stories.
- Do not split horizontall for granullar subfeatures as they are not user stories but mid level features.
---

### FILE MAPPING RULES:
- For each subfeature or microsubfeature, cite only directly relevant files.
- Use only the provided input data to match files â€” no guessing.
- Avoid duplication unless a file is clearly shared between components.

Each `file_path` entry must include:
```json
{
  "module_name": "<Name>",
  "path": "<Path>",
  "critical": <true/false>,
  "git_url": "<Git URL>"
}

OUTPUT FORMAT
If the subfeature should NOT be split:
Return: "None"

If the subfeature should be split, return a list of Parent User Stories with subfeatures inside.
If a subfeature itself can be further split into microsubfeatures, nest them under micro_sub_features like so:

[
  {
    "name": "Parent User Story Title 1",
    "description": "Full description of the original or updated user story and its purpose.",
    "file_path": [...],
    "sub_feature_confidence_score":"confidence score of the subfeature with respect to the Feature, as a percentage (e.g., 80)"
    "micro_sub_features": [
      {
        "name": "Sub-User Story Title 1",
        "description": "Standalone description of a single functionality.",
        "file_path": [...],
        "micro_sub_feature_confidence_score":"confidence score of the micro_sub_feature with respect to the sub_feature, as a percentage (e.g., 90)"
        }
          ...
        ]
      },
      ...
    ]
  }
]
Each layer must preserve independence, clarity, and singular focus of each story.

VALIDATION CHECKLIST
- Each title must express one functionality only (no imperative phrasing)
- description must avoid assumptions and describe the real function. It must be as detailled as possible.
- Each story must make sense independently and fit in the broader feature flow
- if there are multiple user-story under the subfeature, it needs to be in sequence of business logic.
- File mappings must be relevant and scoped accurately
- Do no miss/skip any values in the output json. The output structure must be maintained strictly.
- All subfeature and sub-user-story names and descriptions must be strictly in a declarative tone, not imperative.

* Use generic or speculative statements
"""


db_micro_sub_feature_prompt = """
<Role>
You are an expert Database analyst specializing in decomposing SubFeatures into granular, logically independent components. You support **two levels** of splitting:
You shall ALWAYS process features from a Database perspective ONLY. 
There can be more than one Table in the DB context provided to you.
</Role>

1. **Horizontal splitting**: Split a subfeature into multiple *same-level subfeatures* when it encompasses multiple independently meaningful functionalities. The subfeatures created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.
2. **Vertical splitting**: Further break each of those subfeatures into *microsubfeatures* (if applicable), ensuring each micro-sub-features/micro-user-story describes a single goal or operation. The micro-sub-features/micro-user-story created must be based on facts from the feature description or subfeature description and the files provided. Dont assume functionalities.

<Strict Constraints> 
- You are dealing with Database Information. 
- No matter what, STRICTLY use Database-Specific Language ALWAYS. 
- Use words like Columns / Fields / Schema / DataTypes / Constraints / Foreign Keys / Primary Keys etc.
- Strictly Do not start descriptions with or start with "this micro-feature" / or "this sub-feature".
- You shall do this regardless of the input context and nature.
Remember : Every "FILE" given to you is information of a table. Therefore in your response, ALWAYS refer to "Table" instead of "File".

</Strict Constraints> 


### ðŸ”§ TASK OVERVIEW

Given a Macro-Feature, Subfeature, its description, associated module files and its summary:

- Decide if the subfeature should be split horizontally into multiple same-level subfeatures.
- For each resulting subfeature (or original if not split), analyze whether it can be split vertically into **microsubfeatures** (fine-grained user stories).
- Provide the confidence scores for the subfeature that is split, whether horizontally or vertically.
- Provide the files that are related to the sub_features too, not just the micro_sub_features.
- Each leaf user-story must have files assigned to them, else you should not create/split these subfeatures.
- Provide description of generated subfeature/sub-user-stories in 2-4 lines but only valid information. Do not assume or hallucinate to generate description.
Apply this recursively: if horizontal splitting occurs, then attempt vertical splitting for each. But remember, not to create any duplicates in the process. 

---

### SPLITTING DECISIONS

#### Horizontal Splitting (Same-level Subfeatures):
Split if:
- The subfeature covers ONE / MORE THAN ONE high-level functionalities
- Each function could be planned and developed independently
- Each component has some clear boundaries and responsibilities

#### Vertical Splitting (Microsubfeatures):
Split further if:
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across actions are too complex to isolate.
- There are no tables that can be mapped to the generated user-story.
- The subfeature is too complex to be planned, developed, and deployed independently
- Each micro-subfeature represents one atomic, non-overlapping functionality
Note: Maintain at least 2 subfeatures unless the database has only one table.
- Prioritize brevity, consistency and no informaiton leakage across subfeatures.
- Ensure crisp segregation.
---

### DO NOT SPLIT IF:
- sub-user-stories are tightly coupled in the Subfeature and cannot function independently.
- Splitting of SubFeature fragments user understanding or development planning.
- Dependencies across tables in two features are too complex to isolate.
- There are no tables that can be mapped to the generated user-story.
Note: Maintain at least 2 subfeatures and 1 or more microsubfeatures per subfeature, Unless the database has only one table.
Note : Maintain brevity during splitting at the same level. Do NOT overload the a single feature with too many subfeatures.
---


### FILE MAPPING RULES:
- For each subfeature or microsubfeature, cite only directly relevant tables.
- Use only the provided input data to match files â€” no guessing.
- Avoid duplication unless a file is clearly shared between components.

Each `file_path` entry must include:
```json
{
  "module_name": "<Name>",
  "path": "<Path>",
  "critical": <true/false>,
  "git_url": "<Git URL>"
}

OUTPUT FORMAT
If the subfeature should NOT be split:
Return: "None"

If the subfeature should be split, return a list of Parent User Stories with subfeatures inside.
If a subfeature itself can be further split into microsubfeatures, nest them under micro_sub_features like so:

[
  {
    "name": "Parent User Story Title 1",
    "description": "Full description of the original or updated user story and its purpose.",
    "file_path": [...],
    "sub_feature_confidence_score":"confidence score of the subfeature with respect to the Feature, as a percentage (e.g., 80)"
    "micro_sub_features": [
      {
        "name": "Sub-User Story Title 1",
        "description": "Standalone description of a single functionality.",
        "file_path": [...],
        "micro_sub_feature_confidence_score":"confidence score of the micro_sub_feature with respect to the sub_feature, as a percentage (e.g., 90)"
        }
          ...
        ]
      },
      ...
    ]
  }
]
Each layer must preserve independence, clarity, and singular focus of each story.

VALIDATION CHECKLIST
- Each title must express one functionality only (no imperative phrasing)
- description must avoid assumptions and describe the real function. It must be as detailled as possible.
- Each story must make sense independently and fit in the broader feature flow
- if there are multiple user-story under the subfeature, it needs to be in sequence of business logic.
- File mappings must be relevant and scoped accurately
- Do no miss/skip any values in the output json. The output structure must be maintained strictly.
- All subfeature and sub-user-story names and descriptions must be strictly in a declarative tone, not imperative.
- Use Database-specific schema only. Do not include words like "Attributes" / "Code Files" in your response. 
- Strictly Do not start descriptions with or start with "this micro-feature" / or "this sub-feature".
* Use generic or speculative statements

"""import os
from graphviz import Digraph
import re 
import json

def parse_ddl(ddl: str):
    """
    Parse the DDL to extract columns, primary keys, and foreign keys.
    """
    lines = ddl.splitlines()
    column_lines = []

    for line in lines:
        line = line.strip()
        if (
            line.upper().startswith("CREATE")
            or line.upper().startswith("PRIMARY")
            or line.upper().startswith("FOREIGN")
            or line.upper().startswith(")")
            or line == ""
        ):
            continue

        match = re.match(r'(\w+)\s+\w+', line)
        if match:
            column_lines.append(match.group(1))

    pk_match = re.search(r'PRIMARY KEY\s*\((.*?)\)', ddl)
    primary_keys = [key.strip() for key in pk_match.group(1).split(",")] if pk_match else []

    foreign_keys = []
    for match in re.finditer(r'FOREIGN KEY\s*\(([^)]+)\)\s+REFERENCES\s+`?[\w]+\.(\w+)`\(([^)]+)\)', ddl):
        fk_col = match.group(1).strip()
        ref_table = match.group(2).strip()
        ref_col = match.group(3).strip()
        foreign_keys.append((fk_col, ref_table, ref_col))

    return column_lines, primary_keys, foreign_keys


def generate_combined_graph(tables_data):
    """
    Generate a single combined graph from multiple tables.
    """
    dot = Digraph(comment='Combined Table Diagram')
    dot.attr(rankdir='LR')

    # Store individual table nodes
    for table in tables_data:
        table_name = table['table_name']
        columns = table['columns']
        primary_keys = table['primary_keys']
        
        label_lines = []
        for col in columns:
            if col in primary_keys:
                label_lines.append(f"{col} [PK]")
            else:
                label_lines.append(col)
        dot.node(table_name, shape='box', label=f'{table_name}\\n' + "\\n".join(label_lines))

    # Add relationships
    for table in tables_data:
        table_name = table['table_name']
        for fk_col, ref_table, ref_col in table['foreign_keys']:
            dot.edge(table_name, ref_table, label=f'{fk_col} â†’ {ref_col}')

    return dot

def folder_summary_generation_prompts(
        total_allocated_tokens, 
        file_list, folder_name, 
        folder_path,
        subfolder_list,
        formatted_file_summaries,
        formatted_file_services,
        formatted_subfolder_summaries,
        formatted_subfolder_services,
        formatted_subfolder_features
    ):
    
    system_prompt = f"""
        You are an expert code analyst specialized in creating detailed, informative summaries of software project folders. Your task is to thoroughly analyze files and subfolders to provide a comprehensive understanding of the application or project and provide combined summaries along with required details. These summaries must be detailled enough for further summarization.

        Follow these guidelines:
        1. Conduct a deep analysis of the features to identify its core purpose and functionality
        2. Provide detailed explanation of key implementations and technical approaches of the features
        3. Thoroughly examine the summaries based on files and folders to understand relationship between features and combined smaller features into larger high level application level features.
        4. Explain the features within the broader project architecture with specific connections
        5. Describe technical patterns, design decisions, and architectural choices evident in the code
        6. Include specific functions, classes, and methods that define the feature's behavior
        7. Note dependencies, imports, and external connections that shape the folder's functionality
        8. Identify potential architectural strengths and areas for improvement when evident
        9. Identify all services represented in this folder based on file and subfolder services information
        10. Identify and articulate high-level features or functionalities represented by the folder into the feature_details section, when consolidating multiple subfolders or lower-level files. Derive these insights from both file-level and subfolder-level summaries. Also under each feature, mention which file/folder was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
        11. Do not miss any features that could be formed based on these summaries as this information is required to understand the application's buisness logic.
        12. Gather insights from the summaries provided to generate a high level detailled executive summary that could be used by business stakeholders to understand the folder/project.
        13. When analyzing the root folder, both the executive summary and the features must be strictly formed in a high level business logic standpoint of an application.
        
        IMPORTANT: 
        - Your summary should be thorough and detailed({total_allocated_tokens}) while maintaining technical/business precision and depth. Focus on providing insights that would help both stakeholders and developers understand the application better.
        - feature_details must contain high level feature name and feature description(value of the files/folders) strictly in concise bullet points. The feature inforamtion must be in detail to capture the complete high level knowledge for that feature but not the function level details. Feature names cannot be programmatic function names like Dependency management, json handling etc. instead it should be inventory management, order processing etc. 
        - Your services list should be comprehensive and include all services represented in this folder.
        - is_reuasble_lib if a folder is used as reusable lib make it True otherwise False
        - lib_name if is_reusable_lib is True then provide the name of the reusable lib/component If is_reusable_lib False then add Not Applicable
        - category if is_reusable_lib is True then provide category only between 'Frontend' and 'Backend' If is_reusable_lib False then add Not Applicable
        - sub_category if is_reusable_lib is True then provide sub category only between 'UI Component','Custom Hooks', 'http_client', 'Utils', 'Others' In Frontend & 'Middleware', 'Error Handling', 'Auth', 'Utils', 'Others' In Backend If is_reusable_lib False then add Not Applicable
        - when_to_use if is_reusable_lib is True then provide where this reusable lib/component can be used If is_reusable_lib False then add Not Applicable 
        - associated_files if is_reusable_lib is True then provide the list of files associated(give complete path for the assosciated file) with this reusable lib/component If is_reusable_lib False then add Not Applicable
        - summary must not be technical and only explain the high level details of the folder/project. Understand the file and folder summaries provided to combine the knowledge to form the executive summary. Make it as detailled as possible.
        - Use clear and concise language, avoiding jargon where possible.
        
        - You must provide your response in this exact format:
        ```summary
        [Your detailled high-level executive summary for the folder for business stakeholders]
        ```
        ```feature_details
        [List of high-level features or functionalities represented in this folder]
        ```
        ```services_namess
        [Comma-separated list of all services represented in this folder]
        ```
        ```is_reuasble_lib
        Boolean Value
        ```
        ```lib_name
        [Name of the reusable library if applicable]
        ```
        ```category
        [Category of the reusable library if applicable]
        ```
        ```sub_category
            [Sub category of the reusable library if applicable]
        ```
        ```when_to_use
        [Your detailed use case where or when this reuasble_lib can be usefull]
        ```
        ```associated_files
            [Comma-separated list of associated files with the reusable library, Give the Complete file path as mentioned in the file list]
        ```
        ```example_usage
            [Example code snippet of how to use this reusable library]
        ```
    """

    user_prompt = f"""
        Generate a summary and services list for the folder: "{folder_name}" (Path: {folder_path})

        FOLDER CONTENTS:
        - Files ({len(file_list)}): {", ".join(file_list) if file_list else "None"}
        - Subfolders ({len(subfolder_list)}): {", ".join(subfolder_list) if subfolder_list else "None"}

        FILE SUMMARIES:
        {os.linesep.join(formatted_file_summaries) if formatted_file_summaries else "No file summaries available"}

        FILE SERVICES:
        {os.linesep.join(formatted_file_services) if formatted_file_services else "No file services available"}

        SUBFOLDER SUMMARIES:
        {os.linesep.join(formatted_subfolder_summaries) if formatted_subfolder_summaries else "No subfolder summaries available"}

        SUBFOLDER SERVICES:
        {os.linesep.join(formatted_subfolder_services) if formatted_subfolder_services else "No subfolder services available"}

        SUBFOLDER FEATURES:
        {os.linesep.join(formatted_subfolder_features) if formatted_subfolder_features else "No subfolder features available"}
        
        Based on these components:
        1. Provide a thorough technical summary explaining the folder's purpose, implementation details, and architectural significance
        2. Compile a comprehensive list of all services represented in this folder based on file and subfolder services information
        
        Follow the exact format specified in the system instructions for your response.
    """

    return system_prompt, user_prompt

def services_generation():
    system_prompt = """
        <Task>
        Create an architectural blueprint of the given repository by identifying and classifying both external services and third-party services with no overlap between categories.
        </Task>

        <Definitions>
        - External services: Company-provided services hosted outside the application (AWS S3, Google Cloud, Stripe, Twilio)
        - Third-party services: Libraries, frameworks, and SDKs that are part of the core application stack (Django, React, MongoDB, Redux)
        </Definitions>

        <Output_Format>
        {
        "external_services": [
            {
            "external_service_name": "string",
            "description": "string",
            "associated_files": ["string"],
            "service_class": "string",
            "used_in_files": ["string"]
            }
        ],
        "thirdparty_services": [
            {
            "thirdparty_service_name": "string",
            "description": "string",
            "associated_files": ["string"],
            "service_class": "string",
            "used_in_files": ["string"]
            }
        ]
        }
        </Output_Format>

        <Instructions>
        1. Conduct a thorough repository analysis to identify all services
        2. Classify each service into exactly ONE category:
        - External services: Cloud platforms, payment processors, authentication providers
        - Third-party services: Frameworks, libraries, SDKs integrated into the codebase
        3. For each service, provide:
        - Name: Exact service name
        - Description: Concise explanation of functionality and purpose
        - Associated files: All files directly importing or using the service
        - Service class: Category (e.g., "cloud storage", "web framework", "database")
        - Used in files: Complete paths of files utilizing the service
        4. Ensure ZERO overlap between categories
        5. Prioritize accuracy over comprehensiveness
        6. Validate that identified services are actively used in the project
        7. Include only services with clear evidence of implementation
        8. Do not create a lot of services which are redundant. Keep it to a maximum of 50 services only.
        </Instructions>

        <Examples>
        Good External Service Entry:
        {
        "external_service_name": "AWS S3",
        "description": "Cloud storage service used for storing user-uploaded files",
        "associated_files": ["src/services/storage.js", "src/config/aws.js"],
        "service_class": "cloud storage",
        "used_in_files": ["src/components/FileUpload.js", "src/pages/UserProfile.js"]
        }

        Good Third-Party Service Entry:
        {
        "thirdparty_service_name": "React",
        "description": "Frontend JavaScript library for building user interfaces",
        "associated_files": ["package.json", "src/index.js"],
        "service_class": "frontend framework",
        "used_in_files": ["src/App.js", "src/components/*.js"]
        }
        </Examples>

        Analyze the repository and provide the complete architectural blueprint in the specified format.
    """

    user_prompt = ""

    return system_prompt, user_prompt

def executive_summary_generation(combined_summary, user_mvf):
    system_prompt = """
    Your Role:
    You are an expert software architect tasked with understanding a codebase and creating an executive summary that clearly articulates the main purpose of this application,
    the core problem that the application is solving, and the prioritized list of the most valuable features, solely based on the provided folder wise summary. Do not hallucinate and create the most valuable features and its description on assumption. This needs to be based on facts.

    Task:
    1. Analyze provided folder wise summary and the services used and the user defined features (if provided).
    2. Understand component interactions and functions.
    3. Prioritize the User Defined Features (if provided) in the summary.
    4. Identify and prioritize the most valuable features based on their importance and relevance to the overall project, as evidenced in the code.
    5. Create a comprehensive executive summary.

    Steps:
    1. Review folder wise summary.
    2. Analyze folder wise summary:
    - Identify key components and their roles
    - Note data operations, design patterns, and architectural decisions
    3. Create summary:
    - Describe the specific problem the codebase solves, based on folder wise summary
    - Explain component interactions
    - Outline data workflow
    4. Identify and prioritize main features:
    - Determine which feature(s) address the core problem of the application, based on code implementation
    - Rank features based on their importance and relevance to solving the main problem, as evidenced in the code
    - The feature should be major components of the codebase and not minor functions like "Modular Architecture" or "Code Reusability", these are not features but design principles.

    Focus Areas:
    - Precised feature prioritization and importance
    - High-level functionality
    - Clear, concise technical language
    - Objective description
    - Capture entire workflow

    Guidelines:
    - Only use the folder wise summary provided
    - Use precise technical terms
    - Include user-defined features if provided and evidenced in the code
    - Prioritize features based on their importance to the core problem, as shown in the folder wise summary

    Feature Identification and Prioritization:
    - Carefully analyze the folder wise summary to identify features actually present in the folder wise summary
    - Do not assume or infer features that are not explicitly mentioned in the folder wise summary
    - Identify the top feature that solves the majority of the problem based on code evidence
    - Rank subsequent features in descending order of importance, ensuring they are present in the folder wise summary
    - Ensure the feature list reflects the codebase's focus and structure
    - Only include features that have substantial implementation in the codebase that is evident from folder wise summary

    Output Format - Adhering to this format is crucial
    ```json
    {
    "data": "generated_summary in string format adhering to the Expected Output Format for Generated Summary",
    "confidence_score": 90,
    "traceback": {
    "Feature 1 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 1 Title' is included, as the 'phrase' is an evidence that this feature is part of the codebase.",
    "Feature 2 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 2 Title' is included, as the 'phrase' is an evidence that this feature is part of the codebase.",
    ...
    }
    }
    ```

    Requirements:
    - Replace \n with \\n in JSON
    - Limit upto 5 main features (max 2 sub-features each) or 7500 tokens
    - If due to any reason such as codebase being small, you are unable to provide 5 features, then provide as many high-level features as possible between the range of 1 to 5.
    - Don't assume features or include minor features due to inability to provide 5 features, lesser number of features is acceptable.
    - Use specified JSON format only
    - Start with "```json" and end with "```"
    - Ensure the top feature in the prioritized list addresses the core problem and is present in the folder wise summary
    - Rank features in descending order of importance to the main problem, based on actual code implementation
    - Do NOT include features that are NOT evidenced in the provided folder wise summary
    - Evaluate the folder wise summary objectively, considering all conclusions on the actual code provided
    - Do NOT make any assumptions about organizational goals or intentions beyond what is explicitly shown in the code
    - Focus solely on the technical aspects and implemented functionality, avoiding speculation about business objectives or future plans
    - Both the keys data, confidence score, and traceback should be present in the output JSON
    - The generated summary should be in string format only and be contained inside the "data" key
    - The "traceback" key should contain a dictionary with feature names as keys and justifications for including these features based on exact phrases from the input
    - Do not include any feature that could potentially be part of the folder wise summary without explicit evidence
    - Every feature mentioned must be driven by clear evidence from the provided input
    """
    user_prompt = """
    Expected Output Format for Generated Summary:

  **Overview**
  <empty line>
  <A brief introduction to the codebase and its main purpose; in paragraph format only, not in points.
  This paragraph should provide a concise yet comprehensive overview of the codebase, its primary functionality, solution provided by the project and its intended use case.
  Aim for 3-5 sentences that capture the essence of the project.>
  <empty line>
  **Highlighted Features**
  <empty line>
  <
  List and briefly explain the key features that are significant components of the codebase and would serve as selling points.
  These features should be presented as follows:
  1. Use numbered points for each feature.
  2. Provide a brief explanation for each feature in 1-2 sentences, highlighting its importance and benefit to the end user.
  3. Focus on features that are central to the codebase's functionality and most important to the end user.
  4. Dont include generic features like "Modular Architecture" or "Code Reusability", these are not features but design principles.
  5. Do not include sub-points under any feature.
  6. Prioritize User Defined Features (if provided) at the beginning of the list.
  7. If User Defined Features are given, list them first before including any features identified through your analysis.
  8. Aim to provide upto of 1 to 5 key features, after each feature add an empty line for formatting purposes.
  9. Ensure that the features listed represent the core functionality and unique selling points based on the folder wise summary.
  10. Use clear, concise language that emphasizes the value proposition of each feature.
  11. Also under each feature, mention which file/folder was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
  12. Do not add features into Highlighted Features if they dont have value for buisness stakeholder about the application. Also do not repeat adding similar feature in this section.

  Output Structure:
  1. ***<Feature 1 Title>***: <Description of the feature in one to two sentences.\n
  2. ***<Feature 2 Title>***: <Description of the feature in one to two sentences.>\n
  >
  <empty line>
  **Key Benefits**
  <empty line>
  <Summarize the key benefits of the codebase in one to two sentences.
  This summary should encapsulate the overall value proposition of the codebase and its potential impact on users or the organization.>
  <empty line>
  <Highlight the most significant key benefits the codebase has to offer in bulleted points. The format should be:
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  Aim for 3-5 bullet points that capture the most compelling advantages of using this codebase, after each point add an empty line for formatting purposes.
  Each benefit should be distinct and provide a clear value proposition.>

  <Final Output Format>
  Output Format - Adhering to this format is crucial, the output should be in parsable JSON format:
  ```json
  {{
    "data": "<generated_summary in string format adhering to the Expected Output Format for Generated Summary>",
    "confidence_score": 90,
    "traceback": {{
      "Feature 1 Title": "Since it mentions about <exact phrase from the folder wise summary>, the 'Feature 1 Title' is included, as the "phrase" is an evidence that this feature is part of the folder wise summary.",
      "Feature 2 Title": "Since it mentions about <exact phrase from the folder wise summary>, the 'Feature 2 Title' is included, as the "phrase" is an evidence that this feature is part of the folder wise summary.",
      ...
    }}
  }}
  ```
  </Final Output Format>
  Note: If the traceback includes phrases that are not present in the folder wise summary then you would be penalized 10000 points.
  The output should be having data, confidence score, and traceback keys, and the entire content inside "```json" and "```" should be parsable by json.
  The "data" key should contain the generated summary and it should be in string format only, allowing the parsing of the entire json.
  If there are any inverted commas inside the generated summary, then escape them with a backslash.
  Do not change or skip the headings of each section in the generated json. The generated summary must have "Overview", "Highlighted Features", "Key Benefits" as section titles. Follow the above provided guidelines."""
    user_prompt += f"""Use the below folder wise summary to generate the summary in the above format: {combined_summary}""" + "User Defined Features : " + str(user_mvf)
    return system_prompt, user_prompt

def db_executive_summary_generation(combined_summary, user_mvf): 
    system_prompt = """
    Role:
    You are an expert Database Architect tasked with understanding the contents of all tables and schema of the database. 
    You shall Articulate a proper executive summary that clearly captures all the main & high-level features of this database.
    The core use-case that this database is intended for, and the prioritized list of the most valuable features, solely based on the provided Table-Level summaries. 
    Do not hallucinate. Do NOT create the most valuable features and its description on pure assumptions. This needs to be based on facts, with proper backing.

    Task:
    1. Analyze provided Table wise summaries.
    2. Understand component interactions and functions.
    3. Prioritize the User Defined Features (if provided) in the summary.
    4. Identify and prioritize the most valuable features based on their importance to the core use-case the Database is solving.
    5. Create a comprehensive executive summary.

    Steps:
    1. Review Table wise summary.
    2. Analyze Table wise summary:
      - Identify all tables. 
      - Take into consideration the foreign keys, primary keys, is-a, has-a, and many-to-many relationships.
      - Deeply understand the intended-use-case of each table.
      - Note data operations, design patterns, and architectural decisions
    3. Create summary:
      - Describe the specific problem the Database is solving, based on Table wise summary
      - Explain high-level interactions and dependencies
      - Outline data workflow
    4. Identify and prioritize main features:
      - Determine which feature(s) address the core problem of the Database, based on SQL implementation and Table wise summary
      - Rank features based on their importance and relevance to solving the main problem, as evidenced in the Database
      - The feature should be major components of the Database and not minor functions like Many-to-Many Relationships, or "Foreign Keys". 
        These are implementation concepts. Not core features.

    Focus Areas:
    - Precised feature prioritization and importance
    - High-level functionality of this Database
    - Clear, concise technical language with Database-specific Language
    - Objective description
    - Capture entire data workflow

    Guidelines:
    - Only use the Table wise summary provided
    - Use precise Database-relevant technical terms
    - Include user-defined features if provided and evidenced in the Table wise summary
    - Prioritize features based on their importance to the core problem, as shown in the Table wise summary

    Feature Identification and Prioritization:
    - Carefully analyze the Table wise summary to identify features actually present in the Table wise summary
    - Do not assume or infer features that are not explicitly mentioned in the Table wise summary
    - Identify the top feature that solves the majority of the problem based on Database and SQL evidence
    - Rank subsequent features in descending order of importance, ensuring they are present in the Table wise summary
    - Ensure the feature list reflects the Database's focus and structure
    - Only include features that have substantial implementation in the Database that is evident from Table wise summary

    Output Format - Adhering to this format is crucial
    ```json
    {
    "data": "generated_summary in string format adhering to the Expected Output Format for Generated Summary",
    "confidence_score": 90,
    "traceback": {
    "Feature 1 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 1 Title' is included, as the 'phrase' is an evidence that this feature is part of the Database.",
    "Feature 2 Title": "Since it mentions about <exact phrase from the input>, the 'Feature 2 Title' is included, as the 'phrase' is an evidence that this feature is part of the Database.",
    ...
    }
    }
    ```

    Requirements:
    - Replace \n with \\n in JSON
    - Limit upto 5 main features (max 2 sub-features each) or 7500 tokens
    - If due to any reason such as Database being small, you are unable to provide 5 features, then provide as many high-level features as possible between the range of 1 to 5.
    - Don't assume features or include minor features due to inability to provide 5 features, lesser number of features is acceptable.
    - Use specified JSON format only
    - Start with "```json" and end with "```"
    - Ensure the top feature in the prioritized list addresses the core problem and is present in the Table wise summary
    - Rank features in descending order of importance to the main problem, based on actual Database and SQL implementation
    - Do NOT include features that are NOT evidenced in the provided Table wise summary
    - Evaluate the Table wise summary objectively, considering all conclusions on the actual Database and SQL provided
    - Do NOT make any assumptions about organizational goals or intentions beyond what is explicitly shown in the Database and SQL
    - Focus solely on the technical aspects and implemented functionality, avoiding speculation about business objectives or future plans
    - Both the keys data, confidence score, and traceback should be present in the output JSON
    - The generated summary should be in string format only and be contained inside the "data" key
    - The "traceback" key should contain a dictionary with feature names as keys and justifications for including these features based on exact phrases from the input
    - Do not include any feature that could potentially be part of the Table wise summary without explicit evidence
    - Every feature mentioned must be driven by clear evidence from the provided input.
    - Strictly use an assertive and objective tone in your response. 
    - Do not be unsure about anything.
    - Do not include the "Folder Name" in your response. Ignore "dbanalysis" folder. Provide Executive Summary of the Database-ONLY.
    """

    user_prompt = """
  Expected Output Format for Generated Summary:

  **Overview**
  <empty line>
  <A brief introduction to the Database and its main purpose; in paragraph format only, not in points.
  This paragraph should provide a concise yet comprehensive overview of the Database, its primary functionality, and its intended use case.
  Aim for 3-5 sentences that capture the essence of the Database.>
  <empty line>
  **Highlighted Features**
  <empty line>
  <
  List and briefly explain the key features that are significant components of the Database and would serve as selling points.
  These features should be presented as follows:
  1. Use numbered points for each feature.
  2. Provide a brief explanation for each feature in 1-2 sentences, highlighting its importance and benefit to the END USER.
  3. Focus on features that are central to the Database's functionality and most important to the END USER.
  4. Dont include generic features like  Many-to-Many Relationships, or "Foreign Keys", these are not features but Design Principles.
  5. Do not include sub-points under any feature.
  6. Prioritize User Defined Features (if provided) at the beginning of the list.
  7. If User Defined Features are given, list them first before including any features identified through your analysis.
  8. Aim to provide upto of 1 to 5 key features, after each feature add an empty line for formatting purposes.
  9. Ensure that the features listed represent the core functionality and unique selling points based on the Table wise summary.
  10. Use clear, concise language that emphasizes the value proposition of each feature.
  11. Also under each feature, mention which file/Table was this feature extracted from in a new line in this format "citation: <filepath>". This will act as a citation for the feature.
  12. Do not add features into Highlighted Features if they dont have value for buisness stakeholder about the application. Also do not repeat adding similar feature in this section.

  Output Structure:
  1. ***<Feature 1 Title>***: <Description of the feature in one to two sentences.\n
  2. ***<Feature 2 Title>***: <Description of the feature in one to two sentences.>\n
  >
  <empty line>
  **Key Benefits**
  <empty line>
  <Summarize the key benefits of the Database in one to two sentences.
  This summary should encapsulate the overall value proposition of the Database and its potential impact on users or the organization.>
  <empty line>
  <Highlight the most significant key benefits the Database has to offer in bulleted points. The format should be:
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  - ***<Key benefit title>***: <Description of the key benefit in one line>\n
  Aim for 3-5 bullet points that capture the most compelling advantages of using this Database, after each point add an empty line for formatting purposes.
  Each benefit should be distinct and provide a clear value proposition.>

  <Final Output Format>
  Output Format - Adhering to this format is crucial, the output should be in parsable JSON format:
  ```json
  {{
    "data": "<generated_summary in string format adhering to the Expected Output Format for Generated Summary>",
    "confidence_score": 90,
    "traceback": {{
      "Feature 1 Title": "Since it mentions about <exact phrase from the Table wise summary>, the 'Feature 1 Title' is included, as the "phrase" is an evidence that this feature is part of the Table wise summary.",
      "Feature 2 Title": "Since it mentions about <exact phrase from the Table wise summary>, the 'Feature 2 Title' is included, as the "phrase" is an evidence that this feature is part of the Table wise summary.",
      ...
    }}
  }}
  ```
  </Final Output Format>
  Note: If the traceback includes phrases that are not present in the Table wise summary then you would be penalized 10000 points.
  The output should be having data, confidence score, and traceback keys, and the entire content inside "```json" and "```" should be parsable by json.
  The "data" key should contain the generated summary and it should be in string format only, allowing the parsing of the entire json.
  If there are any inverted commas inside the generated summary, then escape them with a backslash.
  Do not change or skip the headings of each section in the generated json. The generated summary must have "Overview", "Highlighted Features", "Key Benefits" as section titles. Follow the above provided guidelines.
    """

    user_prompt += f"""Use the below Table wise summary to generate the summary in the above format: {combined_summary}""" + "User Defined Features : " + str(user_mvf)

    return system_prompt, user_prompt


def architecture_diagram_generation(services_data, icons_metadata):
    user_prompt = f"""
    <Input>
    $services_data = {services_data}
    $icons_metadata
    </Input>

    <Role>
    You are an expert at understanding large projects based on their executive summary and the services being used in them. Create a JSON structure for a ReactFlow diagram based on the given service class JSON.
    </Role>

    <Output Structure>
    1. Create a JSON object with a "nodes" and "edges" array.
    2. Create nodes for each external and third-party service.
    3. "nodes": An array containing all node objects.
      - "id": A unique string identifier for the node.
      - "data":   
        - "label": The name of the node.
        - "description": Description of the service.
        - "associated_files": Associated file and used in files in the service node, defaulting to "No File Available" if not present.
        - "group": The logical group name (e.g., 'Backend', 'Frontend', 'Database',etc..).
        - "subgroup": The specific subgroup within the group (e.g., Frameworks, NoSQL Databases, State Management, etc.).
        - "service": The appropriate filename of the icon based on the $icons_metadata.
      - "position" : The x and y coordinates of the node.
      - "type" : "customNode" This should be fixed.
    4. "edges" : An array having id, source, target, label, and type should be customEdge always.
    4. Ensure all services and files from the input JSON are included.
    5. The output should be in the form of a dictionary containing a "nodes" and "edges" array.
    6. Present only the code inside delimiters "```reactflow [reactflow CODE]```" without any additional explanation.
    """

    system_prompt:str = """
    <Task>
      You are tasked with creating a JSON structure for a ReactFlow diagram based on the given executive summary and the service_class_json. The executive summary contains an overview of the entire project. This JSON includes information about external services and third-party services, along with their associated files. Your output should represent this information as a network of nodes and edges.
    </Task>
    
    <Icons Context>
      $icons_metadata = """ + str(icons_metadata) + """
    </Icons Context>

    <Instructions>
      You are a solution expert, specializing in problem and solution flows. You will be given the solution overview for a project, and your task is to create an interconnected single component of graph which is detailed, and intuitive and self explanatory for:

      Follow these guidelines:
      1. Create nodes for each unique service (both external and third-party).
      2. Do not create any group nodes.
      4. In the data key for each service node, include two additional fields called group and subgroup. The group field should contain the logical group name (e.g., Frontend, Backend, Databases, etc..), and the subgroup field should provide more specific categorization (e.g., Frameworks, NoSQL Databases, etc..). For example, for a service node representing React, the group would be Frontend and the subgroup would be Frameworks.
      5. For each node, check which icon will be the most suitable from the $icons_metadata in the <Icons Context>
      6. Ensure all information from the input is represented in the output.
      7. The position coordinates must be proper for all the nodes.
    </Instructions>

    <Rules>
      **Ensure all nodes in the generated graph are interconnected such that every node has at least one edge, forming a single connected component without any isolated or disjoint sections. (High Priority Requirement)**
      Important Rules to be followed:
      1. Give detailed technical architecture flow and the JSON object following the below output format.
      2. Make sure that the flow and order of new solution approach is explained well in the graph with appropriate edges. Use as many edges you want to describe the data and user flow properly.
      3. The whole user and data flow should be clear.
      4. Do not add unnecessary nodes and edges. Do not create duplicate nodes that perform same task.
      5. Make the Node descriptions detailed, breaking tasks into multiple sub-tasks if needed.
      6. Ensure your edges show the actual flow, and not just connections of what's related. The connections are meant to show the logical flow, and not the relatedness/similarity.
      7. The group name is meant to classify clusters of nodes within each graph. For instance, if we have multiple nodes in features, they would all have "feature" as group. In Architecture Flow, the "Group" should show the layer each node is in, for instance "Backend Layer", "Database Layer" etc.
      9. for a hierarchy of nodes A -> B -> C; ensure that there is not a connection between A -> C.
    </Rules>
    
    <output_format>
    The output should be in between the delimeters ```reactflow and ```. Only provide the json output. Don't give unnecesary explanation.
    ```reactflow
    {
      "nodes": [
        { 
          "id": "unique_node_identifier_string",
          "data" : {
            "label": "name_of_the_service",
            "description": "description of the service",
            "associated_files": ["file_path_1", "file_path_2", "file_path_3", etc.],  // (default: ["No File Available"] if not present)
            "group": "name_of_group",  // Add the logical group name (e.g., "Frontend", "Backend", etc..)
            "subgroup": "name_of_subgroup",  // Add a more specific subgroup name (e.g., "Frameworks", "NoSQL Databases", etc..)
            "service": "filename" //taken from the $icons_metadata,
          }
          "position":{ "x": "Xcoordinate", "y": "Ycoordinate" },
          "type" : "customNode" //this is hardcoded and will be constant
        }
      ],
      "edges": [
        {
          "id": "unique_egde_identifier_string",
          "source": "label A",
          "target": "label B",
          "label": "Showcase what comes from the source node, to the target node. Be concise and specific with labels, such as 'Ingested Data', 'Converted Text', 'User Query' etc. Use at max 5 words",
          "type" : "customEdge" //this is hardcoded and will be constant
        }
      ]
    }```
    </output_format>
    """
    return system_prompt, user_prompt
  

def erd_generation(services_data, icons_metadata):
  tables_metadata = []
  for entry in services_data:
      table_name = entry["table_name"]
      ddl = entry["ddl"]
      columns, primary_keys, foreign_keys = parse_ddl(ddl)
      tables_metadata.append({
          "table_name": table_name,
          "columns": columns,
          "primary_keys": primary_keys,
          "foreign_keys": foreign_keys
      })

  dot = generate_combined_graph(tables_metadata)

  system_prompt:str = """
    You are tasked with creating a JSON structure for a ReactFlow diagram based on the given database ER diagram and schema JSON. This JSON includes information about database columns and their relationships.Your output should represent this information as a network of nodes and edges.
    </Task>
    
    <Icons Context>
      $icons_metadata = """ + str(icons_metadata) + """
    </Icons Context>

    <Instructions>
      You are a solution expert, specializing in problem and solution flows. You will be given the database schema information of a database, and your task is to create an interconnected single component of graph which is detailed, and intuitive and self explanatory for:

      Follow these guidelines:
      1. Create nodes for each unique service (both external and third-party).
      2. Do not create any group nodes.
      4. In the data key for each service node, include two additional fields called group and subgroup. The group field should contain the logical group name (e.g.,Databases, etc..), and the subgroup field should provide more specific categorization (e.g., 'Transactional Tables', 'Reference Tables' etc..). For example, for a service node representing daily transactions, the group would be Database and the subgroup would be Transactional Tables.
      5. For each node, check which icon will be the most suitable from the $icons_metadata in the <Icons Context>
      6. Ensure all information from the input is represented in the output.
      7. The position coordinates must be proper for all the nodes.
    </Instructions>

    <Rules>
      Important Rules to be followed:
      1. Give detailed technical architecture flow and the JSON object following the below output format.
      2. Make sure that the flow and order of new solution approach is explained well in the graph with appropriate edges. Use as many edges you want to describe the data and user flow properly.
      3. The whole user and data flow should be clear.
      4. Do not add unnecessary nodes and edges. Do not create duplicate nodes that perform same task.
      5. Make the Node descriptions detailed, breaking tasks into multiple sub-tasks if needed.
      6. Ensure your edges show the actual flow, and not just connections of what's related. The connections are meant to show the logical flow, and not the relatedness/similarity.
      7. The group name is meant to classify clusters of nodes within each graph. For instance, if we have multiple nodes in features, they would all have "feature" as group. In Architecture Flow, the "Group" should show the layer each node is in, for instance "Database Layer" etc.
      9. for a hierarchy of nodes A -> B -> C; ensure that there is not a connection between A -> C.
    </Rules>
    
    <output_format>
    The output should be in between the delimeters ```reactflow and ```. Only provide the json output. Don't give unnecesary explanation.
    ```reactflow
    {
      "nodes": [
        { 
          "id": "unique_node_identifier_string",
          "data" : {
            "label": "name_of_the_table",
            "description": "description of the table",
  	    "columns": ["order_id [PK]", "product_sku [PK]", "quantity", "unit_price"]
            "group": "name_of_group",  // Add the logical group name (e.g., "Database", etc..)
            "subgroup": "name_of_subgroup",  // Add a more specific subgroup name (e.g., 'Transactional Tables', 'Reference Tables', etc..)
            "service": "filename" //taken from the $icons_metadata,
          }
          "position":{ "x": "Xcoordinate", "y": "Ycoordinate" },
          "type" : "customNode" //this is hardcoded and will be constant
        }
      ],
      "edges": [
        {
          "id": "unique_egde_identifier_string",
          "source": "label A",
          "target": "label B",
          "label": "Showcase what comes from the source node, to the target node. Be concise and specific with labels, such as 'Ingested Data', 'Converted Text', 'User Query' etc. Use at max 5 words",
          "type" : "customEdge" //this is hardcoded and will be constant
        }
      ]
    }```
    </output_format>
    """
    
  user_prompt:str = f"""
    <Input>
    $database_tables = {dot}
    $icons_metadata
    </Input>

    <Role>
    You are an expert at understanding database architecture based on ER diagrams and relational structures. Create a JSON structure for a ReactFlow diagram based on the given database schema.
    </Role>
    <Output Structure>
      1. Create a JSON object with a "nodes" and "edges" array.
      2. Create nodes for each table in the schema.
      3. "nodes": An array containing all node objects.
      - "id": A unique string identifier for the node.
      - "data":  
        - "label": The name of the table.
        - "description": A brief summary of the table's role or content.
        - "columns": List of column names (mark primary keys with [PK], foreign keys with [FK]).
        - "group": The logical group name (e.g., 'Database').
        - "subgroup": The specific subgroup within the group (e.g., 'Transactional Tables', 'Reference Tables').
        - "service": The appropriate filename of the icon based on the $icons_metadata.
      - "position" : The x and y coordinates of the node.
      - "type" : "customNode" This should be fixed.
      4. "edges" : An array having id, source, target, label, and type should be customEdge always.
      5. The label of the edge should describe the relationship, like "order_id â†’ order_id". 
      6. The output should be in the form of a dictionary containing a "nodes" and "edges" array.
      7. Present only the code inside delimiters "```reactflow [reactflow CODE]```" without any additional explanation.
    """
    
  return system_prompt, user_prompt
    

def feature_summary_generation(formatted_data, user_mvf, executive_summary):
    # if input_type is None:
    #     formatted_data = file_summary_list
    # elif input_type == "batch_summary":
    #     formatted_data = format_batchwise_summary_metadata_for_services(file_summary_list)
    # else:
    #     formatted_data = format_file_summaries(file_summary_list)

    user_prompt = """
    Role: You are an AI code analyst specializing in creating concise, feature-level summaries of codebases.

    Objective: Provide a comprehensive yet concise feature-level summary of a given codebase, highlighting key components, functionality, and the project's overall workflow.

    Input: You will receive information about a codebase, which may include an executive summary or other project details.

    Steps:
    1. Analyze the provided codebase information.
    2. Identify the main features (maximum 5) of the project from the executive summary (if provided in same order)
    3. Create a summary following the specified format, including:
        a. An overview of the project
        b. A list of key features with brief descriptions
        c. A closure statement
    4. Self-evaluate the generated summary and assign a confidence score.
    5. Format the output as specified in the instructions.

    Output Format:
    ```json
    {
        "data": "generated_summary in string format adhering to the Detailed Instructions for Output Format",
        "confidence_score": 90
    }
    ```

    Detailed Instructions for Output Format:

    **Overview**
    <empty line>
    < 
        Summarize all features in 2-3 sentences, introducing the project and its purpose.
        Provide a 2-3 sentence summary of key benefits, highlighting core architecture and value proposition.
    >
    <empty line>
    **Key Features**
    <empty line>
    <   
        List a maximum of 5 main features.
        For each feature, provide up to 2 sub-points describing its functionality.
        Ensure clear explanation of how features interact and contribute to the project's goals.
        1. ***<Key Feature Title>*** : 
        * <Sub point 1 description>
        * <Sub point 2 description>
        <empty line>
    >
    <empty line>
    < 
        Summarize the overall impact and value proposition of the project in one sentence as a conclusion statement.
    >
    <empty line>
    
    -> Self-Evaluation:
        - Score the summary out of 100 based on clarity, precision, detail, knowledge, accuracy, technical correctness, and understanding of the data.

    -> Formatting Requirements:
        - Replace all newline characters (\n) with \\n in the JSON output.
        - Ensure the complete JSON is less than 7500 tokens.
        - Start the output with "```json" and end with "```".
        - If an executive summary is provided, use only the highlighted features from it.

    Example Output Structure:
    ```json
    {
        "data": "**Overview**\\n\\n[Project overview]\\n\\n[Benefits summary]\\n\\n**Key Features**\\n\\n1. *Feature 1*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n2. *Feature 2*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n[...continue for up to 5 features...]\\n\\n[Closure statement]",
        "confidence_score": 90
    }
    ```

    Remember: Adhere strictly to the output format and instructions to maintain consistency and accuracy in your summary.
    """

    user_prompt += "User Defined Features : " + str(user_mvf)

    system_prompt = f"""
        <role>
        You are an assistant to a Senior Software Engineer. You are very capable in reading and understanding huge codebases.
        There is no edge-case, no mistake, no functionality no matter how small goes unnoticed by you.
        You will be given a large codebase and be asked queries regarding it.
        </role>

        <Task>
        You will be given relevant files from a production codebase. The Senior Engineer will consult you to clear his doubts and ask for critical code-level and functionality level analysis of the same.
        <Important>
        1. You will be clear. Feel free to be descriptive but Avoid Jargon
        2. You shall perform critical analysis on the code before responding.
        3. Note that the codebase will be quite complex and have dependencies everywhere, be mindful of them all.
        4. Enclose code in (triple backticks)``` code ```
        </Important>
        </Task>

        Files from Codebase goes here :
        <Repo Structure>
        {formatted_data}
        </Repo Structure>
    """

    start_index = executive_summary.find("Highlighted Features")
    end_index = executive_summary.find("Key Benefits")

    if start_index != -1 and end_index != -1:
        executive_summary = executive_summary[start_index:end_index].strip()

    user_prompt += "Executive Summary : " + str(executive_summary)

    return system_prompt, user_prompt

def feature_summary_generation_db(formatted_data, user_mvf, executive_summary):
    # if input_type is None:
    #     formatted_data = file_summary_list
    # elif input_type == "batch_summary":
    #     formatted_data = format_batchwise_summary_metadata_for_services(file_summary_list)
    # else:
    #     formatted_data = format_file_summaries(file_summary_list)

    user_prompt = """
    Role: You are an AI Database Analyst specializing in creating concise, feature-level summaries of complex database schemas and architectures.

    Objective: Provide a comprehensive yet concise feature-level summary of a given database schema information, highlighting key components, entities, relationships, and the overall data architecture workflow.

    Input: You will receive information about a database design, which may include an executive summary or other schema-level details.

    Steps:
    1. Analyze the provided database schema information.
    2. Identify the main features (maximum 5) of the database from the executive summary (if provided in same order)
    3. Create a summary following the specified format, including:
        a. An overview of the database
        b. A list of key features with brief descriptions
        c. A closure statement
    4. Self-evaluate the generated summary and assign a confidence score.
    5. Format the output as specified in the instructions.

    Output Format:
    ```json
    {
        "data": "generated_summary in string format adhering to the Detailed Instructions for Output Format",
        "confidence_score": 90
    }
    ```

    Detailed Instructions for Output Format:

    **Overview**
    <empty line>
    < 
        Summarize all features in 2-3 sentences, introducing the database and its purpose.
        Provide a 2-3 sentence summary of key benefits, highlighting schema structure, normalization or denormalization logic, and value proposition in handling data.
    >
    <empty line>
    **Key Features**
    <empty line>
    <   
        List a maximum of 5 main features.
        For each feature, provide up to 2 sub-points describing its data handling, relationships, or optimization logic.
        Ensure clear explanation of how features contribute to performance, consistency, and data integrity.
        1. ***<Key Feature Title>*** : 
        * <Sub point 1 description>
        * <Sub point 2 description>
        <empty line>
    >
    <empty line>
    < 
        Summarize the overall impact and value proposition of the database in one sentence as a conclusion statement.
    >
    <empty line>
    
    -> Self-Evaluation:
        - Score the summary out of 100 based on clarity, precision, detail, knowledge, accuracy, technical correctness, and understanding of the schema information.

    -> Formatting Requirements:
        - Replace all newline characters (\n) with \\n in the JSON output.
        - Ensure the complete JSON is less than 7500 tokens.
        - Start the output with "```json" and end with "```".
        - If an executive summary is provided, use only the highlighted features from it.

    Example Output Structure:
    ```json
    {
        "data": "**Overview**\\n\\n[Database overview]\\n\\n[Benefits summary]\\n\\n**Key Features**\\n\\n1. *Feature 1*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n2. *Feature 2*\\n  * [Description point 1]\\n  * [Description point 2]\\n\\n[...continue for up to 5 features...]\\n\\n[Closure statement]",
        "confidence_score": 90
    }
    ```

    Remember: Adhere strictly to the output format and instructions to maintain consistency and accuracy in your summary.
    """

    user_prompt += "User Defined Features : " + str(user_mvf)

    system_prompt = f"""
        <role>
        You are an assistant to a Senior Data Architect. You are very capable in reading, analyzing, and understanding complex database schemas and data models.
        No entity, constraint, relationship, or optimization logic goes unnoticed by you.
        You will be given a comprehensive database structure or schema information and will be asked to analyze, explain, and summarize it at a structural and functional level.
        </role>

        <Task>
        You will be given relevant database schema files or DDL definitions. The Senior Data Architect will consult you to clear doubts and ask for critical schema-level and data model-level analysis.
        <Important>
        1. You will be clear. Feel free to be descriptive but Avoid Jargon
        2. Perform a critical and deep analysis of the schema and the information given before responding.
        3. The schema will often involve multiple tables, foreign keys, views, procedures, and indexing strategies â€” be mindful of their dependencies and relationships.
        4. Enclose code or schema in (triple backticks)``` code ```
        </Important>
        </Task>

        Files from Database schema goes here :
        <Database Structure>
        {formatted_data}
        </Database Structure>
    """

    start_index = executive_summary.find("Highlighted Features")
    end_index = executive_summary.find("Key Benefits")

    if start_index != -1 and end_index != -1:
        executive_summary = executive_summary[start_index:end_index].strip()

    user_prompt += "Executive Summary : " + str(executive_summary)

    return system_prompt, user_prompt


